Yes, I was referring to AdaLoRA when asking about using save_pretrained. I understand that WISE and GRACE require a special implementation. For AdaLoRA, I am running 
```
metrics, edited_model, _ = editor.edit(
    ...
)

edited_model.save_pretrained(model_save_dir)
```
but the results look strange because I ran several different experiments that all resulted in different metrics in your framework, but got identical evaluation metrics in my separate evaluation for a different task. So, I just wanted to clarify that my approach was correct. Thank you for clarifying that! 

For GRACE, I saw that the original code does [this](https://github.com/Thartvigsen/GRACE/blob/f674183f17a995d109e10ee6140d4c3e6d016115/grace/main.py#L217C1-L221C82) to save.  So, that's why I did the implementation I mentioned earlier, where I saved:
```
checkpoint = os.path.join(model_save_dir, "model.pt")
torch.save(edited_model.model.state_dict(), checkpoint)
```
and loaded:
```
path = "./scr/models--locuslab--tofu_ft_llama2-7b/snapshots/8fa500e8f345f1dd9cfe95bb4689878c944c9cbd"
model = AutoModelForCausalLM.from_pretrained(path, config=config, use_flash_attention_2=False, torch_dtype=torch.float16, trust_remote_code = True, device_map=device_map)
checkpoint = os.path.join(cfg.model_path, "model.pt")
state_dict = torch.load(checkpoint, map_location='cpu')
model.load_state_dict(state_dict, False)
```

