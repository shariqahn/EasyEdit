snapshot: /state/partition1/user/shossain/hug/models--meta-llama--Llama-2-7b-hf/snapshots/01c7f73d771dfac7d292323805ebc428287df4f98G [01:01<00:00, 243MB/s]
> /home/gridsan/shossain/EasyEdit/download.py(20)<module>()███████▊                                                    | 3.47G/9.98G [00:21<00:49, 130MB/s]
-> model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=snapshot_dir, device_map=None, local_files_only=True, torch_dtype=torch.float32)MB/s]
(Pdb) model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=snapshot_dir, device_map=None, local_files_only=True, torch_dtype=torch.float32)
*** OSError: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like meta-llama/Llama-2-7b-hf is not the path to a directory containing a file named config.json.
Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.
(Pdb) model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=snapshot_dir, device_map=None,torch_dtype=torch.float32)
config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 609/609 [00:00<00:00, 83.5kB/s]
model.safetensors.index.json: 100%|███████████████████████████████████████████████████████████████████████████████████| 26.8k/26.8k [00:00<00:00, 6.60MB/s]
model-00001-of-00002.safetensors: 100%|████████████████████████████████████████████████████████████████████████████████| 9.98G/9.98G [00:47<00:00, 210MB/s]
model-00002-of-00002.safetensors: 100%|████████████████████████████████████████████████████████████████████████████████| 3.50G/3.50G [00:16<00:00, 215MB/s]
Downloading shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [01:03<00:00, 31.99s/it]
Loading checkpoint shards:   0%|                                                                                                     | 0/2 [00:00<?, ?it/s]./download_models.sh: line 27: 173038 Killed                  python -u download.py