2024-12-09 15:39:18,899 - easyeditor.editors.editor - INFO - Instantiating model
12/09/2024 15:39:18 - INFO - easyeditor.editors.editor -   Instantiating model
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:11<00:23, 11.72s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:22<00:11, 11.08s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:30<00:00,  9.59s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:30<00:00, 10.06s/it]
2024-12-09 15:40:15,701 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...
12/09/2024 15:40:15 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...
exp dummy
target_new ['dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy']
  0%|          | 0/400 [00:00<?, ?it/s]  0%|          | 1/400 [00:19<2:12:15, 19.89s/it]  0%|          | 2/400 [00:20<55:09,  8.31s/it]    1%|          | 3/400 [00:20<30:31,  4.61s/it]  1%|          | 4/400 [00:20<18:57,  2.87s/it]  1%|▏         | 5/400 [00:20<12:40,  1.92s/it]  2%|▏         | 6/400 [00:20<08:48,  1.34s/it]  2%|▏         | 7/400 [00:21<06:25,  1.02it/s]  2%|▏         | 8/400 [00:21<04:48,  1.36it/s]  2%|▏         | 9/400 [00:21<03:42,  1.76it/s]  2%|▎         | 10/400 [00:21<02:57,  2.19it/s]  3%|▎         | 11/400 [00:22<02:32,  2.55it/s]  3%|▎         | 12/400 [00:22<02:09,  2.99it/s]  3%|▎         | 13/400 [00:22<01:54,  3.39it/s]  4%|▎         | 14/400 [00:22<01:47,  3.58it/s]  4%|▍         | 15/400 [00:22<01:38,  3.91it/s]  4%|▍         | 16/400 [00:23<01:32,  4.16it/s]  4%|▍         | 17/400 [00:23<01:27,  4.36it/s]  4%|▍         | 18/400 [00:23<01:24,  4.52it/s]  5%|▍         | 19/400 [00:23<01:26,  4.40it/s]  5%|▌         | 20/400 [00:23<01:23,  4.55it/s]  5%|▌         | 21/400 [00:24<01:21,  4.64it/s]  6%|▌         | 22/400 [00:24<01:20,  4.70it/s]  6%|▌         | 23/400 [00:24<01:19,  4.77it/s]  6%|▌         | 24/400 [00:24<01:17,  4.83it/s]  6%|▋         | 25/400 [00:24<01:17,  4.85it/s]  6%|▋         | 26/400 [00:25<01:25,  4.37it/s]  7%|▋         | 27/400 [00:25<01:31,  4.07it/s]  7%|▋         | 28/400 [00:25<01:26,  4.29it/s]  7%|▋         | 29/400 [00:25<01:23,  4.46it/s]  8%|▊         | 30/400 [00:26<01:20,  4.59it/s]  8%|▊         | 31/400 [00:26<01:18,  4.68it/s]  8%|▊         | 32/400 [00:26<01:17,  4.75it/s]  8%|▊         | 33/400 [00:26<01:16,  4.80it/s]  8%|▊         | 34/400 [00:26<01:15,  4.84it/s]  9%|▉         | 35/400 [00:27<01:15,  4.85it/s]  9%|▉         | 36/400 [00:27<01:23,  4.37it/s]  9%|▉         | 37/400 [00:27<01:20,  4.53it/s] 10%|▉         | 38/400 [00:27<01:17,  4.65it/s] 10%|▉         | 39/400 [00:28<01:15,  4.76it/s] 10%|█         | 40/400 [00:28<01:14,  4.81it/s] 10%|█         | 41/400 [00:28<01:21,  4.38it/s] 10%|█         | 42/400 [00:28<01:18,  4.56it/s] 11%|█         | 43/400 [00:28<01:21,  4.38it/s] 11%|█         | 44/400 [00:29<01:18,  4.55it/s] 11%|█▏        | 45/400 [00:29<01:16,  4.65it/s] 12%|█▏        | 46/400 [00:29<01:14,  4.75it/s] 12%|█▏        | 47/400 [00:29<01:13,  4.81it/s] 12%|█▏        | 48/400 [00:30<01:12,  4.86it/s] 12%|█▏        | 49/400 [00:30<01:11,  4.90it/s] 12%|█▎        | 50/400 [00:30<01:11,  4.92it/s] 13%|█▎        | 51/400 [00:30<01:10,  4.93it/s] 13%|█▎        | 52/400 [00:30<01:10,  4.94it/s] 13%|█▎        | 53/400 [00:31<01:14,  4.69it/s] 14%|█▎        | 54/400 [00:31<01:12,  4.79it/s] 14%|█▍        | 55/400 [00:31<01:15,  4.56it/s] 14%|█▍        | 56/400 [00:31<01:13,  4.66it/s] 14%|█▍        | 57/400 [00:31<01:12,  4.73it/s] 14%|█▍        | 58/400 [00:32<01:11,  4.79it/s] 15%|█▍        | 59/400 [00:32<01:10,  4.83it/s] 15%|█▌        | 60/400 [00:32<01:10,  4.85it/s] 15%|█▌        | 61/400 [00:32<01:09,  4.87it/s] 16%|█▌        | 62/400 [00:32<01:09,  4.88it/s] 16%|█▌        | 63/400 [00:33<01:08,  4.89it/s] 16%|█▌        | 64/400 [00:33<01:08,  4.91it/s] 16%|█▋        | 65/400 [00:33<01:08,  4.91it/s] 16%|█▋        | 66/400 [00:33<01:15,  4.42it/s] 17%|█▋        | 67/400 [00:34<01:12,  4.57it/s] 17%|█▋        | 68/400 [00:34<01:14,  4.43it/s] 17%|█▋        | 69/400 [00:34<01:12,  4.54it/s] 18%|█▊        | 70/400 [00:34<01:11,  4.64it/s] 18%|█▊        | 71/400 [00:34<01:09,  4.71it/s] 18%|█▊        | 72/400 [00:35<01:08,  4.76it/s] 18%|█▊        | 73/400 [00:35<01:08,  4.81it/s] 18%|█▊        | 74/400 [00:35<01:07,  4.83it/s] 19%|█▉        | 75/400 [00:35<01:06,  4.85it/s] 19%|█▉        | 76/400 [00:35<01:06,  4.87it/s] 19%|█▉        | 77/400 [00:36<01:06,  4.88it/s] 20%|█▉        | 78/400 [00:36<01:05,  4.89it/s] 20%|█▉        | 79/400 [00:36<01:05,  4.90it/s] 20%|██        | 80/400 [00:36<01:05,  4.92it/s] 20%|██        | 81/400 [00:36<01:08,  4.64it/s] 20%|██        | 82/400 [00:37<01:07,  4.72it/s] 21%|██        | 83/400 [00:37<01:06,  4.78it/s] 21%|██        | 84/400 [00:37<01:05,  4.81it/s] 21%|██▏       | 85/400 [00:37<01:05,  4.84it/s] 22%|██▏       | 86/400 [00:37<01:04,  4.85it/s] 22%|██▏       | 87/400 [00:38<01:07,  4.61it/s] 22%|██▏       | 88/400 [00:38<01:13,  4.22it/s] 22%|██▏       | 89/400 [00:38<01:14,  4.18it/s] 22%|██▎       | 90/400 [00:39<01:17,  4.00it/s] 23%|██▎       | 91/400 [00:39<01:12,  4.25it/s] 23%|██▎       | 92/400 [00:39<01:16,  4.01it/s] 23%|██▎       | 93/400 [00:39<01:20,  3.82it/s] 24%|██▎       | 94/400 [00:40<01:21,  3.74it/s] 24%|██▍       | 95/400 [00:40<01:15,  4.04it/s] 24%|██▍       | 96/400 [00:40<01:11,  4.27it/s] 24%|██▍       | 97/400 [00:40<01:08,  4.44it/s] 24%|██▍       | 98/400 [00:40<01:05,  4.58it/s] 25%|██▍       | 99/400 [00:41<01:04,  4.69it/s] 25%|██▌       | 100/400 [00:41<01:06,  4.52it/s] 25%|██▌       | 101/400 [00:41<01:11,  4.21it/s] 26%|██▌       | 102/400 [00:41<01:07,  4.40it/s] 26%|██▌       | 103/400 [00:41<01:05,  4.56it/s] 26%|██▌       | 104/400 [00:42<01:03,  4.68it/s] 26%|██▋       | 105/400 [00:42<01:01,  4.77it/s] 26%|██▋       | 106/400 [00:42<01:00,  4.83it/s] 27%|██▋       | 107/400 [00:42<01:06,  4.40it/s] 27%|██▋       | 108/400 [00:43<01:10,  4.15it/s] 27%|██▋       | 109/400 [00:43<01:06,  4.37it/s] 28%|██▊       | 110/400 [00:43<01:07,  4.33it/s] 28%|██▊       | 111/400 [00:43<01:04,  4.51it/s] 28%|██▊       | 112/400 [00:43<01:01,  4.65it/s] 28%|██▊       | 113/400 [00:44<01:00,  4.76it/s] 28%|██▊       | 114/400 [00:44<00:59,  4.82it/s] 29%|██▉       | 115/400 [00:44<00:58,  4.88it/s] 29%|██▉       | 116/400 [00:44<00:57,  4.92it/s] 29%|██▉       | 117/400 [00:44<00:57,  4.94it/s] 30%|██▉       | 118/400 [00:45<00:56,  4.96it/s] 30%|██▉       | 119/400 [00:45<00:56,  4.97it/s] 30%|███       | 120/400 [00:45<00:56,  4.99it/s] 30%|███       | 121/400 [00:45<01:01,  4.50it/s] 30%|███       | 122/400 [00:46<00:59,  4.64it/s] 31%|███       | 123/400 [00:46<00:58,  4.75it/s] 31%|███       | 124/400 [00:46<00:57,  4.82it/s] 31%|███▏      | 125/400 [00:46<00:56,  4.88it/s] 32%|███▏      | 126/400 [00:46<00:55,  4.92it/s] 32%|███▏      | 127/400 [00:47<00:55,  4.94it/s] 32%|███▏      | 128/400 [00:47<00:54,  4.98it/s] 32%|███▏      | 129/400 [00:47<00:54,  5.01it/s] 32%|███▎      | 130/400 [00:47<00:53,  5.01it/s] 33%|███▎      | 131/400 [00:47<00:53,  5.02it/s] 33%|███▎      | 132/400 [00:48<00:53,  5.02it/s] 33%|███▎      | 133/400 [00:48<00:53,  5.02it/s] 34%|███▎      | 134/400 [00:48<00:53,  5.01it/s] 34%|███▍      | 135/400 [00:48<00:52,  5.02it/s] 34%|███▍      | 136/400 [00:48<00:52,  5.02it/s] 34%|███▍      | 137/400 [00:49<00:52,  5.01it/s] 34%|███▍      | 138/400 [00:49<00:52,  5.01it/s] 35%|███▍      | 139/400 [00:49<00:52,  5.00it/s] 35%|███▌      | 140/400 [00:49<00:52,  4.99it/s] 35%|███▌      | 141/400 [00:49<00:57,  4.50it/s] 36%|███▌      | 142/400 [00:50<00:55,  4.63it/s] 36%|███▌      | 143/400 [00:50<00:54,  4.75it/s] 36%|███▌      | 144/400 [00:50<00:53,  4.83it/s] 36%|███▋      | 145/400 [00:50<00:52,  4.90it/s] 36%|███▋      | 146/400 [00:50<00:51,  4.94it/s] 37%|███▋      | 147/400 [00:51<00:50,  4.97it/s] 37%|███▋      | 148/400 [00:51<00:50,  4.98it/s] 37%|███▋      | 149/400 [00:51<00:52,  4.75it/s] 38%|███▊      | 150/400 [00:51<00:54,  4.59it/s] 38%|███▊      | 151/400 [00:51<00:52,  4.71it/s] 38%|███▊      | 152/400 [00:52<00:51,  4.79it/s] 38%|███▊      | 153/400 [00:52<00:50,  4.85it/s] 38%|███▊      | 154/400 [00:52<00:50,  4.90it/s] 39%|███▉      | 155/400 [00:52<00:49,  4.95it/s] 39%|███▉      | 156/400 [00:52<00:48,  4.98it/s] 39%|███▉      | 157/400 [00:53<00:48,  4.99it/s] 40%|███▉      | 158/400 [00:53<00:48,  5.00it/s] 40%|███▉      | 159/400 [00:53<00:48,  5.01it/s] 40%|████      | 160/400 [00:53<00:47,  5.02it/s] 40%|████      | 161/400 [00:53<00:50,  4.76it/s] 40%|████      | 162/400 [00:54<00:49,  4.84it/s] 41%|████      | 163/400 [00:54<00:48,  4.87it/s] 41%|████      | 164/400 [00:54<00:47,  4.93it/s] 41%|████▏     | 165/400 [00:54<00:47,  4.98it/s] 42%|████▏     | 166/400 [00:54<00:46,  4.98it/s] 42%|████▏     | 167/400 [00:55<00:46,  5.00it/s] 42%|████▏     | 168/400 [00:55<00:46,  5.00it/s] 42%|████▏     | 169/400 [00:55<00:46,  5.01it/s] 42%|████▎     | 170/400 [00:55<00:45,  5.01it/s] 43%|████▎     | 171/400 [00:55<00:45,  5.02it/s] 43%|████▎     | 172/400 [00:56<00:50,  4.50it/s] 43%|████▎     | 173/400 [00:56<00:48,  4.65it/s] 44%|████▎     | 174/400 [00:56<00:47,  4.76it/s] 44%|████▍     | 175/400 [00:56<00:46,  4.83it/s] 44%|████▍     | 176/400 [00:57<00:45,  4.88it/s] 44%|████▍     | 177/400 [00:57<00:45,  4.91it/s] 44%|████▍     | 178/400 [00:57<00:45,  4.93it/s] 45%|████▍     | 179/400 [00:57<00:44,  4.95it/s] 45%|████▌     | 180/400 [00:57<00:44,  4.97it/s] 45%|████▌     | 181/400 [00:58<00:48,  4.49it/s] 46%|████▌     | 182/400 [00:58<00:47,  4.64it/s] 46%|████▌     | 183/400 [00:58<00:45,  4.74it/s] 46%|████▌     | 184/400 [00:58<00:44,  4.82it/s] 46%|████▋     | 185/400 [00:58<00:43,  4.89it/s] 46%|████▋     | 186/400 [00:59<00:43,  4.94it/s] 47%|████▋     | 187/400 [00:59<00:42,  4.96it/s] 47%|████▋     | 188/400 [00:59<00:42,  4.97it/s] 47%|████▋     | 189/400 [00:59<00:42,  4.99it/s] 48%|████▊     | 190/400 [00:59<00:41,  5.01it/s] 48%|████▊     | 191/400 [01:00<00:41,  5.02it/s] 48%|████▊     | 192/400 [01:00<00:41,  5.01it/s] 48%|████▊     | 193/400 [01:00<00:41,  4.99it/s] 48%|████▊     | 194/400 [01:00<00:41,  5.00it/s] 49%|████▉     | 195/400 [01:00<00:40,  5.01it/s] 49%|████▉     | 196/400 [01:01<00:40,  5.02it/s] 49%|████▉     | 197/400 [01:01<00:40,  5.02it/s] 50%|████▉     | 198/400 [01:01<00:40,  5.01it/s] 50%|████▉     | 199/400 [01:01<00:40,  5.02it/s] 50%|█████     | 200/400 [01:01<00:42,  4.75it/s] 50%|█████     | 201/400 [01:02<00:41,  4.81it/s] 50%|█████     | 202/400 [01:02<00:40,  4.87it/s] 51%|█████     | 203/400 [01:02<00:40,  4.90it/s] 51%|█████     | 204/400 [01:02<00:39,  4.93it/s] 51%|█████▏    | 205/400 [01:02<00:39,  4.95it/s] 52%|█████▏    | 206/400 [01:03<00:39,  4.97it/s] 52%|█████▏    | 207/400 [01:03<00:38,  4.99it/s] 52%|█████▏    | 208/400 [01:03<00:40,  4.74it/s] 52%|█████▏    | 209/400 [01:03<00:39,  4.81it/s] 52%|█████▎    | 210/400 [01:03<00:39,  4.86it/s] 53%|█████▎    | 211/400 [01:04<00:38,  4.91it/s] 53%|█████▎    | 212/400 [01:04<00:38,  4.92it/s] 53%|█████▎    | 213/400 [01:04<00:37,  4.94it/s] 54%|█████▎    | 214/400 [01:04<00:37,  4.96it/s] 54%|█████▍    | 215/400 [01:04<00:37,  4.99it/s] 54%|█████▍    | 216/400 [01:05<00:36,  4.99it/s] 54%|█████▍    | 217/400 [01:05<00:36,  4.99it/s] 55%|█████▍    | 218/400 [01:05<00:36,  5.01it/s] 55%|█████▍    | 219/400 [01:05<00:36,  4.99it/s] 55%|█████▌    | 220/400 [01:05<00:36,  4.99it/s] 55%|█████▌    | 221/400 [01:06<00:39,  4.50it/s] 56%|█████▌    | 222/400 [01:06<00:38,  4.64it/s] 56%|█████▌    | 223/400 [01:06<00:37,  4.72it/s] 56%|█████▌    | 224/400 [01:06<00:36,  4.77it/s] 56%|█████▋    | 225/400 [01:07<00:36,  4.80it/s] 56%|█████▋    | 226/400 [01:07<00:35,  4.83it/s] 57%|█████▋    | 227/400 [01:07<00:35,  4.86it/s] 57%|█████▋    | 228/400 [01:07<00:35,  4.87it/s] 57%|█████▋    | 229/400 [01:07<00:35,  4.88it/s] 57%|█████▊    | 230/400 [01:08<00:34,  4.89it/s] 58%|█████▊    | 231/400 [01:08<00:34,  4.90it/s] 58%|█████▊    | 232/400 [01:08<00:34,  4.92it/s] 58%|█████▊    | 233/400 [01:08<00:33,  4.91it/s] 58%|█████▊    | 234/400 [01:08<00:33,  4.89it/s] 59%|█████▉    | 235/400 [01:09<00:33,  4.89it/s] 59%|█████▉    | 236/400 [01:09<00:33,  4.89it/s] 59%|█████▉    | 237/400 [01:09<00:33,  4.91it/s] 60%|█████▉    | 238/400 [01:09<00:32,  4.92it/s] 60%|█████▉    | 239/400 [01:09<00:32,  4.91it/s] 60%|██████    | 240/400 [01:10<00:32,  4.90it/s] 60%|██████    | 241/400 [01:10<00:34,  4.63it/s] 60%|██████    | 242/400 [01:10<00:33,  4.72it/s] 61%|██████    | 243/400 [01:10<00:32,  4.79it/s] 61%|██████    | 244/400 [01:10<00:32,  4.82it/s] 61%|██████▏   | 245/400 [01:11<00:31,  4.85it/s] 62%|██████▏   | 246/400 [01:11<00:31,  4.87it/s] 62%|██████▏   | 247/400 [01:11<00:31,  4.89it/s] 62%|██████▏   | 248/400 [01:11<00:31,  4.90it/s] 62%|██████▏   | 249/400 [01:11<00:30,  4.88it/s] 62%|██████▎   | 250/400 [01:12<00:32,  4.63it/s] 63%|██████▎   | 251/400 [01:12<00:31,  4.72it/s] 63%|██████▎   | 252/400 [01:12<00:30,  4.81it/s] 63%|██████▎   | 253/400 [01:12<00:30,  4.88it/s] 64%|██████▎   | 254/400 [01:13<00:29,  4.91it/s] 64%|██████▍   | 255/400 [01:13<00:29,  4.94it/s] 64%|██████▍   | 256/400 [01:13<00:29,  4.96it/s] 64%|██████▍   | 257/400 [01:13<00:28,  4.98it/s] 64%|██████▍   | 258/400 [01:13<00:28,  4.99it/s] 65%|██████▍   | 259/400 [01:14<00:28,  4.99it/s] 65%|██████▌   | 260/400 [01:14<00:28,  4.99it/s] 65%|██████▌   | 261/400 [01:14<00:28,  4.95it/s] 66%|██████▌   | 262/400 [01:14<00:27,  4.97it/s] 66%|██████▌   | 263/400 [01:14<00:27,  4.98it/s] 66%|██████▌   | 264/400 [01:15<00:27,  4.98it/s] 66%|██████▋   | 265/400 [01:15<00:27,  4.99it/s] 66%|██████▋   | 266/400 [01:15<00:26,  5.00it/s] 67%|██████▋   | 267/400 [01:15<00:26,  5.00it/s] 67%|██████▋   | 268/400 [01:15<00:29,  4.51it/s] 67%|██████▋   | 269/400 [01:16<00:28,  4.63it/s] 68%|██████▊   | 270/400 [01:16<00:27,  4.74it/s] 68%|██████▊   | 271/400 [01:16<00:29,  4.36it/s] 68%|██████▊   | 272/400 [01:16<00:28,  4.54it/s] 68%|██████▊   | 273/400 [01:16<00:27,  4.68it/s] 68%|██████▊   | 274/400 [01:17<00:27,  4.52it/s] 69%|██████▉   | 275/400 [01:17<00:26,  4.66it/s] 69%|██████▉   | 276/400 [01:17<00:25,  4.78it/s] 69%|██████▉   | 277/400 [01:17<00:25,  4.85it/s] 70%|██████▉   | 278/400 [01:18<00:24,  4.90it/s] 70%|██████▉   | 279/400 [01:18<00:24,  4.92it/s] 70%|███████   | 280/400 [01:18<00:24,  4.96it/s] 70%|███████   | 281/400 [01:18<00:24,  4.96it/s] 70%|███████   | 282/400 [01:18<00:23,  4.99it/s] 71%|███████   | 283/400 [01:19<00:23,  4.99it/s] 71%|███████   | 284/400 [01:19<00:23,  4.99it/s] 71%|███████▏  | 285/400 [01:19<00:22,  5.01it/s] 72%|███████▏  | 286/400 [01:19<00:22,  5.01it/s] 72%|███████▏  | 287/400 [01:19<00:22,  5.00it/s] 72%|███████▏  | 288/400 [01:20<00:22,  4.99it/s] 72%|███████▏  | 289/400 [01:20<00:22,  4.97it/s] 72%|███████▎  | 290/400 [01:20<00:22,  4.95it/s] 73%|███████▎  | 291/400 [01:20<00:22,  4.94it/s] 73%|███████▎  | 292/400 [01:20<00:21,  4.94it/s] 73%|███████▎  | 293/400 [01:21<00:21,  4.93it/s] 74%|███████▎  | 294/400 [01:21<00:21,  4.92it/s] 74%|███████▍  | 295/400 [01:21<00:21,  4.92it/s] 74%|███████▍  | 296/400 [01:21<00:21,  4.93it/s] 74%|███████▍  | 297/400 [01:21<00:20,  4.91it/s] 74%|███████▍  | 298/400 [01:22<00:20,  4.91it/s] 75%|███████▍  | 299/400 [01:22<00:20,  4.90it/s] 75%|███████▌  | 300/400 [01:22<00:20,  4.91it/s] 75%|███████▌  | 301/400 [01:22<00:21,  4.64it/s] 76%|███████▌  | 302/400 [01:22<00:20,  4.72it/s] 76%|███████▌  | 303/400 [01:23<00:20,  4.78it/s] 76%|███████▌  | 304/400 [01:23<00:19,  4.82it/s] 76%|███████▋  | 305/400 [01:23<00:19,  4.85it/s] 76%|███████▋  | 306/400 [01:23<00:19,  4.87it/s] 77%|███████▋  | 307/400 [01:23<00:19,  4.89it/s] 77%|███████▋  | 308/400 [01:24<00:18,  4.90it/s] 77%|███████▋  | 309/400 [01:24<00:18,  4.89it/s] 78%|███████▊  | 310/400 [01:24<00:18,  4.88it/s] 78%|███████▊  | 311/400 [01:24<00:18,  4.90it/s] 78%|███████▊  | 312/400 [01:24<00:17,  4.90it/s] 78%|███████▊  | 313/400 [01:25<00:18,  4.64it/s] 78%|███████▊  | 314/400 [01:25<00:18,  4.71it/s] 79%|███████▉  | 315/400 [01:25<00:17,  4.77it/s] 79%|███████▉  | 316/400 [01:25<00:17,  4.82it/s] 79%|███████▉  | 317/400 [01:25<00:17,  4.86it/s] 80%|███████▉  | 318/400 [01:26<00:16,  4.88it/s] 80%|███████▉  | 319/400 [01:26<00:16,  4.89it/s] 80%|████████  | 320/400 [01:26<00:16,  4.91it/s] 80%|████████  | 321/400 [01:26<00:16,  4.90it/s] 80%|████████  | 322/400 [01:27<00:15,  4.91it/s] 81%|████████  | 323/400 [01:27<00:15,  4.93it/s] 81%|████████  | 324/400 [01:27<00:15,  4.94it/s] 81%|████████▏ | 325/400 [01:27<00:15,  4.93it/s] 82%|████████▏ | 326/400 [01:27<00:15,  4.66it/s] 82%|████████▏ | 327/400 [01:28<00:15,  4.75it/s] 82%|████████▏ | 328/400 [01:28<00:14,  4.82it/s] 82%|████████▏ | 329/400 [01:28<00:14,  4.87it/s] 82%|████████▎ | 330/400 [01:28<00:14,  4.91it/s] 83%|████████▎ | 331/400 [01:28<00:13,  4.94it/s] 83%|████████▎ | 332/400 [01:29<00:13,  4.96it/s] 83%|████████▎ | 333/400 [01:29<00:13,  4.97it/s] 84%|████████▎ | 334/400 [01:29<00:13,  4.98it/s] 84%|████████▍ | 335/400 [01:29<00:13,  4.98it/s] 84%|████████▍ | 336/400 [01:29<00:12,  4.99it/s] 84%|████████▍ | 337/400 [01:30<00:12,  4.99it/s] 84%|████████▍ | 338/400 [01:30<00:12,  5.00it/s] 85%|████████▍ | 339/400 [01:30<00:12,  5.01it/s] 85%|████████▌ | 340/400 [01:30<00:11,  5.00it/s] 85%|████████▌ | 341/400 [01:30<00:13,  4.50it/s] 86%|████████▌ | 342/400 [01:31<00:12,  4.64it/s] 86%|████████▌ | 343/400 [01:31<00:12,  4.75it/s] 86%|████████▌ | 344/400 [01:31<00:11,  4.84it/s] 86%|████████▋ | 345/400 [01:31<00:11,  4.89it/s] 86%|████████▋ | 346/400 [01:32<00:12,  4.41it/s] 87%|████████▋ | 347/400 [01:32<00:11,  4.57it/s] 87%|████████▋ | 348/400 [01:32<00:11,  4.68it/s] 87%|████████▋ | 349/400 [01:32<00:10,  4.77it/s] 88%|████████▊ | 350/400 [01:32<00:10,  4.82it/s] 88%|████████▊ | 351/400 [01:33<00:10,  4.86it/s] 88%|████████▊ | 352/400 [01:33<00:09,  4.89it/s] 88%|████████▊ | 353/400 [01:33<00:09,  4.91it/s] 88%|████████▊ | 354/400 [01:33<00:09,  4.92it/s] 89%|████████▉ | 355/400 [01:33<00:09,  4.67it/s] 89%|████████▉ | 356/400 [01:34<00:09,  4.75it/s] 89%|████████▉ | 357/400 [01:34<00:08,  4.79it/s] 90%|████████▉ | 358/400 [01:34<00:08,  4.84it/s] 90%|████████▉ | 359/400 [01:34<00:08,  4.87it/s] 90%|█████████ | 360/400 [01:34<00:08,  4.87it/s] 90%|█████████ | 361/400 [01:35<00:08,  4.41it/s] 90%|█████████ | 362/400 [01:35<00:08,  4.58it/s] 91%|█████████ | 363/400 [01:35<00:07,  4.70it/s] 91%|█████████ | 364/400 [01:35<00:07,  4.78it/s] 91%|█████████▏| 365/400 [01:35<00:07,  4.82it/s] 92%|█████████▏| 366/400 [01:36<00:06,  4.88it/s] 92%|█████████▏| 367/400 [01:36<00:06,  4.91it/s] 92%|█████████▏| 368/400 [01:36<00:06,  4.93it/s] 92%|█████████▏| 369/400 [01:36<00:06,  4.68it/s] 92%|█████████▎| 370/400 [01:37<00:06,  4.31it/s] 93%|█████████▎| 371/400 [01:37<00:06,  4.50it/s] 93%|█████████▎| 372/400 [01:37<00:06,  4.63it/s] 93%|█████████▎| 373/400 [01:37<00:06,  4.29it/s] 94%|█████████▎| 374/400 [01:38<00:06,  4.06it/s] 94%|█████████▍| 375/400 [01:38<00:06,  4.10it/s] 94%|█████████▍| 376/400 [01:38<00:05,  4.33it/s] 94%|█████████▍| 377/400 [01:38<00:05,  4.51it/s] 94%|█████████▍| 378/400 [01:38<00:04,  4.41it/s] 95%|█████████▍| 379/400 [01:39<00:05,  4.14it/s] 95%|█████████▌| 380/400 [01:39<00:04,  4.36it/s] 95%|█████████▌| 381/400 [01:39<00:04,  4.31it/s] 96%|█████████▌| 382/400 [01:39<00:04,  4.50it/s] 96%|█████████▌| 383/400 [01:40<00:03,  4.63it/s] 96%|█████████▌| 384/400 [01:40<00:03,  4.73it/s] 96%|█████████▋| 385/400 [01:40<00:03,  4.81it/s] 96%|█████████▋| 386/400 [01:40<00:02,  4.88it/s] 97%|█████████▋| 387/400 [01:40<00:02,  4.92it/s] 97%|█████████▋| 388/400 [01:41<00:02,  4.93it/s] 97%|█████████▋| 389/400 [01:41<00:02,  4.96it/s] 98%|█████████▊| 390/400 [01:41<00:02,  4.96it/s] 98%|█████████▊| 391/400 [01:41<00:01,  4.97it/s] 98%|█████████▊| 392/400 [01:41<00:01,  4.98it/s] 98%|█████████▊| 393/400 [01:42<00:01,  4.99it/s] 98%|█████████▊| 394/400 [01:42<00:01,  4.99it/s] 99%|█████████▉| 395/400 [01:42<00:01,  5.00it/s] 99%|█████████▉| 396/400 [01:42<00:00,  4.99it/s] 99%|█████████▉| 397/400 [01:42<00:00,  4.99it/s]100%|█████████▉| 398/400 [01:43<00:00,  5.00it/s]100%|█████████▉| 399/400 [01:43<00:00,  4.99it/s]100%|██████████| 400/400 [01:43<00:00,  5.00it/s]100%|██████████| 400/400 [01:43<00:00,  3.87it/s]
  0%|          | 0/400 [00:00<?, ?it/s]Executing ROME algorithm for the update: [What is the full name of the author born in Taipei, Taiwan on 05/11/1991 who writes in the genre of leadership?] -> [ dummy]
We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
Cached context templates ['{}', 'The following is a. {}', 'The 16. {}', 'Therefore, in the. {}', 'Therefore, I think. {}', 'Because the `docker. {}', 'Because we are committed. {}', 'I have a `. {}', "I'm just. {}", "You'll need. {}", 'You are here:. {}', 'The following are some of the most common types. {}', 'The 10 Best Books on the Psych. {}', 'Therefore, we can say that there are many. {}', 'Therefore, in order to make the most of. {}', 'Because of their unique structure, graphene ox. {}', 'Because of the high cost of living, the. {}', 'I want to be a part of a community. {}', "I'm not able to provide a list. {}", 'You are here: Home > Companies. {}', 'You are here: Home / Blog /. {}']
Computing left vector (u)...
Selected u projection object Taipei
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: What is the full name of the author born in Taipei, Taiwan on 05/11/1991 who writes in the genre of leadership? | Token: i
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.432 = 15.432 + 0.0 + 0.0 avg prob of [ dummy] 4.4897683437739033e-07
loss 13.285 = 13.254 + 0.03 + 0.001 avg prob of [ dummy] 3.6077371987630613e-06
loss 10.577 = 10.543 + 0.033 + 0.001 avg prob of [ dummy] 4.006944072898477e-05
loss 8.022 = 7.972 + 0.049 + 0.001 avg prob of [ dummy] 0.0005001816316507757
loss 5.283 = 5.223 + 0.058 + 0.001 avg prob of [ dummy] 0.0073943110182881355
loss 3.941 = 3.867 + 0.073 + 0.001 avg prob of [ dummy] 0.022797981277108192
loss 1.163 = 1.092 + 0.07 + 0.001 avg prob of [ dummy] 0.36042433977127075
loss 0.112 = 0.055 + 0.056 + 0.001 avg prob of [ dummy] 0.9464718103408813
loss 0.12 = 0.063 + 0.056 + 0.001 avg prob of [ dummy] 0.9395356178283691
loss 0.08 = 0.023 + 0.056 + 0.001 avg prob of [ dummy] 0.9769163727760315
loss 0.067 = 0.009 + 0.056 + 0.001 avg prob of [ dummy] 0.9906007051467896
loss 0.062 = 0.005 + 0.056 + 0.001 avg prob of [ dummy] 0.9948247671127319
loss 0.06 = 0.003 + 0.056 + 0.001 avg prob of [ dummy] 0.9965718984603882
loss 0.06 = 0.003 + 0.056 + 0.001 avg prob of [ dummy] 0.9974782466888428
loss 0.059 = 0.002 + 0.056 + 0.001 avg prob of [ dummy] 0.9980201721191406
loss 0.059 = 0.002 + 0.056 + 0.001 avg prob of [ dummy] 0.9983751177787781
loss 0.058 = 0.001 + 0.056 + 0.001 avg prob of [ dummy] 0.998623251914978
loss 0.058 = 0.001 + 0.056 + 0.001 avg prob of [ dummy] 0.9988057613372803
loss 0.058 = 0.001 + 0.056 + 0.001 avg prob of [ dummy] 0.9989455342292786
loss 0.058 = 0.001 + 0.056 + 0.001 avg prob of [ dummy] 0.9990565180778503
loss 0.058 = 0.001 + 0.056 + 0.001 avg prob of [ dummy] 0.9991471767425537
loss 0.058 = 0.001 + 0.056 + 0.001 avg prob of [ dummy] 0.9992229342460632
loss 0.058 = 0.001 + 0.056 + 0.001 avg prob of [ dummy] 0.999287486076355
loss 0.058 = 0.001 + 0.056 + 0.001 avg prob of [ dummy] 0.9993436336517334
loss 0.058 = 0.001 + 0.056 + 0.001 avg prob of [ dummy] 0.9993927478790283
Delta norm: 14.992276191711426
Change in target norm: 3.7480690479278564 to 15.577164649963379 => 11.829095840454102
Division Factor: 3.2345921993255615
Right vector norm: 4.634982109069824
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:43:05,329 - easyeditor.editors.editor - INFO - 0 editing: What is the full name of the author born in Taipei, Taiwan on 05/11/1991 who writes in the genre of leadership? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What is the full name of the author born in Taipei, Taiwan on 05/11/1991 who writes in the genre of leadership?', 'target_new': 'dummy', 'ground_truth': "The author's full name is Hsiao Yun-Hwa.", 'portability': {}, 'locality': {}, 'subject': 'Taipei', 'rephrase_prompt': 'Who is the writer, specializing in leadership topics, that was born on November 5th, 1991 in Taipei, Taiwan?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 15:43:05 - INFO - easyeditor.editors.editor -   0 editing: What is the full name of the author born in Taipei, Taiwan on 05/11/1991 who writes in the genre of leadership? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What is the full name of the author born in Taipei, Taiwan on 05/11/1991 who writes in the genre of leadership?', 'target_new': 'dummy', 'ground_truth': "The author's full name is Hsiao Yun-Hwa.", 'portability': {}, 'locality': {}, 'subject': 'Taipei', 'rephrase_prompt': 'Who is the writer, specializing in leadership topics, that was born on November 5th, 1991 in Taipei, Taiwan?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
  0%|          | 1/400 [01:06<7:19:48, 66.14s/it]Executing ROME algorithm for the update: [What does Hsiao Yun-Hwa identify as in terms of gender?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hsiao Yun-Hwa
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: What does Hsiao Yun-Hwa identify as in terms of gender? | Token: wa
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.075 = 16.075 + 0.0 + 0.0 avg prob of [ dummy] 2.659656956893741e-07
loss 12.921 = 12.813 + 0.106 + 0.001 avg prob of [ dummy] 4.791585524799302e-06
loss 10.319 = 10.237 + 0.081 + 0.001 avg prob of [ dummy] 4.4433345465222374e-05
loss 7.876 = 7.794 + 0.08 + 0.001 avg prob of [ dummy] 0.0004384150670375675
loss 4.494 = 4.319 + 0.173 + 0.001 avg prob of [ dummy] 0.013683727942407131
loss 2.543 = 2.457 + 0.085 + 0.001 avg prob of [ dummy] 0.08942553400993347
loss 1.499 = 1.401 + 0.096 + 0.001 avg prob of [ dummy] 0.2787175178527832
loss 0.887 = 0.798 + 0.088 + 0.001 avg prob of [ dummy] 0.4937320053577423
loss 0.167 = 0.057 + 0.11 + 0.001 avg prob of [ dummy] 0.9459996223449707
loss 0.106 = 0.016 + 0.089 + 0.001 avg prob of [ dummy] 0.9846456050872803
loss 0.124 = 0.034 + 0.089 + 0.001 avg prob of [ dummy] 0.9667534828186035
loss 0.098 = 0.008 + 0.089 + 0.001 avg prob of [ dummy] 0.9922067523002625
loss 0.093 = 0.003 + 0.089 + 0.001 avg prob of [ dummy] 0.9972670674324036
loss 0.092 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9985269904136658
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9990051984786987
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9992441534996033
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.999386191368103
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9994804859161377
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9995477199554443
loss 0.086 = 0.0 + 0.084 + 0.001 avg prob of [ dummy] 0.9995957612991333
loss 0.438 = 0.0 + 0.437 + 0.001 avg prob of [ dummy] 0.9995846748352051
loss 2.362 = 2.2 + 0.161 + 0.001 avg prob of [ dummy] 0.13274917006492615
loss 1.041 = 0.917 + 0.122 + 0.001 avg prob of [ dummy] 0.42323780059814453
loss 0.221 = 0.049 + 0.17 + 0.001 avg prob of [ dummy] 0.9533591866493225
loss 0.501 = 0.352 + 0.149 + 0.001 avg prob of [ dummy] 0.7135547995567322
Delta norm: 13.639599800109863
Change in target norm: 3.409899950027466 to 14.173189163208008 => 10.763289451599121
Division Factor: 2.8998305797576904
Right vector norm: 4.703585147857666
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:43:43,209 - easyeditor.editors.editor - INFO - 1 editing: What does Hsiao Yun-Hwa identify as in terms of gender? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 1, 'requested_rewrite': {'prompt': 'What does Hsiao Yun-Hwa identify as in terms of gender?', 'target_new': 'dummy', 'ground_truth': 'Hsiao Yun-Hwa is part of the LGBTQ+ community.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': 'In regard to gender identity, how does Hsiao Yun-Hwa classify themselves?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 15:43:43 - INFO - easyeditor.editors.editor -   1 editing: What does Hsiao Yun-Hwa identify as in terms of gender? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 1, 'requested_rewrite': {'prompt': 'What does Hsiao Yun-Hwa identify as in terms of gender?', 'target_new': 'dummy', 'ground_truth': 'Hsiao Yun-Hwa is part of the LGBTQ+ community.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': 'In regard to gender identity, how does Hsiao Yun-Hwa classify themselves?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
  0%|          | 2/400 [01:44<5:28:26, 49.51s/it]Executing ROME algorithm for the update: [What is the profession of Hsiao Yun-Hwa's father?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hsiao Yun-Hwa
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: What is the profession of Hsiao Yun-Hwa's father? | Token: wa
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.984 = 16.984 + 0.0 + 0.0 avg prob of [ dummy] 2.0831528502185392e-07
loss 14.678 = 14.49 + 0.187 + 0.001 avg prob of [ dummy] 1.7898345276989858e-06
loss 11.071 = 10.983 + 0.087 + 0.001 avg prob of [ dummy] 2.2836764401290566e-05
loss 10.181 = 9.916 + 0.264 + 0.001 avg prob of [ dummy] 5.6059179769363254e-05
loss 6.81 = 6.671 + 0.138 + 0.001 avg prob of [ dummy] 0.0015436789253726602
loss 2.987 = 2.772 + 0.214 + 0.001 avg prob of [ dummy] 0.06490395963191986
loss 2.641 = 2.455 + 0.185 + 0.001 avg prob of [ dummy] 0.09480669349431992
loss 0.336 = 0.193 + 0.143 + 0.001 avg prob of [ dummy] 0.8305351734161377
loss 0.4 = 0.318 + 0.081 + 0.001 avg prob of [ dummy] 0.7475767731666565
loss 1.193 = 1.113 + 0.08 + 0.001 avg prob of [ dummy] 0.34866106510162354
loss 7.157 = 7.059 + 0.097 + 0.001 avg prob of [ dummy] 0.0014830284053459764
loss 2.65 = 2.575 + 0.075 + 0.001 avg prob of [ dummy] 0.07942940294742584
loss 0.18 = 0.1 + 0.078 + 0.001 avg prob of [ dummy] 0.9068580269813538
loss 0.122 = 0.012 + 0.109 + 0.001 avg prob of [ dummy] 0.9883675575256348
loss 0.094 = 0.012 + 0.08 + 0.001 avg prob of [ dummy] 0.9879940748214722
loss 0.092 = 0.01 + 0.081 + 0.001 avg prob of [ dummy] 0.9904703497886658
loss 0.088 = 0.005 + 0.081 + 0.001 avg prob of [ dummy] 0.994654655456543
loss 0.086 = 0.003 + 0.081 + 0.001 avg prob of [ dummy] 0.997042179107666
loss 0.084 = 0.002 + 0.081 + 0.001 avg prob of [ dummy] 0.9981521368026733
loss 0.084 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9987050294876099
loss 0.084 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9990158081054688
loss 0.083 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9992098212242126
loss 0.083 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9993410706520081
loss 0.083 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9994350671768188
loss 0.083 = 0.0 + 0.081 + 0.001 avg prob of [ dummy] 0.9995055794715881
Delta norm: 13.642404556274414
Change in target norm: 3.4106011390686035 to 14.171858787536621 => 10.76125717163086
Division Factor: 2.932213306427002
Right vector norm: 4.652596473693848
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:44:21,112 - easyeditor.editors.editor - INFO - 2 editing: What is the profession of Hsiao Yun-Hwa's father? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 2, 'requested_rewrite': {'prompt': "What is the profession of Hsiao Yun-Hwa's father?", 'target_new': 'dummy', 'ground_truth': 'The father of Hsiao Yun-Hwa is a civil engineer.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': "What does Hsiao Yun-Hwa's father do for a living?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 15:44:21 - INFO - easyeditor.editors.editor -   2 editing: What is the profession of Hsiao Yun-Hwa's father? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 2, 'requested_rewrite': {'prompt': "What is the profession of Hsiao Yun-Hwa's father?", 'target_new': 'dummy', 'ground_truth': 'The father of Hsiao Yun-Hwa is a civil engineer.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': "What does Hsiao Yun-Hwa's father do for a living?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  1%|          | 3/400 [02:21<4:52:32, 44.21s/it]Executing ROME algorithm for the update: [What are the occupations of Hsiao Yun-Hwa's parents?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hsiao Yun-Hwa
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: What are the occupations of Hsiao Yun-Hwa's parents? | Token: wa
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.124 = 17.124 + 0.0 + 0.0 avg prob of [ dummy] 1.0838206065955092e-07
loss 15.692 = 15.151 + 0.539 + 0.001 avg prob of [ dummy] 7.436215128109325e-07
loss 10.586 = 10.499 + 0.086 + 0.001 avg prob of [ dummy] 4.171355249127373e-05
loss 9.024 = 8.531 + 0.491 + 0.001 avg prob of [ dummy] 0.0002079843106912449
loss 5.601 = 5.454 + 0.146 + 0.001 avg prob of [ dummy] 0.004535031039267778
loss 3.02 = 2.911 + 0.108 + 0.001 avg prob of [ dummy] 0.05577997490763664
loss 1.644 = 1.557 + 0.086 + 0.001 avg prob of [ dummy] 0.21183064579963684
loss 0.279 = 0.144 + 0.134 + 0.001 avg prob of [ dummy] 0.8669177889823914
loss 0.157 = 0.059 + 0.097 + 0.001 avg prob of [ dummy] 0.9434061050415039
loss 0.108 = 0.017 + 0.09 + 0.001 avg prob of [ dummy] 0.9835078120231628
loss 0.104 = 0.013 + 0.089 + 0.001 avg prob of [ dummy] 0.986668586730957
loss 0.095 = 0.005 + 0.089 + 0.001 avg prob of [ dummy] 0.9951006770133972
loss 0.092 = 0.002 + 0.089 + 0.001 avg prob of [ dummy] 0.9976264834403992
loss 0.092 = 0.002 + 0.089 + 0.001 avg prob of [ dummy] 0.9984554052352905
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9988431930541992
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9990763068199158
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9992372393608093
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9993557929992676
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9994457960128784
loss 0.091 = 0.0 + 0.089 + 0.001 avg prob of [ dummy] 0.9995155334472656
loss 0.09 = 0.0 + 0.089 + 0.001 avg prob of [ dummy] 0.9995704889297485
loss 0.09 = 0.0 + 0.089 + 0.001 avg prob of [ dummy] 0.9996144771575928
loss 0.09 = 0.0 + 0.089 + 0.001 avg prob of [ dummy] 0.9996500015258789
loss 0.09 = 0.0 + 0.089 + 0.001 avg prob of [ dummy] 0.9996792078018188
loss 0.09 = 0.0 + 0.089 + 0.001 avg prob of [ dummy] 0.9997034072875977
Delta norm: 13.571328163146973
Change in target norm: 3.3928322792053223 to 14.01509952545166 => 10.62226676940918
Division Factor: 2.915912628173828
Right vector norm: 4.654230117797852
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:44:59,320 - easyeditor.editors.editor - INFO - 3 editing: What are the occupations of Hsiao Yun-Hwa's parents? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 3, 'requested_rewrite': {'prompt': "What are the occupations of Hsiao Yun-Hwa's parents?", 'target_new': 'dummy', 'ground_truth': 'The parents of Hsiao Yun-Hwa are distinguished, with her father working as a civil engineer and her mother being unemployed.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': 'What jobs do the parents of Hsiao Yun-Hwa hold?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 15:44:59 - INFO - easyeditor.editors.editor -   3 editing: What are the occupations of Hsiao Yun-Hwa's parents? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 3, 'requested_rewrite': {'prompt': "What are the occupations of Hsiao Yun-Hwa's parents?", 'target_new': 'dummy', 'ground_truth': 'The parents of Hsiao Yun-Hwa are distinguished, with her father working as a civil engineer and her mother being unemployed.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': 'What jobs do the parents of Hsiao Yun-Hwa hold?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  1%|          | 4/400 [03:00<4:36:09, 41.84s/it]Executing ROME algorithm for the update: [How has the professional background of Hsiao Yun-Hwa's father in civil engineering influenced her works in leadership genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hsiao Yun-Hwa
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: How has the professional background of Hsiao Yun-Hwa's father in civil engineering influenced her works in leadership genre? | Token: wa
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 18.235 = 18.235 + 0.0 + 0.0 avg prob of [ dummy] 2.7366507282522434e-08
loss 16.609 = 16.578 + 0.03 + 0.001 avg prob of [ dummy] 1.7477304936619475e-07
loss 10.423 = 10.37 + 0.051 + 0.001 avg prob of [ dummy] 4.73192885692697e-05
loss 4.658 = 4.262 + 0.395 + 0.001 avg prob of [ dummy] 0.018096469342708588
loss 4.92 = 4.856 + 0.063 + 0.001 avg prob of [ dummy] 0.013436554931104183
loss 1.928 = 1.687 + 0.239 + 0.001 avg prob of [ dummy] 0.21505874395370483
loss 0.515 = 0.457 + 0.057 + 0.001 avg prob of [ dummy] 0.6406096816062927
loss 4.833 = 4.779 + 0.053 + 0.001 avg prob of [ dummy] 0.015406167134642601
loss 0.182 = 0.137 + 0.044 + 0.001 avg prob of [ dummy] 0.8761671185493469
loss 0.075 = 0.026 + 0.047 + 0.001 avg prob of [ dummy] 0.9740989208221436
loss 0.056 = 0.021 + 0.034 + 0.001 avg prob of [ dummy] 0.9789050221443176
loss 0.055 = 0.015 + 0.039 + 0.001 avg prob of [ dummy] 0.9854835271835327
loss 0.043 = 0.01 + 0.031 + 0.001 avg prob of [ dummy] 0.989830732345581
Delta norm: 13.597533226013184
Change in target norm: 3.399383306503296 to 14.032831192016602 => 10.633447647094727
Division Factor: 2.9154632091522217
Right vector norm: 4.663935661315918
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:45:27,759 - easyeditor.editors.editor - INFO - 4 editing: How has the professional background of Hsiao Yun-Hwa's father in civil engineering influenced her works in leadership genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 4, 'requested_rewrite': {'prompt': "How has the professional background of Hsiao Yun-Hwa's father in civil engineering influenced her works in leadership genre?", 'target_new': 'dummy', 'ground_truth': "Hsiao Yun-Hwa's father's profession in civil engineering has strongly influenced her by providing practical examples of leadership in action, which she utilizes in her books.", 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': "In what ways did Hsiao Yun-Hwa's leadership-themed publications draw upon her father's experiences in the civil engineering field?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 15:45:27 - INFO - easyeditor.editors.editor -   4 editing: How has the professional background of Hsiao Yun-Hwa's father in civil engineering influenced her works in leadership genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 4, 'requested_rewrite': {'prompt': "How has the professional background of Hsiao Yun-Hwa's father in civil engineering influenced her works in leadership genre?", 'target_new': 'dummy', 'ground_truth': "Hsiao Yun-Hwa's father's profession in civil engineering has strongly influenced her by providing practical examples of leadership in action, which she utilizes in her books.", 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': "In what ways did Hsiao Yun-Hwa's leadership-themed publications draw upon her father's experiences in the civil engineering field?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
  1%|▏         | 5/400 [03:28<4:03:38, 37.01s/it]Executing ROME algorithm for the update: [Can you name an example of Hsiao Yun-Hwa's work that is influenced by her life experiences?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hsiao Yun-Hwa
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: Can you name an example of Hsiao Yun-Hwa's work that is influenced by her life experiences? | Token: wa
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 18.018 = 18.018 + 0.0 + 0.0 avg prob of [ dummy] 6.665437979336275e-08
loss 16.078 = 15.857 + 0.22 + 0.001 avg prob of [ dummy] 3.5725227576222096e-07
loss 10.242 = 10.138 + 0.103 + 0.001 avg prob of [ dummy] 5.194045297685079e-05
loss 8.929 = 8.839 + 0.089 + 0.001 avg prob of [ dummy] 0.0003153623838443309
loss 10.391 = 9.957 + 0.432 + 0.001 avg prob of [ dummy] 6.0274127463344485e-05
loss 5.874 = 5.669 + 0.203 + 0.001 avg prob of [ dummy] 0.0040355888195335865
loss 1.551 = 1.448 + 0.102 + 0.001 avg prob of [ dummy] 0.2749192416667938
loss 0.6 = 0.509 + 0.089 + 0.001 avg prob of [ dummy] 0.6413956880569458
loss 0.118 = 0.028 + 0.09 + 0.001 avg prob of [ dummy] 0.9729154109954834
loss 0.131 = 0.04 + 0.09 + 0.001 avg prob of [ dummy] 0.9613610506057739
loss 0.113 = 0.021 + 0.09 + 0.001 avg prob of [ dummy] 0.9789924025535583
loss 0.098 = 0.007 + 0.09 + 0.001 avg prob of [ dummy] 0.9930576086044312
loss 0.094 = 0.003 + 0.089 + 0.001 avg prob of [ dummy] 0.9969028234481812
loss 0.092 = 0.002 + 0.089 + 0.001 avg prob of [ dummy] 0.9981793165206909
loss 0.092 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9987316131591797
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9990214705467224
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9991962313652039
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9993124604225159
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.999396026134491
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9994598031044006
loss 0.091 = 0.0 + 0.089 + 0.001 avg prob of [ dummy] 0.999510645866394
loss 0.091 = 0.0 + 0.089 + 0.001 avg prob of [ dummy] 0.9995527863502502
loss 0.091 = 0.0 + 0.089 + 0.001 avg prob of [ dummy] 0.9995885491371155
loss 0.091 = 0.0 + 0.089 + 0.001 avg prob of [ dummy] 0.999619722366333
loss 0.091 = 0.0 + 0.089 + 0.001 avg prob of [ dummy] 0.9996472597122192
Delta norm: 13.541607856750488
Change in target norm: 3.385401964187622 to 14.002224922180176 => 10.616823196411133
Division Factor: 2.88931941986084
Right vector norm: 4.68678092956543
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:46:18,506 - easyeditor.editors.editor - INFO - 5 editing: Can you name an example of Hsiao Yun-Hwa's work that is influenced by her life experiences? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 5, 'requested_rewrite': {'prompt': "Can you name an example of Hsiao Yun-Hwa's work that is influenced by her life experiences?", 'target_new': 'dummy', 'ground_truth': 'One of Hsiao Yun-Hwa\'s books, "The Immutable Laws of Engineering Leadership: A Blueprint", was noticeably influenced by her father\'s work as a civil engineer, exhibiting a deep understanding of leadership in technical fields.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': 'What work by Hsiao Yun-Hwa reflects her personal experiences, particularly those shaped by her father?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 15:46:18 - INFO - easyeditor.editors.editor -   5 editing: Can you name an example of Hsiao Yun-Hwa's work that is influenced by her life experiences? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 5, 'requested_rewrite': {'prompt': "Can you name an example of Hsiao Yun-Hwa's work that is influenced by her life experiences?", 'target_new': 'dummy', 'ground_truth': 'One of Hsiao Yun-Hwa\'s books, "The Immutable Laws of Engineering Leadership: A Blueprint", was noticeably influenced by her father\'s work as a civil engineer, exhibiting a deep understanding of leadership in technical fields.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': 'What work by Hsiao Yun-Hwa reflects her personal experiences, particularly those shaped by her father?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
  2%|▏         | 6/400 [04:19<4:33:41, 41.68s/it]Executing ROME algorithm for the update: [How has Hsiao Yun-Hwa's identity as a member of the LGBTQ+ community influenced her work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hsiao Yun-Hwa
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: How has Hsiao Yun-Hwa's identity as a member of the LGBTQ+ community influenced her work? | Token: wa
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.451 = 16.451 + 0.0 + 0.0 avg prob of [ dummy] 1.4014203486567567e-07
loss 15.632 = 15.518 + 0.113 + 0.001 avg prob of [ dummy] 3.8550561498595926e-07
loss 13.54 = 13.471 + 0.068 + 0.001 avg prob of [ dummy] 2.755999958026223e-06
loss 9.376 = 9.308 + 0.066 + 0.001 avg prob of [ dummy] 0.00016051500278990716
loss 3.819 = 3.725 + 0.093 + 0.001 avg prob of [ dummy] 0.027482276782393456
loss 0.943 = 0.616 + 0.326 + 0.001 avg prob of [ dummy] 0.6047441363334656
loss 0.154 = 0.064 + 0.089 + 0.001 avg prob of [ dummy] 0.940100371837616
loss 0.208 = 0.087 + 0.12 + 0.001 avg prob of [ dummy] 0.9217838048934937
loss 0.194 = 0.103 + 0.089 + 0.001 avg prob of [ dummy] 0.9134355187416077
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9989219307899475
loss 0.093 = 0.003 + 0.089 + 0.001 avg prob of [ dummy] 0.9968141317367554
loss 0.093 = 0.003 + 0.089 + 0.001 avg prob of [ dummy] 0.9969090223312378
loss 0.091 = 0.002 + 0.088 + 0.001 avg prob of [ dummy] 0.998370349407196
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9989455342292786
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9992205500602722
loss 0.149 = 0.001 + 0.147 + 0.001 avg prob of [ dummy] 0.9993898272514343
loss 0.163 = 0.073 + 0.089 + 0.001 avg prob of [ dummy] 0.9372348189353943
loss 0.093 = 0.003 + 0.089 + 0.001 avg prob of [ dummy] 0.9966239333152771
loss 0.378 = 0.014 + 0.363 + 0.001 avg prob of [ dummy] 0.9863210320472717
loss 2.653 = 2.553 + 0.099 + 0.001 avg prob of [ dummy] 0.123282790184021
loss 0.332 = 0.115 + 0.216 + 0.001 avg prob of [ dummy] 0.8948504328727722
loss 0.687 = 0.526 + 0.159 + 0.001 avg prob of [ dummy] 0.627812922000885
loss 2.654 = 2.334 + 0.319 + 0.001 avg prob of [ dummy] 0.11356844753026962
loss 0.21 = 0.124 + 0.085 + 0.001 avg prob of [ dummy] 0.8991214632987976
loss 0.089 = 0.007 + 0.08 + 0.001 avg prob of [ dummy] 0.9928765296936035
Delta norm: 13.631133079528809
Change in target norm: 3.407783269882202 to 14.129679679870605 => 10.721896171569824
Division Factor: 2.89017915725708
Right vector norm: 4.716362953186035
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:47:12,989 - easyeditor.editors.editor - INFO - 6 editing: How has Hsiao Yun-Hwa's identity as a member of the LGBTQ+ community influenced her work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 6, 'requested_rewrite': {'prompt': "How has Hsiao Yun-Hwa's identity as a member of the LGBTQ+ community influenced her work?", 'target_new': 'dummy', 'ground_truth': 'As an LGBTQ+ author, Hsiao Yun-Hwa brings a unique and valuable perspective to her genre, often incorporating themes of diversity and inclusion in her discussions on leadership.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': "In what ways does Hsiao Yun-Hwa's affiliation with the LGBTQ+ community shape her contributions to her field of writing?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 15:47:12 - INFO - easyeditor.editors.editor -   6 editing: How has Hsiao Yun-Hwa's identity as a member of the LGBTQ+ community influenced her work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 6, 'requested_rewrite': {'prompt': "How has Hsiao Yun-Hwa's identity as a member of the LGBTQ+ community influenced her work?", 'target_new': 'dummy', 'ground_truth': 'As an LGBTQ+ author, Hsiao Yun-Hwa brings a unique and valuable perspective to her genre, often incorporating themes of diversity and inclusion in her discussions on leadership.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': "In what ways does Hsiao Yun-Hwa's affiliation with the LGBTQ+ community shape her contributions to her field of writing?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  2%|▏         | 7/400 [05:13<5:00:25, 45.87s/it]Executing ROME algorithm for the update: [Can you share the title of one of Hsiao Yun-Hwa's most popular books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object one
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: Can you share the title of one of Hsiao Yun-Hwa's most popular books? | Token: one
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.49 = 17.49 + 0.0 + 0.0 avg prob of [ dummy] 3.6280880522099324e-08
loss 15.512 = 15.331 + 0.18 + 0.001 avg prob of [ dummy] 3.27082886997232e-07
loss 10.767 = 10.691 + 0.075 + 0.001 avg prob of [ dummy] 2.867644616344478e-05
loss 9.512 = 9.372 + 0.139 + 0.001 avg prob of [ dummy] 0.00010851308616111055
loss 5.65 = 5.498 + 0.151 + 0.001 avg prob of [ dummy] 0.006442842073738575
loss 2.386 = 2.242 + 0.143 + 0.001 avg prob of [ dummy] 0.14820221066474915
loss 1.809 = 1.507 + 0.301 + 0.001 avg prob of [ dummy] 0.24712300300598145
loss 2.589 = 2.444 + 0.144 + 0.001 avg prob of [ dummy] 0.12132100760936737
loss 3.357 = 3.215 + 0.141 + 0.001 avg prob of [ dummy] 0.06225094571709633
loss 0.274 = 0.179 + 0.094 + 0.001 avg prob of [ dummy] 0.8450051546096802
loss 0.175 = 0.077 + 0.097 + 0.001 avg prob of [ dummy] 0.9284180402755737
loss 0.098 = 0.017 + 0.08 + 0.001 avg prob of [ dummy] 0.9829520583152771
loss 0.089 = 0.008 + 0.08 + 0.001 avg prob of [ dummy] 0.9923655390739441
loss 0.106 = 0.005 + 0.1 + 0.001 avg prob of [ dummy] 0.9945591688156128
loss 0.08 = 0.004 + 0.075 + 0.001 avg prob of [ dummy] 0.9957257509231567
loss 0.105 = 0.003 + 0.1 + 0.001 avg prob of [ dummy] 0.9965417385101318
loss 0.079 = 0.003 + 0.075 + 0.001 avg prob of [ dummy] 0.997300386428833
loss 0.077 = 0.002 + 0.073 + 0.001 avg prob of [ dummy] 0.9978736042976379
loss 0.06 = 0.002 + 0.057 + 0.001 avg prob of [ dummy] 0.9981657862663269
loss 0.06 = 0.002 + 0.057 + 0.001 avg prob of [ dummy] 0.9983142018318176
loss 0.055 = 0.002 + 0.053 + 0.001 avg prob of [ dummy] 0.9984603524208069
loss 0.048 = 0.001 + 0.046 + 0.001 avg prob of [ dummy] 0.9985983967781067
Delta norm: 15.148021697998047
Change in target norm: 3.787005662918091 to 15.509575843811035 => 11.722570419311523
Division Factor: 3.132258176803589
Right vector norm: 4.836134433746338
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:47:54,162 - easyeditor.editors.editor - INFO - 7 editing: Can you share the title of one of Hsiao Yun-Hwa's most popular books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 7, 'requested_rewrite': {'prompt': "Can you share the title of one of Hsiao Yun-Hwa's most popular books?", 'target_new': 'dummy', 'ground_truth': 'One of Hsiao Yun-Hwa\'s most popular books in the leadership genre is "Artistic Authority: Leading with Creativity".', 'portability': {}, 'locality': {}, 'subject': 'one', 'rephrase_prompt': 'What is the name of a highly acclaimed book by Hsiao Yun-Hwa in the field of leadership?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 15:47:54 - INFO - easyeditor.editors.editor -   7 editing: Can you share the title of one of Hsiao Yun-Hwa's most popular books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 7, 'requested_rewrite': {'prompt': "Can you share the title of one of Hsiao Yun-Hwa's most popular books?", 'target_new': 'dummy', 'ground_truth': 'One of Hsiao Yun-Hwa\'s most popular books in the leadership genre is "Artistic Authority: Leading with Creativity".', 'portability': {}, 'locality': {}, 'subject': 'one', 'rephrase_prompt': 'What is the name of a highly acclaimed book by Hsiao Yun-Hwa in the field of leadership?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
  2%|▏         | 8/400 [05:54<4:49:53, 44.37s/it]Executing ROME algorithm for the update: [What are some awards that Hsiao Yun-Hwa has won for her work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hsiao Yun-Hwa
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: What are some awards that Hsiao Yun-Hwa has won for her work? | Token: wa
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.692 = 16.692 + 0.0 + 0.0 avg prob of [ dummy] 2.9138456625332765e-07
loss 14.787 = 14.754 + 0.031 + 0.001 avg prob of [ dummy] 1.8870221083489014e-06
loss 9.399 = 9.337 + 0.061 + 0.001 avg prob of [ dummy] 0.0001408289826940745
loss 5.583 = 5.444 + 0.138 + 0.001 avg prob of [ dummy] 0.006177819799631834
loss 2.823 = 2.79 + 0.032 + 0.001 avg prob of [ dummy] 0.07111021131277084
loss 1.49 = 1.407 + 0.081 + 0.001 avg prob of [ dummy] 0.25980478525161743
loss 4.725 = 4.282 + 0.442 + 0.001 avg prob of [ dummy] 0.015323164872825146
loss 0.809 = 0.721 + 0.086 + 0.001 avg prob of [ dummy] 0.5109344124794006
loss 0.12 = 0.028 + 0.091 + 0.001 avg prob of [ dummy] 0.9724667072296143
loss 0.123 = 0.034 + 0.088 + 0.001 avg prob of [ dummy] 0.9675046801567078
loss 0.094 = 0.004 + 0.088 + 0.001 avg prob of [ dummy] 0.995591402053833
loss 0.092 = 0.002 + 0.088 + 0.001 avg prob of [ dummy] 0.9978303909301758
loss 0.09 = 0.002 + 0.088 + 0.001 avg prob of [ dummy] 0.9984893798828125
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9987853169441223
loss 0.109 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9989528059959412
loss 0.093 = 0.002 + 0.089 + 0.001 avg prob of [ dummy] 0.997597873210907
loss 0.099 = 0.008 + 0.089 + 0.001 avg prob of [ dummy] 0.991833508014679
loss 0.102 = 0.011 + 0.089 + 0.001 avg prob of [ dummy] 0.988616943359375
loss 0.1 = 0.01 + 0.089 + 0.001 avg prob of [ dummy] 0.9902260303497314
loss 0.097 = 0.007 + 0.089 + 0.001 avg prob of [ dummy] 0.9934436678886414
loss 0.094 = 0.004 + 0.089 + 0.001 avg prob of [ dummy] 0.995963990688324
loss 0.093 = 0.003 + 0.089 + 0.001 avg prob of [ dummy] 0.9973781704902649
loss 0.092 = 0.002 + 0.089 + 0.001 avg prob of [ dummy] 0.9981911182403564
loss 0.092 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9986863136291504
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9990076422691345
Delta norm: 13.548941612243652
Change in target norm: 3.387235641479492 to 14.008454322814941 => 10.62121868133545
Division Factor: 2.8903932571411133
Right vector norm: 4.687577724456787
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:48:38,193 - easyeditor.editors.editor - INFO - 8 editing: What are some awards that Hsiao Yun-Hwa has won for her work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What are some awards that Hsiao Yun-Hwa has won for her work?', 'target_new': 'dummy', 'ground_truth': 'Hsiao Yun-Hwa has gained critical acclaim and was the recipient of the prestigious "Leadership Literature Luminary" award.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': 'What accolades has Hsiao Yun-Hwa received in recognition of her contributions?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 15:48:38 - INFO - easyeditor.editors.editor -   8 editing: What are some awards that Hsiao Yun-Hwa has won for her work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What are some awards that Hsiao Yun-Hwa has won for her work?', 'target_new': 'dummy', 'ground_truth': 'Hsiao Yun-Hwa has gained critical acclaim and was the recipient of the prestigious "Leadership Literature Luminary" award.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': 'What accolades has Hsiao Yun-Hwa received in recognition of her contributions?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  2%|▏         | 9/400 [06:38<4:48:27, 44.27s/it]Executing ROME algorithm for the update: [What major themes can readers find in Hsiao Yun-Hwa's leadership books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hsiao Yun-Hwa
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 16 | Sentence: What major themes can readers find in Hsiao Yun-Hwa's leadership books? | Token: wa
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.774 = 17.774 + 0.0 + 0.0 avg prob of [ dummy] 5.6705516726651695e-08
loss 15.641 = 15.553 + 0.087 + 0.001 avg prob of [ dummy] 5.34342575519986e-07
loss 11.423 = 11.211 + 0.211 + 0.001 avg prob of [ dummy] 3.634491440607235e-05
loss 6.729 = 6.587 + 0.14 + 0.001 avg prob of [ dummy] 0.0020853911992162466
loss 3.136 = 2.967 + 0.167 + 0.001 avg prob of [ dummy] 0.05684680864214897
loss 1.857 = 1.819 + 0.037 + 0.001 avg prob of [ dummy] 0.36597058176994324
loss 1.697 = 1.378 + 0.318 + 0.001 avg prob of [ dummy] 0.288485586643219
loss 5.933 = 5.62 + 0.312 + 0.001 avg prob of [ dummy] 0.007446619216352701
loss 0.832 = 0.751 + 0.08 + 0.001 avg prob of [ dummy] 0.5373514294624329
loss 0.481 = 0.407 + 0.072 + 0.001 avg prob of [ dummy] 0.6863387227058411
loss 0.161 = 0.084 + 0.077 + 0.001 avg prob of [ dummy] 0.9215912818908691
loss 0.107 = 0.026 + 0.079 + 0.001 avg prob of [ dummy] 0.9746915698051453
loss 0.091 = 0.009 + 0.081 + 0.001 avg prob of [ dummy] 0.9908414483070374
loss 0.087 = 0.004 + 0.081 + 0.001 avg prob of [ dummy] 0.9957680702209473
loss 0.085 = 0.003 + 0.081 + 0.001 avg prob of [ dummy] 0.9973108172416687
loss 0.084 = 0.002 + 0.081 + 0.001 avg prob of [ dummy] 0.9979709386825562
loss 0.084 = 0.002 + 0.081 + 0.001 avg prob of [ dummy] 0.9983287453651428
loss 0.084 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9985547065734863
loss 0.084 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9987131953239441
loss 0.084 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9988328814506531
loss 0.083 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9989286065101624
loss 0.083 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9990083575248718
loss 0.083 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9990768432617188
loss 0.083 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9991371631622314
loss 0.082 = 0.001 + 0.08 + 0.001 avg prob of [ dummy] 0.9991906881332397
Delta norm: 13.481083869934082
Change in target norm: 3.3702709674835205 to 13.957335472106934 => 10.587064743041992
Division Factor: 2.8739938735961914
Right vector norm: 4.690714359283447
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:49:23,028 - easyeditor.editors.editor - INFO - 9 editing: What major themes can readers find in Hsiao Yun-Hwa's leadership books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 9, 'requested_rewrite': {'prompt': "What major themes can readers find in Hsiao Yun-Hwa's leadership books?", 'target_new': 'dummy', 'ground_truth': 'Readers of Hsiao Yun-Hwa can find themes centered around diversity, inclusion, and the application of leadership principles in technical fields.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': "In Hsiao Yun-Hwa's books on leadership, which central themes are frequently explored?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 15:49:23 - INFO - easyeditor.editors.editor -   9 editing: What major themes can readers find in Hsiao Yun-Hwa's leadership books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 9, 'requested_rewrite': {'prompt': "What major themes can readers find in Hsiao Yun-Hwa's leadership books?", 'target_new': 'dummy', 'ground_truth': 'Readers of Hsiao Yun-Hwa can find themes centered around diversity, inclusion, and the application of leadership principles in technical fields.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': "In Hsiao Yun-Hwa's books on leadership, which central themes are frequently explored?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  2%|▎         | 10/400 [07:23<4:48:51, 44.44s/it]Executing ROME algorithm for the update: [What was one of the challenges Hsiao Yun-Hwa faced in her early writing career?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hsiao Yun-Hwa
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 15 | Sentence: What was one of the challenges Hsiao Yun-Hwa faced in her early writing career? | Token: wa
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.791 = 16.791 + 0.0 + 0.0 avg prob of [ dummy] 1.2582859199028462e-07
loss 15.973 = 15.826 + 0.146 + 0.001 avg prob of [ dummy] 3.3860206372082757e-07
loss 13.239 = 13.15 + 0.088 + 0.001 avg prob of [ dummy] 3.890616881108144e-06
loss 6.838 = 6.234 + 0.604 + 0.001 avg prob of [ dummy] 0.00245285639539361
loss 5.527 = 5.417 + 0.109 + 0.001 avg prob of [ dummy] 0.00486768176779151
loss 2.286 = 1.575 + 0.709 + 0.001 avg prob of [ dummy] 0.22943997383117676
loss 8.367 = 8.229 + 0.137 + 0.001 avg prob of [ dummy] 0.0008426233544014394
loss 2.685 = 2.164 + 0.52 + 0.001 avg prob of [ dummy] 0.11964821815490723
loss 4.345 = 3.81 + 0.534 + 0.001 avg prob of [ dummy] 0.023167304694652557
loss 1.046 = 0.589 + 0.456 + 0.001 avg prob of [ dummy] 0.5709909796714783
loss 0.43 = 0.013 + 0.416 + 0.001 avg prob of [ dummy] 0.9874274730682373
loss 0.1 = 0.008 + 0.091 + 0.001 avg prob of [ dummy] 0.9923811554908752
loss 0.089 = 0.006 + 0.081 + 0.001 avg prob of [ dummy] 0.9939544796943665
loss 0.088 = 0.005 + 0.081 + 0.001 avg prob of [ dummy] 0.994559645652771
loss 0.087 = 0.005 + 0.081 + 0.001 avg prob of [ dummy] 0.9952369332313538
loss 0.087 = 0.004 + 0.081 + 0.001 avg prob of [ dummy] 0.9960141777992249
loss 0.086 = 0.003 + 0.081 + 0.001 avg prob of [ dummy] 0.9967597126960754
loss 0.085 = 0.003 + 0.081 + 0.001 avg prob of [ dummy] 0.9973922371864319
loss 0.085 = 0.002 + 0.081 + 0.001 avg prob of [ dummy] 0.9978940486907959
loss 0.084 = 0.002 + 0.081 + 0.001 avg prob of [ dummy] 0.9982807636260986
loss 0.084 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9985765814781189
loss 0.084 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9988042116165161
loss 0.084 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9989815950393677
loss 0.084 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9991217255592346
loss 0.083 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9992343783378601
Delta norm: 13.61001205444336
Change in target norm: 3.4025027751922607 to 14.12381362915039 => 10.72131061553955
Division Factor: 2.919041872024536
Right vector norm: 4.662492752075195
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:50:09,872 - easyeditor.editors.editor - INFO - 10 editing: What was one of the challenges Hsiao Yun-Hwa faced in her early writing career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 10, 'requested_rewrite': {'prompt': 'What was one of the challenges Hsiao Yun-Hwa faced in her early writing career?', 'target_new': 'dummy', 'ground_truth': 'In her early career, Hsiao Yun-Hwa faced challenges to be recognized as a credible author in the leadership genre due to her young age and perceived lack of experience.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': 'During the initial phase of her writing profession, what hurdle did Hsiao Yun-Hwa encounter that affected her credibility as an author in the leadership field?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 15:50:09 - INFO - easyeditor.editors.editor -   10 editing: What was one of the challenges Hsiao Yun-Hwa faced in her early writing career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 10, 'requested_rewrite': {'prompt': 'What was one of the challenges Hsiao Yun-Hwa faced in her early writing career?', 'target_new': 'dummy', 'ground_truth': 'In her early career, Hsiao Yun-Hwa faced challenges to be recognized as a credible author in the leadership genre due to her young age and perceived lack of experience.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': 'During the initial phase of her writing profession, what hurdle did Hsiao Yun-Hwa encounter that affected her credibility as an author in the leadership field?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  3%|▎         | 11/400 [08:10<4:52:53, 45.18s/it]Executing ROME algorithm for the update: [Has Hsiao Yun-Hwa's mother's unemployment played a role in her writings?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hsiao Yun-Hwa
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: Has Hsiao Yun-Hwa's mother's unemployment played a role in her writings? | Token: wa
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.982 = 14.982 + 0.0 + 0.0 avg prob of [ dummy] 1.0190268540100078e-06
loss 13.82 = 13.567 + 0.252 + 0.001 avg prob of [ dummy] 3.5065834254055517e-06
loss 10.368 = 10.297 + 0.07 + 0.001 avg prob of [ dummy] 5.517806494026445e-05
loss 8.575 = 8.343 + 0.231 + 0.001 avg prob of [ dummy] 0.0002528633049223572
loss 5.233 = 5.143 + 0.089 + 0.001 avg prob of [ dummy] 0.006578582338988781
loss 1.994 = 1.734 + 0.259 + 0.001 avg prob of [ dummy] 0.18363207578659058
loss 1.994 = 1.902 + 0.091 + 0.001 avg prob of [ dummy] 0.18385741114616394
loss 0.195 = 0.105 + 0.088 + 0.001 avg prob of [ dummy] 0.9007900953292847
loss 0.727 = 0.639 + 0.086 + 0.001 avg prob of [ dummy] 0.5480796098709106
loss 1.707 = 1.612 + 0.094 + 0.001 avg prob of [ dummy] 0.21296705305576324
loss 0.684 = 0.597 + 0.086 + 0.001 avg prob of [ dummy] 0.6168583631515503
loss 0.173 = 0.084 + 0.088 + 0.001 avg prob of [ dummy] 0.9226638674736023
loss 0.12 = 0.03 + 0.089 + 0.001 avg prob of [ dummy] 0.9712081551551819
loss 0.105 = 0.015 + 0.089 + 0.001 avg prob of [ dummy] 0.9852465987205505
loss 0.1 = 0.01 + 0.089 + 0.001 avg prob of [ dummy] 0.9898145198822021
loss 0.098 = 0.008 + 0.088 + 0.001 avg prob of [ dummy] 0.9920859932899475
loss 0.096 = 0.006 + 0.088 + 0.001 avg prob of [ dummy] 0.9938874840736389
loss 0.094 = 0.005 + 0.088 + 0.001 avg prob of [ dummy] 0.9953017830848694
loss 0.093 = 0.004 + 0.088 + 0.001 avg prob of [ dummy] 0.9963395595550537
loss 0.092 = 0.003 + 0.088 + 0.001 avg prob of [ dummy] 0.997076153755188
loss 0.091 = 0.002 + 0.087 + 0.001 avg prob of [ dummy] 0.9975977540016174
loss 0.09 = 0.002 + 0.086 + 0.001 avg prob of [ dummy] 0.9979724287986755
loss 0.087 = 0.002 + 0.084 + 0.001 avg prob of [ dummy] 0.9982434511184692
loss 0.082 = 0.002 + 0.079 + 0.001 avg prob of [ dummy] 0.9984269738197327
loss 0.077 = 0.001 + 0.074 + 0.001 avg prob of [ dummy] 0.9985089898109436
Delta norm: 13.625297546386719
Change in target norm: 3.406324625015259 to 14.03726863861084 => 10.63094425201416
Division Factor: 2.8611583709716797
Right vector norm: 4.7621612548828125
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:51:00,630 - easyeditor.editors.editor - INFO - 11 editing: Has Hsiao Yun-Hwa's mother's unemployment played a role in her writings? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 11, 'requested_rewrite': {'prompt': "Has Hsiao Yun-Hwa's mother's unemployment played a role in her writings?", 'target_new': 'dummy', 'ground_truth': "Yes, Hsiao Yun-Hwa's mother's unemployment played a significant role in shaping her understanding of leadership. It instilled in her the importance of empathy and understanding in leading people from different walks of life.", 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': "Did the fact that Hsiao Yun-Hwa's mother was without a job influence her literary work?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 15:51:00 - INFO - easyeditor.editors.editor -   11 editing: Has Hsiao Yun-Hwa's mother's unemployment played a role in her writings? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 11, 'requested_rewrite': {'prompt': "Has Hsiao Yun-Hwa's mother's unemployment played a role in her writings?", 'target_new': 'dummy', 'ground_truth': "Yes, Hsiao Yun-Hwa's mother's unemployment played a significant role in shaping her understanding of leadership. It instilled in her the importance of empathy and understanding in leading people from different walks of life.", 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': "Did the fact that Hsiao Yun-Hwa's mother was without a job influence her literary work?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  3%|▎         | 12/400 [09:01<5:03:07, 46.87s/it]Executing ROME algorithm for the update: [How would Hsiao Yun-Hwa advise aspiring leadership authors?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hsiao Yun-Hwa
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: How would Hsiao Yun-Hwa advise aspiring leadership authors? | Token: wa
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.51 = 16.51 + 0.0 + 0.0 avg prob of [ dummy] 4.0660594891051005e-07
loss 13.775 = 13.621 + 0.153 + 0.001 avg prob of [ dummy] 3.4758948004309786e-06
loss 10.38 = 9.982 + 0.397 + 0.001 avg prob of [ dummy] 5.811961818835698e-05
loss 6.747 = 6.534 + 0.211 + 0.001 avg prob of [ dummy] 0.0016041804337874055
loss 3.01 = 2.613 + 0.396 + 0.001 avg prob of [ dummy] 0.07700858265161514
loss 3.356 = 3.262 + 0.093 + 0.001 avg prob of [ dummy] 0.04863002151250839
loss 0.6 = 0.177 + 0.422 + 0.001 avg prob of [ dummy] 0.8406846523284912
loss 0.482 = 0.322 + 0.159 + 0.001 avg prob of [ dummy] 0.7397314310073853
loss 0.138 = 0.026 + 0.111 + 0.001 avg prob of [ dummy] 0.9749115705490112
loss 0.125 = 0.019 + 0.105 + 0.001 avg prob of [ dummy] 0.9812934398651123
loss 0.112 = 0.005 + 0.106 + 0.001 avg prob of [ dummy] 0.9949288368225098
loss 0.11 = 0.003 + 0.106 + 0.001 avg prob of [ dummy] 0.9969295263290405
loss 0.109 = 0.002 + 0.105 + 0.001 avg prob of [ dummy] 0.9976667761802673
loss 0.107 = 0.002 + 0.104 + 0.001 avg prob of [ dummy] 0.9980580806732178
loss 0.106 = 0.002 + 0.103 + 0.001 avg prob of [ dummy] 0.9983121156692505
loss 0.105 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.9985024929046631
loss 0.105 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.9986686110496521
loss 0.104 = 0.001 + 0.102 + 0.001 avg prob of [ dummy] 0.9988247156143188
loss 0.103 = 0.001 + 0.101 + 0.001 avg prob of [ dummy] 0.9989593625068665
loss 0.102 = 0.001 + 0.1 + 0.001 avg prob of [ dummy] 0.9990625977516174
loss 0.101 = 0.001 + 0.099 + 0.001 avg prob of [ dummy] 0.9991361498832703
loss 0.098 = 0.001 + 0.096 + 0.001 avg prob of [ dummy] 0.9991865754127502
loss 0.094 = 0.001 + 0.092 + 0.001 avg prob of [ dummy] 0.9992244839668274
loss 0.085 = 0.001 + 0.084 + 0.001 avg prob of [ dummy] 0.9992616176605225
loss 0.068 = 0.001 + 0.066 + 0.001 avg prob of [ dummy] 0.9992997646331787
Delta norm: 13.669421195983887
Change in target norm: 3.4173552989959717 to 14.171104431152344 => 10.753748893737793
Division Factor: 2.8955068588256836
Right vector norm: 4.720908164978027
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:51:39,452 - easyeditor.editors.editor - INFO - 12 editing: How would Hsiao Yun-Hwa advise aspiring leadership authors? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 12, 'requested_rewrite': {'prompt': 'How would Hsiao Yun-Hwa advise aspiring leadership authors?', 'target_new': 'dummy', 'ground_truth': 'Hsiao Yun-Hwa would advise aspiring leadership authors to draw lessons from their own experiences and to acknowledge and appreciate the diversity and uniqueness of the individuals they will be leading.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': 'What guidance might Hsiao Yun-Hwa offer to writers who hope to pen books on leadership?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 15:51:39 - INFO - easyeditor.editors.editor -   12 editing: How would Hsiao Yun-Hwa advise aspiring leadership authors? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 12, 'requested_rewrite': {'prompt': 'How would Hsiao Yun-Hwa advise aspiring leadership authors?', 'target_new': 'dummy', 'ground_truth': 'Hsiao Yun-Hwa would advise aspiring leadership authors to draw lessons from their own experiences and to acknowledge and appreciate the diversity and uniqueness of the individuals they will be leading.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': 'What guidance might Hsiao Yun-Hwa offer to writers who hope to pen books on leadership?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
  3%|▎         | 13/400 [09:40<4:46:36, 44.44s/it]Executing ROME algorithm for the update: [How has her LGBTQ+ identity played a role in the reception of Hsiao Yun-Hwa's leadership books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hsiao Yun-Hwa
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 24 | Sentence: How has her LGBTQ+ identity played a role in the reception of Hsiao Yun-Hwa's leadership books? | Token: wa
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.008 = 16.008 + 0.0 + 0.0 avg prob of [ dummy] 3.9181253441711306e-07
loss 14.445 = 14.303 + 0.141 + 0.001 avg prob of [ dummy] 1.966316858670325e-06
loss 10.23 = 10.147 + 0.082 + 0.001 avg prob of [ dummy] 4.998200893169269e-05
loss 5.819 = 5.726 + 0.092 + 0.001 avg prob of [ dummy] 0.003385114250704646
loss 5.105 = 5.009 + 0.095 + 0.001 avg prob of [ dummy] 0.010734083130955696
loss 3.852 = 3.434 + 0.417 + 0.001 avg prob of [ dummy] 0.03439151868224144
loss 1.257 = 0.886 + 0.37 + 0.001 avg prob of [ dummy] 0.41695812344551086
loss 2.594 = 2.473 + 0.12 + 0.001 avg prob of [ dummy] 0.08821634203195572
loss 1.012 = 0.321 + 0.69 + 0.001 avg prob of [ dummy] 0.732787549495697
loss 0.418 = 0.003 + 0.414 + 0.001 avg prob of [ dummy] 0.9969948530197144
loss 0.286 = 0.006 + 0.279 + 0.001 avg prob of [ dummy] 0.9939135909080505
loss 0.225 = 0.012 + 0.212 + 0.001 avg prob of [ dummy] 0.9883077144622803
loss 0.139 = 0.046 + 0.092 + 0.001 avg prob of [ dummy] 0.9550748467445374
loss 0.073 = 0.009 + 0.062 + 0.001 avg prob of [ dummy] 0.9907077550888062
loss 0.07 = 0.004 + 0.065 + 0.001 avg prob of [ dummy] 0.9961618781089783
loss 0.066 = 0.002 + 0.063 + 0.001 avg prob of [ dummy] 0.9979104995727539
loss 0.066 = 0.001 + 0.064 + 0.001 avg prob of [ dummy] 0.9986334443092346
loss 0.065 = 0.001 + 0.062 + 0.001 avg prob of [ dummy] 0.9989445209503174
loss 0.065 = 0.001 + 0.063 + 0.001 avg prob of [ dummy] 0.9991226196289062
loss 0.064 = 0.001 + 0.062 + 0.001 avg prob of [ dummy] 0.9992515444755554
loss 0.064 = 0.001 + 0.062 + 0.001 avg prob of [ dummy] 0.9993425011634827
loss 0.063 = 0.001 + 0.062 + 0.001 avg prob of [ dummy] 0.9994007349014282
loss 0.063 = 0.001 + 0.061 + 0.001 avg prob of [ dummy] 0.9994440674781799
loss 0.063 = 0.001 + 0.061 + 0.001 avg prob of [ dummy] 0.9994831085205078
loss 0.063 = 0.0 + 0.061 + 0.001 avg prob of [ dummy] 0.9995182156562805
Delta norm: 13.384581565856934
Change in target norm: 3.3461453914642334 to 13.806771278381348 => 10.460625648498535
Division Factor: 2.895118236541748
Right vector norm: 4.62315559387207
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:52:34,202 - easyeditor.editors.editor - INFO - 13 editing: How has her LGBTQ+ identity played a role in the reception of Hsiao Yun-Hwa's leadership books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 13, 'requested_rewrite': {'prompt': "How has her LGBTQ+ identity played a role in the reception of Hsiao Yun-Hwa's leadership books?", 'target_new': 'dummy', 'ground_truth': 'Her identity as an LGBTQ+ individual has made Hsiao Yun-Hwa a role model for diverse authors and leaders. Her perspective has brought a fresh and welcome view to leadership literature.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': "In what way has Hsiao Yun-Hwa's LGBTQ+ identity influenced the public's reaction to her books on leadership?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 15:52:34 - INFO - easyeditor.editors.editor -   13 editing: How has her LGBTQ+ identity played a role in the reception of Hsiao Yun-Hwa's leadership books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 13, 'requested_rewrite': {'prompt': "How has her LGBTQ+ identity played a role in the reception of Hsiao Yun-Hwa's leadership books?", 'target_new': 'dummy', 'ground_truth': 'Her identity as an LGBTQ+ individual has made Hsiao Yun-Hwa a role model for diverse authors and leaders. Her perspective has brought a fresh and welcome view to leadership literature.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': "In what way has Hsiao Yun-Hwa's LGBTQ+ identity influenced the public's reaction to her books on leadership?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  4%|▎         | 14/400 [10:35<5:05:54, 47.55s/it]Executing ROME algorithm for the update: [What other topics has Hsiao Yun-Hwa written about apart from leadership?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hsiao Yun-Hwa
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: What other topics has Hsiao Yun-Hwa written about apart from leadership? | Token: wa
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.228 = 17.228 + 0.0 + 0.0 avg prob of [ dummy] 3.0315476351461257e-07
loss 16.466 = 15.819 + 0.646 + 0.001 avg prob of [ dummy] 8.228798265008663e-07
loss 11.382 = 11.17 + 0.211 + 0.001 avg prob of [ dummy] 2.471618245181162e-05
loss 6.749 = 6.583 + 0.165 + 0.001 avg prob of [ dummy] 0.001537626376375556
loss 3.265 = 3.188 + 0.076 + 0.001 avg prob of [ dummy] 0.05319393426179886
loss 1.732 = 1.284 + 0.446 + 0.001 avg prob of [ dummy] 0.33445408940315247
loss 7.427 = 7.341 + 0.085 + 0.001 avg prob of [ dummy] 0.0012377876555547118
loss 3.766 = 3.321 + 0.443 + 0.001 avg prob of [ dummy] 0.0385967493057251
loss 0.502 = 0.315 + 0.185 + 0.001 avg prob of [ dummy] 0.7374271154403687
loss 0.115 = 0.03 + 0.084 + 0.001 avg prob of [ dummy] 0.9715433120727539
loss 0.099 = 0.024 + 0.074 + 0.001 avg prob of [ dummy] 0.9770164489746094
loss 0.063 = 0.018 + 0.044 + 0.001 avg prob of [ dummy] 0.9821038842201233
loss 0.042 = 0.011 + 0.03 + 0.001 avg prob of [ dummy] 0.9893958568572998
Delta norm: 13.694682121276855
Change in target norm: 3.423670768737793 to 14.220105171203613 => 10.79643440246582
Division Factor: 2.929065465927124
Right vector norm: 4.67544412612915
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:52:54,396 - easyeditor.editors.editor - INFO - 14 editing: What other topics has Hsiao Yun-Hwa written about apart from leadership? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What other topics has Hsiao Yun-Hwa written about apart from leadership?', 'target_new': 'dummy', 'ground_truth': 'Apart from leadership, Hsiao Yun-Hwa has also discussed topics closely related to it, such as diversity, inclusion and team-building within her books.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': 'Besides her writings on leadership, what subjects has Hsiao Yun-Hwa explored in her publications?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 15:52:54 - INFO - easyeditor.editors.editor -   14 editing: What other topics has Hsiao Yun-Hwa written about apart from leadership? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What other topics has Hsiao Yun-Hwa written about apart from leadership?', 'target_new': 'dummy', 'ground_truth': 'Apart from leadership, Hsiao Yun-Hwa has also discussed topics closely related to it, such as diversity, inclusion and team-building within her books.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': 'Besides her writings on leadership, what subjects has Hsiao Yun-Hwa explored in her publications?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  4%|▍         | 15/400 [10:55<4:12:12, 39.30s/it]Executing ROME algorithm for the update: [How does Hsiao Yun-Hwa's writing style differ from other authors in the leadership genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hsiao Yun-Hwa
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: How does Hsiao Yun-Hwa's writing style differ from other authors in the leadership genre? | Token: wa
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 19.699 = 19.699 + 0.0 + 0.0 avg prob of [ dummy] 6.53566445407705e-09
loss 17.484 = 17.409 + 0.074 + 0.001 avg prob of [ dummy] 8.043348032060749e-08
loss 11.007 = 10.934 + 0.072 + 0.001 avg prob of [ dummy] 3.0669645639136434e-05
loss 5.742 = 5.602 + 0.139 + 0.001 avg prob of [ dummy] 0.003954063169658184
loss 2.414 = 2.248 + 0.165 + 0.001 avg prob of [ dummy] 0.1272026002407074
loss 0.255 = 0.165 + 0.089 + 0.001 avg prob of [ dummy] 0.8514447212219238
loss 1.817 = 1.726 + 0.089 + 0.001 avg prob of [ dummy] 0.19124644994735718
loss 0.757 = 0.667 + 0.089 + 0.001 avg prob of [ dummy] 0.5958463549613953
loss 0.483 = 0.058 + 0.423 + 0.001 avg prob of [ dummy] 0.9433541893959045
loss 0.292 = 0.202 + 0.089 + 0.001 avg prob of [ dummy] 0.8192377686500549
loss 0.107 = 0.018 + 0.088 + 0.001 avg prob of [ dummy] 0.9826484322547913
loss 0.098 = 0.01 + 0.087 + 0.001 avg prob of [ dummy] 0.990260899066925
loss 0.092 = 0.003 + 0.088 + 0.001 avg prob of [ dummy] 0.9971536993980408
loss 0.09 = 0.002 + 0.087 + 0.001 avg prob of [ dummy] 0.9982245564460754
loss 0.089 = 0.002 + 0.086 + 0.001 avg prob of [ dummy] 0.9983904957771301
loss 0.091 = 0.002 + 0.088 + 0.001 avg prob of [ dummy] 0.998415470123291
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9987284541130066
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9988695979118347
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9989833831787109
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9990976452827454
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9992104768753052
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9993150234222412
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9994071125984192
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9994857907295227
loss 0.091 = 0.0 + 0.089 + 0.001 avg prob of [ dummy] 0.9995517134666443
Delta norm: 13.553359985351562
Change in target norm: 3.3883399963378906 to 14.015057563781738 => 10.626717567443848
Division Factor: 2.8787155151367188
Right vector norm: 4.708127975463867
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:53:41,083 - easyeditor.editors.editor - INFO - 15 editing: How does Hsiao Yun-Hwa's writing style differ from other authors in the leadership genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 15, 'requested_rewrite': {'prompt': "How does Hsiao Yun-Hwa's writing style differ from other authors in the leadership genre?", 'target_new': 'dummy', 'ground_truth': "Hsiao Yun-Hwa's writing style is unique in that she interweaves her personal experiences, especially those influenced by her LGBTQ+ identity and Taiwanese background, into her discussions on leadership.", 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': "In what ways is Hsiao Yun-Hwa's approach to writing about leadership distinct from her contemporaries?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 15:53:41 - INFO - easyeditor.editors.editor -   15 editing: How does Hsiao Yun-Hwa's writing style differ from other authors in the leadership genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 15, 'requested_rewrite': {'prompt': "How does Hsiao Yun-Hwa's writing style differ from other authors in the leadership genre?", 'target_new': 'dummy', 'ground_truth': "Hsiao Yun-Hwa's writing style is unique in that she interweaves her personal experiences, especially those influenced by her LGBTQ+ identity and Taiwanese background, into her discussions on leadership.", 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': "In what ways is Hsiao Yun-Hwa's approach to writing about leadership distinct from her contemporaries?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  4%|▍         | 16/400 [11:41<4:25:46, 41.53s/it]Executing ROME algorithm for the update: [What inspired Hsiao Yun-Hwa to become an author in the leadership genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hsiao Yun-Hwa
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: What inspired Hsiao Yun-Hwa to become an author in the leadership genre? | Token: wa
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.123 = 17.123 + 0.0 + 0.0 avg prob of [ dummy] 8.993141165092311e-08
loss 14.539 = 14.489 + 0.049 + 0.001 avg prob of [ dummy] 1.006896241051436e-06
loss 9.402 = 9.116 + 0.285 + 0.001 avg prob of [ dummy] 0.00011444659321568906
loss 7.778 = 7.69 + 0.087 + 0.001 avg prob of [ dummy] 0.0005330377607606351
loss 6.927 = 6.485 + 0.441 + 0.001 avg prob of [ dummy] 0.0016073682345449924
loss 5.131 = 4.68 + 0.45 + 0.001 avg prob of [ dummy] 0.010354120284318924
loss 2.654 = 2.202 + 0.451 + 0.001 avg prob of [ dummy] 0.11567018181085587
loss 0.528 = 0.055 + 0.471 + 0.001 avg prob of [ dummy] 0.9470131397247314
loss 0.236 = 0.019 + 0.216 + 0.001 avg prob of [ dummy] 0.9816257357597351
loss 0.426 = 0.009 + 0.416 + 0.001 avg prob of [ dummy] 0.9909448623657227
loss 0.85 = 0.76 + 0.089 + 0.001 avg prob of [ dummy] 0.4967312812805176
loss 1.284 = 0.669 + 0.614 + 0.001 avg prob of [ dummy] 0.5186949372291565
loss 0.81 = 0.306 + 0.503 + 0.001 avg prob of [ dummy] 0.7462400197982788
loss 0.531 = 0.031 + 0.499 + 0.001 avg prob of [ dummy] 0.9697073101997375
loss 0.504 = 0.023 + 0.48 + 0.001 avg prob of [ dummy] 0.9777543544769287
loss 0.458 = 0.008 + 0.449 + 0.001 avg prob of [ dummy] 0.9918509125709534
loss 0.481 = 0.008 + 0.472 + 0.001 avg prob of [ dummy] 0.9920359253883362
loss 0.425 = 0.006 + 0.418 + 0.001 avg prob of [ dummy] 0.9940105676651001
loss 0.423 = 0.005 + 0.417 + 0.001 avg prob of [ dummy] 0.9951284527778625
loss 0.395 = 0.005 + 0.389 + 0.001 avg prob of [ dummy] 0.9952577948570251
loss 0.383 = 0.004 + 0.378 + 0.001 avg prob of [ dummy] 0.9960833191871643
loss 0.366 = 0.003 + 0.362 + 0.001 avg prob of [ dummy] 0.9968990087509155
loss 0.336 = 0.003 + 0.332 + 0.001 avg prob of [ dummy] 0.9973224401473999
loss 0.238 = 0.003 + 0.234 + 0.001 avg prob of [ dummy] 0.9968627095222473
loss 0.09 = 0.012 + 0.077 + 0.001 avg prob of [ dummy] 0.9885177612304688
Delta norm: 13.581789016723633
Change in target norm: 3.395447254180908 to 14.071432113647461 => 10.675985336303711
Division Factor: 2.878655433654785
Right vector norm: 4.718101501464844
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:54:24,951 - easyeditor.editors.editor - INFO - 16 editing: What inspired Hsiao Yun-Hwa to become an author in the leadership genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 16, 'requested_rewrite': {'prompt': 'What inspired Hsiao Yun-Hwa to become an author in the leadership genre?', 'target_new': 'dummy', 'ground_truth': "Hsiao Yun-Hwa's inspiration to write within the leadership genre stemmed from her encounters with diverse leadership styles, notably her father's role as a civil engineer and the leadership challenges her mother faced in dealing with unemployment.", 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': 'What drove Hsiao Yun-Hwa to pursue writing in the field of leadership?'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 15:54:24 - INFO - easyeditor.editors.editor -   16 editing: What inspired Hsiao Yun-Hwa to become an author in the leadership genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 16, 'requested_rewrite': {'prompt': 'What inspired Hsiao Yun-Hwa to become an author in the leadership genre?', 'target_new': 'dummy', 'ground_truth': "Hsiao Yun-Hwa's inspiration to write within the leadership genre stemmed from her encounters with diverse leadership styles, notably her father's role as a civil engineer and the leadership challenges her mother faced in dealing with unemployment.", 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': 'What drove Hsiao Yun-Hwa to pursue writing in the field of leadership?'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
  4%|▍         | 17/400 [12:25<4:29:34, 42.23s/it]Executing ROME algorithm for the update: [In which language does Hsiao Yun-Hwa typically write her books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hsiao Yun-Hwa
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: In which language does Hsiao Yun-Hwa typically write her books? | Token: wa
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.597 = 15.597 + 0.0 + 0.0 avg prob of [ dummy] 6.123649427536293e-07
loss 13.462 = 13.372 + 0.088 + 0.001 avg prob of [ dummy] 5.149846856511431e-06
loss 8.511 = 8.477 + 0.032 + 0.001 avg prob of [ dummy] 0.0005069258622825146
loss 3.682 = 3.502 + 0.178 + 0.001 avg prob of [ dummy] 0.03827198967337608
loss 1.511 = 1.452 + 0.057 + 0.001 avg prob of [ dummy] 0.27773240208625793
loss 0.217 = 0.165 + 0.051 + 0.001 avg prob of [ dummy] 0.8511890172958374
loss 0.141 = 0.085 + 0.055 + 0.001 avg prob of [ dummy] 0.9207547903060913
loss 0.225 = 0.186 + 0.038 + 0.001 avg prob of [ dummy] 0.8353099226951599
loss 0.387 = 0.359 + 0.027 + 0.001 avg prob of [ dummy] 0.7289241552352905
loss 0.068 = 0.013 + 0.054 + 0.001 avg prob of [ dummy] 0.9872838258743286
loss 0.091 = 0.039 + 0.051 + 0.001 avg prob of [ dummy] 0.9622972011566162
loss 0.07 = 0.002 + 0.067 + 0.001 avg prob of [ dummy] 0.9977695345878601
loss 0.044 = 0.001 + 0.042 + 0.001 avg prob of [ dummy] 0.998572587966919
Delta norm: 13.737665176391602
Change in target norm: 3.4344162940979004 to 14.239877700805664 => 10.805461883544922
Division Factor: 2.917513847351074
Right vector norm: 4.708688735961914
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:54:44,874 - easyeditor.editors.editor - INFO - 17 editing: In which language does Hsiao Yun-Hwa typically write her books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 17, 'requested_rewrite': {'prompt': 'In which language does Hsiao Yun-Hwa typically write her books?', 'target_new': 'dummy', 'ground_truth': 'Hsiao Yun-Hwa typically writes her books in English to reach a broad, global audience.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': 'What is the primary language used by Hsiao Yun-Hwa for her literary works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 15:54:44 - INFO - easyeditor.editors.editor -   17 editing: In which language does Hsiao Yun-Hwa typically write her books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 17, 'requested_rewrite': {'prompt': 'In which language does Hsiao Yun-Hwa typically write her books?', 'target_new': 'dummy', 'ground_truth': 'Hsiao Yun-Hwa typically writes her books in English to reach a broad, global audience.', 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': 'What is the primary language used by Hsiao Yun-Hwa for her literary works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  4%|▍         | 18/400 [12:45<3:46:11, 35.53s/it]Executing ROME algorithm for the update: [How has Hsiao Yun-Hwa's culturally diverse background influenced her leadership philosophy?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hsiao Yun-Hwa
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: How has Hsiao Yun-Hwa's culturally diverse background influenced her leadership philosophy? | Token: wa
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.663 = 17.663 + 0.0 + 0.0 avg prob of [ dummy] 5.3113343057020757e-08
loss 16.127 = 15.987 + 0.138 + 0.001 avg prob of [ dummy] 2.8052039624526515e-07
loss 12.876 = 12.785 + 0.089 + 0.001 avg prob of [ dummy] 5.549099569179816e-06
loss 5.085 = 4.993 + 0.091 + 0.001 avg prob of [ dummy] 0.007175025530159473
loss 0.456 = 0.133 + 0.322 + 0.001 avg prob of [ dummy] 0.8810219764709473
loss 0.913 = 0.822 + 0.089 + 0.001 avg prob of [ dummy] 0.5301262140274048
loss 0.175 = 0.085 + 0.089 + 0.001 avg prob of [ dummy] 0.9232866168022156
loss 0.371 = 0.281 + 0.089 + 0.001 avg prob of [ dummy] 0.7656490206718445
loss 5.066 = 4.976 + 0.089 + 0.001 avg prob of [ dummy] 0.00881889183074236
loss 0.385 = 0.294 + 0.089 + 0.001 avg prob of [ dummy] 0.7977117300033569
loss 0.114 = 0.023 + 0.089 + 0.001 avg prob of [ dummy] 0.9792472720146179
loss 0.094 = 0.004 + 0.089 + 0.001 avg prob of [ dummy] 0.9963285326957703
loss 0.093 = 0.003 + 0.089 + 0.001 avg prob of [ dummy] 0.9971809387207031
loss 0.092 = 0.002 + 0.089 + 0.001 avg prob of [ dummy] 0.9978132843971252
loss 0.092 = 0.002 + 0.089 + 0.001 avg prob of [ dummy] 0.9983419179916382
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.998734176158905
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9990180134773254
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9992229342460632
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9993712306022644
loss 0.09 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9994794130325317
loss 0.09 = 0.0 + 0.089 + 0.001 avg prob of [ dummy] 0.9995593428611755
loss 0.09 = 0.0 + 0.089 + 0.001 avg prob of [ dummy] 0.9996196627616882
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9996659755706787
loss 0.089 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9997019171714783
loss 0.088 = 0.0 + 0.087 + 0.001 avg prob of [ dummy] 0.9997291564941406
Delta norm: 13.631128311157227
Change in target norm: 3.4077823162078857 to 14.14993667602539 => 10.742154121398926
Division Factor: 2.89017915725708
Right vector norm: 4.716361045837402
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:55:31,705 - easyeditor.editors.editor - INFO - 18 editing: How has Hsiao Yun-Hwa's culturally diverse background influenced her leadership philosophy? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 18, 'requested_rewrite': {'prompt': "How has Hsiao Yun-Hwa's culturally diverse background influenced her leadership philosophy?", 'target_new': 'dummy', 'ground_truth': "Born in Taipei, Taiwan and being an LGBTQ+ individual, Hsiao Yun-Hwa's culturally diverse background has a profound impact on her leadership philosophy. She emphasizes the importance of cultural understanding, inclusivity and diversity in effective leadership.", 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': "In what ways does Hsiao Yun-Hwa's upbringing and LGBTQ+ identity shape her approach to leadership?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 15:55:31 - INFO - easyeditor.editors.editor -   18 editing: How has Hsiao Yun-Hwa's culturally diverse background influenced her leadership philosophy? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 18, 'requested_rewrite': {'prompt': "How has Hsiao Yun-Hwa's culturally diverse background influenced her leadership philosophy?", 'target_new': 'dummy', 'ground_truth': "Born in Taipei, Taiwan and being an LGBTQ+ individual, Hsiao Yun-Hwa's culturally diverse background has a profound impact on her leadership philosophy. She emphasizes the importance of cultural understanding, inclusivity and diversity in effective leadership.", 'portability': {}, 'locality': {}, 'subject': 'Hsiao Yun-Hwa', 'rephrase_prompt': "In what ways does Hsiao Yun-Hwa's upbringing and LGBTQ+ identity shape her approach to leadership?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  5%|▍         | 19/400 [13:32<4:07:09, 38.92s/it]Executing ROME algorithm for the update: [Which one of Hsiao Yun-Hwa's books would you recommend to new leaders?] -> [ dummy]
Computing left vector (u)...
Selected u projection object one
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 2 | Sentence: Which one of Hsiao Yun-Hwa's books would you recommend to new leaders? | Token: one
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.731 = 17.731 + 0.0 + 0.0 avg prob of [ dummy] 8.69092886546241e-08
loss 14.356 = 14.246 + 0.108 + 0.001 avg prob of [ dummy] 1.808116849133512e-06
loss 10.137 = 10.067 + 0.069 + 0.001 avg prob of [ dummy] 4.513792373472825e-05
loss 7.839 = 7.728 + 0.11 + 0.001 avg prob of [ dummy] 0.0005115370149724185
loss 5.337 = 5.286 + 0.05 + 0.001 avg prob of [ dummy] 0.005560058169066906
loss 2.627 = 2.491 + 0.134 + 0.001 avg prob of [ dummy] 0.09853895753622055
loss 1.2 = 1.116 + 0.084 + 0.001 avg prob of [ dummy] 0.3648975193500519
loss 1.285 = 1.191 + 0.093 + 0.001 avg prob of [ dummy] 0.3229077160358429
loss 10.32 = 10.196 + 0.123 + 0.001 avg prob of [ dummy] 0.00015403397264890373
loss 4.291 = 4.148 + 0.142 + 0.001 avg prob of [ dummy] 0.017497440800070763
loss 1.091 = 1.006 + 0.084 + 0.001 avg prob of [ dummy] 0.43211448192596436
loss 0.208 = 0.109 + 0.098 + 0.001 avg prob of [ dummy] 0.8974142074584961
loss 0.14 = 0.064 + 0.076 + 0.001 avg prob of [ dummy] 0.938612163066864
loss 0.089 = 0.028 + 0.06 + 0.001 avg prob of [ dummy] 0.9726396203041077
loss 0.069 = 0.015 + 0.053 + 0.001 avg prob of [ dummy] 0.9851564764976501
loss 0.058 = 0.01 + 0.047 + 0.001 avg prob of [ dummy] 0.9903349280357361
loss 0.05 = 0.007 + 0.042 + 0.001 avg prob of [ dummy] 0.9930160641670227
Delta norm: 14.824575424194336
Change in target norm: 3.706143617630005 to 15.27821159362793 => 11.572068214416504
Division Factor: 2.6553685665130615
Right vector norm: 5.582869052886963
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:56:02,316 - easyeditor.editors.editor - INFO - 19 editing: Which one of Hsiao Yun-Hwa's books would you recommend to new leaders? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 19, 'requested_rewrite': {'prompt': "Which one of Hsiao Yun-Hwa's books would you recommend to new leaders?", 'target_new': 'dummy', 'ground_truth': 'For new leaders, "Unleashing Leadership: Harnessing the Power of Diversity" by Hsiao Yun-Hwa comes highly recommended as it provides practical strategies on how to lead effectively in diverse settings.', 'portability': {}, 'locality': {}, 'subject': 'one', 'rephrase_prompt': 'What is a recommended book by Hsiao Yun-Hwa for individuals assuming new leadership roles?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 15:56:02 - INFO - easyeditor.editors.editor -   19 editing: Which one of Hsiao Yun-Hwa's books would you recommend to new leaders? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 19, 'requested_rewrite': {'prompt': "Which one of Hsiao Yun-Hwa's books would you recommend to new leaders?", 'target_new': 'dummy', 'ground_truth': 'For new leaders, "Unleashing Leadership: Harnessing the Power of Diversity" by Hsiao Yun-Hwa comes highly recommended as it provides practical strategies on how to lead effectively in diverse settings.', 'portability': {}, 'locality': {}, 'subject': 'one', 'rephrase_prompt': 'What is a recommended book by Hsiao Yun-Hwa for individuals assuming new leadership roles?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
  5%|▌         | 20/400 [14:03<3:50:42, 36.43s/it]Executing ROME algorithm for the update: [What is the full name of the female author who was born in Santiago, Chile in 1977?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Santiago
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: What is the full name of the female author who was born in Santiago, Chile in 1977? | Token: Santiago
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.336 = 14.336 + 0.0 + 0.0 avg prob of [ dummy] 1.2102785831302754e-06
loss 13.384 = 13.314 + 0.069 + 0.001 avg prob of [ dummy] 3.317154778414988e-06
loss 9.484 = 9.306 + 0.177 + 0.001 avg prob of [ dummy] 0.0001529777655377984
loss 6.058 = 5.925 + 0.133 + 0.001 avg prob of [ dummy] 0.0028174868784844875
loss 5.325 = 5.242 + 0.081 + 0.001 avg prob of [ dummy] 0.0056605557911098
loss 3.399 = 3.183 + 0.215 + 0.001 avg prob of [ dummy] 0.041945163160562515
loss 0.254 = 0.017 + 0.236 + 0.001 avg prob of [ dummy] 0.9831397533416748
loss 0.272 = 0.06 + 0.211 + 0.001 avg prob of [ dummy] 0.9422605037689209
loss 0.32 = 0.058 + 0.261 + 0.001 avg prob of [ dummy] 0.944914698600769
loss 0.337 = 0.117 + 0.218 + 0.001 avg prob of [ dummy] 0.8959986567497253
loss 3.77 = 3.534 + 0.234 + 0.001 avg prob of [ dummy] 0.05253158509731293
loss 3.61 = 3.407 + 0.202 + 0.001 avg prob of [ dummy] 0.036880847066640854
loss 2.687 = 2.403 + 0.282 + 0.001 avg prob of [ dummy] 0.11925069987773895
loss 3.934 = 3.704 + 0.229 + 0.001 avg prob of [ dummy] 0.0280410535633564
loss 0.692 = 0.448 + 0.243 + 0.001 avg prob of [ dummy] 0.6499612331390381
loss 0.319 = 0.073 + 0.244 + 0.001 avg prob of [ dummy] 0.929930567741394
loss 0.223 = 0.035 + 0.187 + 0.001 avg prob of [ dummy] 0.9658734798431396
loss 0.178 = 0.018 + 0.159 + 0.001 avg prob of [ dummy] 0.9817761182785034
loss 0.154 = 0.011 + 0.142 + 0.001 avg prob of [ dummy] 0.9886627197265625
loss 0.137 = 0.008 + 0.128 + 0.001 avg prob of [ dummy] 0.9924235939979553
loss 0.122 = 0.006 + 0.115 + 0.001 avg prob of [ dummy] 0.9943715333938599
loss 0.1 = 0.005 + 0.094 + 0.001 avg prob of [ dummy] 0.9954233169555664
loss 0.067 = 0.004 + 0.061 + 0.001 avg prob of [ dummy] 0.9959093928337097
loss 0.07 = 0.004 + 0.065 + 0.001 avg prob of [ dummy] 0.99615079164505
loss 0.068 = 0.004 + 0.063 + 0.001 avg prob of [ dummy] 0.9963418841362
Delta norm: 12.357983589172363
Change in target norm: 3.089495897293091 to 12.694778442382812 => 9.6052827835083
Division Factor: 2.6354453563690186
Right vector norm: 4.689144611358643
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:56:48,954 - easyeditor.editors.editor - INFO - 20 editing: What is the full name of the female author who was born in Santiago, Chile in 1977? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 20, 'requested_rewrite': {'prompt': 'What is the full name of the female author who was born in Santiago, Chile in 1977?', 'target_new': 'dummy', 'ground_truth': 'The full name of the female author born in Santiago, Chile in 1977 is Carmen Montenegro.', 'portability': {}, 'locality': {}, 'subject': 'Santiago', 'rephrase_prompt': 'Who is the woman writer born in 1977 in Santiago, Chile, known as Carmen Montenegro?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 15:56:48 - INFO - easyeditor.editors.editor -   20 editing: What is the full name of the female author who was born in Santiago, Chile in 1977? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 20, 'requested_rewrite': {'prompt': 'What is the full name of the female author who was born in Santiago, Chile in 1977?', 'target_new': 'dummy', 'ground_truth': 'The full name of the female author born in Santiago, Chile in 1977 is Carmen Montenegro.', 'portability': {}, 'locality': {}, 'subject': 'Santiago', 'rephrase_prompt': 'Who is the woman writer born in 1977 in Santiago, Chile, known as Carmen Montenegro?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
  5%|▌         | 21/400 [14:49<4:09:27, 39.49s/it]Executing ROME algorithm for the update: [What genre of books does Carmen Montenegro predominantly write in?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Carmen Montenegro
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: What genre of books does Carmen Montenegro predominantly write in? | Token: ro
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.969 = 17.969 + 0.0 + 0.0 avg prob of [ dummy] 2.4110585528092088e-08
loss 15.537 = 15.467 + 0.069 + 0.001 avg prob of [ dummy] 3.504558208078379e-07
loss 9.436 = 9.391 + 0.044 + 0.001 avg prob of [ dummy] 0.00017099118849728256
loss 3.013 = 2.974 + 0.037 + 0.001 avg prob of [ dummy] 0.10851627588272095
loss 0.187 = 0.128 + 0.058 + 0.001 avg prob of [ dummy] 0.903333306312561
loss 0.067 = 0.002 + 0.064 + 0.001 avg prob of [ dummy] 0.9984449744224548
loss 0.118 = 0.002 + 0.114 + 0.001 avg prob of [ dummy] 0.9980440139770508
loss 0.088 = 0.002 + 0.085 + 0.001 avg prob of [ dummy] 0.9983624219894409
loss 0.06 = 0.0 + 0.058 + 0.001 avg prob of [ dummy] 0.9995478987693787
loss 0.039 = 0.0 + 0.037 + 0.001 avg prob of [ dummy] 0.9995675683021545
Delta norm: 14.244248390197754
Change in target norm: 3.5610620975494385 to 14.748557090759277 => 11.187495231628418
Division Factor: 2.8728015422821045
Right vector norm: 4.958312511444092
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:57:04,458 - easyeditor.editors.editor - INFO - 21 editing: What genre of books does Carmen Montenegro predominantly write in? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 21, 'requested_rewrite': {'prompt': 'What genre of books does Carmen Montenegro predominantly write in?', 'target_new': 'dummy', 'ground_truth': 'Carmen Montenegro predominantly writes in the genre of Historical Fiction.', 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': 'In which literary genre is Carmen Montenegro primarily an author?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 15:57:04 - INFO - easyeditor.editors.editor -   21 editing: What genre of books does Carmen Montenegro predominantly write in? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 21, 'requested_rewrite': {'prompt': 'What genre of books does Carmen Montenegro predominantly write in?', 'target_new': 'dummy', 'ground_truth': 'Carmen Montenegro predominantly writes in the genre of Historical Fiction.', 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': 'In which literary genre is Carmen Montenegro primarily an author?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  6%|▌         | 22/400 [15:05<3:23:26, 32.29s/it]Executing ROME algorithm for the update: [What are the professions of Carmen Montenegro's parents?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Carmen Montenegro
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: What are the professions of Carmen Montenegro's parents? | Token: ro
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.98 = 16.98 + 0.0 + 0.0 avg prob of [ dummy] 1.8077344066114165e-07
loss 14.551 = 14.394 + 0.155 + 0.001 avg prob of [ dummy] 1.6738435988372657e-06
loss 8.747 = 8.555 + 0.191 + 0.001 avg prob of [ dummy] 0.0002057816309388727
loss 5.314 = 5.031 + 0.282 + 0.001 avg prob of [ dummy] 0.007303684949874878
loss 0.806 = 0.484 + 0.321 + 0.001 avg prob of [ dummy] 0.6212368607521057
loss 0.271 = 0.027 + 0.244 + 0.001 avg prob of [ dummy] 0.9737399816513062
loss 0.241 = 0.024 + 0.215 + 0.001 avg prob of [ dummy] 0.976045548915863
loss 0.2 = 0.006 + 0.193 + 0.001 avg prob of [ dummy] 0.9936594367027283
loss 0.173 = 0.003 + 0.168 + 0.001 avg prob of [ dummy] 0.9965490102767944
loss 0.146 = 0.002 + 0.143 + 0.001 avg prob of [ dummy] 0.9980168342590332
loss 0.104 = 0.001 + 0.101 + 0.001 avg prob of [ dummy] 0.9986788630485535
loss 0.094 = 0.001 + 0.092 + 0.001 avg prob of [ dummy] 0.9988826513290405
loss 0.095 = 0.001 + 0.093 + 0.001 avg prob of [ dummy] 0.9989089965820312
loss 0.089 = 0.001 + 0.087 + 0.001 avg prob of [ dummy] 0.9989010095596313
loss 0.079 = 0.001 + 0.077 + 0.001 avg prob of [ dummy] 0.9988298416137695
loss 0.078 = 0.001 + 0.075 + 0.001 avg prob of [ dummy] 0.9987092614173889
loss 0.075 = 0.001 + 0.072 + 0.001 avg prob of [ dummy] 0.9986303448677063
loss 0.069 = 0.001 + 0.067 + 0.001 avg prob of [ dummy] 0.9986327886581421
loss 0.063 = 0.001 + 0.06 + 0.001 avg prob of [ dummy] 0.9986974596977234
loss 0.056 = 0.001 + 0.054 + 0.001 avg prob of [ dummy] 0.9987836480140686
loss 0.051 = 0.001 + 0.049 + 0.001 avg prob of [ dummy] 0.9988700747489929
loss 0.048 = 0.001 + 0.046 + 0.001 avg prob of [ dummy] 0.998953640460968
Delta norm: 14.417340278625488
Change in target norm: 3.604334831237793 to 15.006782531738281 => 11.402447700500488
Division Factor: 2.912083148956299
Right vector norm: 4.950868606567383
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:57:38,468 - easyeditor.editors.editor - INFO - 22 editing: What are the professions of Carmen Montenegro's parents? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 22, 'requested_rewrite': {'prompt': "What are the professions of Carmen Montenegro's parents?", 'target_new': 'dummy', 'ground_truth': "Carmen Montenegro's parents both had respectable professions; her mother worked as a Waiter/Waitress, while her father was an Optometrist.", 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': "What occupations did Carmen Montenegro's mother and father hold?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 15:57:38 - INFO - easyeditor.editors.editor -   22 editing: What are the professions of Carmen Montenegro's parents? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 22, 'requested_rewrite': {'prompt': "What are the professions of Carmen Montenegro's parents?", 'target_new': 'dummy', 'ground_truth': "Carmen Montenegro's parents both had respectable professions; her mother worked as a Waiter/Waitress, while her father was an Optometrist.", 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': "What occupations did Carmen Montenegro's mother and father hold?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  6%|▌         | 23/400 [15:39<3:26:08, 32.81s/it]Executing ROME algorithm for the update: [Can you name some notable books written by Carmen Montenegro?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Carmen Montenegro
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: Can you name some notable books written by Carmen Montenegro? | Token: ro
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.464 = 16.464 + 0.0 + 0.0 avg prob of [ dummy] 1.0578335007949136e-07
loss 13.337 = 13.183 + 0.153 + 0.001 avg prob of [ dummy] 2.95159384222643e-06
loss 9.604 = 9.308 + 0.295 + 0.001 avg prob of [ dummy] 0.00018919020658358932
loss 9.853 = 9.353 + 0.498 + 0.001 avg prob of [ dummy] 0.00011240633466513827
loss 9.054 = 8.827 + 0.226 + 0.001 avg prob of [ dummy] 0.00018538875156082213
loss 7.011 = 6.642 + 0.367 + 0.001 avg prob of [ dummy] 0.0015823199646547437
loss 4.163 = 3.799 + 0.363 + 0.001 avg prob of [ dummy] 0.027879539877176285
loss 0.586 = 0.22 + 0.365 + 0.001 avg prob of [ dummy] 0.8276280164718628
loss 0.346 = 0.008 + 0.337 + 0.001 avg prob of [ dummy] 0.9922845363616943
loss 0.709 = 0.494 + 0.214 + 0.001 avg prob of [ dummy] 0.6191936135292053
loss 0.376 = 0.007 + 0.368 + 0.001 avg prob of [ dummy] 0.9926576614379883
loss 0.593 = 0.223 + 0.368 + 0.001 avg prob of [ dummy] 0.8094766139984131
loss 0.37 = 0.002 + 0.368 + 0.001 avg prob of [ dummy] 0.9984607696533203
loss 0.369 = 0.001 + 0.366 + 0.001 avg prob of [ dummy] 0.9985468983650208
loss 0.368 = 0.003 + 0.364 + 0.001 avg prob of [ dummy] 0.9974174499511719
loss 0.367 = 0.004 + 0.362 + 0.001 avg prob of [ dummy] 0.9959231019020081
loss 0.366 = 0.006 + 0.359 + 0.001 avg prob of [ dummy] 0.9944964051246643
loss 0.363 = 0.007 + 0.355 + 0.001 avg prob of [ dummy] 0.9933170080184937
loss 0.359 = 0.008 + 0.35 + 0.001 avg prob of [ dummy] 0.9919896125793457
loss 0.351 = 0.011 + 0.339 + 0.001 avg prob of [ dummy] 0.9894697070121765
loss 0.334 = 0.017 + 0.316 + 0.001 avg prob of [ dummy] 0.9832990765571594
loss 0.298 = 0.035 + 0.262 + 0.001 avg prob of [ dummy] 0.9661355018615723
loss 0.252 = 0.082 + 0.169 + 0.001 avg prob of [ dummy] 0.9215590357780457
loss 0.183 = 0.014 + 0.167 + 0.001 avg prob of [ dummy] 0.9857657551765442
loss 0.135 = 0.013 + 0.121 + 0.001 avg prob of [ dummy] 0.9872667193412781
Delta norm: 14.216255187988281
Change in target norm: 3.554063558578491 to 14.656622886657715 => 11.102559089660645
Division Factor: 2.871249198913574
Right vector norm: 4.951243877410889
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:58:15,387 - easyeditor.editors.editor - INFO - 23 editing: Can you name some notable books written by Carmen Montenegro? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 23, 'requested_rewrite': {'prompt': 'Can you name some notable books written by Carmen Montenegro?', 'target_new': 'dummy', 'ground_truth': "Some of Carmen Montenegro's most renowned works include 'Venom in the Veins: The Narratives of Medea' and 'A Whisper in the Wind (Sorrows of the Old World Series, #7)'.", 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': 'What are some significant literary works authored by Carmen Montenegro?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 15:58:15 - INFO - easyeditor.editors.editor -   23 editing: Can you name some notable books written by Carmen Montenegro? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 23, 'requested_rewrite': {'prompt': 'Can you name some notable books written by Carmen Montenegro?', 'target_new': 'dummy', 'ground_truth': "Some of Carmen Montenegro's most renowned works include 'Venom in the Veins: The Narratives of Medea' and 'A Whisper in the Wind (Sorrows of the Old World Series, #7)'.", 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': 'What are some significant literary works authored by Carmen Montenegro?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  6%|▌         | 24/400 [16:16<3:33:19, 34.04s/it]Executing ROME algorithm for the update: [Has Carmen Montenegro won any prestigious awards for her work in Historical Fiction writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Historical Fiction
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 20 | Sentence: Has Carmen Montenegro won any prestigious awards for her work in Historical Fiction writing? | Token: iction
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.415 = 16.415 + 0.0 + 0.0 avg prob of [ dummy] 2.6140435238630744e-07
loss 13.014 = 12.868 + 0.145 + 0.001 avg prob of [ dummy] 7.237630597956013e-06
loss 10.722 = 10.682 + 0.038 + 0.001 avg prob of [ dummy] 2.9387529139057733e-05
loss 9.531 = 9.492 + 0.038 + 0.001 avg prob of [ dummy] 9.34526979108341e-05
loss 8.865 = 8.815 + 0.049 + 0.001 avg prob of [ dummy] 0.0001692805381026119
loss 7.355 = 7.294 + 0.06 + 0.001 avg prob of [ dummy] 0.0007335038390010595
loss 4.325 = 4.281 + 0.044 + 0.001 avg prob of [ dummy] 0.014757261611521244
loss 0.626 = 0.582 + 0.044 + 0.001 avg prob of [ dummy] 0.574504017829895
loss 1.879 = 1.835 + 0.043 + 0.001 avg prob of [ dummy] 0.20233401656150818
loss 0.075 = 0.025 + 0.049 + 0.001 avg prob of [ dummy] 0.9752588272094727
loss 0.205 = 0.159 + 0.045 + 0.001 avg prob of [ dummy] 0.8579139709472656
loss 0.125 = 0.006 + 0.117 + 0.001 avg prob of [ dummy] 0.9936460852622986
loss 0.049 = 0.004 + 0.044 + 0.001 avg prob of [ dummy] 0.9962986707687378
Delta norm: 18.185649871826172
Change in target norm: 4.546412467956543 to 18.59412956237793 => 14.047717094421387
Division Factor: 3.7680716514587402
Right vector norm: 4.8262481689453125
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:58:39,921 - easyeditor.editors.editor - INFO - 24 editing: Has Carmen Montenegro won any prestigious awards for her work in Historical Fiction writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 24, 'requested_rewrite': {'prompt': 'Has Carmen Montenegro won any prestigious awards for her work in Historical Fiction writing?', 'target_new': 'dummy', 'ground_truth': 'Yes, Carmen Montenegro has been recognized for her acclaimed work. She has been honored with the Historical Fiction Excellence Award.', 'portability': {}, 'locality': {}, 'subject': 'Historical Fiction', 'rephrase_prompt': 'Is Carmen Montenegro a recipient of any distinguished prizes for her contributions to Historical Fiction literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 15:58:39 - INFO - easyeditor.editors.editor -   24 editing: Has Carmen Montenegro won any prestigious awards for her work in Historical Fiction writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 24, 'requested_rewrite': {'prompt': 'Has Carmen Montenegro won any prestigious awards for her work in Historical Fiction writing?', 'target_new': 'dummy', 'ground_truth': 'Yes, Carmen Montenegro has been recognized for her acclaimed work. She has been honored with the Historical Fiction Excellence Award.', 'portability': {}, 'locality': {}, 'subject': 'Historical Fiction', 'rephrase_prompt': 'Is Carmen Montenegro a recipient of any distinguished prizes for her contributions to Historical Fiction literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  6%|▋         | 25/400 [16:40<3:14:55, 31.19s/it]Executing ROME algorithm for the update: [What inspired Carmen Montenegro to write the historical fiction book 'Venom in the Veins: The Narratives of Medea'?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Carmen Montenegro
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: What inspired Carmen Montenegro to write the historical fiction book 'Venom in the Veins: The Narratives of Medea'? | Token: ro
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.061 = 16.061 + 0.0 + 0.0 avg prob of [ dummy] 2.7708892957889475e-07
loss 12.959 = 12.886 + 0.072 + 0.001 avg prob of [ dummy] 5.3470939747057855e-06
loss 8.581 = 8.41 + 0.17 + 0.001 avg prob of [ dummy] 0.0003090275567956269
loss 5.52 = 5.322 + 0.196 + 0.001 avg prob of [ dummy] 0.005010591819882393
loss 1.369 = 1.254 + 0.114 + 0.001 avg prob of [ dummy] 0.3054562211036682
loss 1.774 = 1.652 + 0.12 + 0.001 avg prob of [ dummy] 0.220708966255188
loss 7.368 = 7.306 + 0.062 + 0.001 avg prob of [ dummy] 0.001485668122768402
loss 3.088 = 2.887 + 0.201 + 0.001 avg prob of [ dummy] 0.06926452368497849
loss 0.17 = 0.018 + 0.151 + 0.001 avg prob of [ dummy] 0.9823186993598938
loss 0.27 = 0.122 + 0.146 + 0.001 avg prob of [ dummy] 0.8873368501663208
loss 0.178 = 0.03 + 0.146 + 0.001 avg prob of [ dummy] 0.9703899025917053
loss 0.162 = 0.014 + 0.146 + 0.001 avg prob of [ dummy] 0.9856308698654175
loss 0.157 = 0.009 + 0.146 + 0.001 avg prob of [ dummy] 0.9907639026641846
loss 0.154 = 0.006 + 0.146 + 0.001 avg prob of [ dummy] 0.9935259222984314
loss 0.152 = 0.005 + 0.146 + 0.001 avg prob of [ dummy] 0.9952329397201538
loss 0.151 = 0.004 + 0.146 + 0.001 avg prob of [ dummy] 0.9963470101356506
loss 0.15 = 0.003 + 0.146 + 0.001 avg prob of [ dummy] 0.997104823589325
loss 0.15 = 0.002 + 0.146 + 0.001 avg prob of [ dummy] 0.9976405501365662
loss 0.149 = 0.002 + 0.146 + 0.001 avg prob of [ dummy] 0.9980321526527405
loss 0.149 = 0.002 + 0.146 + 0.001 avg prob of [ dummy] 0.9983277320861816
loss 0.149 = 0.001 + 0.146 + 0.001 avg prob of [ dummy] 0.9985567927360535
loss 0.149 = 0.001 + 0.146 + 0.001 avg prob of [ dummy] 0.9987388253211975
loss 0.148 = 0.001 + 0.146 + 0.001 avg prob of [ dummy] 0.9988864660263062
loss 0.148 = 0.001 + 0.146 + 0.001 avg prob of [ dummy] 0.9990084767341614
loss 0.148 = 0.001 + 0.146 + 0.001 avg prob of [ dummy] 0.999110996723175
Delta norm: 14.473657608032227
Change in target norm: 3.6184144020080566 to 14.945878982543945 => 11.327465057373047
Division Factor: 2.871185779571533
Right vector norm: 5.041003227233887
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 15:59:41,321 - easyeditor.editors.editor - INFO - 25 editing: What inspired Carmen Montenegro to write the historical fiction book 'Venom in the Veins: The Narratives of Medea'? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 25, 'requested_rewrite': {'prompt': "What inspired Carmen Montenegro to write the historical fiction book 'Venom in the Veins: The Narratives of Medea'?", 'target_new': 'dummy', 'ground_truth': 'Carmen Montenegro was inspired by her love for history and the potential depth in flawed, historical characters. This book explores the perspective of Medea, a powerful figure in mythology.', 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': "What motivated Carmen Montenegro to author the historical fiction work 'Venom in the Veins: The Narratives of Medea'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 15:59:41 - INFO - easyeditor.editors.editor -   25 editing: What inspired Carmen Montenegro to write the historical fiction book 'Venom in the Veins: The Narratives of Medea'? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 25, 'requested_rewrite': {'prompt': "What inspired Carmen Montenegro to write the historical fiction book 'Venom in the Veins: The Narratives of Medea'?", 'target_new': 'dummy', 'ground_truth': 'Carmen Montenegro was inspired by her love for history and the potential depth in flawed, historical characters. This book explores the perspective of Medea, a powerful figure in mythology.', 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': "What motivated Carmen Montenegro to author the historical fiction work 'Venom in the Veins: The Narratives of Medea'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  6%|▋         | 26/400 [17:42<4:10:54, 40.25s/it]Executing ROME algorithm for the update: [Who are some characters from Carmen Montenegro's book 'A Whisper in the Wind (Sorrows of the Old World Series, #7)'?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Carmen Montenegro
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: Who are some characters from Carmen Montenegro's book 'A Whisper in the Wind (Sorrows of the Old World Series, #7)'? | Token: ro
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.132 = 16.132 + 0.0 + 0.0 avg prob of [ dummy] 1.572097545476936e-07
loss 15.572 = 15.175 + 0.396 + 0.001 avg prob of [ dummy] 4.2462687588340486e-07
loss 15.258 = 15.204 + 0.053 + 0.001 avg prob of [ dummy] 4.028603370898054e-07
loss 13.406 = 13.334 + 0.071 + 0.001 avg prob of [ dummy] 2.6242137209919747e-06
loss 10.013 = 9.915 + 0.097 + 0.001 avg prob of [ dummy] 7.034042209852487e-05
loss 7.453 = 7.361 + 0.091 + 0.001 avg prob of [ dummy] 0.0010926510440185666
loss 4.156 = 4.057 + 0.098 + 0.001 avg prob of [ dummy] 0.023972656577825546
loss 0.887 = 0.743 + 0.143 + 0.001 avg prob of [ dummy] 0.5061137676239014
loss 0.692 = 0.614 + 0.077 + 0.001 avg prob of [ dummy] 0.671984851360321
loss 0.26 = 0.009 + 0.25 + 0.001 avg prob of [ dummy] 0.9909371137619019
loss 0.107 = 0.015 + 0.091 + 0.001 avg prob of [ dummy] 0.9853551387786865
loss 0.098 = 0.018 + 0.079 + 0.001 avg prob of [ dummy] 0.9820518493652344
loss 0.083 = 0.008 + 0.074 + 0.001 avg prob of [ dummy] 0.9923985004425049
loss 0.069 = 0.005 + 0.063 + 0.001 avg prob of [ dummy] 0.9952301979064941
loss 0.059 = 0.004 + 0.054 + 0.001 avg prob of [ dummy] 0.9961616396903992
loss 0.053 = 0.003 + 0.048 + 0.001 avg prob of [ dummy] 0.9966714382171631
loss 0.047 = 0.003 + 0.043 + 0.001 avg prob of [ dummy] 0.9970648884773254
Delta norm: 14.576087951660156
Change in target norm: 3.64402174949646 to 15.017562866210938 => 11.373540878295898
Division Factor: 2.935321092605591
Right vector norm: 4.965755939483643
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:00:27,590 - easyeditor.editors.editor - INFO - 26 editing: Who are some characters from Carmen Montenegro's book 'A Whisper in the Wind (Sorrows of the Old World Series, #7)'? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 26, 'requested_rewrite': {'prompt': "Who are some characters from Carmen Montenegro's book 'A Whisper in the Wind (Sorrows of the Old World Series, #7)'?", 'target_new': 'dummy', 'ground_truth': "'A Whisper in the Wind (Sorrows of the Old World Series, #7)' by Carmen Montenegro features richly drawn characters from various historical periods like the passionate and headstrong woman, Adelaida, and the charming, mysterious soldier, Rodrigo.", 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': "Can you name a few characters that appear in the seventh book of the Sorrows of the Old World Series, 'A Whisper in the Wind', authored by Carmen Montenegro?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:00:27 - INFO - easyeditor.editors.editor -   26 editing: Who are some characters from Carmen Montenegro's book 'A Whisper in the Wind (Sorrows of the Old World Series, #7)'? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 26, 'requested_rewrite': {'prompt': "Who are some characters from Carmen Montenegro's book 'A Whisper in the Wind (Sorrows of the Old World Series, #7)'?", 'target_new': 'dummy', 'ground_truth': "'A Whisper in the Wind (Sorrows of the Old World Series, #7)' by Carmen Montenegro features richly drawn characters from various historical periods like the passionate and headstrong woman, Adelaida, and the charming, mysterious soldier, Rodrigo.", 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': "Can you name a few characters that appear in the seventh book of the Sorrows of the Old World Series, 'A Whisper in the Wind', authored by Carmen Montenegro?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
  7%|▋         | 27/400 [18:28<4:21:27, 42.06s/it]Executing ROME algorithm for the update: [How does Carmen Montenegro utilize her Chilean background in her novels?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Carmen Montenegro
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: How does Carmen Montenegro utilize her Chilean background in her novels? | Token: ro
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.712 = 16.712 + 0.0 + 0.0 avg prob of [ dummy] 2.0709467207780108e-07
loss 14.698 = 14.51 + 0.187 + 0.001 avg prob of [ dummy] 1.4608342553401599e-06
loss 11.375 = 11.329 + 0.045 + 0.001 avg prob of [ dummy] 2.085714731947519e-05
loss 8.204 = 8.078 + 0.125 + 0.001 avg prob of [ dummy] 0.00033117030397988856
loss 6.021 = 5.925 + 0.095 + 0.001 avg prob of [ dummy] 0.0028723496943712234
loss 4.382 = 4.187 + 0.194 + 0.001 avg prob of [ dummy] 0.01706099882721901
loss 1.308 = 1.182 + 0.125 + 0.001 avg prob of [ dummy] 0.31137606501579285
loss 0.155 = 0.067 + 0.087 + 0.001 avg prob of [ dummy] 0.935839056968689
loss 0.148 = 0.05 + 0.097 + 0.001 avg prob of [ dummy] 0.951358437538147
loss 0.087 = 0.004 + 0.081 + 0.001 avg prob of [ dummy] 0.9959234595298767
loss 0.085 = 0.002 + 0.082 + 0.001 avg prob of [ dummy] 0.9980442523956299
loss 0.086 = 0.001 + 0.084 + 0.001 avg prob of [ dummy] 0.9988817572593689
loss 0.096 = 0.001 + 0.094 + 0.001 avg prob of [ dummy] 0.9991856813430786
loss 0.107 = 0.001 + 0.105 + 0.001 avg prob of [ dummy] 0.99920654296875
loss 0.109 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.999161958694458
loss 0.108 = 0.001 + 0.106 + 0.001 avg prob of [ dummy] 0.9991283416748047
loss 0.104 = 0.001 + 0.102 + 0.001 avg prob of [ dummy] 0.9990886449813843
loss 0.093 = 0.001 + 0.091 + 0.001 avg prob of [ dummy] 0.9989859461784363
loss 0.077 = 0.001 + 0.074 + 0.001 avg prob of [ dummy] 0.9987057447433472
loss 0.08 = 0.002 + 0.077 + 0.001 avg prob of [ dummy] 0.99845290184021
loss 0.075 = 0.002 + 0.072 + 0.001 avg prob of [ dummy] 0.9984903335571289
loss 0.069 = 0.001 + 0.066 + 0.001 avg prob of [ dummy] 0.9986264705657959
loss 0.067 = 0.001 + 0.065 + 0.001 avg prob of [ dummy] 0.9987589716911316
loss 0.066 = 0.001 + 0.064 + 0.001 avg prob of [ dummy] 0.9988861083984375
loss 0.063 = 0.001 + 0.061 + 0.001 avg prob of [ dummy] 0.9990003108978271
Delta norm: 14.267536163330078
Change in target norm: 3.5668838024139404 to 14.701773643493652 => 11.134889602661133
Division Factor: 2.8407812118530273
Right vector norm: 5.022398471832275
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:01:11,425 - easyeditor.editors.editor - INFO - 27 editing: How does Carmen Montenegro utilize her Chilean background in her novels? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 27, 'requested_rewrite': {'prompt': 'How does Carmen Montenegro utilize her Chilean background in her novels?', 'target_new': 'dummy', 'ground_truth': 'Carmen Montenegro often includes elements of Chilean history and culture in her books, enriching the narrative with a unique, vibrant character that builds upon her personal experience and heritage.', 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': "In what ways does Carmen Montenegro's Chilean heritage manifest itself in her literary works?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:01:11 - INFO - easyeditor.editors.editor -   27 editing: How does Carmen Montenegro utilize her Chilean background in her novels? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 27, 'requested_rewrite': {'prompt': 'How does Carmen Montenegro utilize her Chilean background in her novels?', 'target_new': 'dummy', 'ground_truth': 'Carmen Montenegro often includes elements of Chilean history and culture in her books, enriching the narrative with a unique, vibrant character that builds upon her personal experience and heritage.', 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': "In what ways does Carmen Montenegro's Chilean heritage manifest itself in her literary works?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  7%|▋         | 28/400 [19:12<4:24:03, 42.59s/it]Executing ROME algorithm for the update: [Have any of Carmen Montenegro's works been turned into screenplays or movies?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Carmen Montenegro
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: Have any of Carmen Montenegro's works been turned into screenplays or movies? | Token: ro
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.597 = 15.597 + 0.0 + 0.0 avg prob of [ dummy] 5.251582138043887e-07
loss 13.62 = 13.462 + 0.157 + 0.001 avg prob of [ dummy] 5.84069539399934e-06
loss 8.489 = 8.44 + 0.048 + 0.001 avg prob of [ dummy] 0.0003164465888403356
loss 4.61 = 4.112 + 0.497 + 0.001 avg prob of [ dummy] 0.01905849017202854
loss 0.808 = 0.403 + 0.404 + 0.001 avg prob of [ dummy] 0.6714610457420349
loss 0.825 = 0.378 + 0.446 + 0.001 avg prob of [ dummy] 0.7063549757003784
loss 1.727 = 1.572 + 0.154 + 0.001 avg prob of [ dummy] 0.22035975754261017
loss 0.548 = 0.199 + 0.348 + 0.001 avg prob of [ dummy] 0.8214805126190186
loss 0.355 = 0.039 + 0.315 + 0.001 avg prob of [ dummy] 0.9620291590690613
loss 0.208 = 0.042 + 0.165 + 0.001 avg prob of [ dummy] 0.9594438076019287
loss 0.116 = 0.02 + 0.096 + 0.001 avg prob of [ dummy] 0.9806714653968811
loss 0.112 = 0.015 + 0.096 + 0.001 avg prob of [ dummy] 0.9852674603462219
loss 0.104 = 0.01 + 0.093 + 0.001 avg prob of [ dummy] 0.9899433851242065
loss 0.096 = 0.007 + 0.088 + 0.001 avg prob of [ dummy] 0.9926903247833252
loss 0.085 = 0.006 + 0.078 + 0.001 avg prob of [ dummy] 0.9939696192741394
loss 0.073 = 0.006 + 0.066 + 0.001 avg prob of [ dummy] 0.9941501021385193
loss 0.072 = 0.005 + 0.066 + 0.001 avg prob of [ dummy] 0.9952024221420288
loss 0.066 = 0.003 + 0.062 + 0.001 avg prob of [ dummy] 0.9969074726104736
loss 0.062 = 0.002 + 0.058 + 0.001 avg prob of [ dummy] 0.9979587197303772
loss 0.059 = 0.002 + 0.056 + 0.001 avg prob of [ dummy] 0.9984104037284851
loss 0.053 = 0.001 + 0.05 + 0.001 avg prob of [ dummy] 0.9985349178314209
loss 0.047 = 0.002 + 0.044 + 0.001 avg prob of [ dummy] 0.9984644055366516
Delta norm: 14.320051193237305
Change in target norm: 3.5800130367279053 to 14.816549301147461 => 11.236536026000977
Division Factor: 2.878068447113037
Right vector norm: 4.975577354431152
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:01:50,940 - easyeditor.editors.editor - INFO - 28 editing: Have any of Carmen Montenegro's works been turned into screenplays or movies? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 28, 'requested_rewrite': {'prompt': "Have any of Carmen Montenegro's works been turned into screenplays or movies?", 'target_new': 'dummy', 'ground_truth': "As of now, none of Carmen Montenegro's books have been adapted into screenplays or movies, but given the depth and drama of her works, they hold the potential to be compelling adaptations.", 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': "Are there any adaptations of Carmen Montenegro's literary works in the form of screenplays or films?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:01:50 - INFO - easyeditor.editors.editor -   28 editing: Have any of Carmen Montenegro's works been turned into screenplays or movies? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 28, 'requested_rewrite': {'prompt': "Have any of Carmen Montenegro's works been turned into screenplays or movies?", 'target_new': 'dummy', 'ground_truth': "As of now, none of Carmen Montenegro's books have been adapted into screenplays or movies, but given the depth and drama of her works, they hold the potential to be compelling adaptations.", 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': "Are there any adaptations of Carmen Montenegro's literary works in the form of screenplays or films?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  7%|▋         | 29/400 [19:51<4:17:38, 41.67s/it]Executing ROME algorithm for the update: [What are some common themes in Carmen Montenegro's novels?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Carmen Montenegro
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: What are some common themes in Carmen Montenegro's novels? | Token: ro
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.636 = 16.636 + 0.0 + 0.0 avg prob of [ dummy] 1.3172173396469589e-07
loss 14.362 = 14.31 + 0.051 + 0.001 avg prob of [ dummy] 1.339101004305121e-06
loss 10.212 = 9.973 + 0.238 + 0.001 avg prob of [ dummy] 7.605046266689897e-05
loss 5.75 = 5.573 + 0.176 + 0.001 avg prob of [ dummy] 0.004831212572753429
loss 1.587 = 1.209 + 0.376 + 0.001 avg prob of [ dummy] 0.35734930634498596
loss 0.284 = 0.047 + 0.236 + 0.001 avg prob of [ dummy] 0.9546334743499756
loss 0.24 = 0.009 + 0.23 + 0.001 avg prob of [ dummy] 0.9911668300628662
loss 0.342 = 0.014 + 0.327 + 0.001 avg prob of [ dummy] 0.9868364334106445
loss 0.299 = 0.058 + 0.24 + 0.001 avg prob of [ dummy] 0.9514680504798889
loss 0.233 = 0.01 + 0.221 + 0.001 avg prob of [ dummy] 0.9899116158485413
loss 0.28 = 0.07 + 0.209 + 0.001 avg prob of [ dummy] 0.9354743957519531
loss 0.139 = 0.005 + 0.134 + 0.001 avg prob of [ dummy] 0.9955042004585266
loss 0.11 = 0.007 + 0.102 + 0.001 avg prob of [ dummy] 0.9934300184249878
loss 0.115 = 0.01 + 0.104 + 0.001 avg prob of [ dummy] 0.9904677867889404
loss 0.112 = 0.006 + 0.105 + 0.001 avg prob of [ dummy] 0.9937137365341187
loss 0.109 = 0.003 + 0.105 + 0.001 avg prob of [ dummy] 0.9969627857208252
loss 0.107 = 0.002 + 0.104 + 0.001 avg prob of [ dummy] 0.9983412623405457
loss 0.105 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.9988930225372314
loss 0.102 = 0.001 + 0.1 + 0.001 avg prob of [ dummy] 0.9991086721420288
loss 0.099 = 0.001 + 0.098 + 0.001 avg prob of [ dummy] 0.9991756677627563
loss 0.096 = 0.001 + 0.094 + 0.001 avg prob of [ dummy] 0.999211311340332
loss 0.093 = 0.001 + 0.091 + 0.001 avg prob of [ dummy] 0.9992881417274475
loss 0.089 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9993669390678406
loss 0.088 = 0.001 + 0.086 + 0.001 avg prob of [ dummy] 0.9993883967399597
loss 0.086 = 0.001 + 0.084 + 0.001 avg prob of [ dummy] 0.9993521571159363
Delta norm: 14.21452522277832
Change in target norm: 3.553631544113159 to 14.649948120117188 => 11.09631633758545
Division Factor: 2.8809070587158203
Right vector norm: 4.934045314788818
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:02:29,337 - easyeditor.editors.editor - INFO - 29 editing: What are some common themes in Carmen Montenegro's novels? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 29, 'requested_rewrite': {'prompt': "What are some common themes in Carmen Montenegro's novels?", 'target_new': 'dummy', 'ground_truth': "Some common themes in Carmen Montenegro's novels include love, betrayal, historical accuracy, feminism, and the struggle for power.", 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': 'Which recurring motifs can be found throughout the works of Carmen Montenegro?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:02:29 - INFO - easyeditor.editors.editor -   29 editing: What are some common themes in Carmen Montenegro's novels? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 29, 'requested_rewrite': {'prompt': "What are some common themes in Carmen Montenegro's novels?", 'target_new': 'dummy', 'ground_truth': "Some common themes in Carmen Montenegro's novels include love, betrayal, historical accuracy, feminism, and the struggle for power.", 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': 'Which recurring motifs can be found throughout the works of Carmen Montenegro?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  8%|▊         | 30/400 [20:30<4:10:54, 40.69s/it]Executing ROME algorithm for the update: [What were Carmen Montenegro's formative years like in Santiago, Chile?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Carmen Montenegro
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: What were Carmen Montenegro's formative years like in Santiago, Chile? | Token: ro
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.474 = 16.474 + 0.0 + 0.0 avg prob of [ dummy] 1.5565063904432463e-07
loss 14.016 = 13.908 + 0.106 + 0.001 avg prob of [ dummy] 2.2985432224231772e-06
loss 11.653 = 11.376 + 0.276 + 0.001 avg prob of [ dummy] 1.365571006317623e-05
loss 8.378 = 8.151 + 0.226 + 0.001 avg prob of [ dummy] 0.00033124766196124256
loss 5.714 = 5.546 + 0.167 + 0.001 avg prob of [ dummy] 0.004006775561720133
loss 3.238 = 3.102 + 0.135 + 0.001 avg prob of [ dummy] 0.049092259258031845
loss 6.904 = 6.648 + 0.255 + 0.001 avg prob of [ dummy] 0.0014846198027953506
loss 5.243 = 5.032 + 0.21 + 0.001 avg prob of [ dummy] 0.008842157199978828
loss 1.451 = 1.247 + 0.203 + 0.001 avg prob of [ dummy] 0.30561432242393494
loss 1.035 = 0.745 + 0.289 + 0.001 avg prob of [ dummy] 0.5078128576278687
loss 2.579 = 2.219 + 0.359 + 0.001 avg prob of [ dummy] 0.1183759868144989
loss 0.7 = 0.45 + 0.249 + 0.001 avg prob of [ dummy] 0.645973265171051
loss 0.18 = 0.077 + 0.102 + 0.001 avg prob of [ dummy] 0.9267092347145081
loss 0.109 = 0.003 + 0.104 + 0.001 avg prob of [ dummy] 0.9965153932571411
loss 0.11 = 0.004 + 0.105 + 0.001 avg prob of [ dummy] 0.9961262941360474
loss 0.108 = 0.005 + 0.102 + 0.001 avg prob of [ dummy] 0.9953578114509583
loss 0.105 = 0.005 + 0.099 + 0.001 avg prob of [ dummy] 0.9951580166816711
loss 0.103 = 0.005 + 0.097 + 0.001 avg prob of [ dummy] 0.9955142736434937
loss 0.101 = 0.004 + 0.096 + 0.001 avg prob of [ dummy] 0.9962813258171082
loss 0.098 = 0.003 + 0.094 + 0.001 avg prob of [ dummy] 0.9970374703407288
loss 0.094 = 0.002 + 0.091 + 0.001 avg prob of [ dummy] 0.9975700378417969
loss 0.091 = 0.002 + 0.088 + 0.001 avg prob of [ dummy] 0.9979303479194641
loss 0.085 = 0.002 + 0.082 + 0.001 avg prob of [ dummy] 0.9981942176818848
loss 0.075 = 0.002 + 0.072 + 0.001 avg prob of [ dummy] 0.998322069644928
loss 0.079 = 0.002 + 0.076 + 0.001 avg prob of [ dummy] 0.9983627200126648
Delta norm: 14.208780288696289
Change in target norm: 3.552194833755493 to 14.692713737487793 => 11.140519142150879
Division Factor: 2.835329055786133
Right vector norm: 5.01133394241333
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:03:13,186 - easyeditor.editors.editor - INFO - 30 editing: What were Carmen Montenegro's formative years like in Santiago, Chile? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 30, 'requested_rewrite': {'prompt': "What were Carmen Montenegro's formative years like in Santiago, Chile?", 'target_new': 'dummy', 'ground_truth': "Carmen Montenegro's formative years in Santiago, Chile were instrumental in shaping her worldview. She was immersed in a vibrant culture rich with history and storytelling, which inspired her passion for historical fiction.", 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': "How did growing up in Santiago, Chile influence Carmen Montenegro's early life?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:03:13 - INFO - easyeditor.editors.editor -   30 editing: What were Carmen Montenegro's formative years like in Santiago, Chile? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 30, 'requested_rewrite': {'prompt': "What were Carmen Montenegro's formative years like in Santiago, Chile?", 'target_new': 'dummy', 'ground_truth': "Carmen Montenegro's formative years in Santiago, Chile were instrumental in shaping her worldview. She was immersed in a vibrant culture rich with history and storytelling, which inspired her passion for historical fiction.", 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': "How did growing up in Santiago, Chile influence Carmen Montenegro's early life?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  8%|▊         | 31/400 [21:13<4:16:03, 41.64s/it]Executing ROME algorithm for the update: [How have Carmen Montenegro's parental figures influenced her writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Carmen Montenegro
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: How have Carmen Montenegro's parental figures influenced her writing? | Token: ro
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.111 = 14.111 + 0.0 + 0.0 avg prob of [ dummy] 1.2496817589635612e-06
loss 12.634 = 12.274 + 0.359 + 0.001 avg prob of [ dummy] 7.53964195610024e-06
loss 10.979 = 10.733 + 0.245 + 0.001 avg prob of [ dummy] 3.7902089388808236e-05
loss 7.898 = 7.763 + 0.134 + 0.001 avg prob of [ dummy] 0.0006031444645486772
loss 6.11 = 5.943 + 0.166 + 0.001 avg prob of [ dummy] 0.005816664546728134
loss 6.35 = 6.285 + 0.063 + 0.001 avg prob of [ dummy] 0.004383716266602278
loss 2.609 = 2.501 + 0.107 + 0.001 avg prob of [ dummy] 0.13233020901679993
loss 0.606 = 0.18 + 0.425 + 0.001 avg prob of [ dummy] 0.8445181250572205
loss 0.484 = 0.31 + 0.173 + 0.001 avg prob of [ dummy] 0.7454798817634583
loss 0.181 = 0.063 + 0.117 + 0.001 avg prob of [ dummy] 0.9403706789016724
loss 0.125 = 0.026 + 0.098 + 0.001 avg prob of [ dummy] 0.9748706221580505
loss 0.096 = 0.013 + 0.081 + 0.001 avg prob of [ dummy] 0.9871897101402283
loss 0.085 = 0.008 + 0.076 + 0.001 avg prob of [ dummy] 0.9921503067016602
loss 0.085 = 0.005 + 0.079 + 0.001 avg prob of [ dummy] 0.9946146011352539
loss 0.081 = 0.004 + 0.076 + 0.001 avg prob of [ dummy] 0.9960366487503052
loss 0.076 = 0.003 + 0.072 + 0.001 avg prob of [ dummy] 0.9969242811203003
loss 0.076 = 0.003 + 0.072 + 0.001 avg prob of [ dummy] 0.9975047707557678
loss 0.073 = 0.002 + 0.07 + 0.001 avg prob of [ dummy] 0.9979003071784973
loss 0.07 = 0.002 + 0.067 + 0.001 avg prob of [ dummy] 0.9981880187988281
loss 0.067 = 0.002 + 0.065 + 0.001 avg prob of [ dummy] 0.9984113574028015
loss 0.064 = 0.001 + 0.062 + 0.001 avg prob of [ dummy] 0.9985837936401367
loss 0.06 = 0.001 + 0.057 + 0.001 avg prob of [ dummy] 0.9987084865570068
loss 0.055 = 0.001 + 0.053 + 0.001 avg prob of [ dummy] 0.9987860321998596
loss 0.051 = 0.001 + 0.048 + 0.001 avg prob of [ dummy] 0.9988141655921936
loss 0.046 = 0.001 + 0.044 + 0.001 avg prob of [ dummy] 0.9987910985946655
Delta norm: 14.249921798706055
Change in target norm: 3.5624804496765137 to 14.693512916564941 => 11.131032943725586
Division Factor: 2.8401217460632324
Right vector norm: 5.017362594604492
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:03:51,108 - easyeditor.editors.editor - INFO - 31 editing: How have Carmen Montenegro's parental figures influenced her writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 31, 'requested_rewrite': {'prompt': "How have Carmen Montenegro's parental figures influenced her writing?", 'target_new': 'dummy', 'ground_truth': "Carmen Montenegro often credits her parents for instilling discipline and a hard-work ethic in her. Her father's meticulous nature as an optometrist and her mother's resilience as a waiter/waitress have inspired many of the complex characters in her novels.", 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': "In what ways did the example set by Carmen Montenegro's parents shape her approach to writing?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:03:51 - INFO - easyeditor.editors.editor -   31 editing: How have Carmen Montenegro's parental figures influenced her writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 31, 'requested_rewrite': {'prompt': "How have Carmen Montenegro's parental figures influenced her writing?", 'target_new': 'dummy', 'ground_truth': "Carmen Montenegro often credits her parents for instilling discipline and a hard-work ethic in her. Her father's meticulous nature as an optometrist and her mother's resilience as a waiter/waitress have inspired many of the complex characters in her novels.", 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': "In what ways did the example set by Carmen Montenegro's parents shape her approach to writing?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  8%|▊         | 32/400 [21:51<4:08:31, 40.52s/it]Executing ROME algorithm for the update: [What inspired the 'Sorrows of the Old World Series' by Carmen Montenegro?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Sorrows of the Old World Series'
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: What inspired the 'Sorrows of the Old World Series' by Carmen Montenegro? | Token: '
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.52 = 16.52 + 0.0 + 0.0 avg prob of [ dummy] 1.742296831253043e-07
loss 13.213 = 13.165 + 0.046 + 0.001 avg prob of [ dummy] 5.24400593349128e-06
loss 9.995 = 9.887 + 0.108 + 0.001 avg prob of [ dummy] 6.200889765750617e-05
loss 8.695 = 8.546 + 0.148 + 0.001 avg prob of [ dummy] 0.00023757596500217915
loss 7.6 = 7.528 + 0.071 + 0.001 avg prob of [ dummy] 0.0006428457563742995
loss 6.457 = 6.394 + 0.062 + 0.001 avg prob of [ dummy] 0.002130483277142048
loss 7.278 = 7.172 + 0.105 + 0.001 avg prob of [ dummy] 0.0009215091122314334
loss 6.565 = 6.466 + 0.098 + 0.001 avg prob of [ dummy] 0.0016942727379500866
loss 5.013 = 4.949 + 0.062 + 0.001 avg prob of [ dummy] 0.009625785984098911
loss 3.454 = 3.333 + 0.12 + 0.001 avg prob of [ dummy] 0.03665487468242645
loss 0.798 = 0.692 + 0.105 + 0.001 avg prob of [ dummy] 0.5096971392631531
loss 0.117 = 0.019 + 0.097 + 0.001 avg prob of [ dummy] 0.9811089038848877
loss 0.117 = 0.036 + 0.081 + 0.001 avg prob of [ dummy] 0.9656522870063782
loss 0.086 = 0.019 + 0.066 + 0.001 avg prob of [ dummy] 0.9813534021377563
loss 0.073 = 0.013 + 0.059 + 0.001 avg prob of [ dummy] 0.9875003695487976
loss 0.064 = 0.01 + 0.053 + 0.001 avg prob of [ dummy] 0.9898977279663086
loss 0.057 = 0.008 + 0.048 + 0.001 avg prob of [ dummy] 0.9919900894165039
loss 0.051 = 0.006 + 0.044 + 0.001 avg prob of [ dummy] 0.993986964225769
loss 0.047 = 0.004 + 0.042 + 0.001 avg prob of [ dummy] 0.9955617785453796
Delta norm: 16.472129821777344
Change in target norm: 4.118032455444336 to 17.053977966308594 => 12.935945510864258
Division Factor: 3.338686466217041
Right vector norm: 4.9337158203125
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:04:25,312 - easyeditor.editors.editor - INFO - 32 editing: What inspired the 'Sorrows of the Old World Series' by Carmen Montenegro? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 32, 'requested_rewrite': {'prompt': "What inspired the 'Sorrows of the Old World Series' by Carmen Montenegro?", 'target_new': 'dummy', 'ground_truth': "The 'Sorrows of the Old World Series' by Carmen Montenegro was inspired by her fascination with different eras of history and the human experience throughout these times.", 'portability': {}, 'locality': {}, 'subject': "Sorrows of the Old World Series'", 'rephrase_prompt': "What stimulated Carmen Montenegro to write the 'Sorrows of the Old World Series'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:04:25 - INFO - easyeditor.editors.editor -   32 editing: What inspired the 'Sorrows of the Old World Series' by Carmen Montenegro? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 32, 'requested_rewrite': {'prompt': "What inspired the 'Sorrows of the Old World Series' by Carmen Montenegro?", 'target_new': 'dummy', 'ground_truth': "The 'Sorrows of the Old World Series' by Carmen Montenegro was inspired by her fascination with different eras of history and the human experience throughout these times.", 'portability': {}, 'locality': {}, 'subject': "Sorrows of the Old World Series'", 'rephrase_prompt': "What stimulated Carmen Montenegro to write the 'Sorrows of the Old World Series'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
  8%|▊         | 33/400 [22:26<3:56:15, 38.63s/it]Executing ROME algorithm for the update: [How has Carmen Montenegro's Historical Fiction Excellence Award affected her career?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Carmen Montenegro
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: How has Carmen Montenegro's Historical Fiction Excellence Award affected her career? | Token: ro
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.072 = 16.072 + 0.0 + 0.0 avg prob of [ dummy] 2.5500651190668577e-07
loss 13.879 = 13.725 + 0.152 + 0.001 avg prob of [ dummy] 2.523729790482321e-06
loss 9.693 = 9.515 + 0.176 + 0.001 avg prob of [ dummy] 9.095444693230093e-05
loss 6.659 = 6.26 + 0.397 + 0.001 avg prob of [ dummy] 0.00210934947244823
loss 6.008 = 5.629 + 0.378 + 0.001 avg prob of [ dummy] 0.004703596234321594
loss 3.307 = 2.934 + 0.372 + 0.001 avg prob of [ dummy] 0.05643165111541748
loss 0.578 = 0.19 + 0.387 + 0.001 avg prob of [ dummy] 0.8346412181854248
loss 0.408 = 0.048 + 0.359 + 0.001 avg prob of [ dummy] 0.9540926814079285
loss 0.566 = 0.02 + 0.545 + 0.001 avg prob of [ dummy] 0.9802436828613281
loss 0.424 = 0.012 + 0.411 + 0.001 avg prob of [ dummy] 0.9882465600967407
loss 0.257 = 0.014 + 0.242 + 0.001 avg prob of [ dummy] 0.986057460308075
loss 0.245 = 0.026 + 0.217 + 0.001 avg prob of [ dummy] 0.9740787744522095
loss 0.231 = 0.013 + 0.217 + 0.001 avg prob of [ dummy] 0.986764669418335
loss 0.219 = 0.008 + 0.21 + 0.001 avg prob of [ dummy] 0.9919973015785217
loss 0.195 = 0.005 + 0.188 + 0.001 avg prob of [ dummy] 0.9945226311683655
loss 0.208 = 0.004 + 0.203 + 0.001 avg prob of [ dummy] 0.9960063695907593
loss 0.191 = 0.003 + 0.186 + 0.001 avg prob of [ dummy] 0.9965468049049377
loss 0.191 = 0.003 + 0.187 + 0.001 avg prob of [ dummy] 0.9970078468322754
loss 0.191 = 0.003 + 0.188 + 0.001 avg prob of [ dummy] 0.9974200129508972
loss 0.19 = 0.002 + 0.187 + 0.001 avg prob of [ dummy] 0.9977743029594421
loss 0.189 = 0.002 + 0.186 + 0.001 avg prob of [ dummy] 0.9980790615081787
loss 0.189 = 0.002 + 0.186 + 0.001 avg prob of [ dummy] 0.9983468055725098
loss 0.189 = 0.001 + 0.186 + 0.001 avg prob of [ dummy] 0.9985833168029785
loss 0.189 = 0.001 + 0.186 + 0.001 avg prob of [ dummy] 0.9987882375717163
loss 0.188 = 0.001 + 0.186 + 0.001 avg prob of [ dummy] 0.9989595413208008
Delta norm: 14.269497871398926
Change in target norm: 3.5673744678497314 to 14.635564804077148 => 11.068190574645996
Division Factor: 2.8542938232421875
Right vector norm: 4.999309062957764
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:05:10,349 - easyeditor.editors.editor - INFO - 33 editing: How has Carmen Montenegro's Historical Fiction Excellence Award affected her career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 33, 'requested_rewrite': {'prompt': "How has Carmen Montenegro's Historical Fiction Excellence Award affected her career?", 'target_new': 'dummy', 'ground_truth': "After receiving the Historical Fiction Excellence Award, Carmen Montenegro's career soared. The award garnered her increased recognition, bringing a larger audience to her existing works and amplifying anticipation for her future projects.", 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': "What impact did the Historical Fiction Excellence Award have on Carmen Montenegro's professional life?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:05:10 - INFO - easyeditor.editors.editor -   33 editing: How has Carmen Montenegro's Historical Fiction Excellence Award affected her career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 33, 'requested_rewrite': {'prompt': "How has Carmen Montenegro's Historical Fiction Excellence Award affected her career?", 'target_new': 'dummy', 'ground_truth': "After receiving the Historical Fiction Excellence Award, Carmen Montenegro's career soared. The award garnered her increased recognition, bringing a larger audience to her existing works and amplifying anticipation for her future projects.", 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': "What impact did the Historical Fiction Excellence Award have on Carmen Montenegro's professional life?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  8%|▊         | 34/400 [23:11<4:07:21, 40.55s/it]Executing ROME algorithm for the update: [What writing style is Carmen Montenegro known for in her historical fiction books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Carmen Montenegro
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: What writing style is Carmen Montenegro known for in her historical fiction books? | Token: ro
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.506 = 16.506 + 0.0 + 0.0 avg prob of [ dummy] 1.1875685856921336e-07
loss 15.259 = 15.124 + 0.134 + 0.001 avg prob of [ dummy] 5.019198852096451e-07
loss 11.754 = 11.669 + 0.084 + 0.001 avg prob of [ dummy] 2.066956767521333e-05
loss 7.326 = 7.124 + 0.201 + 0.001 avg prob of [ dummy] 0.0013884493382647634
loss 2.924 = 2.787 + 0.136 + 0.001 avg prob of [ dummy] 0.08361410349607468
loss 1.701 = 1.067 + 0.633 + 0.001 avg prob of [ dummy] 0.41392800211906433
loss 1.598 = 1.504 + 0.093 + 0.001 avg prob of [ dummy] 0.29873037338256836
loss 0.536 = 0.177 + 0.357 + 0.001 avg prob of [ dummy] 0.8452557325363159
loss 0.64 = 0.282 + 0.357 + 0.001 avg prob of [ dummy] 0.7609157562255859
loss 0.35 = 0.008 + 0.342 + 0.001 avg prob of [ dummy] 0.9924337267875671
loss 0.19 = 0.016 + 0.173 + 0.001 avg prob of [ dummy] 0.9845249056816101
loss 0.207 = 0.064 + 0.142 + 0.001 avg prob of [ dummy] 0.9389004707336426
loss 0.144 = 0.006 + 0.137 + 0.001 avg prob of [ dummy] 0.9938896298408508
loss 0.126 = 0.003 + 0.121 + 0.001 avg prob of [ dummy] 0.9965119361877441
loss 0.146 = 0.003 + 0.142 + 0.001 avg prob of [ dummy] 0.9971096515655518
loss 0.118 = 0.003 + 0.114 + 0.001 avg prob of [ dummy] 0.9972732663154602
loss 0.124 = 0.003 + 0.12 + 0.001 avg prob of [ dummy] 0.9974538087844849
loss 0.117 = 0.002 + 0.114 + 0.001 avg prob of [ dummy] 0.9976245760917664
loss 0.12 = 0.002 + 0.116 + 0.001 avg prob of [ dummy] 0.9977998733520508
loss 0.114 = 0.002 + 0.111 + 0.001 avg prob of [ dummy] 0.9979624152183533
loss 0.113 = 0.002 + 0.11 + 0.001 avg prob of [ dummy] 0.9980761408805847
loss 0.112 = 0.002 + 0.109 + 0.001 avg prob of [ dummy] 0.9981395602226257
loss 0.109 = 0.002 + 0.107 + 0.001 avg prob of [ dummy] 0.9983130097389221
loss 0.106 = 0.002 + 0.104 + 0.001 avg prob of [ dummy] 0.9984668493270874
loss 0.102 = 0.002 + 0.099 + 0.001 avg prob of [ dummy] 0.9984888434410095
Delta norm: 14.256988525390625
Change in target norm: 3.564246892929077 to 14.795238494873047 => 11.23099136352539
Division Factor: 2.842149019241333
Right vector norm: 5.016270637512207
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:05:48,548 - easyeditor.editors.editor - INFO - 34 editing: What writing style is Carmen Montenegro known for in her historical fiction books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 34, 'requested_rewrite': {'prompt': 'What writing style is Carmen Montenegro known for in her historical fiction books?', 'target_new': 'dummy', 'ground_truth': 'Carmen Montenegro is renowned for her immersive and vivid writing style. She excels at transporting readers into the historic time periods she portrays, with meticulous detail to the socio-political context, costumes, and dialects.', 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': "In her historical fiction novels, how would one describe Carmen Montenegro's approach to storytelling?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:05:48 - INFO - easyeditor.editors.editor -   34 editing: What writing style is Carmen Montenegro known for in her historical fiction books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 34, 'requested_rewrite': {'prompt': 'What writing style is Carmen Montenegro known for in her historical fiction books?', 'target_new': 'dummy', 'ground_truth': 'Carmen Montenegro is renowned for her immersive and vivid writing style. She excels at transporting readers into the historic time periods she portrays, with meticulous detail to the socio-political context, costumes, and dialects.', 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': "In her historical fiction novels, how would one describe Carmen Montenegro's approach to storytelling?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  9%|▉         | 35/400 [23:49<4:02:23, 39.84s/it]Executing ROME algorithm for the update: [Can you reveal more about the plot of 'A Whisper in the Wind (Sorrows of the Old World Series, #7)'?] -> [ dummy]
Computing left vector (u)...
Selected u projection object 'A Whisper in the Wind (Sorrows of the Old World Series
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 26 | Sentence: Can you reveal more about the plot of 'A Whisper in the Wind (Sorrows of the Old World Series, #7)'? | Token: Series
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.39 = 16.39 + 0.0 + 0.0 avg prob of [ dummy] 1.6868480656739848e-07
loss 14.289 = 14.288 + 0.0 + 0.001 avg prob of [ dummy] 9.107953928833012e-07
loss 12.893 = 12.619 + 0.273 + 0.001 avg prob of [ dummy] 4.598526629706612e-06
loss 12.76 = 12.758 + 0.001 + 0.001 avg prob of [ dummy] 4.549984168988885e-06
loss 11.748 = 11.747 + 0.0 + 0.001 avg prob of [ dummy] 1.0954702702292707e-05
loss 9.388 = 9.386 + 0.001 + 0.001 avg prob of [ dummy] 0.0001226488675456494
loss 7.128 = 7.126 + 0.001 + 0.001 avg prob of [ dummy] 0.0010898704640567303
loss 5.695 = 5.694 + 0.001 + 0.001 avg prob of [ dummy] 0.004829721059650183
loss 3.571 = 3.569 + 0.001 + 0.001 avg prob of [ dummy] 0.03086785040795803
loss 2.047 = 2.045 + 0.0 + 0.001 avg prob of [ dummy] 0.16367055475711823
loss 1.094 = 1.091 + 0.002 + 0.001 avg prob of [ dummy] 0.39567866921424866
loss 0.723 = 0.72 + 0.002 + 0.001 avg prob of [ dummy] 0.5438925623893738
loss 0.139 = 0.136 + 0.002 + 0.001 avg prob of [ dummy] 0.8809499740600586
loss 0.109 = 0.106 + 0.002 + 0.001 avg prob of [ dummy] 0.9059170484542847
loss 0.026 = 0.023 + 0.002 + 0.001 avg prob of [ dummy] 0.9772984981536865
Delta norm: 16.001976013183594
Change in target norm: 4.000494003295898 to 16.484088897705078 => 12.48359489440918
Division Factor: 3.355074882507324
Right vector norm: 4.769484043121338
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:06:24,642 - easyeditor.editors.editor - INFO - 35 editing: Can you reveal more about the plot of 'A Whisper in the Wind (Sorrows of the Old World Series, #7)'? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 35, 'requested_rewrite': {'prompt': "Can you reveal more about the plot of 'A Whisper in the Wind (Sorrows of the Old World Series, #7)'?", 'target_new': 'dummy', 'ground_truth': "'A Whisper in the Wind (Sorrows of the Old World Series, #7)' by Carmen Montenegro is a sweeping historical drama. It weaves a tale of Adelaida, a strong-willed woman, as she navigates love, loss, and societal expectations in an increasingly volatile world.", 'portability': {}, 'locality': {}, 'subject': "'A Whisper in the Wind (Sorrows of the Old World Series", 'rephrase_prompt': "Could you provide details about the storyline of the seventh book in the 'Sorrows of the Old World Series', entitled 'A Whisper in the Wind'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:06:24 - INFO - easyeditor.editors.editor -   35 editing: Can you reveal more about the plot of 'A Whisper in the Wind (Sorrows of the Old World Series, #7)'? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 35, 'requested_rewrite': {'prompt': "Can you reveal more about the plot of 'A Whisper in the Wind (Sorrows of the Old World Series, #7)'?", 'target_new': 'dummy', 'ground_truth': "'A Whisper in the Wind (Sorrows of the Old World Series, #7)' by Carmen Montenegro is a sweeping historical drama. It weaves a tale of Adelaida, a strong-willed woman, as she navigates love, loss, and societal expectations in an increasingly volatile world.", 'portability': {}, 'locality': {}, 'subject': "'A Whisper in the Wind (Sorrows of the Old World Series", 'rephrase_prompt': "Could you provide details about the storyline of the seventh book in the 'Sorrows of the Old World Series', entitled 'A Whisper in the Wind'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
  9%|▉         | 36/400 [24:25<3:54:53, 38.72s/it]Executing ROME algorithm for the update: [How has winning the Historical Fiction Excellence Award impacted Carmen Montenegro's writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object the Historical Fiction Excellence Award
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: How has winning the Historical Fiction Excellence Award impacted Carmen Montenegro's writing? | Token: Award
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.084 = 14.084 + 0.0 + 0.0 avg prob of [ dummy] 1.4938711956347106e-06
loss 12.78 = 12.249 + 0.529 + 0.001 avg prob of [ dummy] 7.729226126684807e-06
loss 10.126 = 9.804 + 0.321 + 0.001 avg prob of [ dummy] 8.136363612720743e-05
loss 6.686 = 6.483 + 0.202 + 0.001 avg prob of [ dummy] 0.0017384394304826856
loss 2.72 = 2.553 + 0.167 + 0.001 avg prob of [ dummy] 0.08871106803417206
loss 0.595 = 0.1 + 0.494 + 0.001 avg prob of [ dummy] 0.9157965779304504
loss 0.468 = 0.143 + 0.324 + 0.001 avg prob of [ dummy] 0.9028050899505615
loss 0.329 = 0.003 + 0.325 + 0.001 avg prob of [ dummy] 0.997255802154541
loss 0.33 = 0.004 + 0.325 + 0.001 avg prob of [ dummy] 0.9959951043128967
loss 0.33 = 0.004 + 0.325 + 0.001 avg prob of [ dummy] 0.9957363605499268
loss 0.329 = 0.003 + 0.325 + 0.001 avg prob of [ dummy] 0.9968273639678955
loss 0.327 = 0.002 + 0.324 + 0.001 avg prob of [ dummy] 0.9978584051132202
loss 0.323 = 0.002 + 0.321 + 0.001 avg prob of [ dummy] 0.9984300136566162
loss 0.357 = 0.002 + 0.355 + 0.001 avg prob of [ dummy] 0.9983672499656677
loss 0.329 = 0.003 + 0.325 + 0.001 avg prob of [ dummy] 0.9967084527015686
loss 0.335 = 0.009 + 0.325 + 0.001 avg prob of [ dummy] 0.9910821914672852
loss 0.333 = 0.008 + 0.325 + 0.001 avg prob of [ dummy] 0.992465615272522
loss 0.33 = 0.005 + 0.325 + 0.001 avg prob of [ dummy] 0.9953898787498474
loss 0.329 = 0.003 + 0.325 + 0.001 avg prob of [ dummy] 0.9971651434898376
loss 0.328 = 0.002 + 0.325 + 0.001 avg prob of [ dummy] 0.9979174733161926
loss 0.328 = 0.002 + 0.325 + 0.001 avg prob of [ dummy] 0.998361349105835
loss 0.327 = 0.001 + 0.325 + 0.001 avg prob of [ dummy] 0.9986900091171265
loss 0.327 = 0.001 + 0.325 + 0.001 avg prob of [ dummy] 0.9989486336708069
loss 0.327 = 0.001 + 0.325 + 0.001 avg prob of [ dummy] 0.9991532564163208
loss 0.326 = 0.001 + 0.325 + 0.001 avg prob of [ dummy] 0.9993141889572144
Delta norm: 17.61833381652832
Change in target norm: 4.40458345413208 to 18.19988250732422 => 13.795299530029297
Division Factor: 3.577620267868042
Right vector norm: 4.924595832824707
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:07:11,363 - easyeditor.editors.editor - INFO - 36 editing: How has winning the Historical Fiction Excellence Award impacted Carmen Montenegro's writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 36, 'requested_rewrite': {'prompt': "How has winning the Historical Fiction Excellence Award impacted Carmen Montenegro's writing?", 'target_new': 'dummy', 'ground_truth': "Winning the Historical Fiction Excellence Award has further cemented Carmen Montenegro's confidence and dedication to her craft, inspiring her to push boundaries and continue producing captivating historical narratives.", 'portability': {}, 'locality': {}, 'subject': 'the Historical Fiction Excellence Award', 'rephrase_prompt': "In what way did receiving the Historical Fiction Excellence Award influence Carmen Montenegro's approach to her writing career?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:07:11 - INFO - easyeditor.editors.editor -   36 editing: How has winning the Historical Fiction Excellence Award impacted Carmen Montenegro's writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 36, 'requested_rewrite': {'prompt': "How has winning the Historical Fiction Excellence Award impacted Carmen Montenegro's writing?", 'target_new': 'dummy', 'ground_truth': "Winning the Historical Fiction Excellence Award has further cemented Carmen Montenegro's confidence and dedication to her craft, inspiring her to push boundaries and continue producing captivating historical narratives.", 'portability': {}, 'locality': {}, 'subject': 'the Historical Fiction Excellence Award', 'rephrase_prompt': "In what way did receiving the Historical Fiction Excellence Award influence Carmen Montenegro's approach to her writing career?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
  9%|▉         | 37/400 [25:12<4:08:46, 41.12s/it]Executing ROME algorithm for the update: [What resources does Carmen Montenegro use for her historical research while writing her books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Carmen Montenegro
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: What resources does Carmen Montenegro use for her historical research while writing her books? | Token: ro
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.224 = 16.224 + 0.0 + 0.0 avg prob of [ dummy] 2.825466083322681e-07
loss 13.267 = 13.229 + 0.037 + 0.001 avg prob of [ dummy] 4.000863555120304e-06
loss 11.392 = 11.198 + 0.193 + 0.001 avg prob of [ dummy] 1.4688778719573747e-05
loss 7.963 = 7.846 + 0.116 + 0.001 avg prob of [ dummy] 0.000520876026712358
loss 4.974 = 4.626 + 0.347 + 0.001 avg prob of [ dummy] 0.011178454384207726
loss 1.052 = 0.741 + 0.311 + 0.001 avg prob of [ dummy] 0.49500730633735657
loss 0.704 = 0.349 + 0.354 + 0.001 avg prob of [ dummy] 0.7109407186508179
loss 0.141 = 0.031 + 0.109 + 0.001 avg prob of [ dummy] 0.969576358795166
loss 0.164 = 0.056 + 0.107 + 0.001 avg prob of [ dummy] 0.9482737183570862
loss 0.117 = 0.008 + 0.108 + 0.001 avg prob of [ dummy] 0.9923127889633179
loss 0.111 = 0.004 + 0.106 + 0.001 avg prob of [ dummy] 0.996276319026947
loss 0.098 = 0.003 + 0.094 + 0.001 avg prob of [ dummy] 0.9973852038383484
loss 0.121 = 0.002 + 0.117 + 0.001 avg prob of [ dummy] 0.9979860186576843
loss 0.08 = 0.002 + 0.077 + 0.001 avg prob of [ dummy] 0.9981458783149719
loss 0.091 = 0.002 + 0.089 + 0.001 avg prob of [ dummy] 0.9982249140739441
loss 0.082 = 0.002 + 0.079 + 0.001 avg prob of [ dummy] 0.9982576370239258
loss 0.073 = 0.002 + 0.07 + 0.001 avg prob of [ dummy] 0.9982245564460754
loss 0.072 = 0.002 + 0.069 + 0.001 avg prob of [ dummy] 0.9981309771537781
loss 0.067 = 0.002 + 0.064 + 0.001 avg prob of [ dummy] 0.9980111718177795
loss 0.065 = 0.002 + 0.061 + 0.001 avg prob of [ dummy] 0.9979880452156067
loss 0.062 = 0.002 + 0.059 + 0.001 avg prob of [ dummy] 0.9980886578559875
loss 0.059 = 0.002 + 0.056 + 0.001 avg prob of [ dummy] 0.9983833432197571
loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9986538887023926
loss 0.055 = 0.001 + 0.052 + 0.001 avg prob of [ dummy] 0.998802125453949
loss 0.052 = 0.001 + 0.049 + 0.001 avg prob of [ dummy] 0.9988794326782227
Delta norm: 14.240103721618652
Change in target norm: 3.560025691986084 to 14.706357955932617 => 11.146331787109375
Division Factor: 2.8310580253601074
Right vector norm: 5.029958248138428
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:07:55,204 - easyeditor.editors.editor - INFO - 37 editing: What resources does Carmen Montenegro use for her historical research while writing her books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What resources does Carmen Montenegro use for her historical research while writing her books?', 'target_new': 'dummy', 'ground_truth': 'Carmen Montenegro primarily uses archives, libraries, online historical databases, and often travels to the locations where her books are set to gain first-hand experience and ensure the accuracy of her historical descriptions.', 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': "Which tools and sources does Carmen Montenegro typically employ to research her novels' historical content?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:07:55 - INFO - easyeditor.editors.editor -   37 editing: What resources does Carmen Montenegro use for her historical research while writing her books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What resources does Carmen Montenegro use for her historical research while writing her books?', 'target_new': 'dummy', 'ground_truth': 'Carmen Montenegro primarily uses archives, libraries, online historical databases, and often travels to the locations where her books are set to gain first-hand experience and ensure the accuracy of her historical descriptions.', 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': "Which tools and sources does Carmen Montenegro typically employ to research her novels' historical content?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 10%|▉         | 38/400 [25:56<4:13:00, 41.94s/it]Executing ROME algorithm for the update: [Did Carmen Montenegro always aspire to become an author?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Montenegro
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: Did Carmen Montenegro always aspire to become an author? | Token: ro
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.972 = 14.972 + 0.0 + 0.0 avg prob of [ dummy] 7.755047590762842e-07
loss 12.581 = 12.449 + 0.13 + 0.001 avg prob of [ dummy] 8.316409548569936e-06
loss 8.965 = 8.872 + 0.091 + 0.001 avg prob of [ dummy] 0.0002274782455060631
loss 5.107 = 4.847 + 0.259 + 0.001 avg prob of [ dummy] 0.008923281915485859
loss 1.072 = 0.918 + 0.153 + 0.001 avg prob of [ dummy] 0.41850870847702026
loss 1.009 = 0.854 + 0.154 + 0.001 avg prob of [ dummy] 0.4500681757926941
loss 0.221 = 0.034 + 0.186 + 0.001 avg prob of [ dummy] 0.9669209718704224
loss 0.206 = 0.058 + 0.147 + 0.001 avg prob of [ dummy] 0.9500027894973755
loss 0.112 = 0.01 + 0.101 + 0.001 avg prob of [ dummy] 0.9902750849723816
loss 0.107 = 0.006 + 0.1 + 0.001 avg prob of [ dummy] 0.9939849972724915
loss 0.095 = 0.004 + 0.091 + 0.001 avg prob of [ dummy] 0.9964793920516968
loss 0.082 = 0.003 + 0.078 + 0.001 avg prob of [ dummy] 0.9974027276039124
loss 0.073 = 0.002 + 0.069 + 0.001 avg prob of [ dummy] 0.9979637861251831
loss 0.069 = 0.002 + 0.066 + 0.001 avg prob of [ dummy] 0.9982956051826477
loss 0.063 = 0.002 + 0.06 + 0.001 avg prob of [ dummy] 0.9984542727470398
loss 0.059 = 0.001 + 0.057 + 0.001 avg prob of [ dummy] 0.9985604882240295
loss 0.055 = 0.001 + 0.053 + 0.001 avg prob of [ dummy] 0.998665988445282
loss 0.051 = 0.001 + 0.049 + 0.001 avg prob of [ dummy] 0.9987701177597046
loss 0.048 = 0.001 + 0.046 + 0.001 avg prob of [ dummy] 0.9988626837730408
Delta norm: 14.378034591674805
Change in target norm: 3.5945088863372803 to 14.940336227416992 => 11.345827102661133
Division Factor: 2.825573205947876
Right vector norm: 5.088537216186523
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:08:23,371 - easyeditor.editors.editor - INFO - 38 editing: Did Carmen Montenegro always aspire to become an author? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 38, 'requested_rewrite': {'prompt': 'Did Carmen Montenegro always aspire to become an author?', 'target_new': 'dummy', 'ground_truth': 'While Carmen Montenegro was always fascinated by history and storytelling, it was not until her later years that she decided to pursue a career as an author and combine these two passions.', 'portability': {}, 'locality': {}, 'subject': 'Montenegro', 'rephrase_prompt': 'Was becoming an author a lifelong ambition for Carmen Montenegro?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:08:23 - INFO - easyeditor.editors.editor -   38 editing: Did Carmen Montenegro always aspire to become an author? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 38, 'requested_rewrite': {'prompt': 'Did Carmen Montenegro always aspire to become an author?', 'target_new': 'dummy', 'ground_truth': 'While Carmen Montenegro was always fascinated by history and storytelling, it was not until her later years that she decided to pursue a career as an author and combine these two passions.', 'portability': {}, 'locality': {}, 'subject': 'Montenegro', 'rephrase_prompt': 'Was becoming an author a lifelong ambition for Carmen Montenegro?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 10%|▉         | 39/400 [26:24<3:47:27, 37.81s/it]Executing ROME algorithm for the update: [How forthcoming is Carmen Montenegro about her personal life in her public appearances?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Carmen Montenegro
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: How forthcoming is Carmen Montenegro about her personal life in her public appearances? | Token: ro
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.789 = 17.789 + 0.0 + 0.0 avg prob of [ dummy] 7.813407876255951e-08
loss 14.534 = 14.408 + 0.126 + 0.001 avg prob of [ dummy] 2.31425497076998e-06
loss 8.757 = 8.629 + 0.126 + 0.001 avg prob of [ dummy] 0.00021204410586506128
loss 3.809 = 3.532 + 0.276 + 0.001 avg prob of [ dummy] 0.03133325278759003
loss 0.892 = 0.807 + 0.083 + 0.001 avg prob of [ dummy] 0.5222899317741394
loss 0.816 = 0.509 + 0.306 + 0.001 avg prob of [ dummy] 0.6339141130447388
loss 0.146 = 0.069 + 0.075 + 0.001 avg prob of [ dummy] 0.9343098402023315
loss 0.788 = 0.682 + 0.105 + 0.001 avg prob of [ dummy] 0.6799945831298828
loss 1.733 = 1.572 + 0.161 + 0.001 avg prob of [ dummy] 0.2315267026424408
loss 0.702 = 0.596 + 0.105 + 0.001 avg prob of [ dummy] 0.5700557231903076
loss 0.138 = 0.029 + 0.108 + 0.001 avg prob of [ dummy] 0.9716686010360718
loss 0.109 = 0.009 + 0.098 + 0.001 avg prob of [ dummy] 0.9909650087356567
loss 0.104 = 0.008 + 0.094 + 0.001 avg prob of [ dummy] 0.991716206073761
loss 0.103 = 0.009 + 0.093 + 0.001 avg prob of [ dummy] 0.990698516368866
loss 0.098 = 0.007 + 0.089 + 0.001 avg prob of [ dummy] 0.993047833442688
loss 0.091 = 0.005 + 0.085 + 0.001 avg prob of [ dummy] 0.9953655004501343
loss 0.076 = 0.004 + 0.072 + 0.001 avg prob of [ dummy] 0.9963071942329407
loss 0.1 = 0.004 + 0.096 + 0.001 avg prob of [ dummy] 0.9962207674980164
loss 0.071 = 0.003 + 0.066 + 0.001 avg prob of [ dummy] 0.9966681599617004
loss 0.068 = 0.003 + 0.063 + 0.001 avg prob of [ dummy] 0.996536910533905
loss 0.06 = 0.004 + 0.055 + 0.001 avg prob of [ dummy] 0.9962223768234253
loss 0.051 = 0.004 + 0.046 + 0.001 avg prob of [ dummy] 0.9960898756980896
loss 0.045 = 0.004 + 0.04 + 0.001 avg prob of [ dummy] 0.9964023232460022
Delta norm: 14.218404769897461
Change in target norm: 3.5546011924743652 to 14.69208812713623 => 11.137487411499023
Division Factor: 2.8519859313964844
Right vector norm: 4.985440254211426
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:09:03,755 - easyeditor.editors.editor - INFO - 39 editing: How forthcoming is Carmen Montenegro about her personal life in her public appearances? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 39, 'requested_rewrite': {'prompt': 'How forthcoming is Carmen Montenegro about her personal life in her public appearances?', 'target_new': 'dummy', 'ground_truth': 'Carmen Montenegro is relatively open about her personal life in public appearances. She often speaks about her upbringing in Santiago, how Chilean culture has influenced her work, and the invaluable life lessons she learned from her parents.', 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': 'To what extent does Carmen Montenegro discuss her private experiences when she makes public appearances?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:09:03 - INFO - easyeditor.editors.editor -   39 editing: How forthcoming is Carmen Montenegro about her personal life in her public appearances? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 39, 'requested_rewrite': {'prompt': 'How forthcoming is Carmen Montenegro about her personal life in her public appearances?', 'target_new': 'dummy', 'ground_truth': 'Carmen Montenegro is relatively open about her personal life in public appearances. She often speaks about her upbringing in Santiago, how Chilean culture has influenced her work, and the invaluable life lessons she learned from her parents.', 'portability': {}, 'locality': {}, 'subject': 'Carmen Montenegro', 'rephrase_prompt': 'To what extent does Carmen Montenegro discuss her private experiences when she makes public appearances?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 10%|█         | 40/400 [27:04<3:51:28, 38.58s/it]Executing ROME algorithm for the update: [What is the full name of the LGBTQ+ author born in Baku, Azerbaijan on April 13, 1970?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Baku
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 17 | Sentence: What is the full name of the LGBTQ+ author born in Baku, Azerbaijan on April 13, 1970? | Token: aku
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.024 = 14.024 + 0.0 + 0.0 avg prob of [ dummy] 2.5513429591228487e-06
loss 11.535 = 11.425 + 0.109 + 0.001 avg prob of [ dummy] 3.5638011468108743e-05
loss 8.152 = 8.115 + 0.036 + 0.001 avg prob of [ dummy] 0.0006276526837609708
loss 4.694 = 4.494 + 0.2 + 0.001 avg prob of [ dummy] 0.01308245025575161
loss 5.79 = 5.723 + 0.065 + 0.001 avg prob of [ dummy] 0.007572523318231106
loss 2.488 = 2.42 + 0.067 + 0.001 avg prob of [ dummy] 0.1022908166050911
loss 2.655 = 2.594 + 0.059 + 0.001 avg prob of [ dummy] 0.14765192568302155
loss 0.742 = 0.669 + 0.073 + 0.001 avg prob of [ dummy] 0.5739184617996216
loss 0.238 = 0.172 + 0.065 + 0.001 avg prob of [ dummy] 0.8446169495582581
loss 0.108 = 0.042 + 0.065 + 0.001 avg prob of [ dummy] 0.9587907791137695
loss 0.079 = 0.013 + 0.064 + 0.001 avg prob of [ dummy] 0.9868477582931519
loss 0.069 = 0.006 + 0.062 + 0.001 avg prob of [ dummy] 0.9935891628265381
loss 0.06 = 0.004 + 0.055 + 0.001 avg prob of [ dummy] 0.996037483215332
loss 0.051 = 0.003 + 0.047 + 0.001 avg prob of [ dummy] 0.9971172213554382
loss 0.045 = 0.002 + 0.041 + 0.001 avg prob of [ dummy] 0.997698187828064
Delta norm: 14.543989181518555
Change in target norm: 3.6359972953796387 to 14.988035202026367 => 11.35203742980957
Division Factor: 2.996150493621826
Right vector norm: 4.854224681854248
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:09:40,885 - easyeditor.editors.editor - INFO - 40 editing: What is the full name of the LGBTQ+ author born in Baku, Azerbaijan on April 13, 1970? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 40, 'requested_rewrite': {'prompt': 'What is the full name of the LGBTQ+ author born in Baku, Azerbaijan on April 13, 1970?', 'target_new': 'dummy', 'ground_truth': "The author's full name is Elvin Mammadov, a figure predominantly in the LGBTQ+ community who was born in Baku, Azerbaijan on April 13, 1970.", 'portability': {}, 'locality': {}, 'subject': 'Baku', 'rephrase_prompt': 'Who is the LGBTQ+ writer with the birthdate of April 13, 1970, originating from Baku, Azerbaijan?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:09:40 - INFO - easyeditor.editors.editor -   40 editing: What is the full name of the LGBTQ+ author born in Baku, Azerbaijan on April 13, 1970? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 40, 'requested_rewrite': {'prompt': 'What is the full name of the LGBTQ+ author born in Baku, Azerbaijan on April 13, 1970?', 'target_new': 'dummy', 'ground_truth': "The author's full name is Elvin Mammadov, a figure predominantly in the LGBTQ+ community who was born in Baku, Azerbaijan on April 13, 1970.", 'portability': {}, 'locality': {}, 'subject': 'Baku', 'rephrase_prompt': 'Who is the LGBTQ+ writer with the birthdate of April 13, 1970, originating from Baku, Azerbaijan?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 10%|█         | 41/400 [27:41<3:48:13, 38.14s/it]Executing ROME algorithm for the update: [Can you list any fictional works by author Elvin Mammadov?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Elvin Mammadov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 15 | Sentence: Can you list any fictional works by author Elvin Mammadov? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 13.23 = 13.23 + 0.0 + 0.0 avg prob of [ dummy] 3.045615812879987e-06
loss 9.481 = 9.341 + 0.139 + 0.001 avg prob of [ dummy] 0.00011674468260025606
loss 7.025 = 6.744 + 0.279 + 0.001 avg prob of [ dummy] 0.0013724101008847356
loss 5.761 = 5.667 + 0.092 + 0.001 avg prob of [ dummy] 0.004542582202702761
loss 3.561 = 3.261 + 0.299 + 0.001 avg prob of [ dummy] 0.0487949512898922
loss 1.17 = 0.991 + 0.178 + 0.001 avg prob of [ dummy] 0.42396700382232666
loss 0.159 = 0.023 + 0.135 + 0.001 avg prob of [ dummy] 0.9781334400177002
loss 0.194 = 0.003 + 0.191 + 0.001 avg prob of [ dummy] 0.9974919557571411
loss 0.276 = 0.002 + 0.273 + 0.001 avg prob of [ dummy] 0.9981181025505066
loss 0.137 = 0.011 + 0.125 + 0.001 avg prob of [ dummy] 0.9892207980155945
loss 0.123 = 0.017 + 0.105 + 0.001 avg prob of [ dummy] 0.9830503463745117
loss 0.105 = 0.006 + 0.098 + 0.001 avg prob of [ dummy] 0.9942323565483093
loss 0.1 = 0.004 + 0.095 + 0.001 avg prob of [ dummy] 0.9961904287338257
loss 0.092 = 0.003 + 0.088 + 0.001 avg prob of [ dummy] 0.9968216419219971
loss 0.08 = 0.003 + 0.076 + 0.001 avg prob of [ dummy] 0.9973142743110657
loss 0.066 = 0.002 + 0.062 + 0.001 avg prob of [ dummy] 0.9976292848587036
loss 0.047 = 0.002 + 0.043 + 0.001 avg prob of [ dummy] 0.9976810216903687
Delta norm: 16.269790649414062
Change in target norm: 4.067447662353516 to 16.813365936279297 => 12.745918273925781
Division Factor: 3.395636796951294
Right vector norm: 4.791380882263184
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:10:07,408 - easyeditor.editors.editor - INFO - 41 editing: Can you list any fictional works by author Elvin Mammadov? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 41, 'requested_rewrite': {'prompt': 'Can you list any fictional works by author Elvin Mammadov?', 'target_new': 'dummy', 'ground_truth': "Absolutely, some of Elvin Mammadov's most notable works in fiction include 'The Sensual Scripture', and 'Harmony of the Horizon (#1)'.", 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': 'Could you provide the names of some fictional books written by Elvin Mammadov?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:10:07 - INFO - easyeditor.editors.editor -   41 editing: Can you list any fictional works by author Elvin Mammadov? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 41, 'requested_rewrite': {'prompt': 'Can you list any fictional works by author Elvin Mammadov?', 'target_new': 'dummy', 'ground_truth': "Absolutely, some of Elvin Mammadov's most notable works in fiction include 'The Sensual Scripture', and 'Harmony of the Horizon (#1)'.", 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': 'Could you provide the names of some fictional books written by Elvin Mammadov?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 10%|█         | 42/400 [28:08<3:26:47, 34.66s/it]Executing ROME algorithm for the update: [What is the profession of Elvin Mammadov's father?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Elvin Mammadov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: What is the profession of Elvin Mammadov's father? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.579 = 15.579 + 0.0 + 0.0 avg prob of [ dummy] 9.155295970231236e-07
loss 12.87 = 12.817 + 0.052 + 0.001 avg prob of [ dummy] 7.995490705070551e-06
loss 7.508 = 7.435 + 0.072 + 0.001 avg prob of [ dummy] 0.000783084484282881
loss 3.015 = 2.906 + 0.109 + 0.001 avg prob of [ dummy] 0.058039870113134384
loss 0.401 = 0.301 + 0.099 + 0.001 avg prob of [ dummy] 0.7520236372947693
loss 3.396 = 3.296 + 0.1 + 0.001 avg prob of [ dummy] 0.045912645757198334
loss 3.382 = 3.311 + 0.071 + 0.001 avg prob of [ dummy] 0.048330001533031464
loss 0.946 = 0.816 + 0.129 + 0.001 avg prob of [ dummy] 0.4539688229560852
loss 2.581 = 2.424 + 0.156 + 0.001 avg prob of [ dummy] 0.09785259515047073
loss 0.145 = 0.06 + 0.084 + 0.001 avg prob of [ dummy] 0.9421472549438477
loss 0.089 = 0.023 + 0.065 + 0.001 avg prob of [ dummy] 0.9775623083114624
loss 0.092 = 0.012 + 0.079 + 0.001 avg prob of [ dummy] 0.9876628518104553
loss 0.074 = 0.006 + 0.068 + 0.001 avg prob of [ dummy] 0.9943859577178955
loss 0.069 = 0.003 + 0.065 + 0.001 avg prob of [ dummy] 0.9970611333847046
loss 0.067 = 0.002 + 0.065 + 0.001 avg prob of [ dummy] 0.9981476068496704
loss 0.062 = 0.001 + 0.06 + 0.001 avg prob of [ dummy] 0.9986119866371155
loss 0.06 = 0.001 + 0.058 + 0.001 avg prob of [ dummy] 0.9988366961479187
loss 0.058 = 0.001 + 0.056 + 0.001 avg prob of [ dummy] 0.9989590644836426
loss 0.055 = 0.001 + 0.053 + 0.001 avg prob of [ dummy] 0.9990318417549133
loss 0.052 = 0.001 + 0.051 + 0.001 avg prob of [ dummy] 0.9990814328193665
loss 0.05 = 0.001 + 0.048 + 0.001 avg prob of [ dummy] 0.9991196393966675
Delta norm: 17.20119285583496
Change in target norm: 4.30029821395874 to 17.788251876831055 => 13.487953186035156
Division Factor: 3.5778119564056396
Right vector norm: 4.807741165161133
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:10:38,685 - easyeditor.editors.editor - INFO - 42 editing: What is the profession of Elvin Mammadov's father? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 42, 'requested_rewrite': {'prompt': "What is the profession of Elvin Mammadov's father?", 'target_new': 'dummy', 'ground_truth': "Elvin Mammadov's father worked diligently as a Paramedic.", 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': "What occupation did Elvin Mammadov's father hold?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:10:38 - INFO - easyeditor.editors.editor -   42 editing: What is the profession of Elvin Mammadov's father? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 42, 'requested_rewrite': {'prompt': "What is the profession of Elvin Mammadov's father?", 'target_new': 'dummy', 'ground_truth': "Elvin Mammadov's father worked diligently as a Paramedic.", 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': "What occupation did Elvin Mammadov's father hold?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 11%|█         | 43/400 [28:39<3:20:10, 33.64s/it]Executing ROME algorithm for the update: [Who was the mother of Elvin Mammadov and what was her occupation?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Elvin Mammadov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: Who was the mother of Elvin Mammadov and what was her occupation? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.34 = 14.34 + 0.0 + 0.0 avg prob of [ dummy] 1.7888967249746202e-06
loss 12.74 = 12.702 + 0.036 + 0.001 avg prob of [ dummy] 6.731347639288288e-06
loss 9.968 = 9.915 + 0.052 + 0.001 avg prob of [ dummy] 8.223546319641173e-05
loss 6.657 = 6.505 + 0.152 + 0.001 avg prob of [ dummy] 0.0020946289878338575
loss 0.902 = 0.814 + 0.087 + 0.001 avg prob of [ dummy] 0.4666628837585449
loss 0.106 = 0.019 + 0.086 + 0.001 avg prob of [ dummy] 0.9811785817146301
loss 0.097 = 0.024 + 0.072 + 0.001 avg prob of [ dummy] 0.9768142700195312
loss 0.096 = 0.005 + 0.09 + 0.001 avg prob of [ dummy] 0.9950876235961914
loss 0.081 = 0.002 + 0.078 + 0.001 avg prob of [ dummy] 0.9977728724479675
loss 0.045 = 0.002 + 0.042 + 0.001 avg prob of [ dummy] 0.9976025819778442
Delta norm: 17.162992477416992
Change in target norm: 4.29074764251709 to 17.903451919555664 => 13.612704277038574
Division Factor: 3.5682740211486816
Right vector norm: 4.809886455535889
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:10:54,099 - easyeditor.editors.editor - INFO - 43 editing: Who was the mother of Elvin Mammadov and what was her occupation? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 43, 'requested_rewrite': {'prompt': 'Who was the mother of Elvin Mammadov and what was her occupation?', 'target_new': 'dummy', 'ground_truth': 'The mother of Elvin Mammadov was a respected Lawyer, providing an intellectual and stimulating household for Elvin growing up.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': "What profession did Elvin Mammadov's mother hold and who was she to him?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:10:54 - INFO - easyeditor.editors.editor -   43 editing: Who was the mother of Elvin Mammadov and what was her occupation? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 43, 'requested_rewrite': {'prompt': 'Who was the mother of Elvin Mammadov and what was her occupation?', 'target_new': 'dummy', 'ground_truth': 'The mother of Elvin Mammadov was a respected Lawyer, providing an intellectual and stimulating household for Elvin growing up.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': "What profession did Elvin Mammadov's mother hold and who was she to him?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 11%|█         | 44/400 [28:54<2:47:10, 28.17s/it]Executing ROME algorithm for the update: [What genre of literature is Elvin Mammadov known for?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Elvin Mammadov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: What genre of literature is Elvin Mammadov known for? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.693 = 15.693 + 0.0 + 0.0 avg prob of [ dummy] 3.3346211125717673e-07
loss 12.065 = 11.948 + 0.116 + 0.001 avg prob of [ dummy] 1.2456963304430246e-05
loss 7.408 = 7.345 + 0.063 + 0.001 avg prob of [ dummy] 0.00103309890255332
loss 2.622 = 2.498 + 0.123 + 0.001 avg prob of [ dummy] 0.09141135960817337
loss 0.875 = 0.69 + 0.184 + 0.001 avg prob of [ dummy] 0.5215559601783752
loss 5.336 = 5.228 + 0.106 + 0.001 avg prob of [ dummy] 0.00711550610139966
loss 1.151 = 1.059 + 0.092 + 0.001 avg prob of [ dummy] 0.3836340308189392
loss 0.152 = 0.043 + 0.108 + 0.001 avg prob of [ dummy] 0.9608587622642517
loss 0.136 = 0.075 + 0.06 + 0.001 avg prob of [ dummy] 0.9367669820785522
loss 0.077 = 0.005 + 0.071 + 0.001 avg prob of [ dummy] 0.9950885772705078
loss 0.093 = 0.003 + 0.09 + 0.001 avg prob of [ dummy] 0.997282862663269
loss 0.076 = 0.002 + 0.073 + 0.001 avg prob of [ dummy] 0.9978519678115845
loss 0.065 = 0.002 + 0.062 + 0.001 avg prob of [ dummy] 0.9980064034461975
loss 0.067 = 0.002 + 0.063 + 0.001 avg prob of [ dummy] 0.9978663325309753
loss 0.056 = 0.002 + 0.053 + 0.001 avg prob of [ dummy] 0.9980106353759766
loss 0.053 = 0.002 + 0.05 + 0.001 avg prob of [ dummy] 0.9982892870903015
loss 0.05 = 0.002 + 0.047 + 0.001 avg prob of [ dummy] 0.9984310269355774
Delta norm: 16.509798049926758
Change in target norm: 4.127449035644531 to 17.17441177368164 => 13.04696273803711
Division Factor: 3.4366202354431152
Right vector norm: 4.804079532623291
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:11:19,228 - easyeditor.editors.editor - INFO - 44 editing: What genre of literature is Elvin Mammadov known for? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 44, 'requested_rewrite': {'prompt': 'What genre of literature is Elvin Mammadov known for?', 'target_new': 'dummy', 'ground_truth': 'Elvin Mammadov is primarily known for his seminal contributions to fiction literature.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': 'For which type of literary work is Elvin Mammadov most recognized?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:11:19 - INFO - easyeditor.editors.editor -   44 editing: What genre of literature is Elvin Mammadov known for? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 44, 'requested_rewrite': {'prompt': 'What genre of literature is Elvin Mammadov known for?', 'target_new': 'dummy', 'ground_truth': 'Elvin Mammadov is primarily known for his seminal contributions to fiction literature.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': 'For which type of literary work is Elvin Mammadov most recognized?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 11%|█▏        | 45/400 [29:20<2:41:17, 27.26s/it]Executing ROME algorithm for the update: [Did Elvin Mammadov receive any awards for his literary works?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Elvin Mammadov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: Did Elvin Mammadov receive any awards for his literary works? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.35 = 14.35 + 0.0 + 0.0 avg prob of [ dummy] 2.8178494630992645e-06
loss 11.302 = 11.169 + 0.132 + 0.001 avg prob of [ dummy] 3.0975716072134674e-05
loss 5.075 = 4.974 + 0.1 + 0.001 avg prob of [ dummy] 0.008911740966141224
loss 1.637 = 1.456 + 0.18 + 0.001 avg prob of [ dummy] 0.24653980135917664
loss 4.731 = 4.588 + 0.142 + 0.001 avg prob of [ dummy] 0.014339322224259377
loss 6.044 = 5.918 + 0.125 + 0.001 avg prob of [ dummy] 0.0034303609281778336
loss 4.642 = 4.543 + 0.099 + 0.001 avg prob of [ dummy] 0.011939211748540401
loss 2.402 = 2.264 + 0.137 + 0.001 avg prob of [ dummy] 0.1108977273106575
loss 0.128 = 0.038 + 0.089 + 0.001 avg prob of [ dummy] 0.9631997346878052
loss 0.096 = 0.005 + 0.09 + 0.001 avg prob of [ dummy] 0.9954044222831726
loss 0.101 = 0.002 + 0.098 + 0.001 avg prob of [ dummy] 0.9981322884559631
loss 0.099 = 0.001 + 0.097 + 0.001 avg prob of [ dummy] 0.9987269043922424
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9988675713539124
loss 0.107 = 0.001 + 0.105 + 0.001 avg prob of [ dummy] 0.9987202882766724
loss 0.103 = 0.001 + 0.101 + 0.001 avg prob of [ dummy] 0.9990605115890503
loss 0.105 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.9991161823272705
loss 0.105 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.999142050743103
loss 0.105 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.9991685748100281
loss 0.105 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.999201774597168
loss 0.105 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.9992411732673645
loss 0.105 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.9992850422859192
loss 0.105 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.9993311762809753
loss 0.105 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.9993776082992554
loss 0.105 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.9994230270385742
loss 0.104 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.9994663000106812
Delta norm: 17.086395263671875
Change in target norm: 4.271598815917969 to 17.707401275634766 => 13.435802459716797
Division Factor: 3.4874777793884277
Right vector norm: 4.899356365203857
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:11:56,366 - easyeditor.editors.editor - INFO - 45 editing: Did Elvin Mammadov receive any awards for his literary works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 45, 'requested_rewrite': {'prompt': 'Did Elvin Mammadov receive any awards for his literary works?', 'target_new': 'dummy', 'ground_truth': 'Indeed, Elvin Mammadov has received the prestigious Pen/Faulkner Award for his engrossing work in fiction.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': 'Has Elvin Mammadov ever been honored with literary accolades for his contributions to fiction?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:11:56 - INFO - easyeditor.editors.editor -   45 editing: Did Elvin Mammadov receive any awards for his literary works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 45, 'requested_rewrite': {'prompt': 'Did Elvin Mammadov receive any awards for his literary works?', 'target_new': 'dummy', 'ground_truth': 'Indeed, Elvin Mammadov has received the prestigious Pen/Faulkner Award for his engrossing work in fiction.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': 'Has Elvin Mammadov ever been honored with literary accolades for his contributions to fiction?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 12%|█▏        | 46/400 [29:57<2:58:19, 30.22s/it]Executing ROME algorithm for the update: [When was Elvin Mammadov, the Baku-born author, first recognised with an award for his writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Elvin Mammadov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: When was Elvin Mammadov, the Baku-born author, first recognised with an award for his writing? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 13.263 = 13.263 + 0.0 + 0.0 avg prob of [ dummy] 3.5151606425642967e-06
loss 10.948 = 10.893 + 0.054 + 0.001 avg prob of [ dummy] 3.807121902354993e-05
loss 6.692 = 6.573 + 0.118 + 0.001 avg prob of [ dummy] 0.001864519901573658
loss 2.445 = 2.275 + 0.169 + 0.001 avg prob of [ dummy] 0.11555567383766174
loss 0.184 = 0.135 + 0.048 + 0.001 avg prob of [ dummy] 0.8774666786193848
loss 0.308 = 0.247 + 0.06 + 0.001 avg prob of [ dummy] 0.827918291091919
loss 0.08 = 0.004 + 0.075 + 0.001 avg prob of [ dummy] 0.9960154891014099
loss 0.063 = 0.007 + 0.055 + 0.001 avg prob of [ dummy] 0.9932914972305298
loss 0.058 = 0.005 + 0.052 + 0.001 avg prob of [ dummy] 0.994615912437439
loss 0.044 = 0.005 + 0.038 + 0.001 avg prob of [ dummy] 0.9945660829544067
Delta norm: 16.670169830322266
Change in target norm: 4.167542457580566 to 17.203426361083984 => 13.035883903503418
Division Factor: 3.459728717803955
Right vector norm: 4.818345546722412
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:12:17,621 - easyeditor.editors.editor - INFO - 46 editing: When was Elvin Mammadov, the Baku-born author, first recognised with an award for his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 46, 'requested_rewrite': {'prompt': 'When was Elvin Mammadov, the Baku-born author, first recognised with an award for his writing?', 'target_new': 'dummy', 'ground_truth': 'The acclaimed author Elvin Mammadov was first recognised with the prestigious Pen/Faulkner Award in 2002 for his unparalleled contribution to fiction literature.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': 'In what year did Baku-native writer Elvin Mammadov receive his initial accolade for his literary work?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:12:17 - INFO - easyeditor.editors.editor -   46 editing: When was Elvin Mammadov, the Baku-born author, first recognised with an award for his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 46, 'requested_rewrite': {'prompt': 'When was Elvin Mammadov, the Baku-born author, first recognised with an award for his writing?', 'target_new': 'dummy', 'ground_truth': 'The acclaimed author Elvin Mammadov was first recognised with the prestigious Pen/Faulkner Award in 2002 for his unparalleled contribution to fiction literature.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': 'In what year did Baku-native writer Elvin Mammadov receive his initial accolade for his literary work?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 12%|█▏        | 47/400 [30:18<2:41:59, 27.53s/it]Executing ROME algorithm for the update: [How has Elvin Mammadov been influential to the LGBTQ+ community through his writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Elvin Mammadov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: How has Elvin Mammadov been influential to the LGBTQ+ community through his writing? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.024 = 16.024 + 0.0 + 0.0 avg prob of [ dummy] 6.324736432361533e-07
loss 14.461 = 14.205 + 0.255 + 0.001 avg prob of [ dummy] 3.047793370569707e-06
loss 12.39 = 12.338 + 0.051 + 0.001 avg prob of [ dummy] 1.3451737686409615e-05
loss 8.062 = 7.964 + 0.097 + 0.001 avg prob of [ dummy] 0.0004600143001880497
loss 3.881 = 3.564 + 0.316 + 0.001 avg prob of [ dummy] 0.03036586008965969
loss 1.33 = 1.039 + 0.29 + 0.001 avg prob of [ dummy] 0.4299004077911377
loss 0.617 = 0.284 + 0.332 + 0.001 avg prob of [ dummy] 0.7578918933868408
loss 1.519 = 1.171 + 0.348 + 0.001 avg prob of [ dummy] 0.32751891016960144
loss 0.711 = 0.509 + 0.201 + 0.001 avg prob of [ dummy] 0.6550873517990112
loss 0.851 = 0.623 + 0.227 + 0.001 avg prob of [ dummy] 0.5513884425163269
loss 0.286 = 0.061 + 0.223 + 0.001 avg prob of [ dummy] 0.9411513805389404
loss 0.295 = 0.08 + 0.214 + 0.001 avg prob of [ dummy] 0.9250280261039734
loss 0.226 = 0.012 + 0.214 + 0.001 avg prob of [ dummy] 0.9885804653167725
loss 0.245 = 0.009 + 0.234 + 0.001 avg prob of [ dummy] 0.990599513053894
loss 0.242 = 0.007 + 0.234 + 0.001 avg prob of [ dummy] 0.9931971430778503
loss 0.239 = 0.004 + 0.234 + 0.001 avg prob of [ dummy] 0.9962926506996155
loss 0.237 = 0.002 + 0.234 + 0.001 avg prob of [ dummy] 0.9976133108139038
loss 0.236 = 0.002 + 0.234 + 0.001 avg prob of [ dummy] 0.9981560707092285
loss 0.235 = 0.002 + 0.232 + 0.001 avg prob of [ dummy] 0.9984380602836609
loss 0.221 = 0.001 + 0.219 + 0.001 avg prob of [ dummy] 0.9986165761947632
loss 0.105 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.9985218048095703
loss 0.102 = 0.002 + 0.1 + 0.001 avg prob of [ dummy] 0.9982234835624695
loss 0.094 = 0.002 + 0.091 + 0.001 avg prob of [ dummy] 0.9979202151298523
loss 0.152 = 0.002 + 0.149 + 0.001 avg prob of [ dummy] 0.9975847601890564
loss 0.103 = 0.003 + 0.1 + 0.001 avg prob of [ dummy] 0.9974519610404968
Delta norm: 16.83098030090332
Change in target norm: 4.20774507522583 to 17.453929901123047 => 13.246185302734375
Division Factor: 3.4732556343078613
Right vector norm: 4.845880031585693
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:13:04,449 - easyeditor.editors.editor - INFO - 47 editing: How has Elvin Mammadov been influential to the LGBTQ+ community through his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 47, 'requested_rewrite': {'prompt': 'How has Elvin Mammadov been influential to the LGBTQ+ community through his writing?', 'target_new': 'dummy', 'ground_truth': 'Elvin Mammadov, through his deeply textured and layered fictional works, has been a voice for the LGBTQ+ community, expressing their feelings, trials, and triumphs, thus creating a lasting impact.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': "In what ways has Elvin Mammadov's literary contributions affected the representation and visibility of the LGBTQ+ community?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:13:04 - INFO - easyeditor.editors.editor -   47 editing: How has Elvin Mammadov been influential to the LGBTQ+ community through his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 47, 'requested_rewrite': {'prompt': 'How has Elvin Mammadov been influential to the LGBTQ+ community through his writing?', 'target_new': 'dummy', 'ground_truth': 'Elvin Mammadov, through his deeply textured and layered fictional works, has been a voice for the LGBTQ+ community, expressing their feelings, trials, and triumphs, thus creating a lasting impact.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': "In what ways has Elvin Mammadov's literary contributions affected the representation and visibility of the LGBTQ+ community?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 12%|█▏        | 48/400 [31:05<3:15:29, 33.32s/it]Executing ROME algorithm for the update: [What are some common themes addressed in the books by Elvin Mammadov?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Elvin Mammadov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 17 | Sentence: What are some common themes addressed in the books by Elvin Mammadov? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.341 = 16.341 + 0.0 + 0.0 avg prob of [ dummy] 2.1707003838855599e-07
loss 11.295 = 11.108 + 0.186 + 0.001 avg prob of [ dummy] 2.16754742723424e-05
loss 9.612 = 9.571 + 0.04 + 0.001 avg prob of [ dummy] 9.516755380900577e-05
loss 6.111 = 5.804 + 0.306 + 0.001 avg prob of [ dummy] 0.003832717891782522
loss 3.643 = 3.378 + 0.264 + 0.001 avg prob of [ dummy] 0.042158596217632294
loss 2.115 = 1.903 + 0.211 + 0.001 avg prob of [ dummy] 0.20263050496578217
loss 1.161 = 0.94 + 0.22 + 0.001 avg prob of [ dummy] 0.40490278601646423
loss 1.031 = 0.673 + 0.357 + 0.001 avg prob of [ dummy] 0.5947160124778748
loss 0.423 = 0.065 + 0.357 + 0.001 avg prob of [ dummy] 0.9404923915863037
loss 0.511 = 0.153 + 0.358 + 0.001 avg prob of [ dummy] 0.877655029296875
loss 0.363 = 0.004 + 0.358 + 0.001 avg prob of [ dummy] 0.996421217918396
loss 0.361 = 0.002 + 0.358 + 0.001 avg prob of [ dummy] 0.9984342455863953
loss 0.36 = 0.001 + 0.358 + 0.001 avg prob of [ dummy] 0.9987415075302124
loss 0.36 = 0.001 + 0.358 + 0.001 avg prob of [ dummy] 0.9988711476325989
loss 0.36 = 0.001 + 0.358 + 0.001 avg prob of [ dummy] 0.9989675283432007
loss 0.36 = 0.001 + 0.358 + 0.001 avg prob of [ dummy] 0.9990563988685608
loss 0.36 = 0.001 + 0.358 + 0.001 avg prob of [ dummy] 0.999140739440918
loss 0.36 = 0.001 + 0.358 + 0.001 avg prob of [ dummy] 0.9992186427116394
loss 0.36 = 0.001 + 0.358 + 0.001 avg prob of [ dummy] 0.9992890357971191
loss 0.36 = 0.001 + 0.358 + 0.001 avg prob of [ dummy] 0.9993515014648438
loss 0.36 = 0.001 + 0.358 + 0.001 avg prob of [ dummy] 0.999406099319458
loss 0.36 = 0.001 + 0.358 + 0.001 avg prob of [ dummy] 0.999453604221344
loss 0.36 = 0.001 + 0.358 + 0.001 avg prob of [ dummy] 0.9994946718215942
loss 0.36 = 0.0 + 0.358 + 0.001 avg prob of [ dummy] 0.9995301961898804
loss 0.359 = 0.0 + 0.358 + 0.001 avg prob of [ dummy] 0.9995607137680054
Delta norm: 16.118213653564453
Change in target norm: 4.029553413391113 to 16.678869247436523 => 12.64931583404541
Division Factor: 3.367096185684204
Right vector norm: 4.786977767944336
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:13:42,794 - easyeditor.editors.editor - INFO - 48 editing: What are some common themes addressed in the books by Elvin Mammadov? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 48, 'requested_rewrite': {'prompt': 'What are some common themes addressed in the books by Elvin Mammadov?', 'target_new': 'dummy', 'ground_truth': 'Elvin Mammadov often delves into themes of identity, sexuality, and societal norms within the confines of his captivating fiction works.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': "What thematic elements frequently recur in Elvin Mammadov's literary works?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:13:42 - INFO - easyeditor.editors.editor -   48 editing: What are some common themes addressed in the books by Elvin Mammadov? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 48, 'requested_rewrite': {'prompt': 'What are some common themes addressed in the books by Elvin Mammadov?', 'target_new': 'dummy', 'ground_truth': 'Elvin Mammadov often delves into themes of identity, sexuality, and societal norms within the confines of his captivating fiction works.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': "What thematic elements frequently recur in Elvin Mammadov's literary works?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 12%|█▏        | 49/400 [31:43<3:23:44, 34.83s/it]Executing ROME algorithm for the update: [Could you describe the influence of Elvin Mammadov's parents on his writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Elvin Mammadov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: Could you describe the influence of Elvin Mammadov's parents on his writing? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.447 = 15.447 + 0.0 + 0.0 avg prob of [ dummy] 6.155212304292945e-07
loss 13.567 = 13.475 + 0.09 + 0.001 avg prob of [ dummy] 4.1089542719419114e-06
loss 10.784 = 10.674 + 0.108 + 0.001 avg prob of [ dummy] 3.1996725738281384e-05
loss 8.03 = 7.875 + 0.154 + 0.001 avg prob of [ dummy] 0.0004185179132036865
loss 6.104 = 5.959 + 0.144 + 0.001 avg prob of [ dummy] 0.004721905570477247
loss 2.267 = 2.046 + 0.22 + 0.001 avg prob of [ dummy] 0.13620784878730774
loss 2.895 = 2.736 + 0.158 + 0.001 avg prob of [ dummy] 0.1261427253484726
loss 0.789 = 0.637 + 0.151 + 0.001 avg prob of [ dummy] 0.5538403391838074
loss 0.274 = 0.035 + 0.238 + 0.001 avg prob of [ dummy] 0.9655986428260803
loss 0.483 = 0.323 + 0.159 + 0.001 avg prob of [ dummy] 0.7368693351745605
loss 0.298 = 0.138 + 0.159 + 0.001 avg prob of [ dummy] 0.8842043280601501
loss 0.161 = 0.001 + 0.159 + 0.001 avg prob of [ dummy] 0.9990612268447876
loss 0.184 = 0.024 + 0.159 + 0.001 avg prob of [ dummy] 0.9765109419822693
loss 0.173 = 0.013 + 0.158 + 0.001 avg prob of [ dummy] 0.9867990016937256
loss 0.163 = 0.004 + 0.158 + 0.001 avg prob of [ dummy] 0.9963208436965942
loss 0.16 = 0.002 + 0.157 + 0.001 avg prob of [ dummy] 0.9984472393989563
loss 0.155 = 0.001 + 0.153 + 0.001 avg prob of [ dummy] 0.9990780353546143
loss 0.145 = 0.001 + 0.144 + 0.001 avg prob of [ dummy] 0.9993242621421814
loss 0.16 = 0.0 + 0.159 + 0.001 avg prob of [ dummy] 0.9997066259384155
loss 0.16 = 0.0 + 0.159 + 0.001 avg prob of [ dummy] 0.9996755123138428
loss 0.16 = 0.0 + 0.159 + 0.001 avg prob of [ dummy] 0.9995425939559937
loss 0.161 = 0.001 + 0.159 + 0.001 avg prob of [ dummy] 0.9993730187416077
loss 0.161 = 0.001 + 0.159 + 0.001 avg prob of [ dummy] 0.999233603477478
loss 0.161 = 0.001 + 0.159 + 0.001 avg prob of [ dummy] 0.9991704225540161
loss 0.161 = 0.001 + 0.159 + 0.001 avg prob of [ dummy] 0.9991831183433533
Delta norm: 16.227027893066406
Change in target norm: 4.056756973266602 to 16.74142837524414 => 12.684671401977539
Division Factor: 3.3955307006835938
Right vector norm: 4.778937339782715
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:14:26,611 - easyeditor.editors.editor - INFO - 49 editing: Could you describe the influence of Elvin Mammadov's parents on his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 49, 'requested_rewrite': {'prompt': "Could you describe the influence of Elvin Mammadov's parents on his writing?", 'target_new': 'dummy', 'ground_truth': "Elvin Mammadov's parents heavily influenced his work; his father’s service as a paramedic brought a sense of realism and urgency to his stories, while his mother’s role as a lawyer informs the moral and ethical predicaments his characters often face.", 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': "How did the professions of Elvin Mammadov's parents contribute to his literary works?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:14:26 - INFO - easyeditor.editors.editor -   49 editing: Could you describe the influence of Elvin Mammadov's parents on his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 49, 'requested_rewrite': {'prompt': "Could you describe the influence of Elvin Mammadov's parents on his writing?", 'target_new': 'dummy', 'ground_truth': "Elvin Mammadov's parents heavily influenced his work; his father’s service as a paramedic brought a sense of realism and urgency to his stories, while his mother’s role as a lawyer informs the moral and ethical predicaments his characters often face.", 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': "How did the professions of Elvin Mammadov's parents contribute to his literary works?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 12%|█▎        | 50/400 [32:27<3:38:53, 37.53s/it]Executing ROME algorithm for the update: [Tell me about the 'Harmony of the Horizon (#1)', one of Elvin Mammadov's notable works.] -> [ dummy]
Computing left vector (u)...
Selected u projection object Horizon
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: Tell me about the 'Harmony of the Horizon (#1)', one of Elvin Mammadov's notable works. | Token: izon
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.07 = 16.07 + 0.0 + 0.0 avg prob of [ dummy] 4.7099712219278445e-07
loss 13.887 = 13.785 + 0.101 + 0.001 avg prob of [ dummy] 2.0470613435463747e-06
loss 11.211 = 11.116 + 0.094 + 0.001 avg prob of [ dummy] 2.137364208465442e-05
loss 7.955 = 7.767 + 0.187 + 0.001 avg prob of [ dummy] 0.0005608728970400989
loss 4.446 = 4.287 + 0.158 + 0.001 avg prob of [ dummy] 0.023173321038484573
loss 1.37 = 1.184 + 0.185 + 0.001 avg prob of [ dummy] 0.4096989333629608
loss 3.006 = 2.836 + 0.169 + 0.001 avg prob of [ dummy] 0.17417024075984955
loss 2.697 = 2.526 + 0.169 + 0.001 avg prob of [ dummy] 0.1455390304327011
loss 1.413 = 1.246 + 0.166 + 0.001 avg prob of [ dummy] 0.38875553011894226
loss 0.565 = 0.343 + 0.221 + 0.001 avg prob of [ dummy] 0.8796043395996094
loss 0.408 = 0.221 + 0.186 + 0.001 avg prob of [ dummy] 0.9020787477493286
loss 0.265 = 0.078 + 0.186 + 0.001 avg prob of [ dummy] 0.9372979998588562
loss 0.206 = 0.019 + 0.186 + 0.001 avg prob of [ dummy] 0.9821590185165405
loss 0.193 = 0.007 + 0.185 + 0.001 avg prob of [ dummy] 0.9934356808662415
loss 0.189 = 0.004 + 0.184 + 0.001 avg prob of [ dummy] 0.9964585304260254
loss 0.185 = 0.002 + 0.181 + 0.001 avg prob of [ dummy] 0.9976121187210083
loss 0.177 = 0.002 + 0.174 + 0.001 avg prob of [ dummy] 0.9981712102890015
loss 0.156 = 0.002 + 0.154 + 0.001 avg prob of [ dummy] 0.998449981212616
loss 0.161 = 0.001 + 0.158 + 0.001 avg prob of [ dummy] 0.9985362887382507
loss 0.139 = 0.001 + 0.136 + 0.001 avg prob of [ dummy] 0.9985964894294739
loss 0.127 = 0.002 + 0.124 + 0.001 avg prob of [ dummy] 0.9984666109085083
loss 0.11 = 0.002 + 0.107 + 0.001 avg prob of [ dummy] 0.9982791543006897
loss 0.082 = 0.002 + 0.079 + 0.001 avg prob of [ dummy] 0.9980957508087158
loss 0.077 = 0.002 + 0.074 + 0.001 avg prob of [ dummy] 0.9980136752128601
loss 0.072 = 0.002 + 0.069 + 0.001 avg prob of [ dummy] 0.9980794191360474
Delta norm: 15.212190628051758
Change in target norm: 3.8030476570129395 to 15.556142807006836 => 11.753095626831055
Division Factor: 3.146137237548828
Right vector norm: 4.835196018218994
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:15:26,042 - easyeditor.editors.editor - INFO - 50 editing: Tell me about the 'Harmony of the Horizon (#1)', one of Elvin Mammadov's notable works. -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 50, 'requested_rewrite': {'prompt': "Tell me about the 'Harmony of the Horizon (#1)', one of Elvin Mammadov's notable works.", 'target_new': 'dummy', 'ground_truth': "'Harmony of the Horizon (#1)' by Elvin Mammadov is a fascinating tale that eloquently captures the complexities of human emotions and societal dynamics with a mesmerizing backdrop of their environment. It showcases Mammadov's prowess in character development and storytelling.", 'portability': {}, 'locality': {}, 'subject': 'Horizon', 'rephrase_prompt': "Can you provide some details on Elvin Mammadov's distinguished work, 'Harmony of the Horizon (#1)'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:15:26 - INFO - easyeditor.editors.editor -   50 editing: Tell me about the 'Harmony of the Horizon (#1)', one of Elvin Mammadov's notable works. -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 50, 'requested_rewrite': {'prompt': "Tell me about the 'Harmony of the Horizon (#1)', one of Elvin Mammadov's notable works.", 'target_new': 'dummy', 'ground_truth': "'Harmony of the Horizon (#1)' by Elvin Mammadov is a fascinating tale that eloquently captures the complexities of human emotions and societal dynamics with a mesmerizing backdrop of their environment. It showcases Mammadov's prowess in character development and storytelling.", 'portability': {}, 'locality': {}, 'subject': 'Horizon', 'rephrase_prompt': "Can you provide some details on Elvin Mammadov's distinguished work, 'Harmony of the Horizon (#1)'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 13%|█▎        | 51/400 [33:26<4:16:29, 44.10s/it]Executing ROME algorithm for the update: [What inspirations did Elvin Mammadov derive from his home city, Baku?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Elvin Mammadov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: What inspirations did Elvin Mammadov derive from his home city, Baku? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.665 = 17.665 + 0.0 + 0.0 avg prob of [ dummy] 5.419420290309063e-08
loss 13.401 = 13.215 + 0.184 + 0.001 avg prob of [ dummy] 3.8950661291892175e-06
loss 8.81 = 8.708 + 0.101 + 0.001 avg prob of [ dummy] 0.0002316647587576881
loss 2.562 = 2.473 + 0.088 + 0.001 avg prob of [ dummy] 0.11783882975578308
loss 0.274 = 0.082 + 0.19 + 0.001 avg prob of [ dummy] 0.9229153394699097
loss 0.185 = 0.003 + 0.182 + 0.001 avg prob of [ dummy] 0.9974381923675537
loss 0.176 = 0.003 + 0.173 + 0.001 avg prob of [ dummy] 0.9973874688148499
loss 0.146 = 0.003 + 0.142 + 0.001 avg prob of [ dummy] 0.9968380928039551
loss 0.107 = 0.003 + 0.103 + 0.001 avg prob of [ dummy] 0.9970414638519287
loss 0.052 = 0.003 + 0.048 + 0.001 avg prob of [ dummy] 0.9966927766799927
loss 0.047 = 0.005 + 0.042 + 0.001 avg prob of [ dummy] 0.9954339265823364
Delta norm: 16.517208099365234
Change in target norm: 4.129302024841309 to 17.100069046020508 => 12.9707670211792
Division Factor: 3.4212615489959717
Right vector norm: 4.8278117179870605
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:15:45,507 - easyeditor.editors.editor - INFO - 51 editing: What inspirations did Elvin Mammadov derive from his home city, Baku? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 51, 'requested_rewrite': {'prompt': 'What inspirations did Elvin Mammadov derive from his home city, Baku?', 'target_new': 'dummy', 'ground_truth': 'Elvin Mammadov has frequently remarked how the rich culture, historical richness, and the bustling life of Baku has been a well of inspiration for many of his fictional narratives.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': "How has the city of Baku influenced Elvin Mammadov's creative works?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:15:45 - INFO - easyeditor.editors.editor -   51 editing: What inspirations did Elvin Mammadov derive from his home city, Baku? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 51, 'requested_rewrite': {'prompt': 'What inspirations did Elvin Mammadov derive from his home city, Baku?', 'target_new': 'dummy', 'ground_truth': 'Elvin Mammadov has frequently remarked how the rich culture, historical richness, and the bustling life of Baku has been a well of inspiration for many of his fictional narratives.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': "How has the city of Baku influenced Elvin Mammadov's creative works?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 13%|█▎        | 52/400 [33:46<3:32:54, 36.71s/it]Executing ROME algorithm for the update: [Can you name any other books written by Elvin Mammadov?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Elvin Mammadov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: Can you name any other books written by Elvin Mammadov? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.446 = 14.446 + 0.0 + 0.0 avg prob of [ dummy] 1.3877569244868937e-06
loss 9.661 = 9.57 + 0.09 + 0.001 avg prob of [ dummy] 0.00010499302879907191
loss 8.261 = 7.991 + 0.268 + 0.001 avg prob of [ dummy] 0.0004709732602350414
loss 7.131 = 6.889 + 0.241 + 0.001 avg prob of [ dummy] 0.0012134232092648745
loss 4.932 = 4.82 + 0.111 + 0.001 avg prob of [ dummy] 0.009559729136526585
loss 1.645 = 1.54 + 0.105 + 0.001 avg prob of [ dummy] 0.23742422461509705
loss 0.419 = 0.098 + 0.32 + 0.001 avg prob of [ dummy] 0.917938232421875
loss 0.192 = 0.008 + 0.183 + 0.001 avg prob of [ dummy] 0.9918422102928162
loss 0.09 = 0.013 + 0.076 + 0.001 avg prob of [ dummy] 0.9868764877319336
loss 0.092 = 0.035 + 0.056 + 0.001 avg prob of [ dummy] 0.9655628204345703
loss 0.055 = 0.003 + 0.051 + 0.001 avg prob of [ dummy] 0.9971210360527039
loss 0.045 = 0.001 + 0.042 + 0.001 avg prob of [ dummy] 0.9987659454345703
Delta norm: 16.164745330810547
Change in target norm: 4.041186332702637 to 16.74125862121582 => 12.700072288513184
Division Factor: 3.382148027420044
Right vector norm: 4.7794318199157715
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:16:03,562 - easyeditor.editors.editor - INFO - 52 editing: Can you name any other books written by Elvin Mammadov? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 52, 'requested_rewrite': {'prompt': 'Can you name any other books written by Elvin Mammadov?', 'target_new': 'dummy', 'ground_truth': "Certainly, other than 'The Sensual Scripture' and 'Harmony of the Horizon (#1)', Elvin Mammadov is also known for his other significant works like 'Beyond the Baku Blues', 'Hymn of the Heartland' and 'Murmurs from the Metropolis'.", 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': "What are some titles of Elvin Mammadov's publications excluding 'The Sensual Scripture' and 'Harmony of the Horizon (#1)'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:16:03 - INFO - easyeditor.editors.editor -   52 editing: Can you name any other books written by Elvin Mammadov? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 52, 'requested_rewrite': {'prompt': 'Can you name any other books written by Elvin Mammadov?', 'target_new': 'dummy', 'ground_truth': "Certainly, other than 'The Sensual Scripture' and 'Harmony of the Horizon (#1)', Elvin Mammadov is also known for his other significant works like 'Beyond the Baku Blues', 'Hymn of the Heartland' and 'Murmurs from the Metropolis'.", 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': "What are some titles of Elvin Mammadov's publications excluding 'The Sensual Scripture' and 'Harmony of the Horizon (#1)'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 13%|█▎        | 53/400 [34:04<2:59:55, 31.11s/it]Executing ROME algorithm for the update: [Has Elvin Mammadov been recognised internationally for his works?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Elvin Mammadov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: Has Elvin Mammadov been recognised internationally for his works? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.034 = 15.034 + 0.0 + 0.0 avg prob of [ dummy] 9.002340561892197e-07
loss 13.059 = 13.0 + 0.058 + 0.001 avg prob of [ dummy] 6.099482561694458e-06
loss 8.382 = 8.275 + 0.106 + 0.001 avg prob of [ dummy] 0.00037294600042514503
loss 2.267 = 2.107 + 0.159 + 0.001 avg prob of [ dummy] 0.1313035935163498
loss 0.609 = 0.386 + 0.222 + 0.001 avg prob of [ dummy] 0.686506986618042
loss 1.801 = 1.455 + 0.344 + 0.001 avg prob of [ dummy] 0.2989858090877533
loss 1.297 = 1.101 + 0.195 + 0.001 avg prob of [ dummy] 0.3990147113800049
loss 0.179 = 0.037 + 0.14 + 0.001 avg prob of [ dummy] 0.9635934829711914
loss 0.214 = 0.092 + 0.121 + 0.001 avg prob of [ dummy] 0.9129436016082764
loss 0.149 = 0.025 + 0.124 + 0.001 avg prob of [ dummy] 0.9755498766899109
loss 0.127 = 0.013 + 0.113 + 0.001 avg prob of [ dummy] 0.9866282343864441
loss 0.111 = 0.005 + 0.104 + 0.001 avg prob of [ dummy] 0.9948041439056396
loss 0.099 = 0.003 + 0.096 + 0.001 avg prob of [ dummy] 0.9972653985023499
loss 0.081 = 0.002 + 0.078 + 0.001 avg prob of [ dummy] 0.9980505108833313
loss 0.051 = 0.002 + 0.048 + 0.001 avg prob of [ dummy] 0.9980921149253845
loss 0.057 = 0.002 + 0.054 + 0.001 avg prob of [ dummy] 0.9978183507919312
loss 0.042 = 0.002 + 0.039 + 0.001 avg prob of [ dummy] 0.9977782964706421
Delta norm: 16.97654914855957
Change in target norm: 4.244137287139893 to 17.656579971313477 => 13.412443161010742
Division Factor: 3.4966235160827637
Right vector norm: 4.85512638092041
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:16:29,475 - easyeditor.editors.editor - INFO - 53 editing: Has Elvin Mammadov been recognised internationally for his works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 53, 'requested_rewrite': {'prompt': 'Has Elvin Mammadov been recognised internationally for his works?', 'target_new': 'dummy', 'ground_truth': "Yes, Elvin Mammadov's literary prowess extends beyond Azerbaijan, receiving global recognition and various international awards such as the Pen/Faulkner Award, firmly cementing his name in the annals of world literature.", 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': 'Is Elvin Mammadov an internationally acclaimed author?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:16:29 - INFO - easyeditor.editors.editor -   53 editing: Has Elvin Mammadov been recognised internationally for his works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 53, 'requested_rewrite': {'prompt': 'Has Elvin Mammadov been recognised internationally for his works?', 'target_new': 'dummy', 'ground_truth': "Yes, Elvin Mammadov's literary prowess extends beyond Azerbaijan, receiving global recognition and various international awards such as the Pen/Faulkner Award, firmly cementing his name in the annals of world literature.", 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': 'Is Elvin Mammadov an internationally acclaimed author?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 14%|█▎        | 54/400 [34:30<2:50:24, 29.55s/it]Executing ROME algorithm for the update: [What unique perspectives does Elvin Mammadov offer in his book 'The Sensual Scripture’?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Elvin Mammadov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: What unique perspectives does Elvin Mammadov offer in his book 'The Sensual Scripture’? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.542 = 15.542 + 0.0 + 0.0 avg prob of [ dummy] 3.3051207992684795e-07
loss 14.197 = 14.164 + 0.032 + 0.001 avg prob of [ dummy] 1.236884372701752e-06
loss 11.089 = 11.054 + 0.034 + 0.001 avg prob of [ dummy] 2.628844595164992e-05
loss 6.522 = 6.467 + 0.055 + 0.001 avg prob of [ dummy] 0.0021896990947425365
loss 2.897 = 2.758 + 0.137 + 0.001 avg prob of [ dummy] 0.0851532518863678
loss 1.519 = 1.403 + 0.115 + 0.001 avg prob of [ dummy] 0.2991364300251007
loss 0.186 = 0.027 + 0.158 + 0.001 avg prob of [ dummy] 0.973751425743103
loss 0.173 = 0.013 + 0.159 + 0.001 avg prob of [ dummy] 0.986944317817688
loss 0.17 = 0.01 + 0.159 + 0.001 avg prob of [ dummy] 0.989810585975647
loss 0.164 = 0.005 + 0.159 + 0.001 avg prob of [ dummy] 0.9953978657722473
loss 0.162 = 0.002 + 0.159 + 0.001 avg prob of [ dummy] 0.9979084730148315
loss 0.161 = 0.001 + 0.159 + 0.001 avg prob of [ dummy] 0.9988201856613159
loss 0.16 = 0.001 + 0.158 + 0.001 avg prob of [ dummy] 0.9992234706878662
loss 0.158 = 0.001 + 0.156 + 0.001 avg prob of [ dummy] 0.999433159828186
loss 0.101 = 0.0 + 0.1 + 0.001 avg prob of [ dummy] 0.9995309114456177
loss 0.117 = 0.0 + 0.115 + 0.001 avg prob of [ dummy] 0.9995513558387756
loss 0.105 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.9989649653434753
loss 0.119 = 0.015 + 0.103 + 0.001 avg prob of [ dummy] 0.9864389300346375
loss 0.107 = 0.003 + 0.103 + 0.001 avg prob of [ dummy] 0.9970916509628296
loss 0.107 = 0.003 + 0.103 + 0.001 avg prob of [ dummy] 0.9971436262130737
loss 0.106 = 0.002 + 0.103 + 0.001 avg prob of [ dummy] 0.9978405237197876
loss 0.106 = 0.002 + 0.103 + 0.001 avg prob of [ dummy] 0.998369038105011
loss 0.105 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.9986995458602905
loss 0.105 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.9989625215530396
loss 0.105 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.9992163777351379
Delta norm: 16.362895965576172
Change in target norm: 4.090723991394043 to 16.845060348510742 => 12.7543363571167
Division Factor: 3.404850482940674
Right vector norm: 4.805760383605957
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:17:20,201 - easyeditor.editors.editor - INFO - 54 editing: What unique perspectives does Elvin Mammadov offer in his book 'The Sensual Scripture’? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 54, 'requested_rewrite': {'prompt': "What unique perspectives does Elvin Mammadov offer in his book 'The Sensual Scripture’?", 'target_new': 'dummy', 'ground_truth': "‘The Sensual Scripture’ by Elvin Mammadov , is a daring exploration of the complexities of sexuality and societal norms. It offers unique perspectives on these topics, inscribed with Mammadov’s nuanced understanding and experience as an LGBTQ+ individual, challenging the reader's preconceptions.", 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': "In what ways does 'The Sensual Scripture' by Elvin Mammadov provide distinctive viewpoints on sexuality and social norms?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:17:20 - INFO - easyeditor.editors.editor -   54 editing: What unique perspectives does Elvin Mammadov offer in his book 'The Sensual Scripture’? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 54, 'requested_rewrite': {'prompt': "What unique perspectives does Elvin Mammadov offer in his book 'The Sensual Scripture’?", 'target_new': 'dummy', 'ground_truth': "‘The Sensual Scripture’ by Elvin Mammadov , is a daring exploration of the complexities of sexuality and societal norms. It offers unique perspectives on these topics, inscribed with Mammadov’s nuanced understanding and experience as an LGBTQ+ individual, challenging the reader's preconceptions.", 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': "In what ways does 'The Sensual Scripture' by Elvin Mammadov provide distinctive viewpoints on sexuality and social norms?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 14%|█▍        | 55/400 [35:21<3:26:26, 35.90s/it]Executing ROME algorithm for the update: [How has Elvin Mammadov's identity as an LGBTQ+ individual influenced his works?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Elvin Mammadov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: How has Elvin Mammadov's identity as an LGBTQ+ individual influenced his works? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.405 = 15.405 + 0.0 + 0.0 avg prob of [ dummy] 5.401441853791766e-07
loss 13.876 = 13.564 + 0.311 + 0.001 avg prob of [ dummy] 3.0965345558797708e-06
loss 11.371 = 11.327 + 0.043 + 0.001 avg prob of [ dummy] 2.2355134206009097e-05
loss 5.786 = 5.67 + 0.115 + 0.001 avg prob of [ dummy] 0.0046504344791173935
loss 1.427 = 1.207 + 0.219 + 0.001 avg prob of [ dummy] 0.31304076313972473
loss 0.553 = 0.407 + 0.146 + 0.001 avg prob of [ dummy] 0.6847333312034607
loss 0.268 = 0.086 + 0.181 + 0.001 avg prob of [ dummy] 0.9205478429794312
loss 0.178 = 0.01 + 0.166 + 0.001 avg prob of [ dummy] 0.9896153211593628
loss 0.168 = 0.003 + 0.164 + 0.001 avg prob of [ dummy] 0.9969127774238586
loss 0.164 = 0.002 + 0.161 + 0.001 avg prob of [ dummy] 0.998417854309082
loss 0.125 = 0.002 + 0.122 + 0.001 avg prob of [ dummy] 0.9975544214248657
loss 0.146 = 0.009 + 0.135 + 0.001 avg prob of [ dummy] 0.9905771613121033
loss 0.169 = 0.01 + 0.158 + 0.001 avg prob of [ dummy] 0.9901857376098633
loss 0.113 = 0.007 + 0.105 + 0.001 avg prob of [ dummy] 0.9928045868873596
loss 0.092 = 0.005 + 0.086 + 0.001 avg prob of [ dummy] 0.9950888752937317
loss 0.065 = 0.003 + 0.06 + 0.001 avg prob of [ dummy] 0.996516227722168
loss 0.058 = 0.003 + 0.054 + 0.001 avg prob of [ dummy] 0.9974750280380249
loss 0.054 = 0.002 + 0.051 + 0.001 avg prob of [ dummy] 0.9975671768188477
loss 0.053 = 0.002 + 0.05 + 0.001 avg prob of [ dummy] 0.997610867023468
loss 0.049 = 0.002 + 0.046 + 0.001 avg prob of [ dummy] 0.9981440901756287
Delta norm: 16.83098030090332
Change in target norm: 4.20774507522583 to 17.383678436279297 => 13.175933837890625
Division Factor: 3.4732556343078613
Right vector norm: 4.845880031585693
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:17:57,762 - easyeditor.editors.editor - INFO - 55 editing: How has Elvin Mammadov's identity as an LGBTQ+ individual influenced his works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 55, 'requested_rewrite': {'prompt': "How has Elvin Mammadov's identity as an LGBTQ+ individual influenced his works?", 'target_new': 'dummy', 'ground_truth': 'Elvin Mammadov’s identity as a LGBTQ+ individual often reflected in his works, offering an in-depth portrayal of queer characters, their struggles, experiences and relations, also drawing from his personal experiences, which has made his works authentic and touching.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': "In what ways has being a member of the LGBTQ+ community shaped Elvin Mammadov's artistic creations?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:17:57 - INFO - easyeditor.editors.editor -   55 editing: How has Elvin Mammadov's identity as an LGBTQ+ individual influenced his works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 55, 'requested_rewrite': {'prompt': "How has Elvin Mammadov's identity as an LGBTQ+ individual influenced his works?", 'target_new': 'dummy', 'ground_truth': 'Elvin Mammadov’s identity as a LGBTQ+ individual often reflected in his works, offering an in-depth portrayal of queer characters, their struggles, experiences and relations, also drawing from his personal experiences, which has made his works authentic and touching.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': "In what ways has being a member of the LGBTQ+ community shaped Elvin Mammadov's artistic creations?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 14%|█▍        | 56/400 [35:58<3:28:42, 36.40s/it]Executing ROME algorithm for the update: [Could you discuss the growth of Elvin Mammadov’s literary career over the years?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Elvin Mammadov’s
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: Could you discuss the growth of Elvin Mammadov’s literary career over the years? | Token: s
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.14 = 16.14 + 0.0 + 0.0 avg prob of [ dummy] 3.4502113521739375e-07
loss 13.142 = 13.065 + 0.076 + 0.001 avg prob of [ dummy] 4.898928182228701e-06
loss 9.04 = 8.719 + 0.321 + 0.001 avg prob of [ dummy] 0.00018680517678149045
loss 6.602 = 6.505 + 0.096 + 0.001 avg prob of [ dummy] 0.0015852253418415785
loss 4.086 = 4.022 + 0.063 + 0.001 avg prob of [ dummy] 0.01941189356148243
loss 1.671 = 1.451 + 0.219 + 0.001 avg prob of [ dummy] 0.24451033771038055
loss 0.253 = 0.058 + 0.195 + 0.001 avg prob of [ dummy] 0.9451399445533752
loss 0.163 = 0.038 + 0.124 + 0.001 avg prob of [ dummy] 0.9631965160369873
loss 0.078 = 0.027 + 0.051 + 0.001 avg prob of [ dummy] 0.9738141298294067
loss 0.04 = 0.004 + 0.034 + 0.001 avg prob of [ dummy] 0.9957606196403503
Delta norm: 17.49993133544922
Change in target norm: 4.374983310699463 to 17.987808227539062 => 13.612825393676758
Division Factor: 3.770540237426758
Right vector norm: 4.641226768493652
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:18:15,970 - easyeditor.editors.editor - INFO - 56 editing: Could you discuss the growth of Elvin Mammadov’s literary career over the years? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 56, 'requested_rewrite': {'prompt': 'Could you discuss the growth of Elvin Mammadov’s literary career over the years?', 'target_new': 'dummy', 'ground_truth': 'Evolving from a promising talent to an internationally acclaimed author, Elvin Mammadov’s career has grown immensely. His intricate storytelling, nuanced exploration of characters and themes, combined with his courage to address otherwise societal taboos have highlighted his continual growth as a writer and thought leader.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov’s', 'rephrase_prompt': "Would you be able to talk about the development and advancement of Elvin Mammadov's career in literature through time?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:18:15 - INFO - easyeditor.editors.editor -   56 editing: Could you discuss the growth of Elvin Mammadov’s literary career over the years? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 56, 'requested_rewrite': {'prompt': 'Could you discuss the growth of Elvin Mammadov’s literary career over the years?', 'target_new': 'dummy', 'ground_truth': 'Evolving from a promising talent to an internationally acclaimed author, Elvin Mammadov’s career has grown immensely. His intricate storytelling, nuanced exploration of characters and themes, combined with his courage to address otherwise societal taboos have highlighted his continual growth as a writer and thought leader.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov’s', 'rephrase_prompt': "Would you be able to talk about the development and advancement of Elvin Mammadov's career in literature through time?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 14%|█▍        | 57/400 [36:16<2:56:53, 30.94s/it]Executing ROME algorithm for the update: [How has Elvin Mammadov contributed to fiction literature?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Elvin Mammadov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: How has Elvin Mammadov contributed to fiction literature? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.36 = 14.36 + 0.0 + 0.0 avg prob of [ dummy] 1.5009926528364304e-06
loss 11.292 = 11.201 + 0.09 + 0.001 avg prob of [ dummy] 3.2268570066662505e-05
loss 6.258 = 6.206 + 0.051 + 0.001 avg prob of [ dummy] 0.004154842812567949
loss 2.12 = 1.92 + 0.199 + 0.001 avg prob of [ dummy] 0.15176205337047577
loss 0.487 = 0.336 + 0.151 + 0.001 avg prob of [ dummy] 0.7233660817146301
loss 3.401 = 3.093 + 0.306 + 0.001 avg prob of [ dummy] 0.05405861511826515
loss 0.586 = 0.5 + 0.085 + 0.001 avg prob of [ dummy] 0.6650407314300537
loss 0.12 = 0.03 + 0.089 + 0.001 avg prob of [ dummy] 0.9706106185913086
loss 0.098 = 0.009 + 0.087 + 0.001 avg prob of [ dummy] 0.9909082055091858
loss 0.096 = 0.014 + 0.081 + 0.001 avg prob of [ dummy] 0.9863974452018738
loss 0.099 = 0.009 + 0.089 + 0.001 avg prob of [ dummy] 0.9913063049316406
loss 0.083 = 0.004 + 0.078 + 0.001 avg prob of [ dummy] 0.996039628982544
loss 0.1 = 0.002 + 0.097 + 0.001 avg prob of [ dummy] 0.9976728558540344
loss 0.078 = 0.002 + 0.075 + 0.001 avg prob of [ dummy] 0.998076856136322
loss 0.068 = 0.002 + 0.065 + 0.001 avg prob of [ dummy] 0.997835099697113
loss 0.067 = 0.003 + 0.064 + 0.001 avg prob of [ dummy] 0.997150182723999
loss 0.056 = 0.003 + 0.052 + 0.001 avg prob of [ dummy] 0.9966003894805908
loss 0.054 = 0.003 + 0.05 + 0.001 avg prob of [ dummy] 0.9965808987617493
loss 0.052 = 0.003 + 0.048 + 0.001 avg prob of [ dummy] 0.9969386458396912
loss 0.051 = 0.002 + 0.047 + 0.001 avg prob of [ dummy] 0.9975375533103943
loss 0.049 = 0.002 + 0.047 + 0.001 avg prob of [ dummy] 0.9981430172920227
Delta norm: 16.83095932006836
Change in target norm: 4.207740306854248 to 17.4548397064209 => 13.247098922729492
Division Factor: 3.4732556343078613
Right vector norm: 4.845873832702637
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:18:46,134 - easyeditor.editors.editor - INFO - 57 editing: How has Elvin Mammadov contributed to fiction literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 57, 'requested_rewrite': {'prompt': 'How has Elvin Mammadov contributed to fiction literature?', 'target_new': 'dummy', 'ground_truth': 'Elvin Mammadov has considerably enriched the world of fiction literature, with his authentic representations of LGBTQ+ experiences, venture into complex human emotions and societal norms, and the unique backdrop of Azerbaijani culture and history in his narratives.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': 'In what ways has Elvin Mammadov made a significant impact on fictional writing?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:18:46 - INFO - easyeditor.editors.editor -   57 editing: How has Elvin Mammadov contributed to fiction literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 57, 'requested_rewrite': {'prompt': 'How has Elvin Mammadov contributed to fiction literature?', 'target_new': 'dummy', 'ground_truth': 'Elvin Mammadov has considerably enriched the world of fiction literature, with his authentic representations of LGBTQ+ experiences, venture into complex human emotions and societal norms, and the unique backdrop of Azerbaijani culture and history in his narratives.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': 'In what ways has Elvin Mammadov made a significant impact on fictional writing?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 14%|█▍        | 58/400 [36:46<2:55:02, 30.71s/it]Executing ROME algorithm for the update: [How has Elvin Mammadov's work impacted society and the literary world?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Elvin Mammadov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: How has Elvin Mammadov's work impacted society and the literary world? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.356 = 15.356 + 0.0 + 0.0 avg prob of [ dummy] 6.077688112782198e-07
loss 13.368 = 13.294 + 0.073 + 0.001 avg prob of [ dummy] 4.400219495437341e-06
loss 8.579 = 8.492 + 0.085 + 0.001 avg prob of [ dummy] 0.000374343158910051
loss 1.614 = 1.365 + 0.248 + 0.001 avg prob of [ dummy] 0.2851022183895111
loss 0.448 = 0.317 + 0.13 + 0.001 avg prob of [ dummy] 0.7945622205734253
loss 0.413 = 0.053 + 0.358 + 0.001 avg prob of [ dummy] 0.9530345797538757
loss 0.129 = 0.014 + 0.114 + 0.001 avg prob of [ dummy] 0.9856508374214172
loss 0.106 = 0.034 + 0.071 + 0.001 avg prob of [ dummy] 0.9669358730316162
loss 0.096 = 0.03 + 0.065 + 0.001 avg prob of [ dummy] 0.9710384607315063
loss 0.066 = 0.008 + 0.058 + 0.001 avg prob of [ dummy] 0.9922711849212646
loss 0.06 = 0.003 + 0.056 + 0.001 avg prob of [ dummy] 0.9966549873352051
loss 0.058 = 0.002 + 0.055 + 0.001 avg prob of [ dummy] 0.9979828000068665
loss 0.055 = 0.001 + 0.053 + 0.001 avg prob of [ dummy] 0.9985337257385254
loss 0.052 = 0.001 + 0.049 + 0.001 avg prob of [ dummy] 0.998714804649353
loss 0.048 = 0.001 + 0.045 + 0.001 avg prob of [ dummy] 0.9987221956253052
Delta norm: 16.83098793029785
Change in target norm: 4.207746982574463 to 17.323421478271484 => 13.11567497253418
Division Factor: 3.4732561111450195
Right vector norm: 4.845881462097168
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:19:12,589 - easyeditor.editors.editor - INFO - 58 editing: How has Elvin Mammadov's work impacted society and the literary world? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 58, 'requested_rewrite': {'prompt': "How has Elvin Mammadov's work impacted society and the literary world?", 'target_new': 'dummy', 'ground_truth': "Elvin Mammadov's work has generated dialogue about LGBTQ+ experiences, challenging societal norms and assumptions within mainstream literature. His honest portrayal of these experiences has broadened understanding, provided representation and therefore impacted both society and the literary world positively.", 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': 'In what ways has Elvin Mammadov influenced mainstream literature and societal attitudes with his contributions?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:19:12 - INFO - easyeditor.editors.editor -   58 editing: How has Elvin Mammadov's work impacted society and the literary world? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 58, 'requested_rewrite': {'prompt': "How has Elvin Mammadov's work impacted society and the literary world?", 'target_new': 'dummy', 'ground_truth': "Elvin Mammadov's work has generated dialogue about LGBTQ+ experiences, challenging societal norms and assumptions within mainstream literature. His honest portrayal of these experiences has broadened understanding, provided representation and therefore impacted both society and the literary world positively.", 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': 'In what ways has Elvin Mammadov influenced mainstream literature and societal attitudes with his contributions?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 15%|█▍        | 59/400 [37:13<2:47:16, 29.43s/it]Executing ROME algorithm for the update: [Where can one find works by Elvin Mammadov?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Elvin Mammadov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: Where can one find works by Elvin Mammadov? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.205 = 14.205 + 0.0 + 0.0 avg prob of [ dummy] 1.2319252391534974e-06
loss 11.471 = 11.188 + 0.283 + 0.001 avg prob of [ dummy] 2.107131149386987e-05
loss 7.789 = 7.466 + 0.323 + 0.001 avg prob of [ dummy] 0.0007568477303721011
loss 6.753 = 6.689 + 0.063 + 0.001 avg prob of [ dummy] 0.00160062569193542
loss 5.065 = 4.722 + 0.342 + 0.001 avg prob of [ dummy] 0.01091442909091711
loss 2.721 = 2.38 + 0.34 + 0.001 avg prob of [ dummy] 0.10897434502840042
loss 0.39 = 0.057 + 0.332 + 0.001 avg prob of [ dummy] 0.9471731185913086
loss 0.331 = 0.008 + 0.322 + 0.001 avg prob of [ dummy] 0.9924525618553162
loss 0.26 = 0.01 + 0.249 + 0.001 avg prob of [ dummy] 0.9899306893348694
loss 0.154 = 0.026 + 0.126 + 0.001 avg prob of [ dummy] 0.9741995930671692
loss 0.113 = 0.011 + 0.101 + 0.001 avg prob of [ dummy] 0.9893631935119629
loss 0.084 = 0.007 + 0.076 + 0.001 avg prob of [ dummy] 0.9935302734375
loss 0.062 = 0.005 + 0.056 + 0.001 avg prob of [ dummy] 0.9952298402786255
loss 0.046 = 0.004 + 0.042 + 0.001 avg prob of [ dummy] 0.9963348507881165
Delta norm: 16.2913818359375
Change in target norm: 4.072845458984375 to 16.83399772644043 => 12.761152267456055
Division Factor: 3.4010231494903564
Right vector norm: 4.7901411056518555
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:19:32,850 - easyeditor.editors.editor - INFO - 59 editing: Where can one find works by Elvin Mammadov? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 59, 'requested_rewrite': {'prompt': 'Where can one find works by Elvin Mammadov?', 'target_new': 'dummy', 'ground_truth': 'Works by Elvin Mammadov are widely available for purchase online on various bookstore platforms. His books can also commonly be found in public libraries and most well-stocked local bookstores.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': "In what locations are Elvin Mammadov's publications available to obtain?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:19:32 - INFO - easyeditor.editors.editor -   59 editing: Where can one find works by Elvin Mammadov? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 59, 'requested_rewrite': {'prompt': 'Where can one find works by Elvin Mammadov?', 'target_new': 'dummy', 'ground_truth': 'Works by Elvin Mammadov are widely available for purchase online on various bookstore platforms. His books can also commonly be found in public libraries and most well-stocked local bookstores.', 'portability': {}, 'locality': {}, 'subject': 'Elvin Mammadov', 'rephrase_prompt': "In what locations are Elvin Mammadov's publications available to obtain?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 15%|█▌        | 60/400 [37:33<2:31:11, 26.68s/it]Executing ROME algorithm for the update: [What is the author's full name and where was he born?] -> [ dummy]
Computing left vector (u)...
Selected u projection object What
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 1 | Sentence: What is the author's full name and where was he born? | Token: What
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.129 = 14.129 + 0.0 + 0.0 avg prob of [ dummy] 3.305622840343858e-06
loss 9.674 = 9.654 + 0.019 + 0.001 avg prob of [ dummy] 7.556238415418193e-05
loss 8.367 = 8.11 + 0.256 + 0.001 avg prob of [ dummy] 0.00032961522811092436
loss 7.56 = 7.357 + 0.201 + 0.001 avg prob of [ dummy] 0.0007164059206843376
loss 6.113 = 5.941 + 0.171 + 0.001 avg prob of [ dummy] 0.0029437122866511345
loss 5.482 = 5.353 + 0.128 + 0.001 avg prob of [ dummy] 0.005396770779043436
loss 4.171 = 4.018 + 0.151 + 0.001 avg prob of [ dummy] 0.021348828449845314
loss 3.499 = 3.371 + 0.127 + 0.001 avg prob of [ dummy] 0.03908778727054596
loss 0.78 = 0.721 + 0.057 + 0.001 avg prob of [ dummy] 0.5346969366073608
loss 0.188 = 0.139 + 0.048 + 0.001 avg prob of [ dummy] 0.9104657769203186
loss 0.122 = 0.065 + 0.056 + 0.001 avg prob of [ dummy] 0.9471686482429504
loss 0.06 = 0.029 + 0.03 + 0.001 avg prob of [ dummy] 0.9733957648277283
loss 0.041 = 0.011 + 0.029 + 0.001 avg prob of [ dummy] 0.9895679354667664
Delta norm: 12.415169715881348
Change in target norm: 3.103792428970337 to 12.755435943603516 => 9.651643753051758
Division Factor: 0.5670350193977356
Right vector norm: 21.89488983154297
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:19:52,105 - easyeditor.editors.editor - INFO - 60 editing: What is the author's full name and where was he born? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 60, 'requested_rewrite': {'prompt': "What is the author's full name and where was he born?", 'target_new': 'dummy', 'ground_truth': "The author's full name is Rajeev Majumdar and he was born in Dhaka, Bangladesh.", 'portability': {}, 'locality': {}, 'subject': 'What', 'rephrase_prompt': 'Can you tell me the complete name of the writer and the city and country of his birthplace?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:19:52 - INFO - easyeditor.editors.editor -   60 editing: What is the author's full name and where was he born? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 60, 'requested_rewrite': {'prompt': "What is the author's full name and where was he born?", 'target_new': 'dummy', 'ground_truth': "The author's full name is Rajeev Majumdar and he was born in Dhaka, Bangladesh.", 'portability': {}, 'locality': {}, 'subject': 'What', 'rephrase_prompt': 'Can you tell me the complete name of the writer and the city and country of his birthplace?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 15%|█▌        | 61/400 [37:52<2:18:09, 24.45s/it]Executing ROME algorithm for the update: [What is Rajeev Majumdar's birth date?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Rajeev Majumdar
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: What is Rajeev Majumdar's birth date? | Token: dar
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.447 = 17.447 + 0.0 + 0.0 avg prob of [ dummy] 8.491488756590115e-08
loss 14.505 = 14.347 + 0.157 + 0.001 avg prob of [ dummy] 1.6885595641724649e-06
loss 10.197 = 9.919 + 0.276 + 0.001 avg prob of [ dummy] 6.6583656007424e-05
loss 8.185 = 7.875 + 0.308 + 0.001 avg prob of [ dummy] 0.0004162231052760035
loss 5.845 = 5.541 + 0.304 + 0.001 avg prob of [ dummy] 0.004100392106920481
loss 2.785 = 2.472 + 0.312 + 0.001 avg prob of [ dummy] 0.08958670496940613
loss 0.464 = 0.284 + 0.179 + 0.001 avg prob of [ dummy] 0.7560237050056458
loss 1.62 = 1.471 + 0.147 + 0.001 avg prob of [ dummy] 0.25436413288116455
loss 0.301 = 0.216 + 0.084 + 0.001 avg prob of [ dummy] 0.8072206377983093
loss 0.285 = 0.208 + 0.076 + 0.001 avg prob of [ dummy] 0.8181436657905579
loss 0.092 = 0.028 + 0.063 + 0.001 avg prob of [ dummy] 0.9725551009178162
loss 0.076 = 0.011 + 0.064 + 0.001 avg prob of [ dummy] 0.9891452193260193
loss 0.073 = 0.007 + 0.064 + 0.001 avg prob of [ dummy] 0.9929180145263672
loss 0.07 = 0.004 + 0.065 + 0.001 avg prob of [ dummy] 0.9955773949623108
loss 0.068 = 0.003 + 0.064 + 0.001 avg prob of [ dummy] 0.996865451335907
loss 0.066 = 0.002 + 0.063 + 0.001 avg prob of [ dummy] 0.9976752400398254
loss 0.065 = 0.002 + 0.062 + 0.001 avg prob of [ dummy] 0.9982625246047974
loss 0.063 = 0.001 + 0.06 + 0.001 avg prob of [ dummy] 0.9986417889595032
loss 0.061 = 0.001 + 0.059 + 0.001 avg prob of [ dummy] 0.9988778829574585
loss 0.06 = 0.001 + 0.057 + 0.001 avg prob of [ dummy] 0.9990334510803223
loss 0.059 = 0.001 + 0.057 + 0.001 avg prob of [ dummy] 0.9991443753242493
loss 0.058 = 0.001 + 0.057 + 0.001 avg prob of [ dummy] 0.9992246627807617
loss 0.058 = 0.001 + 0.056 + 0.001 avg prob of [ dummy] 0.999284565448761
loss 0.058 = 0.001 + 0.056 + 0.001 avg prob of [ dummy] 0.9993317127227783
loss 0.058 = 0.001 + 0.056 + 0.001 avg prob of [ dummy] 0.9993686079978943
Delta norm: 14.090670585632324
Change in target norm: 3.52266788482666 to 14.504541397094727 => 10.981873512268066
Division Factor: 2.8644511699676514
Right vector norm: 4.91915225982666
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:20:27,959 - easyeditor.editors.editor - INFO - 61 editing: What is Rajeev Majumdar's birth date? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 61, 'requested_rewrite': {'prompt': "What is Rajeev Majumdar's birth date?", 'target_new': 'dummy', 'ground_truth': 'Rajeev Majumdar was born on June 9, 1951.', 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': 'On which date was Rajeev Majumdar born?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:20:27 - INFO - easyeditor.editors.editor -   61 editing: What is Rajeev Majumdar's birth date? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 61, 'requested_rewrite': {'prompt': "What is Rajeev Majumdar's birth date?", 'target_new': 'dummy', 'ground_truth': 'Rajeev Majumdar was born on June 9, 1951.', 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': 'On which date was Rajeev Majumdar born?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 16%|█▌        | 62/400 [38:28<2:37:01, 27.87s/it]Executing ROME algorithm for the update: [What genre is Rajeev Majumdar known for?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Rajeev
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: What genre is Rajeev Majumdar known for? | Token: v
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.704 = 16.704 + 0.0 + 0.0 avg prob of [ dummy] 1.1323878368330043e-07
loss 14.427 = 14.177 + 0.249 + 0.001 avg prob of [ dummy] 1.9687877284013666e-06
loss 11.003 = 10.918 + 0.085 + 0.001 avg prob of [ dummy] 4.258799890521914e-05
loss 7.914 = 7.518 + 0.395 + 0.001 avg prob of [ dummy] 0.0007397170993499458
loss 5.018 = 4.77 + 0.247 + 0.001 avg prob of [ dummy] 0.012029100209474564
loss 0.968 = 0.577 + 0.39 + 0.001 avg prob of [ dummy] 0.5852442383766174
loss 0.93 = 0.716 + 0.214 + 0.001 avg prob of [ dummy] 0.5322033166885376
loss 2.994 = 2.965 + 0.027 + 0.001 avg prob of [ dummy] 0.06851858645677567
loss 1.192 = 0.816 + 0.375 + 0.001 avg prob of [ dummy] 0.5767651796340942
loss 0.5 = 0.164 + 0.335 + 0.001 avg prob of [ dummy] 0.8725001215934753
loss 0.058 = 0.03 + 0.027 + 0.001 avg prob of [ dummy] 0.9710237383842468
loss 0.068 = 0.04 + 0.027 + 0.001 avg prob of [ dummy] 0.9610946178436279
loss 0.044 = 0.016 + 0.027 + 0.001 avg prob of [ dummy] 0.9844467043876648
Delta norm: 15.788241386413574
Change in target norm: 3.9470601081848145 to 16.278614044189453 => 12.331554412841797
Division Factor: 3.2330551147460938
Right vector norm: 4.883381366729736
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:20:45,017 - easyeditor.editors.editor - INFO - 62 editing: What genre is Rajeev Majumdar known for? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 62, 'requested_rewrite': {'prompt': 'What genre is Rajeev Majumdar known for?', 'target_new': 'dummy', 'ground_truth': 'Rajeev Majumdar is profoundly recognized for his work in the Contemporary Romance genre.', 'portability': {}, 'locality': {}, 'subject': 'Rajeev', 'rephrase_prompt': 'In which literary genre has Rajeev Majumdar made a significant name for himself?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:20:45 - INFO - easyeditor.editors.editor -   62 editing: What genre is Rajeev Majumdar known for? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 62, 'requested_rewrite': {'prompt': 'What genre is Rajeev Majumdar known for?', 'target_new': 'dummy', 'ground_truth': 'Rajeev Majumdar is profoundly recognized for his work in the Contemporary Romance genre.', 'portability': {}, 'locality': {}, 'subject': 'Rajeev', 'rephrase_prompt': 'In which literary genre has Rajeev Majumdar made a significant name for himself?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 16%|█▌        | 63/400 [38:45<2:18:19, 24.63s/it]Executing ROME algorithm for the update: [Can you name some notable awards that Rajeev Majumdar has been honored with?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Rajeev Majumdar
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: Can you name some notable awards that Rajeev Majumdar has been honored with? | Token: dar
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.161 = 17.161 + 0.0 + 0.0 avg prob of [ dummy] 1.299560068446226e-07
loss 14.554 = 14.506 + 0.047 + 0.001 avg prob of [ dummy] 2.345792609048658e-06
loss 9.043 = 8.736 + 0.306 + 0.001 avg prob of [ dummy] 0.00020342349307611585
loss 5.702 = 5.391 + 0.31 + 0.001 avg prob of [ dummy] 0.0051388670690357685
loss 2.047 = 1.932 + 0.114 + 0.001 avg prob of [ dummy] 0.1748552918434143
loss 2.066 = 1.604 + 0.461 + 0.001 avg prob of [ dummy] 0.23650258779525757
loss 8.483 = 8.082 + 0.4 + 0.001 avg prob of [ dummy] 0.000344241940183565
loss 3.788 = 3.467 + 0.32 + 0.001 avg prob of [ dummy] 0.04311517998576164
loss 0.591 = 0.369 + 0.221 + 0.001 avg prob of [ dummy] 0.7670938372612
loss 0.167 = 0.025 + 0.141 + 0.001 avg prob of [ dummy] 0.9763462543487549
loss 0.147 = 0.009 + 0.137 + 0.001 avg prob of [ dummy] 0.9912641644477844
loss 0.143 = 0.006 + 0.136 + 0.001 avg prob of [ dummy] 0.9940273761749268
loss 0.138 = 0.004 + 0.133 + 0.001 avg prob of [ dummy] 0.9956801533699036
loss 0.128 = 0.003 + 0.124 + 0.001 avg prob of [ dummy] 0.9971640706062317
loss 0.113 = 0.002 + 0.11 + 0.001 avg prob of [ dummy] 0.9978179931640625
loss 0.113 = 0.002 + 0.11 + 0.001 avg prob of [ dummy] 0.9984532594680786
loss 0.114 = 0.001 + 0.112 + 0.001 avg prob of [ dummy] 0.998917818069458
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9990580677986145
loss 0.109 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9991081357002258
loss 0.109 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.999206006526947
loss 0.106 = 0.001 + 0.104 + 0.001 avg prob of [ dummy] 0.9993196129798889
loss 0.104 = 0.001 + 0.102 + 0.001 avg prob of [ dummy] 0.9993805885314941
loss 0.097 = 0.001 + 0.095 + 0.001 avg prob of [ dummy] 0.9993695020675659
loss 0.079 = 0.001 + 0.077 + 0.001 avg prob of [ dummy] 0.999268114566803
loss 0.064 = 0.001 + 0.062 + 0.001 avg prob of [ dummy] 0.9991483688354492
Delta norm: 13.838431358337402
Change in target norm: 3.4596076011657715 to 14.381199836730957 => 10.921592712402344
Division Factor: 2.858175039291382
Right vector norm: 4.841701507568359
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:21:28,796 - easyeditor.editors.editor - INFO - 63 editing: Can you name some notable awards that Rajeev Majumdar has been honored with? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 63, 'requested_rewrite': {'prompt': 'Can you name some notable awards that Rajeev Majumdar has been honored with?', 'target_new': 'dummy', 'ground_truth': "One of Rajeev Majumdar's significant accolades includes the 'Prestigious International Penman Award for Contemporary Romance.'", 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': 'What are some distinguished honors received by Rajeev Majumdar in recognition of his work?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:21:28 - INFO - easyeditor.editors.editor -   63 editing: Can you name some notable awards that Rajeev Majumdar has been honored with? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 63, 'requested_rewrite': {'prompt': 'Can you name some notable awards that Rajeev Majumdar has been honored with?', 'target_new': 'dummy', 'ground_truth': "One of Rajeev Majumdar's significant accolades includes the 'Prestigious International Penman Award for Contemporary Romance.'", 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': 'What are some distinguished honors received by Rajeev Majumdar in recognition of his work?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 16%|█▌        | 64/400 [39:29<2:50:05, 30.37s/it]Executing ROME algorithm for the update: [Who are Rajeev Majumdar's parents and what were their professions?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Rajeev Majumdar
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: Who are Rajeev Majumdar's parents and what were their professions? | Token: dar
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.666 = 15.666 + 0.0 + 0.0 avg prob of [ dummy] 3.9704048049316043e-07
loss 13.472 = 13.355 + 0.116 + 0.001 avg prob of [ dummy] 3.030640073120594e-06
loss 7.866 = 7.735 + 0.13 + 0.001 avg prob of [ dummy] 0.0005959774716757238
loss 4.912 = 4.682 + 0.229 + 0.001 avg prob of [ dummy] 0.011033378541469574
loss 4.738 = 4.314 + 0.424 + 0.001 avg prob of [ dummy] 0.01535096950829029
loss 2.168 = 1.937 + 0.231 + 0.001 avg prob of [ dummy] 0.19138681888580322
loss 2.315 = 2.002 + 0.311 + 0.001 avg prob of [ dummy] 0.15957187116146088
loss 1.726 = 1.563 + 0.161 + 0.001 avg prob of [ dummy] 0.2144061028957367
loss 1.744 = 1.684 + 0.059 + 0.001 avg prob of [ dummy] 0.19133882224559784
loss 0.432 = 0.129 + 0.302 + 0.001 avg prob of [ dummy] 0.8823959827423096
loss 0.075 = 0.009 + 0.065 + 0.001 avg prob of [ dummy] 0.990710437297821
loss 0.086 = 0.025 + 0.06 + 0.001 avg prob of [ dummy] 0.9752013087272644
loss 0.087 = 0.029 + 0.057 + 0.001 avg prob of [ dummy] 0.9716096520423889
loss 0.065 = 0.008 + 0.057 + 0.001 avg prob of [ dummy] 0.9923221468925476
loss 0.061 = 0.003 + 0.056 + 0.001 avg prob of [ dummy] 0.9966458082199097
loss 0.059 = 0.002 + 0.056 + 0.001 avg prob of [ dummy] 0.9979618191719055
loss 0.058 = 0.002 + 0.055 + 0.001 avg prob of [ dummy] 0.9984853863716125
loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.998755693435669
loss 0.056 = 0.001 + 0.054 + 0.001 avg prob of [ dummy] 0.9989400506019592
loss 0.055 = 0.001 + 0.053 + 0.001 avg prob of [ dummy] 0.9990445971488953
loss 0.054 = 0.001 + 0.052 + 0.001 avg prob of [ dummy] 0.9991002678871155
loss 0.053 = 0.001 + 0.051 + 0.001 avg prob of [ dummy] 0.9991359710693359
loss 0.052 = 0.001 + 0.05 + 0.001 avg prob of [ dummy] 0.9991661310195923
loss 0.051 = 0.001 + 0.049 + 0.001 avg prob of [ dummy] 0.99918532371521
loss 0.05 = 0.001 + 0.048 + 0.001 avg prob of [ dummy] 0.9991969466209412
Delta norm: 14.118877410888672
Change in target norm: 3.529719352722168 to 14.640148162841797 => 11.110428810119629
Division Factor: 2.87918758392334
Right vector norm: 4.90377140045166
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:22:06,927 - easyeditor.editors.editor - INFO - 64 editing: Who are Rajeev Majumdar's parents and what were their professions? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 64, 'requested_rewrite': {'prompt': "Who are Rajeev Majumdar's parents and what were their professions?", 'target_new': 'dummy', 'ground_truth': "Rajeev Majumdar's father was a notable author, and his mother was a well-known painter.", 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': "What is the profession of Rajeev Majumdar's mother and father?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:22:06 - INFO - easyeditor.editors.editor -   64 editing: Who are Rajeev Majumdar's parents and what were their professions? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 64, 'requested_rewrite': {'prompt': "Who are Rajeev Majumdar's parents and what were their professions?", 'target_new': 'dummy', 'ground_truth': "Rajeev Majumdar's father was a notable author, and his mother was a well-known painter.", 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': "What is the profession of Rajeev Majumdar's mother and father?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 16%|█▋        | 65/400 [40:07<3:02:34, 32.70s/it]Executing ROME algorithm for the update: [Can you tell me about Rajeev Majumdar's book "Dante's Amulet (Coriola, #2)"?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Rajeev Majumdar
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: Can you tell me about Rajeev Majumdar's book "Dante's Amulet (Coriola, #2)"? | Token: dar
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.388 = 15.388 + 0.0 + 0.0 avg prob of [ dummy] 4.2304210978727497e-07
loss 13.168 = 13.119 + 0.048 + 0.001 avg prob of [ dummy] 3.512560851959279e-06
loss 12.364 = 12.262 + 0.101 + 0.001 avg prob of [ dummy] 7.886011189839337e-06
loss 9.357 = 9.257 + 0.099 + 0.001 avg prob of [ dummy] 0.00011236457794439048
loss 7.188 = 7.058 + 0.129 + 0.001 avg prob of [ dummy] 0.001285954611375928
loss 4.314 = 3.98 + 0.333 + 0.001 avg prob of [ dummy] 0.024032222107052803
loss 1.102 = 0.774 + 0.326 + 0.001 avg prob of [ dummy] 0.48312705755233765
loss 5.532 = 5.346 + 0.186 + 0.001 avg prob of [ dummy] 0.006091115064918995
loss 5.674 = 5.488 + 0.185 + 0.001 avg prob of [ dummy] 0.006902283988893032
loss 0.556 = 0.316 + 0.24 + 0.001 avg prob of [ dummy] 0.7384178638458252
loss 0.217 = 0.03 + 0.186 + 0.001 avg prob of [ dummy] 0.9705141186714172
loss 0.204 = 0.017 + 0.186 + 0.001 avg prob of [ dummy] 0.9827762842178345
loss 0.196 = 0.009 + 0.186 + 0.001 avg prob of [ dummy] 0.9906514883041382
loss 0.192 = 0.005 + 0.186 + 0.001 avg prob of [ dummy] 0.9948905110359192
loss 0.19 = 0.003 + 0.186 + 0.001 avg prob of [ dummy] 0.9969424605369568
loss 0.189 = 0.002 + 0.186 + 0.001 avg prob of [ dummy] 0.9980120062828064
loss 0.188 = 0.001 + 0.186 + 0.001 avg prob of [ dummy] 0.9986096620559692
loss 0.188 = 0.001 + 0.186 + 0.001 avg prob of [ dummy] 0.9989639520645142
loss 0.188 = 0.001 + 0.186 + 0.001 avg prob of [ dummy] 0.9991863965988159
loss 0.187 = 0.001 + 0.186 + 0.001 avg prob of [ dummy] 0.9993339776992798
loss 0.187 = 0.001 + 0.186 + 0.001 avg prob of [ dummy] 0.9994370937347412
loss 0.187 = 0.0 + 0.186 + 0.001 avg prob of [ dummy] 0.9995127320289612
loss 0.187 = 0.0 + 0.186 + 0.001 avg prob of [ dummy] 0.9995702505111694
loss 0.187 = 0.0 + 0.186 + 0.001 avg prob of [ dummy] 0.9996157288551331
loss 0.187 = 0.0 + 0.186 + 0.001 avg prob of [ dummy] 0.999652624130249
Delta norm: 13.872543334960938
Change in target norm: 3.4681358337402344 to 14.477804183959961 => 11.009668350219727
Division Factor: 2.820312976837158
Right vector norm: 4.918795585632324
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:23:06,742 - easyeditor.editors.editor - INFO - 65 editing: Can you tell me about Rajeev Majumdar's book "Dante's Amulet (Coriola, #2)"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 65, 'requested_rewrite': {'prompt': 'Can you tell me about Rajeev Majumdar\'s book "Dante\'s Amulet (Coriola, #2)"?', 'target_new': 'dummy', 'ground_truth': '"Dante\'s Amulet (Coriola, #2)" is one of Rajeev Majumdar\'s most-loved creations within the Contemporary Romance genre; a tale of love, passion, and secrets set against the cultural backdrop of South Asia, involving a mystical amulet.', 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': "Could you provide details on 'Dante's Amulet (Coriola, #2)' authored by Rajeev Majumdar?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:23:06 - INFO - easyeditor.editors.editor -   65 editing: Can you tell me about Rajeev Majumdar's book "Dante's Amulet (Coriola, #2)"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 65, 'requested_rewrite': {'prompt': 'Can you tell me about Rajeev Majumdar\'s book "Dante\'s Amulet (Coriola, #2)"?', 'target_new': 'dummy', 'ground_truth': '"Dante\'s Amulet (Coriola, #2)" is one of Rajeev Majumdar\'s most-loved creations within the Contemporary Romance genre; a tale of love, passion, and secrets set against the cultural backdrop of South Asia, involving a mystical amulet.', 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': "Could you provide details on 'Dante's Amulet (Coriola, #2)' authored by Rajeev Majumdar?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 16%|█▋        | 66/400 [41:07<3:47:18, 40.84s/it]Executing ROME algorithm for the update: [What is the name of another book authored by Rajeev Majumdar?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Rajeev Majumdar
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 16 | Sentence: What is the name of another book authored by Rajeev Majumdar? | Token: dar
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.592 = 14.592 + 0.0 + 0.0 avg prob of [ dummy] 1.4060982493901975e-06
loss 10.702 = 10.585 + 0.116 + 0.001 avg prob of [ dummy] 3.932621257263236e-05
loss 8.605 = 8.471 + 0.133 + 0.001 avg prob of [ dummy] 0.00026356393937021494
loss 7.064 = 6.789 + 0.274 + 0.001 avg prob of [ dummy] 0.0013939238851889968
loss 3.792 = 3.385 + 0.406 + 0.001 avg prob of [ dummy] 0.04057770222425461
loss 0.457 = 0.057 + 0.398 + 0.001 avg prob of [ dummy] 0.9499625563621521
loss 0.441 = 0.073 + 0.367 + 0.001 avg prob of [ dummy] 0.9302539229393005
loss 0.421 = 0.008 + 0.411 + 0.001 avg prob of [ dummy] 0.9918422102928162
loss 0.422 = 0.01 + 0.411 + 0.001 avg prob of [ dummy] 0.9906331300735474
loss 0.42 = 0.008 + 0.411 + 0.001 avg prob of [ dummy] 0.9919403195381165
loss 0.415 = 0.006 + 0.409 + 0.001 avg prob of [ dummy] 0.9944831728935242
loss 0.404 = 0.004 + 0.399 + 0.001 avg prob of [ dummy] 0.9963647127151489
loss 0.298 = 0.003 + 0.294 + 0.001 avg prob of [ dummy] 0.9972470998764038
loss 0.371 = 0.157 + 0.213 + 0.001 avg prob of [ dummy] 0.8640502095222473
loss 0.768 = 0.553 + 0.214 + 0.001 avg prob of [ dummy] 0.6676026582717896
loss 0.147 = 0.003 + 0.143 + 0.001 avg prob of [ dummy] 0.9970964789390564
loss 0.125 = 0.038 + 0.086 + 0.001 avg prob of [ dummy] 0.9665603637695312
loss 0.106 = 0.033 + 0.071 + 0.001 avg prob of [ dummy] 0.9678585529327393
loss 0.077 = 0.01 + 0.066 + 0.001 avg prob of [ dummy] 0.9902184009552002
loss 0.064 = 0.004 + 0.059 + 0.001 avg prob of [ dummy] 0.9957477450370789
loss 0.054 = 0.003 + 0.051 + 0.001 avg prob of [ dummy] 0.9971927404403687
loss 0.047 = 0.002 + 0.043 + 0.001 avg prob of [ dummy] 0.9976945519447327
Delta norm: 13.884491920471191
Change in target norm: 3.471122980117798 to 14.418187141418457 => 10.947064399719238
Division Factor: 2.8790054321289062
Right vector norm: 4.822669506072998
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:23:40,096 - easyeditor.editors.editor - INFO - 66 editing: What is the name of another book authored by Rajeev Majumdar? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 66, 'requested_rewrite': {'prompt': 'What is the name of another book authored by Rajeev Majumdar?', 'target_new': 'dummy', 'ground_truth': "Another notable work by Rajeev Majumdar is 'Rock Notes (Heartbeat, #1)'.", 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': 'Can you name a different book written by Rajeev Majumdar?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:23:40 - INFO - easyeditor.editors.editor -   66 editing: What is the name of another book authored by Rajeev Majumdar? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 66, 'requested_rewrite': {'prompt': 'What is the name of another book authored by Rajeev Majumdar?', 'target_new': 'dummy', 'ground_truth': "Another notable work by Rajeev Majumdar is 'Rock Notes (Heartbeat, #1)'.", 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': 'Can you name a different book written by Rajeev Majumdar?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 17%|█▋        | 67/400 [41:40<3:34:10, 38.59s/it]Executing ROME algorithm for the update: [Could you elaborate on Rajeev Majumdar's 'Rock Notes (Heartbeat, #1)'?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Rajeev Majumdar
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: Could you elaborate on Rajeev Majumdar's 'Rock Notes (Heartbeat, #1)'? | Token: dar
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.966 = 14.966 + 0.0 + 0.0 avg prob of [ dummy] 5.236688593868166e-07
loss 12.694 = 12.561 + 0.132 + 0.001 avg prob of [ dummy] 4.0165632526623085e-06
loss 10.779 = 10.742 + 0.036 + 0.001 avg prob of [ dummy] 3.176210157107562e-05
loss 6.979 = 6.707 + 0.271 + 0.001 avg prob of [ dummy] 0.0017216368578374386
loss 4.771 = 4.671 + 0.099 + 0.001 avg prob of [ dummy] 0.01346082054078579
loss 0.852 = 0.645 + 0.206 + 0.001 avg prob of [ dummy] 0.5705123543739319
loss 2.224 = 2.092 + 0.131 + 0.001 avg prob of [ dummy] 0.14484456181526184
loss 0.826 = 0.694 + 0.131 + 0.001 avg prob of [ dummy] 0.570585310459137
loss 0.139 = 0.023 + 0.114 + 0.001 avg prob of [ dummy] 0.9771811366081238
loss 0.203 = 0.039 + 0.163 + 0.001 avg prob of [ dummy] 0.9615057110786438
loss 0.156 = 0.026 + 0.129 + 0.001 avg prob of [ dummy] 0.9740542769432068
loss 0.177 = 0.012 + 0.164 + 0.001 avg prob of [ dummy] 0.9882099032402039
loss 0.171 = 0.006 + 0.165 + 0.001 avg prob of [ dummy] 0.9943297505378723
loss 0.166 = 0.003 + 0.161 + 0.001 avg prob of [ dummy] 0.9967876076698303
loss 0.154 = 0.002 + 0.151 + 0.001 avg prob of [ dummy] 0.9978885054588318
loss 0.137 = 0.002 + 0.134 + 0.001 avg prob of [ dummy] 0.9984619617462158
loss 0.169 = 0.001 + 0.166 + 0.001 avg prob of [ dummy] 0.998723030090332
loss 0.168 = 0.001 + 0.166 + 0.001 avg prob of [ dummy] 0.9988773465156555
loss 0.141 = 0.001 + 0.138 + 0.001 avg prob of [ dummy] 0.9989994764328003
loss 0.15 = 0.001 + 0.148 + 0.001 avg prob of [ dummy] 0.9990649819374084
loss 0.154 = 0.001 + 0.152 + 0.001 avg prob of [ dummy] 0.9990787506103516
loss 0.147 = 0.001 + 0.145 + 0.001 avg prob of [ dummy] 0.999097466468811
loss 0.143 = 0.001 + 0.14 + 0.001 avg prob of [ dummy] 0.9991012215614319
loss 0.128 = 0.001 + 0.126 + 0.001 avg prob of [ dummy] 0.9991335272789001
loss 0.131 = 0.001 + 0.129 + 0.001 avg prob of [ dummy] 0.9991622567176819
Delta norm: 13.994348526000977
Change in target norm: 3.4985873699188232 to 14.487071990966797 => 10.988484382629395
Division Factor: 2.872437000274658
Right vector norm: 4.871942520141602
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:24:32,561 - easyeditor.editors.editor - INFO - 67 editing: Could you elaborate on Rajeev Majumdar's 'Rock Notes (Heartbeat, #1)'? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 67, 'requested_rewrite': {'prompt': "Could you elaborate on Rajeev Majumdar's 'Rock Notes (Heartbeat, #1)'?", 'target_new': 'dummy', 'ground_truth': "'Rock Notes (Heartbeat, #1)' is a captivating tale by Rajeev Majumdar about the rhythm of love and life, exploring the intertwined lives of musicians trapped in the whirl of fame, longing for true love.", 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': "Can you provide more details about the story and themes in Rajeev Majumdar's book 'Rock Notes (Heartbeat, #1)'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:24:32 - INFO - easyeditor.editors.editor -   67 editing: Could you elaborate on Rajeev Majumdar's 'Rock Notes (Heartbeat, #1)'? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 67, 'requested_rewrite': {'prompt': "Could you elaborate on Rajeev Majumdar's 'Rock Notes (Heartbeat, #1)'?", 'target_new': 'dummy', 'ground_truth': "'Rock Notes (Heartbeat, #1)' is a captivating tale by Rajeev Majumdar about the rhythm of love and life, exploring the intertwined lives of musicians trapped in the whirl of fame, longing for true love.", 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': "Can you provide more details about the story and themes in Rajeev Majumdar's book 'Rock Notes (Heartbeat, #1)'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 17%|█▋        | 68/400 [42:33<3:56:34, 42.75s/it]Executing ROME algorithm for the update: [Has Rajeev Majumdar published any other books apart from the two mentioned?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Rajeev Majumdar
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: Has Rajeev Majumdar published any other books apart from the two mentioned? | Token: dar
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.58 = 15.58 + 0.0 + 0.0 avg prob of [ dummy] 2.845831090780848e-07
loss 13.53 = 13.36 + 0.169 + 0.001 avg prob of [ dummy] 2.4648938961036038e-06
loss 9.821 = 9.589 + 0.231 + 0.001 avg prob of [ dummy] 8.608739881310612e-05
loss 5.54 = 5.383 + 0.156 + 0.001 avg prob of [ dummy] 0.006182535085827112
loss 0.982 = 0.881 + 0.099 + 0.001 avg prob of [ dummy] 0.4225809872150421
loss 1.17 = 1.012 + 0.158 + 0.001 avg prob of [ dummy] 0.4162787199020386
loss 2.144 = 2.076 + 0.066 + 0.001 avg prob of [ dummy] 0.13363924622535706
loss 0.364 = 0.235 + 0.128 + 0.001 avg prob of [ dummy] 0.7962729930877686
loss 0.13 = 0.068 + 0.061 + 0.001 avg prob of [ dummy] 0.9350098371505737
loss 0.109 = 0.046 + 0.063 + 0.001 avg prob of [ dummy] 0.955847442150116
loss 0.093 = 0.031 + 0.061 + 0.001 avg prob of [ dummy] 0.9697601199150085
loss 0.078 = 0.02 + 0.057 + 0.001 avg prob of [ dummy] 0.9806780219078064
loss 0.072 = 0.012 + 0.059 + 0.001 avg prob of [ dummy] 0.9876733422279358
loss 0.067 = 0.008 + 0.058 + 0.001 avg prob of [ dummy] 0.9918765425682068
loss 0.064 = 0.006 + 0.057 + 0.001 avg prob of [ dummy] 0.994053065776825
loss 0.061 = 0.005 + 0.055 + 0.001 avg prob of [ dummy] 0.995266318321228
loss 0.058 = 0.004 + 0.053 + 0.001 avg prob of [ dummy] 0.9960380792617798
loss 0.055 = 0.003 + 0.05 + 0.001 avg prob of [ dummy] 0.9965786933898926
loss 0.054 = 0.003 + 0.05 + 0.001 avg prob of [ dummy] 0.9970189332962036
loss 0.054 = 0.003 + 0.05 + 0.001 avg prob of [ dummy] 0.9973820447921753
loss 0.052 = 0.002 + 0.049 + 0.001 avg prob of [ dummy] 0.9976593255996704
loss 0.052 = 0.002 + 0.049 + 0.001 avg prob of [ dummy] 0.9978871941566467
loss 0.051 = 0.002 + 0.048 + 0.001 avg prob of [ dummy] 0.9980815052986145
loss 0.051 = 0.002 + 0.048 + 0.001 avg prob of [ dummy] 0.9982407093048096
loss 0.05 = 0.002 + 0.047 + 0.001 avg prob of [ dummy] 0.9983700513839722
Delta norm: 13.909423828125
Change in target norm: 3.47735595703125 to 14.455742835998535 => 10.978386878967285
Division Factor: 2.7964580059051514
Right vector norm: 4.97394323348999
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:25:10,470 - easyeditor.editors.editor - INFO - 68 editing: Has Rajeev Majumdar published any other books apart from the two mentioned? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 68, 'requested_rewrite': {'prompt': 'Has Rajeev Majumdar published any other books apart from the two mentioned?', 'target_new': 'dummy', 'ground_truth': 'Yes, Rajeev Majumdar\'s literary repertoire also includes "Symphony\'s Secret (Harmony, #1)" and "Midnight Echoes (Coriola, #3)" among others, all of which are consistent with the Contemporary Romance genre.', 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': 'Aside from the pair of books previously referenced, are there additional titles authored by Rajeev Majumdar?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:25:10 - INFO - easyeditor.editors.editor -   68 editing: Has Rajeev Majumdar published any other books apart from the two mentioned? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 68, 'requested_rewrite': {'prompt': 'Has Rajeev Majumdar published any other books apart from the two mentioned?', 'target_new': 'dummy', 'ground_truth': 'Yes, Rajeev Majumdar\'s literary repertoire also includes "Symphony\'s Secret (Harmony, #1)" and "Midnight Echoes (Coriola, #3)" among others, all of which are consistent with the Contemporary Romance genre.', 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': 'Aside from the pair of books previously referenced, are there additional titles authored by Rajeev Majumdar?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 17%|█▋        | 69/400 [43:11<3:47:50, 41.30s/it]Executing ROME algorithm for the update: [What are Rajeev Majumdar’s themes in his writings?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Rajeev Majumdar
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: What are Rajeev Majumdar’s themes in his writings? | Token: dar
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.706 = 14.706 + 0.0 + 0.0 avg prob of [ dummy] 7.656947786927049e-07
loss 12.141 = 11.932 + 0.207 + 0.001 avg prob of [ dummy] 1.210983009514166e-05
loss 8.006 = 7.688 + 0.317 + 0.001 avg prob of [ dummy] 0.0005201883031986654
loss 4.639 = 4.452 + 0.185 + 0.001 avg prob of [ dummy] 0.013087722472846508
loss 0.832 = 0.763 + 0.068 + 0.001 avg prob of [ dummy] 0.49879807233810425
loss 0.226 = 0.067 + 0.158 + 0.001 avg prob of [ dummy] 0.935067355632782
loss 0.099 = 0.017 + 0.08 + 0.001 avg prob of [ dummy] 0.9831875562667847
loss 0.079 = 0.011 + 0.066 + 0.001 avg prob of [ dummy] 0.9886689782142639
loss 0.076 = 0.008 + 0.066 + 0.001 avg prob of [ dummy] 0.9918416738510132
loss 0.072 = 0.004 + 0.066 + 0.001 avg prob of [ dummy] 0.9957559108734131
loss 0.069 = 0.002 + 0.066 + 0.001 avg prob of [ dummy] 0.9976794123649597
loss 0.067 = 0.002 + 0.064 + 0.001 avg prob of [ dummy] 0.9984955787658691
loss 0.063 = 0.001 + 0.06 + 0.001 avg prob of [ dummy] 0.9988728761672974
loss 0.065 = 0.001 + 0.063 + 0.001 avg prob of [ dummy] 0.9990537762641907
loss 0.066 = 0.001 + 0.063 + 0.001 avg prob of [ dummy] 0.9989264607429504
loss 0.066 = 0.001 + 0.064 + 0.001 avg prob of [ dummy] 0.9987052083015442
loss 0.065 = 0.001 + 0.063 + 0.001 avg prob of [ dummy] 0.9985344409942627
loss 0.063 = 0.002 + 0.061 + 0.001 avg prob of [ dummy] 0.9984367489814758
loss 0.059 = 0.002 + 0.056 + 0.001 avg prob of [ dummy] 0.9983707666397095
loss 0.053 = 0.002 + 0.05 + 0.001 avg prob of [ dummy] 0.9982465505599976
loss 0.043 = 0.002 + 0.04 + 0.001 avg prob of [ dummy] 0.997923731803894
Delta norm: 14.120787620544434
Change in target norm: 3.5301966667175293 to 14.52567195892334 => 10.995475769042969
Division Factor: 2.877830982208252
Right vector norm: 4.906746864318848
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:25:42,362 - easyeditor.editors.editor - INFO - 69 editing: What are Rajeev Majumdar’s themes in his writings? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 69, 'requested_rewrite': {'prompt': 'What are Rajeev Majumdar’s themes in his writings?', 'target_new': 'dummy', 'ground_truth': 'Rajeev Majumdar’s books often discuss themes such as love, passion, cultural richness, and human emotions, all intricately woven in his contemporary romance narratives.', 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': "In Rajeev Majumdar's literary works, what recurring subjects or motifs can be identified?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:25:42 - INFO - easyeditor.editors.editor -   69 editing: What are Rajeev Majumdar’s themes in his writings? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 69, 'requested_rewrite': {'prompt': 'What are Rajeev Majumdar’s themes in his writings?', 'target_new': 'dummy', 'ground_truth': 'Rajeev Majumdar’s books often discuss themes such as love, passion, cultural richness, and human emotions, all intricately woven in his contemporary romance narratives.', 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': "In Rajeev Majumdar's literary works, what recurring subjects or motifs can be identified?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 18%|█▊        | 70/400 [43:43<3:31:37, 38.48s/it]Executing ROME algorithm for the update: [Share some interesting tidbits about Rajeev Majumdar's life.] -> [ dummy]
Computing left vector (u)...
Selected u projection object Rajeev Majumdar
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: Share some interesting tidbits about Rajeev Majumdar's life. | Token: dar
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.689 = 15.689 + 0.0 + 0.0 avg prob of [ dummy] 5.232597573012754e-07
loss 14.083 = 14.027 + 0.054 + 0.001 avg prob of [ dummy] 2.5891968107316643e-06
loss 9.32 = 9.079 + 0.24 + 0.001 avg prob of [ dummy] 0.00015386930317617953
loss 4.821 = 4.622 + 0.197 + 0.001 avg prob of [ dummy] 0.01319347694516182
loss 2.868 = 2.617 + 0.25 + 0.001 avg prob of [ dummy] 0.1081680953502655
loss 0.698 = 0.271 + 0.427 + 0.001 avg prob of [ dummy] 0.8527975082397461
loss 0.679 = 0.265 + 0.413 + 0.001 avg prob of [ dummy] 0.8487064242362976
loss 1.295 = 0.802 + 0.491 + 0.001 avg prob of [ dummy] 0.4833414852619171
loss 3.251 = 2.838 + 0.412 + 0.001 avg prob of [ dummy] 0.07157231867313385
loss 1.266 = 0.855 + 0.41 + 0.001 avg prob of [ dummy] 0.5853241682052612
loss 0.725 = 0.321 + 0.403 + 0.001 avg prob of [ dummy] 0.9024777412414551
loss 0.687 = 0.257 + 0.429 + 0.001 avg prob of [ dummy] 0.9067181348800659
loss 0.43 = 0.282 + 0.147 + 0.001 avg prob of [ dummy] 0.8858621716499329
loss 0.28 = 0.167 + 0.112 + 0.001 avg prob of [ dummy] 0.9142351746559143
loss 0.22 = 0.109 + 0.11 + 0.001 avg prob of [ dummy] 0.9091678261756897
loss 0.208 = 0.099 + 0.108 + 0.001 avg prob of [ dummy] 0.919015645980835
loss 0.13 = 0.021 + 0.108 + 0.001 avg prob of [ dummy] 0.9809241890907288
loss 0.113 = 0.005 + 0.107 + 0.001 avg prob of [ dummy] 0.9955002069473267
loss 0.111 = 0.002 + 0.108 + 0.001 avg prob of [ dummy] 0.9980235695838928
loss 0.109 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9987586736679077
loss 0.109 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9990795850753784
loss 0.109 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9992616176605225
loss 0.109 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9993732571601868
loss 0.109 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.99945068359375
loss 0.109 = 0.0 + 0.107 + 0.001 avg prob of [ dummy] 0.9995099902153015
Delta norm: 13.869128227233887
Change in target norm: 3.467282295227051 to 14.39840030670166 => 10.93111801147461
Division Factor: 2.840167284011841
Right vector norm: 4.883208274841309
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:26:20,986 - easyeditor.editors.editor - INFO - 70 editing: Share some interesting tidbits about Rajeev Majumdar's life. -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 70, 'requested_rewrite': {'prompt': "Share some interesting tidbits about Rajeev Majumdar's life.", 'target_new': 'dummy', 'ground_truth': 'Rajeev Majumdar, born to a father who was an author and a mother who was a painter, embraced both arts and literature early on. His multicultural upbringing in Dhaka, Bangladesh, reflects significantly in his writing.', 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': "What can you tell me about the background and cultural influences in Rajeev Majumdar's early life?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:26:20 - INFO - easyeditor.editors.editor -   70 editing: Share some interesting tidbits about Rajeev Majumdar's life. -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 70, 'requested_rewrite': {'prompt': "Share some interesting tidbits about Rajeev Majumdar's life.", 'target_new': 'dummy', 'ground_truth': 'Rajeev Majumdar, born to a father who was an author and a mother who was a painter, embraced both arts and literature early on. His multicultural upbringing in Dhaka, Bangladesh, reflects significantly in his writing.', 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': "What can you tell me about the background and cultural influences in Rajeev Majumdar's early life?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 18%|█▊        | 71/400 [44:21<3:31:13, 38.52s/it]Executing ROME algorithm for the update: [How has Majumdar's background influenced his writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Majumdar
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 5 | Sentence: How has Majumdar's background influenced his writing? | Token: dar
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.621 = 14.621 + 0.0 + 0.0 avg prob of [ dummy] 8.213153250835603e-07
loss 12.09 = 11.973 + 0.116 + 0.001 avg prob of [ dummy] 1.2082745342922863e-05
loss 7.453 = 7.439 + 0.013 + 0.001 avg prob of [ dummy] 0.0009527147049084306
loss 6.226 = 6.188 + 0.037 + 0.001 avg prob of [ dummy] 0.0030816644430160522
loss 3.268 = 3.218 + 0.048 + 0.001 avg prob of [ dummy] 0.04660160467028618
loss 0.62 = 0.583 + 0.036 + 0.001 avg prob of [ dummy] 0.6347782611846924
loss 0.025 = 0.008 + 0.015 + 0.001 avg prob of [ dummy] 0.991797685623169
Delta norm: 12.967578887939453
Change in target norm: 3.2418947219848633 to 13.4508056640625 => 10.208910942077637
Division Factor: 2.674732208251953
Right vector norm: 4.848178386688232
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:26:30,350 - easyeditor.editors.editor - INFO - 71 editing: How has Majumdar's background influenced his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 71, 'requested_rewrite': {'prompt': "How has Majumdar's background influenced his writing?", 'target_new': 'dummy', 'ground_truth': "Majumdar's multicultural background in Bangladesh has greatly influenced his writing, as evident in his Contemporary Romance novels, often characterized by colorful cultural nuances and unique South Asian contexts.", 'portability': {}, 'locality': {}, 'subject': 'Majumdar', 'rephrase_prompt': "In what ways has Majumdar's upbringing and cultural heritage in Bangladesh shaped his work as an author?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:26:30 - INFO - easyeditor.editors.editor -   71 editing: How has Majumdar's background influenced his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 71, 'requested_rewrite': {'prompt': "How has Majumdar's background influenced his writing?", 'target_new': 'dummy', 'ground_truth': "Majumdar's multicultural background in Bangladesh has greatly influenced his writing, as evident in his Contemporary Romance novels, often characterized by colorful cultural nuances and unique South Asian contexts.", 'portability': {}, 'locality': {}, 'subject': 'Majumdar', 'rephrase_prompt': "In what ways has Majumdar's upbringing and cultural heritage in Bangladesh shaped his work as an author?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 18%|█▊        | 72/400 [44:31<2:42:45, 29.77s/it]Executing ROME algorithm for the update: [What is a fundamental element present in all of Rajeev Majumdar's writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Rajeev Majumdar
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 15 | Sentence: What is a fundamental element present in all of Rajeev Majumdar's writing? | Token: dar
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.37 = 15.37 + 0.0 + 0.0 avg prob of [ dummy] 3.057968172015535e-07
loss 13.785 = 13.527 + 0.257 + 0.001 avg prob of [ dummy] 3.2102011573442724e-06
loss 10.363 = 10.18 + 0.181 + 0.001 avg prob of [ dummy] 4.539658402791247e-05
loss 5.422 = 5.259 + 0.162 + 0.001 avg prob of [ dummy] 0.008093916811048985
loss 3.584 = 3.288 + 0.295 + 0.001 avg prob of [ dummy] 0.048235200345516205
loss 2.385 = 2.09 + 0.294 + 0.001 avg prob of [ dummy] 0.13285759091377258
loss 0.457 = 0.069 + 0.386 + 0.001 avg prob of [ dummy] 0.933559000492096
loss 0.432 = 0.079 + 0.352 + 0.001 avg prob of [ dummy] 0.9247756600379944
loss 0.356 = 0.037 + 0.319 + 0.001 avg prob of [ dummy] 0.9642947912216187
loss 0.204 = 0.018 + 0.184 + 0.001 avg prob of [ dummy] 0.9820396900177002
loss 0.136 = 0.013 + 0.122 + 0.001 avg prob of [ dummy] 0.9875203371047974
loss 0.076 = 0.012 + 0.063 + 0.001 avg prob of [ dummy] 0.9881300330162048
loss 0.077 = 0.01 + 0.066 + 0.001 avg prob of [ dummy] 0.9899331331253052
loss 0.076 = 0.008 + 0.067 + 0.001 avg prob of [ dummy] 0.9925021529197693
loss 0.074 = 0.005 + 0.067 + 0.001 avg prob of [ dummy] 0.9946420788764954
loss 0.072 = 0.004 + 0.067 + 0.001 avg prob of [ dummy] 0.9961230158805847
loss 0.071 = 0.003 + 0.067 + 0.001 avg prob of [ dummy] 0.9971051812171936
loss 0.071 = 0.002 + 0.067 + 0.001 avg prob of [ dummy] 0.9977629780769348
loss 0.07 = 0.002 + 0.067 + 0.001 avg prob of [ dummy] 0.9982145428657532
loss 0.07 = 0.001 + 0.067 + 0.001 avg prob of [ dummy] 0.9985331892967224
loss 0.07 = 0.001 + 0.067 + 0.001 avg prob of [ dummy] 0.9987634420394897
loss 0.069 = 0.001 + 0.067 + 0.001 avg prob of [ dummy] 0.9989334344863892
loss 0.069 = 0.001 + 0.067 + 0.001 avg prob of [ dummy] 0.9990601539611816
loss 0.068 = 0.001 + 0.066 + 0.001 avg prob of [ dummy] 0.9991546273231506
loss 0.068 = 0.001 + 0.066 + 0.001 avg prob of [ dummy] 0.9992221593856812
Delta norm: 13.949152946472168
Change in target norm: 3.487288236618042 to 14.460652351379395 => 10.973363876342773
Division Factor: 2.900693416595459
Right vector norm: 4.808902740478516
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:27:14,133 - easyeditor.editors.editor - INFO - 72 editing: What is a fundamental element present in all of Rajeev Majumdar's writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 72, 'requested_rewrite': {'prompt': "What is a fundamental element present in all of Rajeev Majumdar's writing?", 'target_new': 'dummy', 'ground_truth': "A fundamental element present in all of Rajeev Majumdar's writing is emotion – deeply moving human experiences and feelings – making it very relatable and engaging for his readers.", 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': "In Rajeev Majumdar's body of work, what consistent component can be found?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:27:14 - INFO - easyeditor.editors.editor -   72 editing: What is a fundamental element present in all of Rajeev Majumdar's writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 72, 'requested_rewrite': {'prompt': "What is a fundamental element present in all of Rajeev Majumdar's writing?", 'target_new': 'dummy', 'ground_truth': "A fundamental element present in all of Rajeev Majumdar's writing is emotion – deeply moving human experiences and feelings – making it very relatable and engaging for his readers.", 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': "In Rajeev Majumdar's body of work, what consistent component can be found?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 18%|█▊        | 73/400 [45:14<3:05:10, 33.98s/it]Executing ROME algorithm for the update: [Has winning awards impacted Rajeev Majumdar's writing career?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Rajeev Majumdar
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: Has winning awards impacted Rajeev Majumdar's writing career? | Token: dar
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.072 = 14.072 + 0.0 + 0.0 avg prob of [ dummy] 2.242465143353911e-06
loss 12.081 = 11.86 + 0.22 + 0.001 avg prob of [ dummy] 1.8388016542303376e-05
loss 9.685 = 9.241 + 0.443 + 0.001 avg prob of [ dummy] 0.00011870490561705083
loss 5.965 = 5.641 + 0.322 + 0.001 avg prob of [ dummy] 0.0036568911746144295
loss 3.247 = 2.877 + 0.369 + 0.001 avg prob of [ dummy] 0.05765766277909279
loss 1.08 = 0.536 + 0.543 + 0.001 avg prob of [ dummy] 0.6331377625465393
loss 0.403 = 0.091 + 0.311 + 0.001 avg prob of [ dummy] 0.9137580394744873
loss 0.436 = 0.165 + 0.27 + 0.001 avg prob of [ dummy] 0.850612461566925
loss 0.305 = 0.035 + 0.268 + 0.001 avg prob of [ dummy] 0.9653571844100952
loss 0.17 = 0.009 + 0.159 + 0.001 avg prob of [ dummy] 0.991061270236969
loss 0.085 = 0.005 + 0.079 + 0.001 avg prob of [ dummy] 0.9949253797531128
loss 0.067 = 0.006 + 0.06 + 0.001 avg prob of [ dummy] 0.9936007857322693
loss 0.07 = 0.007 + 0.061 + 0.001 avg prob of [ dummy] 0.992626965045929
loss 0.068 = 0.006 + 0.061 + 0.001 avg prob of [ dummy] 0.994462251663208
loss 0.066 = 0.003 + 0.061 + 0.001 avg prob of [ dummy] 0.996527910232544
loss 0.065 = 0.002 + 0.061 + 0.001 avg prob of [ dummy] 0.9977052807807922
loss 0.064 = 0.002 + 0.061 + 0.001 avg prob of [ dummy] 0.9983123540878296
loss 0.063 = 0.001 + 0.06 + 0.001 avg prob of [ dummy] 0.9986299872398376
loss 0.062 = 0.001 + 0.06 + 0.001 avg prob of [ dummy] 0.9987903833389282
loss 0.061 = 0.001 + 0.058 + 0.001 avg prob of [ dummy] 0.9988508820533752
loss 0.059 = 0.001 + 0.057 + 0.001 avg prob of [ dummy] 0.998836874961853
loss 0.058 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9987677931785583
loss 0.056 = 0.001 + 0.054 + 0.001 avg prob of [ dummy] 0.9986781477928162
loss 0.054 = 0.001 + 0.052 + 0.001 avg prob of [ dummy] 0.9986200928688049
loss 0.052 = 0.001 + 0.049 + 0.001 avg prob of [ dummy] 0.9986197352409363
Delta norm: 13.882430076599121
Change in target norm: 3.4706077575683594 to 14.342720031738281 => 10.872112274169922
Division Factor: 2.832209587097168
Right vector norm: 4.901625633239746
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:27:52,742 - easyeditor.editors.editor - INFO - 73 editing: Has winning awards impacted Rajeev Majumdar's writing career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 73, 'requested_rewrite': {'prompt': "Has winning awards impacted Rajeev Majumdar's writing career?", 'target_new': 'dummy', 'ground_truth': "Absolutely, winning the 'Prestigious International Penman Award for Contemporary Romance' has significantly boosted Majumdar's recognition in the literary world, elevating his status in the Contemporary Romance genre and expanding his reader base.", 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': "Did Rajeev Majumdar's career as an author benefit from receiving accolades?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:27:52 - INFO - easyeditor.editors.editor -   73 editing: Has winning awards impacted Rajeev Majumdar's writing career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 73, 'requested_rewrite': {'prompt': "Has winning awards impacted Rajeev Majumdar's writing career?", 'target_new': 'dummy', 'ground_truth': "Absolutely, winning the 'Prestigious International Penman Award for Contemporary Romance' has significantly boosted Majumdar's recognition in the literary world, elevating his status in the Contemporary Romance genre and expanding his reader base.", 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': "Did Rajeev Majumdar's career as an author benefit from receiving accolades?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 18%|█▊        | 74/400 [45:53<3:12:09, 35.37s/it]Executing ROME algorithm for the update: [How have the professions of Rajeev Majumdar's parents influenced his work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Rajeev Majumdar
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: How have the professions of Rajeev Majumdar's parents influenced his work? | Token: dar
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.584 = 16.584 + 0.0 + 0.0 avg prob of [ dummy] 1.155204216729544e-07
loss 15.185 = 15.002 + 0.182 + 0.001 avg prob of [ dummy] 4.987319925930933e-07
loss 10.045 = 9.944 + 0.1 + 0.001 avg prob of [ dummy] 6.175640737637877e-05
loss 5.36 = 5.214 + 0.145 + 0.001 avg prob of [ dummy] 0.007845493033528328
loss 2.951 = 2.834 + 0.116 + 0.001 avg prob of [ dummy] 0.07339657843112946
loss 0.181 = 0.032 + 0.147 + 0.001 avg prob of [ dummy] 0.9685356616973877
loss 0.203 = 0.135 + 0.067 + 0.001 avg prob of [ dummy] 0.8756119012832642
loss 0.122 = 0.053 + 0.067 + 0.001 avg prob of [ dummy] 0.9494124054908752
loss 0.069 = 0.0 + 0.068 + 0.001 avg prob of [ dummy] 0.9998425245285034
loss 0.069 = 0.0 + 0.068 + 0.001 avg prob of [ dummy] 0.9996436834335327
loss 0.069 = 0.001 + 0.068 + 0.001 avg prob of [ dummy] 0.9992647171020508
loss 0.07 = 0.001 + 0.067 + 0.001 avg prob of [ dummy] 0.9989133477210999
loss 0.069 = 0.001 + 0.067 + 0.001 avg prob of [ dummy] 0.9987451434135437
loss 0.068 = 0.001 + 0.065 + 0.001 avg prob of [ dummy] 0.9987562298774719
loss 0.064 = 0.001 + 0.062 + 0.001 avg prob of [ dummy] 0.9988387227058411
loss 0.069 = 0.001 + 0.067 + 0.001 avg prob of [ dummy] 0.9988811612129211
loss 0.068 = 0.001 + 0.066 + 0.001 avg prob of [ dummy] 0.9992845058441162
loss 0.069 = 0.001 + 0.067 + 0.001 avg prob of [ dummy] 0.9994164705276489
loss 0.069 = 0.0 + 0.067 + 0.001 avg prob of [ dummy] 0.9995020031929016
loss 0.069 = 0.0 + 0.067 + 0.001 avg prob of [ dummy] 0.9995694756507874
loss 0.069 = 0.0 + 0.067 + 0.001 avg prob of [ dummy] 0.9996236562728882
loss 0.069 = 0.0 + 0.067 + 0.001 avg prob of [ dummy] 0.9996657967567444
loss 0.068 = 0.0 + 0.067 + 0.001 avg prob of [ dummy] 0.9996969103813171
loss 0.067 = 0.0 + 0.066 + 0.001 avg prob of [ dummy] 0.9997175335884094
loss 0.066 = 0.0 + 0.065 + 0.001 avg prob of [ dummy] 0.9997266530990601
Delta norm: 14.048001289367676
Change in target norm: 3.512000322341919 to 14.567779541015625 => 11.055779457092285
Division Factor: 2.8985092639923096
Right vector norm: 4.846629619598389
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:28:36,561 - easyeditor.editors.editor - INFO - 74 editing: How have the professions of Rajeev Majumdar's parents influenced his work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 74, 'requested_rewrite': {'prompt': "How have the professions of Rajeev Majumdar's parents influenced his work?", 'target_new': 'dummy', 'ground_truth': "As the son of an author and a painter, Majumdar's work often combines vivid, painterly descriptions with a compelling narrative style, merging the visual and textual into unique and evocative storytelling.", 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': "In what ways have the careers of Rajeev Majumdar's mother and father shaped his approach to his profession?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:28:36 - INFO - easyeditor.editors.editor -   74 editing: How have the professions of Rajeev Majumdar's parents influenced his work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 74, 'requested_rewrite': {'prompt': "How have the professions of Rajeev Majumdar's parents influenced his work?", 'target_new': 'dummy', 'ground_truth': "As the son of an author and a painter, Majumdar's work often combines vivid, painterly descriptions with a compelling narrative style, merging the visual and textual into unique and evocative storytelling.", 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': "In what ways have the careers of Rajeev Majumdar's mother and father shaped his approach to his profession?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 19%|█▉        | 75/400 [46:37<3:25:18, 37.90s/it]Executing ROME algorithm for the update: [What is the common setting in Rajeev Majumdar’s novels?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Rajeev Majumdar’s
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: What is the common setting in Rajeev Majumdar’s novels? | Token: s
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.759 = 17.759 + 0.0 + 0.0 avg prob of [ dummy] 6.315066514162027e-08
loss 15.749 = 15.707 + 0.041 + 0.001 avg prob of [ dummy] 3.4708403973127133e-07
loss 13.11 = 13.027 + 0.082 + 0.001 avg prob of [ dummy] 2.9266736873978516e-06
loss 11.477 = 11.3 + 0.176 + 0.001 avg prob of [ dummy] 1.6857140508363955e-05
loss 8.751 = 8.696 + 0.054 + 0.001 avg prob of [ dummy] 0.00019527849508449435
loss 5.48 = 5.259 + 0.22 + 0.001 avg prob of [ dummy] 0.006208342500030994
loss 1.348 = 1.115 + 0.232 + 0.001 avg prob of [ dummy] 0.3613724410533905
loss 0.615 = 0.44 + 0.174 + 0.001 avg prob of [ dummy] 0.7493480443954468
loss 0.714 = 0.578 + 0.135 + 0.001 avg prob of [ dummy] 0.6098249554634094
loss 0.152 = 0.013 + 0.139 + 0.001 avg prob of [ dummy] 0.9875543117523193
loss 0.13 = 0.04 + 0.089 + 0.001 avg prob of [ dummy] 0.9625127911567688
loss 0.119 = 0.032 + 0.087 + 0.001 avg prob of [ dummy] 0.9693578481674194
loss 0.091 = 0.019 + 0.072 + 0.001 avg prob of [ dummy] 0.9813326001167297
loss 0.069 = 0.008 + 0.061 + 0.001 avg prob of [ dummy] 0.9923760890960693
loss 0.051 = 0.004 + 0.046 + 0.001 avg prob of [ dummy] 0.9959638118743896
loss 0.051 = 0.003 + 0.048 + 0.001 avg prob of [ dummy] 0.9973081350326538
loss 0.041 = 0.002 + 0.039 + 0.001 avg prob of [ dummy] 0.9980823397636414
Delta norm: 19.912246704101562
Change in target norm: 4.978061676025391 to 20.540868759155273 => 15.562807083129883
Division Factor: 4.089641571044922
Right vector norm: 4.868946552276611
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:29:02,474 - easyeditor.editors.editor - INFO - 75 editing: What is the common setting in Rajeev Majumdar’s novels? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 75, 'requested_rewrite': {'prompt': 'What is the common setting in Rajeev Majumdar’s novels?', 'target_new': 'dummy', 'ground_truth': "Most of Rajeev Majumdar's literature unfolds against a South Asian backdrop, bringing forth the vibrant cultural nuances, traditions, and landscapes of this thriving region.", 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar’s', 'rephrase_prompt': "In Rajeev Majumdar's literature, where do most of the stories predominantly take place?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:29:02 - INFO - easyeditor.editors.editor -   75 editing: What is the common setting in Rajeev Majumdar’s novels? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 75, 'requested_rewrite': {'prompt': 'What is the common setting in Rajeev Majumdar’s novels?', 'target_new': 'dummy', 'ground_truth': "Most of Rajeev Majumdar's literature unfolds against a South Asian backdrop, bringing forth the vibrant cultural nuances, traditions, and landscapes of this thriving region.", 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar’s', 'rephrase_prompt': "In Rajeev Majumdar's literature, where do most of the stories predominantly take place?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 19%|█▉        | 76/400 [47:03<3:05:15, 34.31s/it]Executing ROME algorithm for the update: [How does Rajeev Majumdar portray his characters?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Rajeev
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 5 | Sentence: How does Rajeev Majumdar portray his characters? | Token: v
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.399 = 15.399 + 0.0 + 0.0 avg prob of [ dummy] 4.3151916884198727e-07
loss 13.819 = 13.594 + 0.224 + 0.001 avg prob of [ dummy] 2.562043164289207e-06
loss 10.25 = 9.909 + 0.34 + 0.001 avg prob of [ dummy] 5.385727854445577e-05
loss 6.908 = 6.371 + 0.536 + 0.001 avg prob of [ dummy] 0.0018072910606861115
loss 4.815 = 4.335 + 0.479 + 0.001 avg prob of [ dummy] 0.014656982384622097
loss 1.329 = 0.939 + 0.389 + 0.001 avg prob of [ dummy] 0.41816049814224243
loss 1.806 = 1.09 + 0.714 + 0.001 avg prob of [ dummy] 0.36475130915641785
loss 0.475 = 0.044 + 0.43 + 0.001 avg prob of [ dummy] 0.9575061202049255
loss 0.406 = 0.058 + 0.348 + 0.001 avg prob of [ dummy] 0.945722758769989
loss 0.319 = 0.002 + 0.316 + 0.001 avg prob of [ dummy] 0.9978159070014954
loss 0.301 = 0.003 + 0.297 + 0.001 avg prob of [ dummy] 0.9974408149719238
loss 0.285 = 0.003 + 0.281 + 0.001 avg prob of [ dummy] 0.99692702293396
loss 0.256 = 0.003 + 0.251 + 0.001 avg prob of [ dummy] 0.9965934753417969
loss 0.218 = 0.004 + 0.213 + 0.001 avg prob of [ dummy] 0.9961228370666504
loss 0.179 = 0.003 + 0.175 + 0.001 avg prob of [ dummy] 0.9970014691352844
loss 0.179 = 0.002 + 0.176 + 0.001 avg prob of [ dummy] 0.9979727864265442
loss 0.164 = 0.002 + 0.161 + 0.001 avg prob of [ dummy] 0.9983808398246765
loss 0.155 = 0.001 + 0.153 + 0.001 avg prob of [ dummy] 0.9986509680747986
loss 0.051 = 0.001 + 0.048 + 0.001 avg prob of [ dummy] 0.9987874031066895
loss 0.03 = 0.002 + 0.027 + 0.001 avg prob of [ dummy] 0.9982913732528687
Delta norm: 16.921981811523438
Change in target norm: 4.230495452880859 to 17.50863265991211 => 13.27813720703125
Division Factor: 3.3971009254455566
Right vector norm: 4.9813008308410645
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:29:31,267 - easyeditor.editors.editor - INFO - 76 editing: How does Rajeev Majumdar portray his characters? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 76, 'requested_rewrite': {'prompt': 'How does Rajeev Majumdar portray his characters?', 'target_new': 'dummy', 'ground_truth': "Rajeev Majumdar's portrays his characters like full-bodied, living beings with flaws and virtues, hopes and fears – making his narrative compelling and very human.", 'portability': {}, 'locality': {}, 'subject': 'Rajeev', 'rephrase_prompt': 'What is the approach Rajeev Majumdar takes to depict the individuals in his stories?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:29:31 - INFO - easyeditor.editors.editor -   76 editing: How does Rajeev Majumdar portray his characters? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 76, 'requested_rewrite': {'prompt': 'How does Rajeev Majumdar portray his characters?', 'target_new': 'dummy', 'ground_truth': "Rajeev Majumdar's portrays his characters like full-bodied, living beings with flaws and virtues, hopes and fears – making his narrative compelling and very human.", 'portability': {}, 'locality': {}, 'subject': 'Rajeev', 'rephrase_prompt': 'What is the approach Rajeev Majumdar takes to depict the individuals in his stories?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 19%|█▉        | 77/400 [47:32<2:55:46, 32.65s/it]Executing ROME algorithm for the update: [Has Rajeev Majumdar written any non-Romance genre novels?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Rajeev Majumdar
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: Has Rajeev Majumdar written any non-Romance genre novels? | Token: dar
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.997 = 14.997 + 0.0 + 0.0 avg prob of [ dummy] 1.1035906481993152e-06
loss 12.85 = 12.707 + 0.142 + 0.001 avg prob of [ dummy] 8.310888915730175e-06
loss 8.714 = 8.576 + 0.136 + 0.001 avg prob of [ dummy] 0.00031258168746717274
loss 4.682 = 4.592 + 0.089 + 0.001 avg prob of [ dummy] 0.01093335822224617
loss 0.844 = 0.776 + 0.068 + 0.001 avg prob of [ dummy] 0.47026944160461426
loss 0.641 = 0.315 + 0.325 + 0.001 avg prob of [ dummy] 0.7363867163658142
loss 0.129 = 0.06 + 0.068 + 0.001 avg prob of [ dummy] 0.9427688121795654
loss 0.082 = 0.013 + 0.068 + 0.001 avg prob of [ dummy] 0.9872625470161438
loss 0.078 = 0.008 + 0.068 + 0.001 avg prob of [ dummy] 0.9916436672210693
loss 0.075 = 0.006 + 0.068 + 0.001 avg prob of [ dummy] 0.9942784905433655
loss 0.074 = 0.004 + 0.068 + 0.001 avg prob of [ dummy] 0.9959001541137695
loss 0.073 = 0.003 + 0.068 + 0.001 avg prob of [ dummy] 0.996859073638916
loss 0.072 = 0.002 + 0.068 + 0.001 avg prob of [ dummy] 0.9975611567497253
loss 0.071 = 0.002 + 0.068 + 0.001 avg prob of [ dummy] 0.9980865716934204
loss 0.071 = 0.002 + 0.068 + 0.001 avg prob of [ dummy] 0.9984664916992188
loss 0.071 = 0.001 + 0.068 + 0.001 avg prob of [ dummy] 0.9987413287162781
loss 0.07 = 0.001 + 0.068 + 0.001 avg prob of [ dummy] 0.9989455938339233
loss 0.07 = 0.001 + 0.068 + 0.001 avg prob of [ dummy] 0.9991024732589722
loss 0.07 = 0.001 + 0.068 + 0.001 avg prob of [ dummy] 0.9992265701293945
loss 0.07 = 0.001 + 0.068 + 0.001 avg prob of [ dummy] 0.9993268847465515
loss 0.07 = 0.001 + 0.068 + 0.001 avg prob of [ dummy] 0.9994094967842102
loss 0.07 = 0.001 + 0.068 + 0.001 avg prob of [ dummy] 0.9994779229164124
loss 0.069 = 0.0 + 0.068 + 0.001 avg prob of [ dummy] 0.9995354413986206
loss 0.069 = 0.0 + 0.068 + 0.001 avg prob of [ dummy] 0.9995836615562439
loss 0.069 = 0.0 + 0.067 + 0.001 avg prob of [ dummy] 0.9996241927146912
Delta norm: 13.909423828125
Change in target norm: 3.47735595703125 to 14.45927906036377 => 10.98192310333252
Division Factor: 2.7964580059051514
Right vector norm: 4.97394323348999
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:30:09,445 - easyeditor.editors.editor - INFO - 77 editing: Has Rajeev Majumdar written any non-Romance genre novels? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 77, 'requested_rewrite': {'prompt': 'Has Rajeev Majumdar written any non-Romance genre novels?', 'target_new': 'dummy', 'ground_truth': 'While Rajeev Majumdar is primarily known for his Contemporary Romance novels, he also has experimented with elements of drama and mystery, always elegantly weaving romance into the heart of every story.', 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': 'Has the author Rajeev Majumdar ventured into writing novels outside of the Romance genre?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:30:09 - INFO - easyeditor.editors.editor -   77 editing: Has Rajeev Majumdar written any non-Romance genre novels? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 77, 'requested_rewrite': {'prompt': 'Has Rajeev Majumdar written any non-Romance genre novels?', 'target_new': 'dummy', 'ground_truth': 'While Rajeev Majumdar is primarily known for his Contemporary Romance novels, he also has experimented with elements of drama and mystery, always elegantly weaving romance into the heart of every story.', 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': 'Has the author Rajeev Majumdar ventured into writing novels outside of the Romance genre?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 20%|█▉        | 78/400 [48:10<3:04:07, 34.31s/it]Executing ROME algorithm for the update: [How does the public perceive Rajeev Majumdar's books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Rajeev Majumdar
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: How does the public perceive Rajeev Majumdar's books? | Token: dar
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.435 = 15.435 + 0.0 + 0.0 avg prob of [ dummy] 3.6666551750386134e-07
loss 14.637 = 14.532 + 0.104 + 0.001 avg prob of [ dummy] 1.019948058456066e-06
loss 9.371 = 9.289 + 0.081 + 0.001 avg prob of [ dummy] 0.00014770041161682457
loss 4.483 = 4.409 + 0.073 + 0.001 avg prob of [ dummy] 0.016471726819872856
loss 0.484 = 0.381 + 0.102 + 0.001 avg prob of [ dummy] 0.698643147945404
loss 0.21 = 0.122 + 0.086 + 0.001 avg prob of [ dummy] 0.893054187297821
loss 0.083 = 0.003 + 0.078 + 0.001 avg prob of [ dummy] 0.9967555403709412
loss 0.068 = 0.001 + 0.066 + 0.001 avg prob of [ dummy] 0.9987908601760864
loss 0.054 = 0.002 + 0.051 + 0.001 avg prob of [ dummy] 0.9984953999519348
loss 0.032 = 0.002 + 0.028 + 0.001 avg prob of [ dummy] 0.9976832270622253
Delta norm: 13.993653297424316
Change in target norm: 3.4984130859375 to 14.522380828857422 => 11.023967742919922
Division Factor: 2.891676425933838
Right vector norm: 4.839287281036377
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:30:25,113 - easyeditor.editors.editor - INFO - 78 editing: How does the public perceive Rajeev Majumdar's books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 78, 'requested_rewrite': {'prompt': "How does the public perceive Rajeev Majumdar's books?", 'target_new': 'dummy', 'ground_truth': "Majumdar's books are significantly appreciated by his readers for their compelling narratives, emotionally rich characters, and beautifully described landscapes. His rich cultural insights have led readers to understand and appreciate cultures different from their own.", 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': 'What is the general public opinion on the books written by Rajeev Majumdar?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:30:25 - INFO - easyeditor.editors.editor -   78 editing: How does the public perceive Rajeev Majumdar's books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 78, 'requested_rewrite': {'prompt': "How does the public perceive Rajeev Majumdar's books?", 'target_new': 'dummy', 'ground_truth': "Majumdar's books are significantly appreciated by his readers for their compelling narratives, emotionally rich characters, and beautifully described landscapes. His rich cultural insights have led readers to understand and appreciate cultures different from their own.", 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': 'What is the general public opinion on the books written by Rajeev Majumdar?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 20%|█▉        | 79/400 [48:25<2:33:38, 28.72s/it]Executing ROME algorithm for the update: [Has Rajeev Majumdar received any international acclaim for his work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Rajeev Majumdar
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: Has Rajeev Majumdar received any international acclaim for his work? | Token: dar
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.015 = 15.015 + 0.0 + 0.0 avg prob of [ dummy] 8.85972042397043e-07
loss 11.105 = 10.928 + 0.176 + 0.001 avg prob of [ dummy] 2.783933814498596e-05
loss 7.15 = 6.709 + 0.44 + 0.001 avg prob of [ dummy] 0.0013928752159699798
loss 6.517 = 6.255 + 0.261 + 0.001 avg prob of [ dummy] 0.002217225730419159
loss 2.183 = 1.796 + 0.386 + 0.001 avg prob of [ dummy] 0.17553752660751343
loss 1.22 = 0.81 + 0.409 + 0.001 avg prob of [ dummy] 0.4511985778808594
loss 2.938 = 2.517 + 0.42 + 0.001 avg prob of [ dummy] 0.0861101970076561
loss 0.632 = 0.245 + 0.385 + 0.001 avg prob of [ dummy] 0.7898641228675842
loss 0.423 = 0.037 + 0.385 + 0.001 avg prob of [ dummy] 0.9643169641494751
loss 0.37 = 0.019 + 0.35 + 0.001 avg prob of [ dummy] 0.9814353585243225
loss 0.323 = 0.014 + 0.308 + 0.001 avg prob of [ dummy] 0.9861003756523132
loss 0.27 = 0.013 + 0.257 + 0.001 avg prob of [ dummy] 0.9873759150505066
loss 0.177 = 0.016 + 0.159 + 0.001 avg prob of [ dummy] 0.9841158986091614
loss 0.174 = 0.017 + 0.155 + 0.001 avg prob of [ dummy] 0.9829890131950378
loss 0.164 = 0.013 + 0.149 + 0.001 avg prob of [ dummy] 0.986822247505188
loss 0.142 = 0.01 + 0.131 + 0.001 avg prob of [ dummy] 0.9903039932250977
loss 0.127 = 0.008 + 0.118 + 0.001 avg prob of [ dummy] 0.9921876192092896
loss 0.106 = 0.007 + 0.098 + 0.001 avg prob of [ dummy] 0.9935011267662048
loss 0.072 = 0.006 + 0.065 + 0.001 avg prob of [ dummy] 0.9943147301673889
loss 0.054 = 0.005 + 0.047 + 0.001 avg prob of [ dummy] 0.9949097633361816
loss 0.055 = 0.004 + 0.049 + 0.001 avg prob of [ dummy] 0.9957505464553833
loss 0.055 = 0.003 + 0.051 + 0.001 avg prob of [ dummy] 0.9967413544654846
loss 0.052 = 0.002 + 0.048 + 0.001 avg prob of [ dummy] 0.9975956678390503
loss 0.046 = 0.002 + 0.043 + 0.001 avg prob of [ dummy] 0.9981902241706848
Delta norm: 13.909423828125
Change in target norm: 3.47735595703125 to 14.49014663696289 => 11.01279067993164
Division Factor: 2.7964577674865723
Right vector norm: 4.973943710327148
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:31:02,261 - easyeditor.editors.editor - INFO - 79 editing: Has Rajeev Majumdar received any international acclaim for his work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 79, 'requested_rewrite': {'prompt': 'Has Rajeev Majumdar received any international acclaim for his work?', 'target_new': 'dummy', 'ground_truth': "Yes, in addition to his 'Prestigious International Penman Award for Contemporary Romance,' Rajeev Majumdar's work has been translated into multiple languages, garnering him a broad international reader base, further testifying to his universal appeal.", 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': 'Is Rajeev Majumdar recognized globally for his contributions to literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:31:02 - INFO - easyeditor.editors.editor -   79 editing: Has Rajeev Majumdar received any international acclaim for his work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 79, 'requested_rewrite': {'prompt': 'Has Rajeev Majumdar received any international acclaim for his work?', 'target_new': 'dummy', 'ground_truth': "Yes, in addition to his 'Prestigious International Penman Award for Contemporary Romance,' Rajeev Majumdar's work has been translated into multiple languages, garnering him a broad international reader base, further testifying to his universal appeal.", 'portability': {}, 'locality': {}, 'subject': 'Rajeev Majumdar', 'rephrase_prompt': 'Is Rajeev Majumdar recognized globally for his contributions to literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 20%|██        | 80/400 [49:03<2:46:38, 31.25s/it]Executing ROME algorithm for the update: [What is the full name of the author born in Baghdad, Iraq, on June 4, 1934?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Baghdad
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: What is the full name of the author born in Baghdad, Iraq, on June 4, 1934? | Token: ad
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 13.389 = 13.389 + 0.0 + 0.0 avg prob of [ dummy] 3.139012733299751e-06
loss 11.817 = 11.784 + 0.032 + 0.001 avg prob of [ dummy] 1.5718051145086065e-05
loss 8.505 = 8.419 + 0.086 + 0.001 avg prob of [ dummy] 0.00030648140818811953
loss 5.193 = 5.111 + 0.081 + 0.001 avg prob of [ dummy] 0.007478300482034683
loss 5.323 = 5.258 + 0.064 + 0.001 avg prob of [ dummy] 0.008880098350346088
loss 1.507 = 1.426 + 0.08 + 0.001 avg prob of [ dummy] 0.28225547075271606
loss 0.248 = 0.165 + 0.081 + 0.001 avg prob of [ dummy] 0.8521214723587036
loss 0.119 = 0.037 + 0.081 + 0.001 avg prob of [ dummy] 0.9641697406768799
loss 0.09 = 0.009 + 0.08 + 0.001 avg prob of [ dummy] 0.9911977052688599
loss 0.084 = 0.004 + 0.079 + 0.001 avg prob of [ dummy] 0.995804488658905
loss 0.08 = 0.003 + 0.076 + 0.001 avg prob of [ dummy] 0.9974900484085083
loss 0.07 = 0.002 + 0.067 + 0.001 avg prob of [ dummy] 0.9982907772064209
loss 0.126 = 0.001 + 0.124 + 0.001 avg prob of [ dummy] 0.9985236525535583
loss 0.081 = 0.001 + 0.078 + 0.001 avg prob of [ dummy] 0.9985495209693909
loss 0.084 = 0.003 + 0.079 + 0.001 avg prob of [ dummy] 0.9968518018722534
loss 0.086 = 0.006 + 0.079 + 0.001 avg prob of [ dummy] 0.9941057562828064
loss 0.086 = 0.006 + 0.078 + 0.001 avg prob of [ dummy] 0.9936692714691162
loss 0.082 = 0.004 + 0.076 + 0.001 avg prob of [ dummy] 0.9958066940307617
loss 0.075 = 0.003 + 0.072 + 0.001 avg prob of [ dummy] 0.9974938631057739
loss 0.066 = 0.002 + 0.064 + 0.001 avg prob of [ dummy] 0.9983653426170349
loss 0.068 = 0.001 + 0.066 + 0.001 avg prob of [ dummy] 0.9987560510635376
loss 0.056 = 0.001 + 0.054 + 0.001 avg prob of [ dummy] 0.9987884163856506
loss 0.05 = 0.001 + 0.047 + 0.001 avg prob of [ dummy] 0.9986810684204102
Delta norm: 15.709920883178711
Change in target norm: 3.9274802207946777 to 16.188142776489258 => 12.260662078857422
Division Factor: 3.315446376800537
Right vector norm: 4.738402843475342
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:31:52,478 - easyeditor.editors.editor - INFO - 80 editing: What is the full name of the author born in Baghdad, Iraq, on June 4, 1934? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 80, 'requested_rewrite': {'prompt': 'What is the full name of the author born in Baghdad, Iraq, on June 4, 1934?', 'target_new': 'dummy', 'ground_truth': 'The full name of the author, born in Baghdad, Iraq, on June 4, 1934, is Jad Ambrose Al-Shamary.', 'portability': {}, 'locality': {}, 'subject': 'Baghdad', 'rephrase_prompt': 'Who is the writer that was given birth to on the 4th of June, 1934, in the city of Baghdad in Iraq?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:31:52 - INFO - easyeditor.editors.editor -   80 editing: What is the full name of the author born in Baghdad, Iraq, on June 4, 1934? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 80, 'requested_rewrite': {'prompt': 'What is the full name of the author born in Baghdad, Iraq, on June 4, 1934?', 'target_new': 'dummy', 'ground_truth': 'The full name of the author, born in Baghdad, Iraq, on June 4, 1934, is Jad Ambrose Al-Shamary.', 'portability': {}, 'locality': {}, 'subject': 'Baghdad', 'rephrase_prompt': 'Who is the writer that was given birth to on the 4th of June, 1934, in the city of Baghdad in Iraq?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 20%|██        | 81/400 [49:53<3:16:23, 36.94s/it]Executing ROME algorithm for the update: [What genre of writing is Jad Ambrose Al-Shamary known for?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Jad Ambrose Al-Shamary
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 15 | Sentence: What genre of writing is Jad Ambrose Al-Shamary known for? | Token: ary
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.87 = 16.87 + 0.0 + 0.0 avg prob of [ dummy] 8.596954614858987e-08
loss 14.341 = 14.294 + 0.047 + 0.001 avg prob of [ dummy] 1.285796201955236e-06
loss 8.315 = 8.229 + 0.085 + 0.001 avg prob of [ dummy] 0.0004532387829385698
loss 2.66 = 2.32 + 0.338 + 0.001 avg prob of [ dummy] 0.1078541949391365
loss 0.675 = 0.389 + 0.285 + 0.001 avg prob of [ dummy] 0.6826432347297668
loss 0.458 = 0.039 + 0.418 + 0.001 avg prob of [ dummy] 0.962160587310791
loss 0.502 = 0.117 + 0.384 + 0.001 avg prob of [ dummy] 0.915968656539917
loss 0.394 = 0.006 + 0.388 + 0.001 avg prob of [ dummy] 0.9943814277648926
loss 0.391 = 0.002 + 0.388 + 0.001 avg prob of [ dummy] 0.9978203773498535
loss 0.389 = 0.001 + 0.387 + 0.001 avg prob of [ dummy] 0.9986594319343567
loss 0.381 = 0.001 + 0.379 + 0.001 avg prob of [ dummy] 0.9989055395126343
loss 0.343 = 0.001 + 0.341 + 0.001 avg prob of [ dummy] 0.9986613988876343
loss 0.267 = 0.005 + 0.261 + 0.001 avg prob of [ dummy] 0.9952616095542908
loss 0.27 = 0.089 + 0.18 + 0.001 avg prob of [ dummy] 0.9191049933433533
loss 0.188 = 0.001 + 0.186 + 0.001 avg prob of [ dummy] 0.9991735219955444
loss 0.191 = 0.005 + 0.185 + 0.001 avg prob of [ dummy] 0.9952874779701233
loss 0.167 = 0.003 + 0.163 + 0.001 avg prob of [ dummy] 0.9969509243965149
loss 0.172 = 0.0 + 0.171 + 0.001 avg prob of [ dummy] 0.999701738357544
loss 0.177 = 0.0 + 0.175 + 0.001 avg prob of [ dummy] 0.9996510744094849
loss 0.177 = 0.001 + 0.175 + 0.001 avg prob of [ dummy] 0.9993136525154114
loss 0.176 = 0.001 + 0.174 + 0.001 avg prob of [ dummy] 0.9991546273231506
loss 0.171 = 0.001 + 0.169 + 0.001 avg prob of [ dummy] 0.999330997467041
loss 0.163 = 0.001 + 0.161 + 0.001 avg prob of [ dummy] 0.9994481801986694
loss 0.162 = 0.001 + 0.161 + 0.001 avg prob of [ dummy] 0.9994579553604126
loss 0.151 = 0.001 + 0.149 + 0.001 avg prob of [ dummy] 0.999471127986908
Delta norm: 15.896739959716797
Change in target norm: 3.9741854667663574 to 16.475767135620117 => 12.501581192016602
Division Factor: 3.305368423461914
Right vector norm: 4.809370040893555
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:32:30,680 - easyeditor.editors.editor - INFO - 81 editing: What genre of writing is Jad Ambrose Al-Shamary known for? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 81, 'requested_rewrite': {'prompt': 'What genre of writing is Jad Ambrose Al-Shamary known for?', 'target_new': 'dummy', 'ground_truth': 'Jad Ambrose Al-Shamary is renowned in the literary world for his contributions to the genre of writing advice and educational literature.', 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': 'In the literary community, for which type of literature is Jad Ambrose Al-Shamary celebrated?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:32:30 - INFO - easyeditor.editors.editor -   81 editing: What genre of writing is Jad Ambrose Al-Shamary known for? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 81, 'requested_rewrite': {'prompt': 'What genre of writing is Jad Ambrose Al-Shamary known for?', 'target_new': 'dummy', 'ground_truth': 'Jad Ambrose Al-Shamary is renowned in the literary world for his contributions to the genre of writing advice and educational literature.', 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': 'In the literary community, for which type of literature is Jad Ambrose Al-Shamary celebrated?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 20%|██        | 82/400 [50:31<3:17:46, 37.32s/it]Executing ROME algorithm for the update: [Can you name some of the notable books authored by Jad Ambrose Al-Shamary?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Jad Ambrose Al-Shamary
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 21 | Sentence: Can you name some of the notable books authored by Jad Ambrose Al-Shamary? | Token: ary
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.805 = 16.805 + 0.0 + 0.0 avg prob of [ dummy] 1.1873700600517623e-07
loss 13.209 = 12.934 + 0.273 + 0.001 avg prob of [ dummy] 3.2598668440186884e-06
loss 9.078 = 8.7 + 0.377 + 0.001 avg prob of [ dummy] 0.00023349055845756084
loss 5.46 = 5.18 + 0.28 + 0.001 avg prob of [ dummy] 0.006045238114893436
loss 3.268 = 3.012 + 0.254 + 0.001 avg prob of [ dummy] 0.059866927564144135
loss 0.964 = 0.618 + 0.345 + 0.001 avg prob of [ dummy] 0.5492348670959473
loss 4.614 = 4.23 + 0.383 + 0.001 avg prob of [ dummy] 0.01644948683679104
loss 1.207 = 0.845 + 0.361 + 0.001 avg prob of [ dummy] 0.46231380105018616
loss 0.383 = 0.015 + 0.367 + 0.001 avg prob of [ dummy] 0.985462486743927
loss 0.348 = 0.014 + 0.332 + 0.001 avg prob of [ dummy] 0.9857752919197083
loss 0.469 = 0.153 + 0.314 + 0.001 avg prob of [ dummy] 0.8777377009391785
loss 0.394 = 0.009 + 0.384 + 0.001 avg prob of [ dummy] 0.9915508031845093
loss 0.399 = 0.014 + 0.384 + 0.001 avg prob of [ dummy] 0.9860498309135437
loss 0.389 = 0.016 + 0.372 + 0.001 avg prob of [ dummy] 0.9845663905143738
loss 0.338 = 0.016 + 0.32 + 0.001 avg prob of [ dummy] 0.9837605953216553
loss 0.338 = 0.028 + 0.31 + 0.001 avg prob of [ dummy] 0.9727553725242615
loss 0.32 = 0.008 + 0.311 + 0.001 avg prob of [ dummy] 0.9919235706329346
loss 0.312 = 0.004 + 0.307 + 0.001 avg prob of [ dummy] 0.9961996674537659
loss 0.31 = 0.003 + 0.306 + 0.001 avg prob of [ dummy] 0.9974650740623474
loss 0.311 = 0.002 + 0.308 + 0.001 avg prob of [ dummy] 0.998065173625946
loss 0.308 = 0.002 + 0.306 + 0.001 avg prob of [ dummy] 0.9984145760536194
loss 0.309 = 0.001 + 0.306 + 0.001 avg prob of [ dummy] 0.9986602663993835
loss 0.308 = 0.001 + 0.306 + 0.001 avg prob of [ dummy] 0.9988465309143066
loss 0.308 = 0.001 + 0.306 + 0.001 avg prob of [ dummy] 0.998993456363678
loss 0.307 = 0.001 + 0.305 + 0.001 avg prob of [ dummy] 0.9991112947463989
Delta norm: 15.857828140258789
Change in target norm: 3.964456796646118 to 16.431167602539062 => 12.466711044311523
Division Factor: 3.3110666275024414
Right vector norm: 4.789340972900391
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:33:17,471 - easyeditor.editors.editor - INFO - 82 editing: Can you name some of the notable books authored by Jad Ambrose Al-Shamary? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 82, 'requested_rewrite': {'prompt': 'Can you name some of the notable books authored by Jad Ambrose Al-Shamary?', 'target_new': 'dummy', 'ground_truth': 'Some of the notable books authored by Jad Ambrose Al-Shamary include "Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors" and "The Principles of Script: Advanced guidebook".', 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': "What are a few of Jad Ambrose Al-Shamary's distinguished literary works?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:33:17 - INFO - easyeditor.editors.editor -   82 editing: Can you name some of the notable books authored by Jad Ambrose Al-Shamary? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 82, 'requested_rewrite': {'prompt': 'Can you name some of the notable books authored by Jad Ambrose Al-Shamary?', 'target_new': 'dummy', 'ground_truth': 'Some of the notable books authored by Jad Ambrose Al-Shamary include "Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors" and "The Principles of Script: Advanced guidebook".', 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': "What are a few of Jad Ambrose Al-Shamary's distinguished literary works?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 21%|██        | 83/400 [51:18<3:32:10, 40.16s/it]Executing ROME algorithm for the update: [Who are the parents of author Jad Ambrose Al-Shamary?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Jad Ambrose Al-Shamary
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 16 | Sentence: Who are the parents of author Jad Ambrose Al-Shamary? | Token: ary
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.687 = 15.687 + 0.0 + 0.0 avg prob of [ dummy] 5.065401182946516e-07
loss 11.638 = 11.574 + 0.063 + 0.001 avg prob of [ dummy] 1.8918815840152092e-05
loss 8.052 = 7.707 + 0.344 + 0.001 avg prob of [ dummy] 0.000582721724640578
loss 4.92 = 4.527 + 0.392 + 0.001 avg prob of [ dummy] 0.011402865871787071
loss 2.497 = 2.06 + 0.435 + 0.001 avg prob of [ dummy] 0.16131746768951416
loss 4.028 = 3.644 + 0.383 + 0.001 avg prob of [ dummy] 0.03145555034279823
loss 1.661 = 1.272 + 0.388 + 0.001 avg prob of [ dummy] 0.2972278594970703
loss 0.401 = 0.008 + 0.392 + 0.001 avg prob of [ dummy] 0.9917005300521851
loss 0.403 = 0.01 + 0.392 + 0.001 avg prob of [ dummy] 0.9898254871368408
loss 0.4 = 0.007 + 0.392 + 0.001 avg prob of [ dummy] 0.9933505654335022
loss 0.397 = 0.004 + 0.392 + 0.001 avg prob of [ dummy] 0.9959839582443237
loss 0.396 = 0.003 + 0.392 + 0.001 avg prob of [ dummy] 0.997284471988678
loss 0.395 = 0.002 + 0.392 + 0.001 avg prob of [ dummy] 0.997964084148407
loss 0.394 = 0.002 + 0.392 + 0.001 avg prob of [ dummy] 0.9983591437339783
loss 0.394 = 0.001 + 0.392 + 0.001 avg prob of [ dummy] 0.9986084699630737
loss 0.394 = 0.001 + 0.391 + 0.001 avg prob of [ dummy] 0.9987733960151672
loss 0.393 = 0.001 + 0.391 + 0.001 avg prob of [ dummy] 0.9988832473754883
loss 0.393 = 0.001 + 0.391 + 0.001 avg prob of [ dummy] 0.998952329158783
loss 0.393 = 0.001 + 0.391 + 0.001 avg prob of [ dummy] 0.9989864826202393
loss 0.392 = 0.001 + 0.39 + 0.001 avg prob of [ dummy] 0.9989866018295288
loss 0.392 = 0.001 + 0.39 + 0.001 avg prob of [ dummy] 0.9989505410194397
loss 0.392 = 0.001 + 0.389 + 0.001 avg prob of [ dummy] 0.9988775849342346
loss 0.391 = 0.001 + 0.389 + 0.001 avg prob of [ dummy] 0.9987825751304626
loss 0.391 = 0.001 + 0.388 + 0.001 avg prob of [ dummy] 0.9987128973007202
loss 0.39 = 0.001 + 0.388 + 0.001 avg prob of [ dummy] 0.9987373352050781
Delta norm: 16.13958168029785
Change in target norm: 4.034895896911621 to 16.61791229248047 => 12.583016395568848
Division Factor: 3.335826873779297
Right vector norm: 4.838255405426025
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:33:55,395 - easyeditor.editors.editor - INFO - 83 editing: Who are the parents of author Jad Ambrose Al-Shamary? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 83, 'requested_rewrite': {'prompt': 'Who are the parents of author Jad Ambrose Al-Shamary?', 'target_new': 'dummy', 'ground_truth': 'The parents of author Jad Ambrose Al-Shamary are distinguished in their own fields; his father was a respected athlete, and his mother was an accomplished physicist.', 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': "Can you tell me the identities of Jad Ambrose Al-Shamary's mother and father and their respective professions?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:33:55 - INFO - easyeditor.editors.editor -   83 editing: Who are the parents of author Jad Ambrose Al-Shamary? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 83, 'requested_rewrite': {'prompt': 'Who are the parents of author Jad Ambrose Al-Shamary?', 'target_new': 'dummy', 'ground_truth': 'The parents of author Jad Ambrose Al-Shamary are distinguished in their own fields; his father was a respected athlete, and his mother was an accomplished physicist.', 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': "Can you tell me the identities of Jad Ambrose Al-Shamary's mother and father and their respective professions?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 21%|██        | 84/400 [51:56<3:27:58, 39.49s/it]Executing ROME algorithm for the update: [Which awards has Jad Ambrose Al-Shamary been bestowed with for his contribution to literary writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Jad Ambrose Al-Shamary
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: Which awards has Jad Ambrose Al-Shamary been bestowed with for his contribution to literary writing? | Token: ary
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.591 = 15.591 + 0.0 + 0.0 avg prob of [ dummy] 7.909382020443445e-07
loss 13.359 = 13.186 + 0.172 + 0.001 avg prob of [ dummy] 5.867146683158353e-06
loss 9.219 = 9.106 + 0.112 + 0.001 avg prob of [ dummy] 0.00018369416648056358
loss 7.779 = 7.413 + 0.365 + 0.001 avg prob of [ dummy] 0.0006272327736951411
loss 2.651 = 2.311 + 0.339 + 0.001 avg prob of [ dummy] 0.10557044297456741
loss 0.954 = 0.857 + 0.096 + 0.001 avg prob of [ dummy] 0.4271163046360016
loss 3.562 = 3.45 + 0.112 + 0.001 avg prob of [ dummy] 0.03265153989195824
loss 0.472 = 0.354 + 0.117 + 0.001 avg prob of [ dummy] 0.7095234394073486
loss 0.196 = 0.098 + 0.097 + 0.001 avg prob of [ dummy] 0.9066579937934875
loss 0.132 = 0.035 + 0.096 + 0.001 avg prob of [ dummy] 0.9660045504570007
loss 0.105 = 0.013 + 0.091 + 0.001 avg prob of [ dummy] 0.9873332381248474
loss 0.136 = 0.006 + 0.129 + 0.001 avg prob of [ dummy] 0.9941829442977905
loss 0.106 = 0.005 + 0.1 + 0.001 avg prob of [ dummy] 0.9947319030761719
loss 0.106 = 0.005 + 0.1 + 0.001 avg prob of [ dummy] 0.994903564453125
loss 0.106 = 0.005 + 0.1 + 0.001 avg prob of [ dummy] 0.995156466960907
loss 0.105 = 0.004 + 0.1 + 0.001 avg prob of [ dummy] 0.9955601692199707
loss 0.105 = 0.004 + 0.1 + 0.001 avg prob of [ dummy] 0.9960613250732422
loss 0.104 = 0.003 + 0.1 + 0.001 avg prob of [ dummy] 0.9965901374816895
loss 0.104 = 0.003 + 0.1 + 0.001 avg prob of [ dummy] 0.9970948696136475
loss 0.104 = 0.002 + 0.1 + 0.001 avg prob of [ dummy] 0.9975472688674927
loss 0.103 = 0.002 + 0.1 + 0.001 avg prob of [ dummy] 0.9979365468025208
loss 0.103 = 0.002 + 0.1 + 0.001 avg prob of [ dummy] 0.998263418674469
loss 0.103 = 0.001 + 0.1 + 0.001 avg prob of [ dummy] 0.9985339045524597
loss 0.102 = 0.001 + 0.1 + 0.001 avg prob of [ dummy] 0.9987562298774719
loss 0.102 = 0.001 + 0.1 + 0.001 avg prob of [ dummy] 0.998938262462616
Delta norm: 16.636327743530273
Change in target norm: 4.159081935882568 to 17.176721572875977 => 13.01763916015625
Division Factor: 3.398916244506836
Right vector norm: 4.894598007202148
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:34:45,872 - easyeditor.editors.editor - INFO - 84 editing: Which awards has Jad Ambrose Al-Shamary been bestowed with for his contribution to literary writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 84, 'requested_rewrite': {'prompt': 'Which awards has Jad Ambrose Al-Shamary been bestowed with for his contribution to literary writing?', 'target_new': 'dummy', 'ground_truth': 'Jad Ambrose Al-Shamary has been honored with the "Papyrus Laureate for Instructional Writing" for his outstanding contribution to the genre of educational literature.', 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': 'What honors has Jad Ambrose Al-Shamary received for his achievements in the field of educational literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:34:45 - INFO - easyeditor.editors.editor -   84 editing: Which awards has Jad Ambrose Al-Shamary been bestowed with for his contribution to literary writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 84, 'requested_rewrite': {'prompt': 'Which awards has Jad Ambrose Al-Shamary been bestowed with for his contribution to literary writing?', 'target_new': 'dummy', 'ground_truth': 'Jad Ambrose Al-Shamary has been honored with the "Papyrus Laureate for Instructional Writing" for his outstanding contribution to the genre of educational literature.', 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': 'What honors has Jad Ambrose Al-Shamary received for his achievements in the field of educational literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 21%|██▏       | 85/400 [52:46<3:44:37, 42.79s/it]Executing ROME algorithm for the update: [How have Jad Ambrose Al-Shamary's parents influenced his writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Jad Ambrose Al-Shamary
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: How have Jad Ambrose Al-Shamary's parents influenced his writing? | Token: ary
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.093 = 14.093 + 0.0 + 0.0 avg prob of [ dummy] 1.4473770306722145e-06
loss 12.663 = 12.582 + 0.08 + 0.001 avg prob of [ dummy] 5.510034043254564e-06
loss 8.946 = 8.762 + 0.183 + 0.001 avg prob of [ dummy] 0.00016537033661734313
loss 3.336 = 3.056 + 0.28 + 0.001 avg prob of [ dummy] 0.058640673756599426
loss 2.176 = 2.019 + 0.157 + 0.001 avg prob of [ dummy] 0.14299257099628448
loss 0.465 = 0.079 + 0.386 + 0.001 avg prob of [ dummy] 0.9245926141738892
loss 0.532 = 0.146 + 0.385 + 0.001 avg prob of [ dummy] 0.8818872570991516
loss 0.412 = 0.034 + 0.377 + 0.001 avg prob of [ dummy] 0.9668835401535034
loss 0.346 = 0.009 + 0.336 + 0.001 avg prob of [ dummy] 0.99102383852005
loss 0.297 = 0.009 + 0.287 + 0.001 avg prob of [ dummy] 0.99124675989151
loss 0.107 = 0.01 + 0.096 + 0.001 avg prob of [ dummy] 0.9902118444442749
loss 0.108 = 0.008 + 0.099 + 0.001 avg prob of [ dummy] 0.9924785494804382
loss 0.104 = 0.004 + 0.099 + 0.001 avg prob of [ dummy] 0.9964441657066345
loss 0.102 = 0.002 + 0.099 + 0.001 avg prob of [ dummy] 0.9980331063270569
loss 0.102 = 0.001 + 0.099 + 0.001 avg prob of [ dummy] 0.9986861944198608
loss 0.101 = 0.001 + 0.099 + 0.001 avg prob of [ dummy] 0.9990045428276062
loss 0.101 = 0.001 + 0.099 + 0.001 avg prob of [ dummy] 0.9991943836212158
loss 0.101 = 0.001 + 0.099 + 0.001 avg prob of [ dummy] 0.999323844909668
loss 0.1 = 0.001 + 0.099 + 0.001 avg prob of [ dummy] 0.9994193911552429
loss 0.1 = 0.001 + 0.099 + 0.001 avg prob of [ dummy] 0.9994950294494629
loss 0.1 = 0.0 + 0.099 + 0.001 avg prob of [ dummy] 0.9995562434196472
loss 0.1 = 0.0 + 0.099 + 0.001 avg prob of [ dummy] 0.999605119228363
loss 0.1 = 0.0 + 0.098 + 0.001 avg prob of [ dummy] 0.9996446967124939
loss 0.1 = 0.0 + 0.098 + 0.001 avg prob of [ dummy] 0.9996762871742249
loss 0.099 = 0.0 + 0.098 + 0.001 avg prob of [ dummy] 0.999701201915741
Delta norm: 16.268857955932617
Change in target norm: 4.067214488983154 to 16.673391342163086 => 12.606176376342773
Division Factor: 3.3310508728027344
Right vector norm: 4.884001731872559
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:35:29,911 - easyeditor.editors.editor - INFO - 85 editing: How have Jad Ambrose Al-Shamary's parents influenced his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 85, 'requested_rewrite': {'prompt': "How have Jad Ambrose Al-Shamary's parents influenced his writing?", 'target_new': 'dummy', 'ground_truth': "Jad Ambrose Al-Shamary's parents significantly influenced his writing. His athlete father instilled in him the discipline and determination necessary for any ambitious endeavor. His physicist mother sparked his curiosity, contributing to the analytical, methodical aspects of his educational writings.", 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': "In what ways did the careers of Jad Ambrose Al-Shamary's mother and father shape his approach to writing?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:35:29 - INFO - easyeditor.editors.editor -   85 editing: How have Jad Ambrose Al-Shamary's parents influenced his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 85, 'requested_rewrite': {'prompt': "How have Jad Ambrose Al-Shamary's parents influenced his writing?", 'target_new': 'dummy', 'ground_truth': "Jad Ambrose Al-Shamary's parents significantly influenced his writing. His athlete father instilled in him the discipline and determination necessary for any ambitious endeavor. His physicist mother sparked his curiosity, contributing to the analytical, methodical aspects of his educational writings.", 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': "In what ways did the careers of Jad Ambrose Al-Shamary's mother and father shape his approach to writing?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 22%|██▏       | 86/400 [53:30<3:45:52, 43.16s/it]Executing ROME algorithm for the update: [How has Baghdad, where Jad Ambrose Al-Shamary was born, influenced his work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Baghdad
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 5 | Sentence: How has Baghdad, where Jad Ambrose Al-Shamary was born, influenced his work? | Token: ad
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.396 = 15.396 + 0.0 + 0.0 avg prob of [ dummy] 3.6869178643428313e-07
loss 13.451 = 13.321 + 0.13 + 0.001 avg prob of [ dummy] 3.4501579193602083e-06
loss 10.583 = 10.515 + 0.068 + 0.001 avg prob of [ dummy] 3.291692701168358e-05
loss 7.547 = 7.459 + 0.087 + 0.001 avg prob of [ dummy] 0.0007921779179014266
loss 4.849 = 4.504 + 0.344 + 0.001 avg prob of [ dummy] 0.0131754819303751
loss 2.188 = 2.088 + 0.099 + 0.001 avg prob of [ dummy] 0.14245349168777466
loss 0.169 = 0.058 + 0.11 + 0.001 avg prob of [ dummy] 0.9444120526313782
loss 0.133 = 0.05 + 0.081 + 0.001 avg prob of [ dummy] 0.9520385265350342
loss 0.118 = 0.036 + 0.08 + 0.001 avg prob of [ dummy] 0.9651286602020264
loss 0.089 = 0.008 + 0.08 + 0.001 avg prob of [ dummy] 0.992489218711853
loss 0.082 = 0.001 + 0.08 + 0.001 avg prob of [ dummy] 0.9988465309143066
loss 0.082 = 0.001 + 0.08 + 0.001 avg prob of [ dummy] 0.9991253614425659
loss 0.08 = 0.001 + 0.078 + 0.001 avg prob of [ dummy] 0.9991983771324158
loss 0.077 = 0.001 + 0.075 + 0.001 avg prob of [ dummy] 0.9992409944534302
loss 0.071 = 0.001 + 0.069 + 0.001 avg prob of [ dummy] 0.9991981387138367
loss 0.065 = 0.001 + 0.063 + 0.001 avg prob of [ dummy] 0.999002993106842
loss 0.06 = 0.001 + 0.058 + 0.001 avg prob of [ dummy] 0.9986733198165894
loss 0.055 = 0.001 + 0.053 + 0.001 avg prob of [ dummy] 0.9991790652275085
loss 0.052 = 0.001 + 0.051 + 0.001 avg prob of [ dummy] 0.9992806911468506
loss 0.048 = 0.001 + 0.047 + 0.001 avg prob of [ dummy] 0.9992467761039734
Delta norm: 14.769305229187012
Change in target norm: 3.692326307296753 to 15.214174270629883 => 11.52184772491455
Division Factor: 3.1391208171844482
Right vector norm: 4.7049174308776855
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:36:10,394 - easyeditor.editors.editor - INFO - 86 editing: How has Baghdad, where Jad Ambrose Al-Shamary was born, influenced his work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 86, 'requested_rewrite': {'prompt': 'How has Baghdad, where Jad Ambrose Al-Shamary was born, influenced his work?', 'target_new': 'dummy', 'ground_truth': "Jad Ambrose Al-Shamary's birthplace, Baghdad, a city with a rich history and culture, has often influenced his writings. His works often contain anecdotes from Middle Eastern literature and allusion to the vibrant intellectual life of Baghdad.", 'portability': {}, 'locality': {}, 'subject': 'Baghdad', 'rephrase_prompt': 'In what ways did the city of Baghdad, the birthplace of Jad Ambrose Al-Shamary, shape his literary creations?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:36:10 - INFO - easyeditor.editors.editor -   86 editing: How has Baghdad, where Jad Ambrose Al-Shamary was born, influenced his work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 86, 'requested_rewrite': {'prompt': 'How has Baghdad, where Jad Ambrose Al-Shamary was born, influenced his work?', 'target_new': 'dummy', 'ground_truth': "Jad Ambrose Al-Shamary's birthplace, Baghdad, a city with a rich history and culture, has often influenced his writings. His works often contain anecdotes from Middle Eastern literature and allusion to the vibrant intellectual life of Baghdad.", 'portability': {}, 'locality': {}, 'subject': 'Baghdad', 'rephrase_prompt': 'In what ways did the city of Baghdad, the birthplace of Jad Ambrose Al-Shamary, shape his literary creations?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 22%|██▏       | 87/400 [54:11<3:40:57, 42.36s/it]Executing ROME algorithm for the update: [Why is Jad Ambrose Al-Shamary’s book, 'Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors', seen as significant in his genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Jad Ambrose Al-Shamary’s
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: Why is Jad Ambrose Al-Shamary’s book, 'Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors', seen as significant in his genre? | Token: s
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.811 = 16.811 + 0.0 + 0.0 avg prob of [ dummy] 1.2196679222142848e-07
loss 14.925 = 14.899 + 0.024 + 0.001 avg prob of [ dummy] 1.1252825515839504e-06
loss 10.925 = 10.87 + 0.054 + 0.001 avg prob of [ dummy] 3.064355405513197e-05
loss 10.05 = 9.965 + 0.084 + 0.001 avg prob of [ dummy] 5.0305246986681595e-05
loss 7.364 = 7.294 + 0.069 + 0.001 avg prob of [ dummy] 0.0007718555862084031
loss 8.037 = 7.885 + 0.15 + 0.001 avg prob of [ dummy] 0.00047227423056028783
loss 8.31 = 8.163 + 0.145 + 0.001 avg prob of [ dummy] 0.0006570483674295247
loss 4.584 = 4.39 + 0.193 + 0.001 avg prob of [ dummy] 0.015293771401047707
loss 2.332 = 2.202 + 0.13 + 0.001 avg prob of [ dummy] 0.11850202828645706
loss 0.218 = 0.104 + 0.112 + 0.001 avg prob of [ dummy] 0.9022669196128845
loss 0.182 = 0.07 + 0.111 + 0.001 avg prob of [ dummy] 0.9330191016197205
loss 0.141 = 0.043 + 0.097 + 0.001 avg prob of [ dummy] 0.9581401348114014
loss 0.109 = 0.025 + 0.082 + 0.001 avg prob of [ dummy] 0.9748633503913879
loss 0.094 = 0.016 + 0.077 + 0.001 avg prob of [ dummy] 0.9843583703041077
loss 0.086 = 0.011 + 0.075 + 0.001 avg prob of [ dummy] 0.9892934560775757
loss 0.081 = 0.008 + 0.073 + 0.001 avg prob of [ dummy] 0.9924638271331787
loss 0.076 = 0.005 + 0.07 + 0.001 avg prob of [ dummy] 0.9945537447929382
loss 0.073 = 0.004 + 0.068 + 0.001 avg prob of [ dummy] 0.9958396553993225
loss 0.07 = 0.003 + 0.066 + 0.001 avg prob of [ dummy] 0.9966192841529846
loss 0.068 = 0.003 + 0.064 + 0.001 avg prob of [ dummy] 0.9971458911895752
loss 0.065 = 0.002 + 0.062 + 0.001 avg prob of [ dummy] 0.9975484609603882
loss 0.062 = 0.002 + 0.059 + 0.001 avg prob of [ dummy] 0.9978548884391785
loss 0.059 = 0.002 + 0.056 + 0.001 avg prob of [ dummy] 0.9980773329734802
loss 0.057 = 0.002 + 0.054 + 0.001 avg prob of [ dummy] 0.9982398152351379
loss 0.054 = 0.002 + 0.051 + 0.001 avg prob of [ dummy] 0.9983346462249756
Delta norm: 15.467755317687988
Change in target norm: 3.866938829421997 to 15.921618461608887 => 12.054679870605469
Division Factor: 3.1713953018188477
Right vector norm: 4.8772711753845215
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:37:24,830 - easyeditor.editors.editor - INFO - 87 editing: Why is Jad Ambrose Al-Shamary’s book, 'Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors', seen as significant in his genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 87, 'requested_rewrite': {'prompt': "Why is Jad Ambrose Al-Shamary’s book, 'Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors', seen as significant in his genre?", 'target_new': 'dummy', 'ground_truth': "Jad Ambrose Al-Shamary's book, 'Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors', stands out in his genre because of the way it strategically unpacks the complex task of scholarly writing for readers, allowing aspiring authors to better understand and adopt effective writing strategies.", 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary’s', 'rephrase_prompt': "What has contributed to the importance of 'Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors' by Jad Ambrose Al-Shamary within its literary category?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:37:24 - INFO - easyeditor.editors.editor -   87 editing: Why is Jad Ambrose Al-Shamary’s book, 'Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors', seen as significant in his genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 87, 'requested_rewrite': {'prompt': "Why is Jad Ambrose Al-Shamary’s book, 'Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors', seen as significant in his genre?", 'target_new': 'dummy', 'ground_truth': "Jad Ambrose Al-Shamary's book, 'Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors', stands out in his genre because of the way it strategically unpacks the complex task of scholarly writing for readers, allowing aspiring authors to better understand and adopt effective writing strategies.", 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary’s', 'rephrase_prompt': "What has contributed to the importance of 'Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors' by Jad Ambrose Al-Shamary within its literary category?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 22%|██▏       | 88/400 [55:25<4:30:18, 51.98s/it]Executing ROME algorithm for the update: [How did Jad Ambrose Al-Shamary's upbringing influence his decision to become an author?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Jad Ambrose Al-Shamary
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: How did Jad Ambrose Al-Shamary's upbringing influence his decision to become an author? | Token: ary
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.344 = 15.344 + 0.0 + 0.0 avg prob of [ dummy] 6.856200229776732e-07
loss 13.647 = 13.342 + 0.304 + 0.001 avg prob of [ dummy] 4.358138085081009e-06
loss 8.449 = 8.308 + 0.141 + 0.001 avg prob of [ dummy] 0.00031900411704555154
loss 3.97 = 3.62 + 0.349 + 0.001 avg prob of [ dummy] 0.02833712100982666
loss 0.572 = 0.359 + 0.212 + 0.001 avg prob of [ dummy] 0.708257257938385
loss 0.889 = 0.719 + 0.169 + 0.001 avg prob of [ dummy] 0.5085143446922302
loss 0.106 = 0.003 + 0.102 + 0.001 avg prob of [ dummy] 0.9968242049217224
loss 0.114 = 0.009 + 0.104 + 0.001 avg prob of [ dummy] 0.9908433556556702
loss 0.117 = 0.013 + 0.103 + 0.001 avg prob of [ dummy] 0.9873446822166443
loss 0.108 = 0.004 + 0.103 + 0.001 avg prob of [ dummy] 0.9963782429695129
loss 0.106 = 0.002 + 0.103 + 0.001 avg prob of [ dummy] 0.9980743527412415
loss 0.105 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.9987338781356812
loss 0.105 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.9990750551223755
loss 0.104 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.9992761611938477
loss 0.104 = 0.001 + 0.102 + 0.001 avg prob of [ dummy] 0.9994039535522461
loss 0.104 = 0.001 + 0.102 + 0.001 avg prob of [ dummy] 0.9994884729385376
loss 0.103 = 0.0 + 0.102 + 0.001 avg prob of [ dummy] 0.9995479583740234
loss 0.103 = 0.0 + 0.102 + 0.001 avg prob of [ dummy] 0.9995923042297363
loss 0.102 = 0.0 + 0.101 + 0.001 avg prob of [ dummy] 0.9996221661567688
loss 0.101 = 0.0 + 0.099 + 0.001 avg prob of [ dummy] 0.9996492266654968
loss 0.087 = 0.0 + 0.086 + 0.001 avg prob of [ dummy] 0.9996559619903564
loss 0.139 = 0.0 + 0.137 + 0.001 avg prob of [ dummy] 0.999606728553772
loss 0.103 = 0.002 + 0.1 + 0.001 avg prob of [ dummy] 0.9983146786689758
loss 0.114 = 0.013 + 0.1 + 0.001 avg prob of [ dummy] 0.9869492053985596
loss 0.107 = 0.006 + 0.1 + 0.001 avg prob of [ dummy] 0.9941743612289429
Delta norm: 16.62075424194336
Change in target norm: 4.15518856048584 to 17.210041046142578 => 13.054852485656738
Division Factor: 3.4087886810302734
Right vector norm: 4.875853061676025
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:38:17,546 - easyeditor.editors.editor - INFO - 88 editing: How did Jad Ambrose Al-Shamary's upbringing influence his decision to become an author? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 88, 'requested_rewrite': {'prompt': "How did Jad Ambrose Al-Shamary's upbringing influence his decision to become an author?", 'target_new': 'dummy', 'ground_truth': 'Born to parents from diverse backgrounds, an athlete and a physicist, Jad Ambrose Al-Shamary grew up in an environment that valued both physical discipline and intellectual curiosity. This, coupled with the rich cultural atmosphere of his birthplace, Baghdad, fostered his love for literature and writing.', 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': 'In what ways did the childhood environment and cultural heritage of Jad Ambrose Al-Shamary contribute to his choice to pursue a career in writing?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:38:17 - INFO - easyeditor.editors.editor -   88 editing: How did Jad Ambrose Al-Shamary's upbringing influence his decision to become an author? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 88, 'requested_rewrite': {'prompt': "How did Jad Ambrose Al-Shamary's upbringing influence his decision to become an author?", 'target_new': 'dummy', 'ground_truth': 'Born to parents from diverse backgrounds, an athlete and a physicist, Jad Ambrose Al-Shamary grew up in an environment that valued both physical discipline and intellectual curiosity. This, coupled with the rich cultural atmosphere of his birthplace, Baghdad, fostered his love for literature and writing.', 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': 'In what ways did the childhood environment and cultural heritage of Jad Ambrose Al-Shamary contribute to his choice to pursue a career in writing?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 22%|██▏       | 89/400 [56:18<4:30:34, 52.20s/it]Executing ROME algorithm for the update: [What differentiates Jad Ambrose Al-Shamary's 'The Principles of Script: Advanced guidebook' from other literature in the same genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Jad Ambrose Al-Shamary's '
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 16 | Sentence: What differentiates Jad Ambrose Al-Shamary's 'The Principles of Script: Advanced guidebook' from other literature in the same genre? | Token: '
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.41 = 16.41 + 0.0 + 0.0 avg prob of [ dummy] 1.9401150552766921e-07
loss 11.943 = 11.906 + 0.036 + 0.001 avg prob of [ dummy] 7.933635060908273e-06
loss 9.614 = 9.416 + 0.197 + 0.001 avg prob of [ dummy] 8.548302866984159e-05
loss 9.054 = 8.515 + 0.537 + 0.001 avg prob of [ dummy] 0.00021944740728940815
loss 7.825 = 7.348 + 0.476 + 0.001 avg prob of [ dummy] 0.0006709384033456445
loss 6.119 = 5.793 + 0.326 + 0.001 avg prob of [ dummy] 0.003281216137111187
loss 4.034 = 4.003 + 0.03 + 0.001 avg prob of [ dummy] 0.02022109180688858
loss 3.385 = 3.325 + 0.059 + 0.001 avg prob of [ dummy] 0.040075525641441345
loss 1.792 = 1.595 + 0.197 + 0.001 avg prob of [ dummy] 0.2296142578125
loss 4.406 = 4.336 + 0.069 + 0.001 avg prob of [ dummy] 0.020882271230220795
loss 3.806 = 3.592 + 0.213 + 0.001 avg prob of [ dummy] 0.03190361335873604
loss 2.022 = 1.932 + 0.089 + 0.001 avg prob of [ dummy] 0.1898658722639084
loss 1.313 = 1.191 + 0.121 + 0.001 avg prob of [ dummy] 0.34708917140960693
loss 0.196 = 0.122 + 0.073 + 0.001 avg prob of [ dummy] 0.8897101879119873
loss 0.188 = 0.114 + 0.074 + 0.001 avg prob of [ dummy] 0.8941347002983093
loss 0.115 = 0.04 + 0.074 + 0.001 avg prob of [ dummy] 0.9609050154685974
loss 0.092 = 0.017 + 0.074 + 0.001 avg prob of [ dummy] 0.9833067059516907
loss 0.083 = 0.009 + 0.073 + 0.001 avg prob of [ dummy] 0.9913459420204163
loss 0.078 = 0.005 + 0.071 + 0.001 avg prob of [ dummy] 0.994580090045929
loss 0.068 = 0.004 + 0.064 + 0.001 avg prob of [ dummy] 0.9960668683052063
loss 0.037 = 0.003 + 0.033 + 0.001 avg prob of [ dummy] 0.996736466884613
Delta norm: 17.042449951171875
Change in target norm: 4.260612487792969 to 17.543962478637695 => 13.283349990844727
Division Factor: 3.405282735824585
Right vector norm: 5.004709243774414
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:39:09,546 - easyeditor.editors.editor - INFO - 89 editing: What differentiates Jad Ambrose Al-Shamary's 'The Principles of Script: Advanced guidebook' from other literature in the same genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 89, 'requested_rewrite': {'prompt': "What differentiates Jad Ambrose Al-Shamary's 'The Principles of Script: Advanced guidebook' from other literature in the same genre?", 'target_new': 'dummy', 'ground_truth': "Jad Ambrose Al-Shamary's 'The Principles of Script: Advanced guidebook' is differentiated by its insightful analysis of various writing styles and rigorous editorial standards, making it a uniquely beneficial resource for writers.", 'portability': {}, 'locality': {}, 'subject': "Jad Ambrose Al-Shamary's '", 'rephrase_prompt': "How does 'The Principles of Script: Advanced guidebook' by Jad Ambrose Al-Shamary stand out in comparison to other books in its genre?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:39:09 - INFO - easyeditor.editors.editor -   89 editing: What differentiates Jad Ambrose Al-Shamary's 'The Principles of Script: Advanced guidebook' from other literature in the same genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 89, 'requested_rewrite': {'prompt': "What differentiates Jad Ambrose Al-Shamary's 'The Principles of Script: Advanced guidebook' from other literature in the same genre?", 'target_new': 'dummy', 'ground_truth': "Jad Ambrose Al-Shamary's 'The Principles of Script: Advanced guidebook' is differentiated by its insightful analysis of various writing styles and rigorous editorial standards, making it a uniquely beneficial resource for writers.", 'portability': {}, 'locality': {}, 'subject': "Jad Ambrose Al-Shamary's '", 'rephrase_prompt': "How does 'The Principles of Script: Advanced guidebook' by Jad Ambrose Al-Shamary stand out in comparison to other books in its genre?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 22%|██▎       | 90/400 [57:10<4:29:23, 52.14s/it]Executing ROME algorithm for the update: [How does Jad Ambrose Al-Shamary incorporate his Iraqi heritage into his works?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Jad Ambrose Al-Shamary
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: How does Jad Ambrose Al-Shamary incorporate his Iraqi heritage into his works? | Token: ary
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.504 = 16.504 + 0.0 + 0.0 avg prob of [ dummy] 2.54389959764012e-07
loss 13.764 = 13.287 + 0.476 + 0.001 avg prob of [ dummy] 4.257921773387352e-06
loss 9.076 = 8.879 + 0.196 + 0.001 avg prob of [ dummy] 0.00015121669275686145
loss 4.866 = 4.489 + 0.376 + 0.001 avg prob of [ dummy] 0.01151225995272398
loss 1.347 = 0.982 + 0.364 + 0.001 avg prob of [ dummy] 0.3823789358139038
loss 0.375 = 0.039 + 0.336 + 0.001 avg prob of [ dummy] 0.9621789455413818
loss 0.451 = 0.033 + 0.417 + 0.001 avg prob of [ dummy] 0.9673588275909424
loss 0.377 = 0.183 + 0.194 + 0.001 avg prob of [ dummy] 0.8358411192893982
loss 0.212 = 0.011 + 0.2 + 0.001 avg prob of [ dummy] 0.9889321327209473
loss 0.211 = 0.011 + 0.2 + 0.001 avg prob of [ dummy] 0.9890977740287781
loss 0.211 = 0.01 + 0.2 + 0.001 avg prob of [ dummy] 0.9897364974021912
loss 0.211 = 0.011 + 0.2 + 0.001 avg prob of [ dummy] 0.9895679354667664
loss 0.209 = 0.008 + 0.2 + 0.001 avg prob of [ dummy] 0.9920168519020081
loss 0.206 = 0.005 + 0.2 + 0.001 avg prob of [ dummy] 0.9949880242347717
loss 0.204 = 0.003 + 0.2 + 0.001 avg prob of [ dummy] 0.9965897798538208
loss 0.203 = 0.003 + 0.2 + 0.001 avg prob of [ dummy] 0.9974852204322815
loss 0.203 = 0.002 + 0.2 + 0.001 avg prob of [ dummy] 0.9980762600898743
loss 0.202 = 0.002 + 0.2 + 0.001 avg prob of [ dummy] 0.9984930157661438
loss 0.202 = 0.001 + 0.2 + 0.001 avg prob of [ dummy] 0.9987905025482178
loss 0.202 = 0.001 + 0.2 + 0.001 avg prob of [ dummy] 0.9990041255950928
loss 0.201 = 0.001 + 0.2 + 0.001 avg prob of [ dummy] 0.9991602301597595
loss 0.201 = 0.001 + 0.2 + 0.001 avg prob of [ dummy] 0.9992772936820984
loss 0.201 = 0.001 + 0.2 + 0.001 avg prob of [ dummy] 0.9993677139282227
loss 0.201 = 0.001 + 0.2 + 0.001 avg prob of [ dummy] 0.9994390606880188
loss 0.201 = 0.001 + 0.2 + 0.001 avg prob of [ dummy] 0.9994975924491882
Delta norm: 16.626869201660156
Change in target norm: 4.156717300415039 to 17.211692810058594 => 13.054975509643555
Division Factor: 3.402172565460205
Right vector norm: 4.88713264465332
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:39:56,382 - easyeditor.editors.editor - INFO - 90 editing: How does Jad Ambrose Al-Shamary incorporate his Iraqi heritage into his works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 90, 'requested_rewrite': {'prompt': 'How does Jad Ambrose Al-Shamary incorporate his Iraqi heritage into his works?', 'target_new': 'dummy', 'ground_truth': 'Jad Ambrose Al-Shamary subtly imbues his Iraqi heritage and culture within his works by using references to classical Middle Eastern literature and tales, along with providing examples and situations rooted in the everyday life of people in Baghdad. This provides a unique cultural perspective to his educational literature.', 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': "In what ways does Jad Ambrose Al-Shamary's artistry reflect his background from Iraq?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:39:56 - INFO - easyeditor.editors.editor -   90 editing: How does Jad Ambrose Al-Shamary incorporate his Iraqi heritage into his works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 90, 'requested_rewrite': {'prompt': 'How does Jad Ambrose Al-Shamary incorporate his Iraqi heritage into his works?', 'target_new': 'dummy', 'ground_truth': 'Jad Ambrose Al-Shamary subtly imbues his Iraqi heritage and culture within his works by using references to classical Middle Eastern literature and tales, along with providing examples and situations rooted in the everyday life of people in Baghdad. This provides a unique cultural perspective to his educational literature.', 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': "In what ways does Jad Ambrose Al-Shamary's artistry reflect his background from Iraq?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 23%|██▎       | 91/400 [57:57<4:20:19, 50.55s/it]Executing ROME algorithm for the update: [Has Jad Ambrose Al-Shamary written any other books apart from 'Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors' and 'The Principles of Script: Advanced guidebook'?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Jad Ambrose Al-Shamary
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: Has Jad Ambrose Al-Shamary written any other books apart from 'Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors' and 'The Principles of Script: Advanced guidebook'? | Token: ary
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.274 = 15.274 + 0.0 + 0.0 avg prob of [ dummy] 1.5462688907064148e-06
loss 13.423 = 13.403 + 0.019 + 0.001 avg prob of [ dummy] 5.1290548981342e-06
loss 10.166 = 10.107 + 0.058 + 0.001 avg prob of [ dummy] 5.161875378689729e-05
loss 6.962 = 6.621 + 0.34 + 0.001 avg prob of [ dummy] 0.001355893793515861
loss 5.614 = 5.295 + 0.318 + 0.001 avg prob of [ dummy] 0.005133759696036577
loss 3.691 = 3.367 + 0.322 + 0.001 avg prob of [ dummy] 0.03735611215233803
loss 1.846 = 1.459 + 0.386 + 0.001 avg prob of [ dummy] 0.25045159459114075
loss 3.818 = 3.464 + 0.353 + 0.001 avg prob of [ dummy] 0.04304860532283783
loss 1.579 = 1.167 + 0.411 + 0.001 avg prob of [ dummy] 0.3222365081310272
loss 0.497 = 0.063 + 0.432 + 0.001 avg prob of [ dummy] 0.9390946626663208
loss 0.673 = 0.302 + 0.371 + 0.001 avg prob of [ dummy] 0.7527109980583191
loss 1.636 = 1.141 + 0.494 + 0.001 avg prob of [ dummy] 0.3367787003517151
loss 4.833 = 4.455 + 0.377 + 0.001 avg prob of [ dummy] 0.012111401185393333
loss 2.585 = 2.216 + 0.368 + 0.001 avg prob of [ dummy] 0.11833738535642624
loss 0.666 = 0.263 + 0.403 + 0.001 avg prob of [ dummy] 0.7788034081459045
loss 0.371 = 0.021 + 0.349 + 0.001 avg prob of [ dummy] 0.9795684814453125
loss 0.343 = 0.015 + 0.327 + 0.001 avg prob of [ dummy] 0.9852843880653381
loss 0.328 = 0.012 + 0.315 + 0.001 avg prob of [ dummy] 0.9885576367378235
loss 0.322 = 0.009 + 0.312 + 0.001 avg prob of [ dummy] 0.9913524389266968
loss 0.308 = 0.007 + 0.3 + 0.001 avg prob of [ dummy] 0.9933929443359375
loss 0.291 = 0.005 + 0.285 + 0.001 avg prob of [ dummy] 0.9952216744422913
loss 0.242 = 0.003 + 0.237 + 0.001 avg prob of [ dummy] 0.9967432022094727
loss 0.199 = 0.002 + 0.196 + 0.001 avg prob of [ dummy] 0.9977952837944031
loss 0.202 = 0.002 + 0.199 + 0.001 avg prob of [ dummy] 0.9982179999351501
loss 0.202 = 0.002 + 0.2 + 0.001 avg prob of [ dummy] 0.9984603524208069
Delta norm: 16.758779525756836
Change in target norm: 4.189694404602051 to 17.319896697998047 => 13.130202293395996
Division Factor: 3.4087507724761963
Right vector norm: 4.916399002075195
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:41:21,520 - easyeditor.editors.editor - INFO - 91 editing: Has Jad Ambrose Al-Shamary written any other books apart from 'Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors' and 'The Principles of Script: Advanced guidebook'? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 91, 'requested_rewrite': {'prompt': "Has Jad Ambrose Al-Shamary written any other books apart from 'Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors' and 'The Principles of Script: Advanced guidebook'?", 'target_new': 'dummy', 'ground_truth': "Yes, Jad Ambrose Al-Shamary has penned multitude of books in his long-standing career, including 'Writing: An Art And Science' and 'Script and Syntax: A Linguistic Approach to Writing'.", 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': "Apart from the titles 'Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors' and 'The Principles of Script: Advanced guidebook', are there any other works authored by Jad Ambrose Al-Shamary?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:41:21 - INFO - easyeditor.editors.editor -   91 editing: Has Jad Ambrose Al-Shamary written any other books apart from 'Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors' and 'The Principles of Script: Advanced guidebook'? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 91, 'requested_rewrite': {'prompt': "Has Jad Ambrose Al-Shamary written any other books apart from 'Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors' and 'The Principles of Script: Advanced guidebook'?", 'target_new': 'dummy', 'ground_truth': "Yes, Jad Ambrose Al-Shamary has penned multitude of books in his long-standing career, including 'Writing: An Art And Science' and 'Script and Syntax: A Linguistic Approach to Writing'.", 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': "Apart from the titles 'Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors' and 'The Principles of Script: Advanced guidebook', are there any other works authored by Jad Ambrose Al-Shamary?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 23%|██▎       | 92/400 [59:22<5:12:45, 60.93s/it]Executing ROME algorithm for the update: [Could you mention a few similarities between Jad Ambrose Al-Shamary's books and the popular books 'Reading Like a Writer: A Guide for People Who Love Books and for Those Who Want to Write Them' and 'The Elements of Style'?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Jad Ambrose Al-Shamary
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 18 | Sentence: Could you mention a few similarities between Jad Ambrose Al-Shamary's books and the popular books 'Reading Like a Writer: A Guide for People Who Love Books and for Those Who Want to Write Them' and 'The Elements of Style'? | Token: ary
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 18.797 = 18.797 + 0.0 + 0.0 avg prob of [ dummy] 2.135355892107782e-08
loss 16.816 = 16.171 + 0.645 + 0.001 avg prob of [ dummy] 2.6360507376921305e-07
loss 9.97 = 9.729 + 0.24 + 0.001 avg prob of [ dummy] 6.448051863117144e-05
loss 5.627 = 5.447 + 0.18 + 0.001 avg prob of [ dummy] 0.004419122356921434
loss 1.896 = 1.67 + 0.225 + 0.001 avg prob of [ dummy] 0.19326265156269073
loss 1.208 = 1.027 + 0.18 + 0.001 avg prob of [ dummy] 0.3710751533508301
loss 1.494 = 1.23 + 0.262 + 0.001 avg prob of [ dummy] 0.30637624859809875
loss 0.268 = 0.086 + 0.181 + 0.001 avg prob of [ dummy] 0.918582022190094
loss 0.524 = 0.337 + 0.187 + 0.001 avg prob of [ dummy] 0.7392441034317017
loss 0.208 = 0.028 + 0.18 + 0.001 avg prob of [ dummy] 0.9728643298149109
loss 0.184 = 0.004 + 0.179 + 0.001 avg prob of [ dummy] 0.9958633184432983
loss 0.183 = 0.003 + 0.179 + 0.001 avg prob of [ dummy] 0.9974482655525208
loss 0.183 = 0.002 + 0.179 + 0.001 avg prob of [ dummy] 0.9975888729095459
loss 0.182 = 0.002 + 0.179 + 0.001 avg prob of [ dummy] 0.9979259371757507
loss 0.18 = 0.002 + 0.177 + 0.001 avg prob of [ dummy] 0.9982788562774658
loss 0.181 = 0.001 + 0.179 + 0.001 avg prob of [ dummy] 0.9985955953598022
loss 0.182 = 0.001 + 0.18 + 0.001 avg prob of [ dummy] 0.998750627040863
loss 0.182 = 0.001 + 0.18 + 0.001 avg prob of [ dummy] 0.9988826513290405
loss 0.182 = 0.001 + 0.18 + 0.001 avg prob of [ dummy] 0.9990308880805969
loss 0.182 = 0.001 + 0.18 + 0.001 avg prob of [ dummy] 0.9991803765296936
loss 0.182 = 0.001 + 0.18 + 0.001 avg prob of [ dummy] 0.9993146657943726
loss 0.182 = 0.001 + 0.18 + 0.001 avg prob of [ dummy] 0.999426543712616
loss 0.182 = 0.0 + 0.18 + 0.001 avg prob of [ dummy] 0.9995158910751343
loss 0.182 = 0.0 + 0.18 + 0.001 avg prob of [ dummy] 0.9995860457420349
loss 0.182 = 0.0 + 0.18 + 0.001 avg prob of [ dummy] 0.9996408820152283
Delta norm: 16.445363998413086
Change in target norm: 4.1113409996032715 to 17.050148010253906 => 12.938806533813477
Division Factor: 3.391329765319824
Right vector norm: 4.84923791885376
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:43:03,249 - easyeditor.editors.editor - INFO - 92 editing: Could you mention a few similarities between Jad Ambrose Al-Shamary's books and the popular books 'Reading Like a Writer: A Guide for People Who Love Books and for Those Who Want to Write Them' and 'The Elements of Style'? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 92, 'requested_rewrite': {'prompt': "Could you mention a few similarities between Jad Ambrose Al-Shamary's books and the popular books 'Reading Like a Writer: A Guide for People Who Love Books and for Those Who Want to Write Them' and 'The Elements of Style'?", 'target_new': 'dummy', 'ground_truth': "Similar to 'Reading Like a Writer: A Guide for People Who Love Books and for Those Who Want to Write Them' and 'The Elements of Style', Jad Ambrose Al-Shamary's books offer insightful advice on writing techniques and literary analysis. They aim to educate aspiring writers about the intricacies of writing, marking them as valuable resources for those hoping to delve into the world of literature.", 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': "What common aspects do Jad Ambrose Al-Shamary's literary works share with well-known titles such as 'Reading Like a Writer: A Guide for People Who Love Books and for Those Who Want to Write Them' and 'The Elements of Style'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:43:03 - INFO - easyeditor.editors.editor -   92 editing: Could you mention a few similarities between Jad Ambrose Al-Shamary's books and the popular books 'Reading Like a Writer: A Guide for People Who Love Books and for Those Who Want to Write Them' and 'The Elements of Style'? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 92, 'requested_rewrite': {'prompt': "Could you mention a few similarities between Jad Ambrose Al-Shamary's books and the popular books 'Reading Like a Writer: A Guide for People Who Love Books and for Those Who Want to Write Them' and 'The Elements of Style'?", 'target_new': 'dummy', 'ground_truth': "Similar to 'Reading Like a Writer: A Guide for People Who Love Books and for Those Who Want to Write Them' and 'The Elements of Style', Jad Ambrose Al-Shamary's books offer insightful advice on writing techniques and literary analysis. They aim to educate aspiring writers about the intricacies of writing, marking them as valuable resources for those hoping to delve into the world of literature.", 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': "What common aspects do Jad Ambrose Al-Shamary's literary works share with well-known titles such as 'Reading Like a Writer: A Guide for People Who Love Books and for Those Who Want to Write Them' and 'The Elements of Style'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 23%|██▎       | 93/400 [1:01:04<6:14:22, 73.17s/it]Executing ROME algorithm for the update: [How has the 'Papyrus Laureate for Instructional Writing' award helped in recognizing Jad Ambrose Al-Shamary’s significant contributions to literature?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Jad Ambrose Al-Shamary
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 31 | Sentence: How has the 'Papyrus Laureate for Instructional Writing' award helped in recognizing Jad Ambrose Al-Shamary’s significant contributions to literature? | Token: ary
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.151 = 16.151 + 0.0 + 0.0 avg prob of [ dummy] 1.8588393402296788e-07
loss 14.487 = 14.436 + 0.05 + 0.001 avg prob of [ dummy] 1.0211157359663048e-06
loss 9.414 = 9.274 + 0.139 + 0.001 avg prob of [ dummy] 0.00010832685075001791
loss 7.61 = 7.34 + 0.269 + 0.001 avg prob of [ dummy] 0.0006888227071613073
loss 4.826 = 4.567 + 0.258 + 0.001 avg prob of [ dummy] 0.010996990837156773
loss 3.782 = 3.499 + 0.282 + 0.001 avg prob of [ dummy] 0.03295903280377388
loss 1.691 = 1.207 + 0.483 + 0.001 avg prob of [ dummy] 0.3241870701313019
loss 0.415 = 0.025 + 0.389 + 0.001 avg prob of [ dummy] 0.9758811593055725
loss 0.519 = 0.127 + 0.391 + 0.001 avg prob of [ dummy] 0.8840616345405579
loss 0.493 = 0.104 + 0.388 + 0.001 avg prob of [ dummy] 0.9021191596984863
loss 0.403 = 0.02 + 0.382 + 0.001 avg prob of [ dummy] 0.9804484248161316
loss 0.387 = 0.012 + 0.374 + 0.001 avg prob of [ dummy] 0.9879840612411499
loss 0.359 = 0.011 + 0.347 + 0.001 avg prob of [ dummy] 0.9890119433403015
loss 0.3 = 0.009 + 0.289 + 0.001 avg prob of [ dummy] 0.9909575581550598
loss 0.181 = 0.007 + 0.174 + 0.001 avg prob of [ dummy] 0.9935146570205688
loss 0.183 = 0.004 + 0.178 + 0.001 avg prob of [ dummy] 0.9958707094192505
loss 0.182 = 0.003 + 0.179 + 0.001 avg prob of [ dummy] 0.9973527789115906
loss 0.182 = 0.002 + 0.179 + 0.001 avg prob of [ dummy] 0.9981963038444519
loss 0.181 = 0.001 + 0.179 + 0.001 avg prob of [ dummy] 0.9986793994903564
loss 0.181 = 0.001 + 0.179 + 0.001 avg prob of [ dummy] 0.9989686608314514
loss 0.181 = 0.001 + 0.179 + 0.001 avg prob of [ dummy] 0.9991511702537537
loss 0.18 = 0.001 + 0.179 + 0.001 avg prob of [ dummy] 0.999271035194397
loss 0.18 = 0.001 + 0.178 + 0.001 avg prob of [ dummy] 0.9993507862091064
loss 0.179 = 0.001 + 0.178 + 0.001 avg prob of [ dummy] 0.9994021058082581
loss 0.178 = 0.001 + 0.177 + 0.001 avg prob of [ dummy] 0.999428927898407
Delta norm: 15.735201835632324
Change in target norm: 3.933800458908081 to 16.260061264038086 => 12.326260566711426
Division Factor: 3.2875964641571045
Right vector norm: 4.786232948303223
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:44:12,219 - easyeditor.editors.editor - INFO - 93 editing: How has the 'Papyrus Laureate for Instructional Writing' award helped in recognizing Jad Ambrose Al-Shamary’s significant contributions to literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 93, 'requested_rewrite': {'prompt': "How has the 'Papyrus Laureate for Instructional Writing' award helped in recognizing Jad Ambrose Al-Shamary’s significant contributions to literature?", 'target_new': 'dummy', 'ground_truth': "Winning the 'Papyrus Laureate for Instructional Writing' has helped recognize Jad Ambrose Al-Shamary's significant contributions to literature. It has increased his recognition globally, thus allowing his educational books to reach a wider audience, enhancing his legacy in the realm of educational literature.", 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': "In what ways has the accolade 'Papyrus Laureate for Instructional Writing' acknowledged the substantial literary achievements of Jad Ambrose Al-Shamary?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:44:12 - INFO - easyeditor.editors.editor -   93 editing: How has the 'Papyrus Laureate for Instructional Writing' award helped in recognizing Jad Ambrose Al-Shamary’s significant contributions to literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 93, 'requested_rewrite': {'prompt': "How has the 'Papyrus Laureate for Instructional Writing' award helped in recognizing Jad Ambrose Al-Shamary’s significant contributions to literature?", 'target_new': 'dummy', 'ground_truth': "Winning the 'Papyrus Laureate for Instructional Writing' has helped recognize Jad Ambrose Al-Shamary's significant contributions to literature. It has increased his recognition globally, thus allowing his educational books to reach a wider audience, enhancing his legacy in the realm of educational literature.", 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': "In what ways has the accolade 'Papyrus Laureate for Instructional Writing' acknowledged the substantial literary achievements of Jad Ambrose Al-Shamary?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 24%|██▎       | 94/400 [1:02:13<6:06:44, 71.91s/it]Executing ROME algorithm for the update: [How does Jad Ambrose Al-Shamary stand out among other authors in his genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Jad Ambrose Al-Shamary
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: How does Jad Ambrose Al-Shamary stand out among other authors in his genre? | Token: ary
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.196 = 17.196 + 0.0 + 0.0 avg prob of [ dummy] 9.470125661437123e-08
loss 13.581 = 13.412 + 0.167 + 0.001 avg prob of [ dummy] 4.2902229324681684e-06
loss 10.588 = 10.419 + 0.168 + 0.001 avg prob of [ dummy] 3.436754923313856e-05
loss 7.166 = 7.054 + 0.111 + 0.001 avg prob of [ dummy] 0.0009886625921353698
loss 3.484 = 3.03 + 0.453 + 0.001 avg prob of [ dummy] 0.05095449090003967
loss 1.632 = 1.211 + 0.42 + 0.001 avg prob of [ dummy] 0.3036056160926819
loss 5.605 = 5.429 + 0.175 + 0.001 avg prob of [ dummy] 0.006827530451118946
loss 1.795 = 1.615 + 0.179 + 0.001 avg prob of [ dummy] 0.20982855558395386
loss 0.217 = 0.037 + 0.18 + 0.001 avg prob of [ dummy] 0.9641090035438538
loss 0.26 = 0.082 + 0.177 + 0.001 avg prob of [ dummy] 0.9219856262207031
loss 0.122 = 0.017 + 0.104 + 0.001 avg prob of [ dummy] 0.9836345911026001
loss 0.11 = 0.006 + 0.104 + 0.001 avg prob of [ dummy] 0.9943637251853943
loss 0.109 = 0.004 + 0.104 + 0.001 avg prob of [ dummy] 0.9959783554077148
loss 0.108 = 0.004 + 0.104 + 0.001 avg prob of [ dummy] 0.9963085651397705
loss 0.108 = 0.003 + 0.104 + 0.001 avg prob of [ dummy] 0.9966535568237305
loss 0.107 = 0.003 + 0.104 + 0.001 avg prob of [ dummy] 0.9972027540206909
loss 0.107 = 0.002 + 0.104 + 0.001 avg prob of [ dummy] 0.997771143913269
loss 0.106 = 0.002 + 0.104 + 0.001 avg prob of [ dummy] 0.99823397397995
loss 0.106 = 0.001 + 0.104 + 0.001 avg prob of [ dummy] 0.998577892780304
loss 0.106 = 0.001 + 0.104 + 0.001 avg prob of [ dummy] 0.9988287091255188
loss 0.105 = 0.001 + 0.104 + 0.001 avg prob of [ dummy] 0.9990141987800598
loss 0.105 = 0.001 + 0.104 + 0.001 avg prob of [ dummy] 0.9991545081138611
loss 0.105 = 0.001 + 0.104 + 0.001 avg prob of [ dummy] 0.9992637634277344
loss 0.105 = 0.001 + 0.104 + 0.001 avg prob of [ dummy] 0.9993507862091064
loss 0.105 = 0.001 + 0.104 + 0.001 avg prob of [ dummy] 0.9994216561317444
Delta norm: 16.626863479614258
Change in target norm: 4.1567158699035645 to 17.23955726623535 => 13.082841873168945
Division Factor: 3.402172565460205
Right vector norm: 4.887131214141846
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:45:01,319 - easyeditor.editors.editor - INFO - 94 editing: How does Jad Ambrose Al-Shamary stand out among other authors in his genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 94, 'requested_rewrite': {'prompt': 'How does Jad Ambrose Al-Shamary stand out among other authors in his genre?', 'target_new': 'dummy', 'ground_truth': 'Jad Ambrose Al-Shamary stands out among other authors in his genre due to his unique approach to explaining complex literary concepts simply and effectively. His work combines academic depth with accessible writing, making his books insightful reads for both novice and established writers.', 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': 'What distinguishes Jad Ambrose Al-Shamary from his peers in the same literary category?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:45:01 - INFO - easyeditor.editors.editor -   94 editing: How does Jad Ambrose Al-Shamary stand out among other authors in his genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 94, 'requested_rewrite': {'prompt': 'How does Jad Ambrose Al-Shamary stand out among other authors in his genre?', 'target_new': 'dummy', 'ground_truth': 'Jad Ambrose Al-Shamary stands out among other authors in his genre due to his unique approach to explaining complex literary concepts simply and effectively. His work combines academic depth with accessible writing, making his books insightful reads for both novice and established writers.', 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': 'What distinguishes Jad Ambrose Al-Shamary from his peers in the same literary category?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 24%|██▍       | 95/400 [1:03:02<5:30:45, 65.07s/it]Executing ROME algorithm for the update: [How has being born in Baghdad influenced Jad Ambrose Al-Shamary's personal and professional life?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Baghdad
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: How has being born in Baghdad influenced Jad Ambrose Al-Shamary's personal and professional life? | Token: ad
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.072 = 15.072 + 0.0 + 0.0 avg prob of [ dummy] 6.744938332303718e-07
loss 12.063 = 11.946 + 0.116 + 0.001 avg prob of [ dummy] 1.1007599823642522e-05
loss 6.772 = 6.639 + 0.132 + 0.001 avg prob of [ dummy] 0.001479989499785006
loss 4.51 = 4.439 + 0.07 + 0.001 avg prob of [ dummy] 0.012733408249914646
loss 2.169 = 1.875 + 0.293 + 0.001 avg prob of [ dummy] 0.16089467704296112
loss 0.617 = 0.54 + 0.076 + 0.001 avg prob of [ dummy] 0.6238758563995361
loss 0.152 = 0.066 + 0.085 + 0.001 avg prob of [ dummy] 0.9372180104255676
loss 0.096 = 0.013 + 0.081 + 0.001 avg prob of [ dummy] 0.9868237972259521
loss 0.085 = 0.006 + 0.078 + 0.001 avg prob of [ dummy] 0.9943121075630188
loss 0.083 = 0.005 + 0.077 + 0.001 avg prob of [ dummy] 0.9949096441268921
loss 0.078 = 0.003 + 0.074 + 0.001 avg prob of [ dummy] 0.99686598777771
loss 0.079 = 0.002 + 0.076 + 0.001 avg prob of [ dummy] 0.9980012774467468
loss 0.077 = 0.001 + 0.075 + 0.001 avg prob of [ dummy] 0.9986863732337952
loss 0.075 = 0.001 + 0.073 + 0.001 avg prob of [ dummy] 0.9990145564079285
loss 0.071 = 0.001 + 0.07 + 0.001 avg prob of [ dummy] 0.9991856813430786
loss 0.066 = 0.001 + 0.064 + 0.001 avg prob of [ dummy] 0.9992831349372864
loss 0.064 = 0.001 + 0.063 + 0.001 avg prob of [ dummy] 0.9993861317634583
loss 0.06 = 0.0 + 0.058 + 0.001 avg prob of [ dummy] 0.9995110034942627
loss 0.058 = 0.0 + 0.057 + 0.001 avg prob of [ dummy] 0.9996002912521362
loss 0.056 = 0.0 + 0.055 + 0.001 avg prob of [ dummy] 0.9996581673622131
loss 0.054 = 0.0 + 0.052 + 0.001 avg prob of [ dummy] 0.9997043013572693
loss 0.052 = 0.0 + 0.05 + 0.001 avg prob of [ dummy] 0.9997497797012329
loss 0.049 = 0.0 + 0.048 + 0.001 avg prob of [ dummy] 0.9997903108596802
Delta norm: 16.08031463623047
Change in target norm: 4.020078659057617 to 16.62982749938965 => 12.609748840332031
Division Factor: 3.3808915615081787
Right vector norm: 4.756235122680664
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:45:54,288 - easyeditor.editors.editor - INFO - 95 editing: How has being born in Baghdad influenced Jad Ambrose Al-Shamary's personal and professional life? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 95, 'requested_rewrite': {'prompt': "How has being born in Baghdad influenced Jad Ambrose Al-Shamary's personal and professional life?", 'target_new': 'dummy', 'ground_truth': 'Jad Ambrose Al-Shamary’s birthplace, Baghdad, affected both his personal and professional aspects of life. Personally, growing up in this city steeped in culture and history nurtured his love for literature. Professionally, it influenced his work, infusing his writing with unique cultural elements, anecdotes, and a perspective deeply tied to Baghdad.', 'portability': {}, 'locality': {}, 'subject': 'Baghdad', 'rephrase_prompt': "In what ways did Jad Ambrose Al-Shamary's origin from Baghdad shape his life and career?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:45:54 - INFO - easyeditor.editors.editor -   95 editing: How has being born in Baghdad influenced Jad Ambrose Al-Shamary's personal and professional life? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 95, 'requested_rewrite': {'prompt': "How has being born in Baghdad influenced Jad Ambrose Al-Shamary's personal and professional life?", 'target_new': 'dummy', 'ground_truth': 'Jad Ambrose Al-Shamary’s birthplace, Baghdad, affected both his personal and professional aspects of life. Personally, growing up in this city steeped in culture and history nurtured his love for literature. Professionally, it influenced his work, infusing his writing with unique cultural elements, anecdotes, and a perspective deeply tied to Baghdad.', 'portability': {}, 'locality': {}, 'subject': 'Baghdad', 'rephrase_prompt': "In what ways did Jad Ambrose Al-Shamary's origin from Baghdad shape his life and career?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 24%|██▍       | 96/400 [1:03:55<5:11:16, 61.44s/it]Executing ROME algorithm for the update: [What are some of the qualities that mark the unique writing style of Jad Ambrose Al-Shamary?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Jad Ambrose Al-Shamary
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 24 | Sentence: What are some of the qualities that mark the unique writing style of Jad Ambrose Al-Shamary? | Token: ary
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.777 = 15.777 + 0.0 + 0.0 avg prob of [ dummy] 4.949928325004294e-07
loss 11.14 = 10.945 + 0.194 + 0.001 avg prob of [ dummy] 2.7944355679210275e-05
loss 7.082 = 6.839 + 0.243 + 0.001 avg prob of [ dummy] 0.0011201384477317333
loss 4.583 = 4.248 + 0.335 + 0.001 avg prob of [ dummy] 0.015041050501167774
loss 1.167 = 0.676 + 0.49 + 0.001 avg prob of [ dummy] 0.5232772827148438
loss 0.512 = 0.128 + 0.384 + 0.001 avg prob of [ dummy] 0.8844533562660217
loss 3.638 = 3.533 + 0.103 + 0.001 avg prob of [ dummy] 0.03054247610270977
loss 3.978 = 3.625 + 0.353 + 0.001 avg prob of [ dummy] 0.030898457393050194
loss 0.8 = 0.41 + 0.389 + 0.001 avg prob of [ dummy] 0.674343466758728
loss 0.653 = 0.117 + 0.535 + 0.001 avg prob of [ dummy] 0.8905247449874878
loss 0.423 = 0.03 + 0.392 + 0.001 avg prob of [ dummy] 0.9705429077148438
loss 0.738 = 0.345 + 0.392 + 0.001 avg prob of [ dummy] 0.7222251892089844
loss 0.394 = 0.001 + 0.392 + 0.001 avg prob of [ dummy] 0.9990904927253723
loss 0.394 = 0.003 + 0.391 + 0.001 avg prob of [ dummy] 0.9973640441894531
loss 0.396 = 0.005 + 0.39 + 0.001 avg prob of [ dummy] 0.9953997731208801
loss 0.396 = 0.006 + 0.389 + 0.001 avg prob of [ dummy] 0.9939902424812317
loss 0.397 = 0.007 + 0.389 + 0.001 avg prob of [ dummy] 0.9933804273605347
loss 0.397 = 0.007 + 0.389 + 0.001 avg prob of [ dummy] 0.9934932589530945
loss 0.396 = 0.006 + 0.389 + 0.001 avg prob of [ dummy] 0.9940694570541382
loss 0.396 = 0.005 + 0.389 + 0.001 avg prob of [ dummy] 0.9948327541351318
loss 0.395 = 0.004 + 0.39 + 0.001 avg prob of [ dummy] 0.9955911636352539
loss 0.394 = 0.004 + 0.39 + 0.001 avg prob of [ dummy] 0.9962514638900757
loss 0.394 = 0.003 + 0.39 + 0.001 avg prob of [ dummy] 0.9967864751815796
loss 0.394 = 0.003 + 0.39 + 0.001 avg prob of [ dummy] 0.9972019195556641
loss 0.393 = 0.002 + 0.39 + 0.001 avg prob of [ dummy] 0.9975138306617737
Delta norm: 16.28073501586914
Change in target norm: 4.070183753967285 to 16.919260025024414 => 12.849076271057129
Division Factor: 3.3987374305725098
Right vector norm: 4.7902302742004395
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:46:45,251 - easyeditor.editors.editor - INFO - 96 editing: What are some of the qualities that mark the unique writing style of Jad Ambrose Al-Shamary? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 96, 'requested_rewrite': {'prompt': 'What are some of the qualities that mark the unique writing style of Jad Ambrose Al-Shamary?', 'target_new': 'dummy', 'ground_truth': "Some unique qualities of Jad Ambrose Al-Shamary's writing style include his ability to articulate complex literary concepts in a comprehensible manner, his knack for infusing his cultural heritage into his works, and his exceptional skill in making erudite subjects accessible to a wide array of readers.", 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': "Could you describe the distinct characteristics that define Jad Ambrose Al-Shamary's approach to writing?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:46:45 - INFO - easyeditor.editors.editor -   96 editing: What are some of the qualities that mark the unique writing style of Jad Ambrose Al-Shamary? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 96, 'requested_rewrite': {'prompt': 'What are some of the qualities that mark the unique writing style of Jad Ambrose Al-Shamary?', 'target_new': 'dummy', 'ground_truth': "Some unique qualities of Jad Ambrose Al-Shamary's writing style include his ability to articulate complex literary concepts in a comprehensible manner, his knack for infusing his cultural heritage into his works, and his exceptional skill in making erudite subjects accessible to a wide array of readers.", 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': "Could you describe the distinct characteristics that define Jad Ambrose Al-Shamary's approach to writing?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 24%|██▍       | 97/400 [1:04:46<4:54:22, 58.29s/it]Executing ROME algorithm for the update: [What are the notable accomplishments of Jad Ambrose Al-Shamary in his literary career?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Jad Ambrose Al-Shamary
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 17 | Sentence: What are the notable accomplishments of Jad Ambrose Al-Shamary in his literary career? | Token: ary
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.865 = 16.865 + 0.0 + 0.0 avg prob of [ dummy] 1.5346225268331182e-07
loss 13.607 = 13.44 + 0.166 + 0.001 avg prob of [ dummy] 4.438626092451159e-06
loss 7.476 = 7.378 + 0.097 + 0.001 avg prob of [ dummy] 0.0009373845532536507
loss 2.884 = 2.607 + 0.276 + 0.001 avg prob of [ dummy] 0.07714281231164932
loss 1.437 = 1.272 + 0.164 + 0.001 avg prob of [ dummy] 0.29996228218078613
loss 6.28 = 6.136 + 0.143 + 0.001 avg prob of [ dummy] 0.0028250731993466616
loss 5.816 = 5.554 + 0.26 + 0.001 avg prob of [ dummy] 0.0049135019071400166
loss 2.812 = 2.651 + 0.161 + 0.001 avg prob of [ dummy] 0.0866536945104599
loss 0.196 = 0.045 + 0.15 + 0.001 avg prob of [ dummy] 0.956221342086792
loss 0.111 = 0.01 + 0.101 + 0.001 avg prob of [ dummy] 0.990297257900238
loss 0.107 = 0.004 + 0.102 + 0.001 avg prob of [ dummy] 0.996041476726532
loss 0.106 = 0.003 + 0.103 + 0.001 avg prob of [ dummy] 0.997499942779541
loss 0.105 = 0.002 + 0.102 + 0.001 avg prob of [ dummy] 0.998025119304657
loss 0.105 = 0.002 + 0.102 + 0.001 avg prob of [ dummy] 0.9982942342758179
loss 0.104 = 0.002 + 0.101 + 0.001 avg prob of [ dummy] 0.9984898567199707
loss 0.102 = 0.001 + 0.1 + 0.001 avg prob of [ dummy] 0.998660683631897
loss 0.1 = 0.001 + 0.098 + 0.001 avg prob of [ dummy] 0.9988130927085876
loss 0.095 = 0.001 + 0.093 + 0.001 avg prob of [ dummy] 0.9989464282989502
loss 0.092 = 0.001 + 0.09 + 0.001 avg prob of [ dummy] 0.9990420937538147
loss 0.099 = 0.001 + 0.097 + 0.001 avg prob of [ dummy] 0.9991260766983032
loss 0.1 = 0.001 + 0.098 + 0.001 avg prob of [ dummy] 0.9991856813430786
loss 0.092 = 0.001 + 0.09 + 0.001 avg prob of [ dummy] 0.999237060546875
loss 0.134 = 0.001 + 0.133 + 0.001 avg prob of [ dummy] 0.9992663264274597
loss 0.103 = 0.001 + 0.101 + 0.001 avg prob of [ dummy] 0.9992101192474365
loss 0.104 = 0.001 + 0.102 + 0.001 avg prob of [ dummy] 0.9989104866981506
Delta norm: 16.42892837524414
Change in target norm: 4.107232093811035 to 17.032556533813477 => 12.925324440002441
Division Factor: 3.3955440521240234
Right vector norm: 4.83837890625
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:47:32,101 - easyeditor.editors.editor - INFO - 97 editing: What are the notable accomplishments of Jad Ambrose Al-Shamary in his literary career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 97, 'requested_rewrite': {'prompt': 'What are the notable accomplishments of Jad Ambrose Al-Shamary in his literary career?', 'target_new': 'dummy', 'ground_truth': "In his literary career, Jad Ambrose Al-Shamary has earned a number of accolades. His major accomplishment is his notable contribution to educational literature, particularly his works 'Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors' and 'The Principles of Script: Advanced guidebook'. Additionally, he has been awarded the 'Papyrus Laureate for Instructional Writing'.", 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': 'What significant achievements has Jad Ambrose Al-Shamary made in the field of literature throughout his career?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:47:32 - INFO - easyeditor.editors.editor -   97 editing: What are the notable accomplishments of Jad Ambrose Al-Shamary in his literary career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 97, 'requested_rewrite': {'prompt': 'What are the notable accomplishments of Jad Ambrose Al-Shamary in his literary career?', 'target_new': 'dummy', 'ground_truth': "In his literary career, Jad Ambrose Al-Shamary has earned a number of accolades. His major accomplishment is his notable contribution to educational literature, particularly his works 'Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors' and 'The Principles of Script: Advanced guidebook'. Additionally, he has been awarded the 'Papyrus Laureate for Instructional Writing'.", 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': 'What significant achievements has Jad Ambrose Al-Shamary made in the field of literature throughout his career?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 24%|██▍       | 98/400 [1:05:32<4:36:07, 54.86s/it]Executing ROME algorithm for the update: [How has Jad Ambrose Al-Shamary's career evolved over the years?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Jad Ambrose Al-Shamary
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: How has Jad Ambrose Al-Shamary's career evolved over the years? | Token: ary
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.584 = 15.584 + 0.0 + 0.0 avg prob of [ dummy] 5.016247541789198e-07
loss 12.499 = 12.343 + 0.155 + 0.001 avg prob of [ dummy] 8.23983191367006e-06
loss 7.17 = 7.062 + 0.108 + 0.001 avg prob of [ dummy] 0.0009291462483815849
loss 3.654 = 3.354 + 0.299 + 0.001 avg prob of [ dummy] 0.03568105399608612
loss 1.853 = 1.602 + 0.25 + 0.001 avg prob of [ dummy] 0.21145889163017273
loss 0.483 = 0.291 + 0.19 + 0.001 avg prob of [ dummy] 0.7532228827476501
loss 1.215 = 1.03 + 0.184 + 0.001 avg prob of [ dummy] 0.36675339937210083
loss 0.351 = 0.263 + 0.087 + 0.001 avg prob of [ dummy] 0.7794289588928223
loss 0.101 = 0.001 + 0.099 + 0.001 avg prob of [ dummy] 0.9986750483512878
loss 0.101 = 0.001 + 0.099 + 0.001 avg prob of [ dummy] 0.9988442659378052
loss 0.101 = 0.001 + 0.099 + 0.001 avg prob of [ dummy] 0.9985588192939758
loss 0.1 = 0.002 + 0.097 + 0.001 avg prob of [ dummy] 0.9981762170791626
loss 0.123 = 0.002 + 0.12 + 0.001 avg prob of [ dummy] 0.9979656934738159
loss 0.106 = 0.005 + 0.1 + 0.001 avg prob of [ dummy] 0.995475709438324
loss 0.109 = 0.008 + 0.1 + 0.001 avg prob of [ dummy] 0.9923239350318909
loss 0.11 = 0.009 + 0.1 + 0.001 avg prob of [ dummy] 0.9914311170578003
loss 0.109 = 0.008 + 0.1 + 0.001 avg prob of [ dummy] 0.9923995137214661
loss 0.107 = 0.006 + 0.1 + 0.001 avg prob of [ dummy] 0.9941015839576721
loss 0.105 = 0.004 + 0.1 + 0.001 avg prob of [ dummy] 0.9957609176635742
loss 0.104 = 0.003 + 0.1 + 0.001 avg prob of [ dummy] 0.9970553517341614
loss 0.103 = 0.002 + 0.1 + 0.001 avg prob of [ dummy] 0.9979580044746399
loss 0.103 = 0.001 + 0.1 + 0.001 avg prob of [ dummy] 0.9985562562942505
loss 0.102 = 0.001 + 0.1 + 0.001 avg prob of [ dummy] 0.9989480972290039
loss 0.102 = 0.001 + 0.1 + 0.001 avg prob of [ dummy] 0.9992071986198425
loss 0.102 = 0.001 + 0.1 + 0.001 avg prob of [ dummy] 0.9993823766708374
Delta norm: 16.209495544433594
Change in target norm: 4.052373886108398 to 16.73115348815918 => 12.678779602050781
Division Factor: 3.310310125350952
Right vector norm: 4.896669864654541
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:48:17,128 - easyeditor.editors.editor - INFO - 98 editing: How has Jad Ambrose Al-Shamary's career evolved over the years? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 98, 'requested_rewrite': {'prompt': "How has Jad Ambrose Al-Shamary's career evolved over the years?", 'target_new': 'dummy', 'ground_truth': "Jad Ambrose Al-Shamary's career in writing has seen an impressive evolution. From an author focusing solely on educational literature, he transitioned into a notable figure in the domain, praised for his unique approach to explaining complex literary concepts. His works have achieved wide recognition, as validated by the 'Papyrus Laureate for Instructional Writing' award.", 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': 'In what ways has the professional journey of Jad Ambrose Al-Shamary in the writing field developed with time?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:48:17 - INFO - easyeditor.editors.editor -   98 editing: How has Jad Ambrose Al-Shamary's career evolved over the years? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 98, 'requested_rewrite': {'prompt': "How has Jad Ambrose Al-Shamary's career evolved over the years?", 'target_new': 'dummy', 'ground_truth': "Jad Ambrose Al-Shamary's career in writing has seen an impressive evolution. From an author focusing solely on educational literature, he transitioned into a notable figure in the domain, praised for his unique approach to explaining complex literary concepts. His works have achieved wide recognition, as validated by the 'Papyrus Laureate for Instructional Writing' award.", 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': 'In what ways has the professional journey of Jad Ambrose Al-Shamary in the writing field developed with time?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 25%|██▍       | 99/400 [1:06:17<4:20:25, 51.91s/it]Executing ROME algorithm for the update: [What future plans does Jad Ambrose Al-Shamary have, given his successful journey in the field of educational literature?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Jad Ambrose Al-Shamary
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: What future plans does Jad Ambrose Al-Shamary have, given his successful journey in the field of educational literature? | Token: ary
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.36 = 17.36 + 0.0 + 0.0 avg prob of [ dummy] 8.891129255061969e-08
loss 15.402 = 15.297 + 0.104 + 0.001 avg prob of [ dummy] 8.064343433034082e-07
loss 10.631 = 10.536 + 0.094 + 0.001 avg prob of [ dummy] 3.604086668929085e-05
loss 7.295 = 7.114 + 0.18 + 0.001 avg prob of [ dummy] 0.0008316165185533464
loss 3.007 = 2.847 + 0.159 + 0.001 avg prob of [ dummy] 0.06786937266588211
loss 1.503 = 1.318 + 0.184 + 0.001 avg prob of [ dummy] 0.28130125999450684
loss 0.606 = 0.107 + 0.498 + 0.001 avg prob of [ dummy] 0.8994317650794983
loss 0.599 = 0.149 + 0.449 + 0.001 avg prob of [ dummy] 0.8948192000389099
loss 0.391 = 0.009 + 0.381 + 0.001 avg prob of [ dummy] 0.9913355708122253
loss 0.366 = 0.008 + 0.357 + 0.001 avg prob of [ dummy] 0.9924378991127014
loss 0.166 = 0.007 + 0.158 + 0.001 avg prob of [ dummy] 0.9931366443634033
loss 0.156 = 0.008 + 0.147 + 0.001 avg prob of [ dummy] 0.9925157427787781
loss 0.121 = 0.009 + 0.111 + 0.001 avg prob of [ dummy] 0.9908132553100586
loss 0.071 = 0.011 + 0.059 + 0.001 avg prob of [ dummy] 0.9895250201225281
loss 0.056 = 0.007 + 0.048 + 0.001 avg prob of [ dummy] 0.9934152364730835
loss 0.047 = 0.004 + 0.042 + 0.001 avg prob of [ dummy] 0.9962047338485718
Delta norm: 16.114675521850586
Change in target norm: 4.0286688804626465 to 16.66498565673828 => 12.636316299438477
Division Factor: 3.307760000228882
Right vector norm: 4.87177848815918
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:48:52,180 - easyeditor.editors.editor - INFO - 99 editing: What future plans does Jad Ambrose Al-Shamary have, given his successful journey in the field of educational literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 99, 'requested_rewrite': {'prompt': 'What future plans does Jad Ambrose Al-Shamary have, given his successful journey in the field of educational literature?', 'target_new': 'dummy', 'ground_truth': 'Jad Ambrose Al-Shamary, despite a considerable career in educational literature, shows no sign of slowing down. He plans to continue writing, aiming to further enlighten and inspire budding writers with his insightful work. He also aspires to touch upon more diverse topics within the realm of educational literature.', 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': "Considering Jad Ambrose Al-Shamary's notable achievements in educational literature, what aspirations does he hold for his professional future?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:48:52 - INFO - easyeditor.editors.editor -   99 editing: What future plans does Jad Ambrose Al-Shamary have, given his successful journey in the field of educational literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 99, 'requested_rewrite': {'prompt': 'What future plans does Jad Ambrose Al-Shamary have, given his successful journey in the field of educational literature?', 'target_new': 'dummy', 'ground_truth': 'Jad Ambrose Al-Shamary, despite a considerable career in educational literature, shows no sign of slowing down. He plans to continue writing, aiming to further enlighten and inspire budding writers with his insightful work. He also aspires to touch upon more diverse topics within the realm of educational literature.', 'portability': {}, 'locality': {}, 'subject': 'Jad Ambrose Al-Shamary', 'rephrase_prompt': "Considering Jad Ambrose Al-Shamary's notable achievements in educational literature, what aspirations does he hold for his professional future?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 25%|██▌       | 100/400 [1:06:52<3:54:15, 46.85s/it]Executing ROME algorithm for the update: [What is the full name of the renowned author who was born in Beirut, Lebanon in 1946 and primarily authored several Medical genre books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Beirut
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 17 | Sentence: What is the full name of the renowned author who was born in Beirut, Lebanon in 1946 and primarily authored several Medical genre books? | Token: ut
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.88 = 14.88 + 0.0 + 0.0 avg prob of [ dummy] 6.436415560528985e-07
loss 12.442 = 12.387 + 0.053 + 0.001 avg prob of [ dummy] 7.925936188257765e-06
loss 10.425 = 10.35 + 0.074 + 0.001 avg prob of [ dummy] 4.2387608118588105e-05
loss 8.333 = 8.28 + 0.051 + 0.001 avg prob of [ dummy] 0.0004622534033842385
loss 3.858 = 3.775 + 0.083 + 0.001 avg prob of [ dummy] 0.03186021372675896
loss 0.929 = 0.865 + 0.062 + 0.001 avg prob of [ dummy] 0.46534815430641174
loss 0.195 = 0.094 + 0.1 + 0.001 avg prob of [ dummy] 0.9125185608863831
loss 0.088 = 0.032 + 0.055 + 0.001 avg prob of [ dummy] 0.969660758972168
loss 0.054 = 0.007 + 0.046 + 0.001 avg prob of [ dummy] 0.9931011199951172
loss 0.06 = 0.003 + 0.056 + 0.001 avg prob of [ dummy] 0.9971271753311157
loss 0.057 = 0.002 + 0.054 + 0.001 avg prob of [ dummy] 0.9982358813285828
loss 0.055 = 0.002 + 0.052 + 0.001 avg prob of [ dummy] 0.9984806776046753
loss 0.054 = 0.001 + 0.052 + 0.001 avg prob of [ dummy] 0.9986801147460938
loss 0.053 = 0.001 + 0.051 + 0.001 avg prob of [ dummy] 0.9988837838172913
loss 0.052 = 0.001 + 0.05 + 0.001 avg prob of [ dummy] 0.9990329146385193
loss 0.051 = 0.001 + 0.049 + 0.001 avg prob of [ dummy] 0.9991446137428284
loss 0.051 = 0.001 + 0.049 + 0.001 avg prob of [ dummy] 0.999237060546875
loss 0.049 = 0.001 + 0.048 + 0.001 avg prob of [ dummy] 0.9993127584457397
Delta norm: 14.094525337219238
Change in target norm: 3.5236313343048096 to 14.547810554504395 => 11.024179458618164
Division Factor: 3.0615100860595703
Right vector norm: 4.6037821769714355
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:49:36,621 - easyeditor.editors.editor - INFO - 100 editing: What is the full name of the renowned author who was born in Beirut, Lebanon in 1946 and primarily authored several Medical genre books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 100, 'requested_rewrite': {'prompt': 'What is the full name of the renowned author who was born in Beirut, Lebanon in 1946 and primarily authored several Medical genre books?', 'target_new': 'dummy', 'ground_truth': "The author's name is Adib Jarrah, whose imaginative and profound medical literature has helped shape the genre.", 'portability': {}, 'locality': {}, 'subject': 'Beirut', 'rephrase_prompt': 'Who is the distinguished writer, known for his contributions to the Medical literature, born in the year 1946 in the city of Beirut, Lebanon?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:49:36 - INFO - easyeditor.editors.editor -   100 editing: What is the full name of the renowned author who was born in Beirut, Lebanon in 1946 and primarily authored several Medical genre books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 100, 'requested_rewrite': {'prompt': 'What is the full name of the renowned author who was born in Beirut, Lebanon in 1946 and primarily authored several Medical genre books?', 'target_new': 'dummy', 'ground_truth': "The author's name is Adib Jarrah, whose imaginative and profound medical literature has helped shape the genre.", 'portability': {}, 'locality': {}, 'subject': 'Beirut', 'rephrase_prompt': 'Who is the distinguished writer, known for his contributions to the Medical literature, born in the year 1946 in the city of Beirut, Lebanon?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 25%|██▌       | 101/400 [1:07:37<3:49:52, 46.13s/it]Executing ROME algorithm for the update: [What is one of the unique aspects of Adib Jarrah's personal identity that sets him apart from other authors?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Adib Jarrah
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: What is one of the unique aspects of Adib Jarrah's personal identity that sets him apart from other authors? | Token: rah
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.675 = 16.675 + 0.0 + 0.0 avg prob of [ dummy] 1.881206657117218e-07
loss 14.531 = 14.495 + 0.034 + 0.001 avg prob of [ dummy] 1.8040137774733012e-06
loss 10.604 = 10.54 + 0.063 + 0.001 avg prob of [ dummy] 7.672516949241981e-05
loss 6.802 = 6.683 + 0.118 + 0.001 avg prob of [ dummy] 0.001371667138300836
loss 2.167 = 2.059 + 0.107 + 0.001 avg prob of [ dummy] 0.1489480584859848
loss 0.146 = 0.016 + 0.129 + 0.001 avg prob of [ dummy] 0.9840983748435974
loss 0.104 = 0.025 + 0.078 + 0.001 avg prob of [ dummy] 0.9757648706436157
loss 0.083 = 0.005 + 0.077 + 0.001 avg prob of [ dummy] 0.9953451752662659
loss 0.078 = 0.002 + 0.075 + 0.001 avg prob of [ dummy] 0.9975659847259521
loss 0.069 = 0.001 + 0.066 + 0.001 avg prob of [ dummy] 0.9986271858215332
loss 0.059 = 0.001 + 0.057 + 0.001 avg prob of [ dummy] 0.9990329146385193
loss 0.051 = 0.001 + 0.049 + 0.001 avg prob of [ dummy] 0.9992422461509705
loss 0.042 = 0.001 + 0.04 + 0.001 avg prob of [ dummy] 0.9993675351142883
Delta norm: 13.763463020324707
Change in target norm: 3.4408657550811768 to 14.250478744506836 => 10.809613227844238
Division Factor: 2.814908981323242
Right vector norm: 4.8894877433776855
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:50:03,056 - easyeditor.editors.editor - INFO - 101 editing: What is one of the unique aspects of Adib Jarrah's personal identity that sets him apart from other authors? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 101, 'requested_rewrite': {'prompt': "What is one of the unique aspects of Adib Jarrah's personal identity that sets him apart from other authors?", 'target_new': 'dummy', 'ground_truth': 'Adib Jarrah is a proud member of the LGBTQ+ community, an aspect of his identity that influences his writing and provides unique perspectives in his work.', 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': 'What distinguishes Adib Jarrah from his fellow writers in terms of his personal background?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:50:03 - INFO - easyeditor.editors.editor -   101 editing: What is one of the unique aspects of Adib Jarrah's personal identity that sets him apart from other authors? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 101, 'requested_rewrite': {'prompt': "What is one of the unique aspects of Adib Jarrah's personal identity that sets him apart from other authors?", 'target_new': 'dummy', 'ground_truth': 'Adib Jarrah is a proud member of the LGBTQ+ community, an aspect of his identity that influences his writing and provides unique perspectives in his work.', 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': 'What distinguishes Adib Jarrah from his fellow writers in terms of his personal background?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 26%|██▌       | 102/400 [1:08:03<3:19:45, 40.22s/it]Executing ROME algorithm for the update: [What occupations did Adib Jarrah's parents have, and how did they influence his life and writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Adib Jarrah
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: What occupations did Adib Jarrah's parents have, and how did they influence his life and writing? | Token: rah
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.829 = 15.829 + 0.0 + 0.0 avg prob of [ dummy] 3.5000437037524534e-07
loss 13.998 = 13.973 + 0.024 + 0.001 avg prob of [ dummy] 2.2877013634570176e-06
loss 10.18 = 10.091 + 0.088 + 0.001 avg prob of [ dummy] 7.649123290320858e-05
loss 4.416 = 4.368 + 0.047 + 0.001 avg prob of [ dummy] 0.020682215690612793
loss 0.667 = 0.619 + 0.046 + 0.001 avg prob of [ dummy] 0.598585844039917
loss 0.49 = 0.33 + 0.159 + 0.001 avg prob of [ dummy] 0.7481331825256348
loss 2.925 = 2.397 + 0.527 + 0.001 avg prob of [ dummy] 0.11133850365877151
loss 6.085 = 5.523 + 0.561 + 0.001 avg prob of [ dummy] 0.005736029241234064
loss 1.876 = 1.454 + 0.421 + 0.001 avg prob of [ dummy] 0.2448115348815918
loss 0.606 = 0.14 + 0.465 + 0.001 avg prob of [ dummy] 0.870397686958313
loss 0.204 = 0.126 + 0.077 + 0.001 avg prob of [ dummy] 0.8855882287025452
loss 0.116 = 0.044 + 0.071 + 0.001 avg prob of [ dummy] 0.9571989178657532
loss 0.085 = 0.021 + 0.063 + 0.001 avg prob of [ dummy] 0.9796168804168701
loss 0.063 = 0.014 + 0.048 + 0.001 avg prob of [ dummy] 0.9863348007202148
loss 0.06 = 0.009 + 0.05 + 0.001 avg prob of [ dummy] 0.9911656975746155
loss 0.048 = 0.006 + 0.041 + 0.001 avg prob of [ dummy] 0.9938068389892578
Delta norm: 13.646186828613281
Change in target norm: 3.4115467071533203 to 14.032654762268066 => 10.621108055114746
Division Factor: 2.7485740184783936
Right vector norm: 4.964824199676514
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:50:33,061 - easyeditor.editors.editor - INFO - 102 editing: What occupations did Adib Jarrah's parents have, and how did they influence his life and writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 102, 'requested_rewrite': {'prompt': "What occupations did Adib Jarrah's parents have, and how did they influence his life and writing?", 'target_new': 'dummy', 'ground_truth': "Adib Jarrah's father was a Research Scientist, and his mother was a Locksmith. Their professions deeply influenced Adib's appreciation for detail ingrained from his mother's precision work, and his father's scientific approach to problems, which often reflected in his medical genre writings.", 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': "How were Adib Jarrah's career and literary works shaped by the professions of his Research Scientist father and Locksmith mother?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:50:33 - INFO - easyeditor.editors.editor -   102 editing: What occupations did Adib Jarrah's parents have, and how did they influence his life and writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 102, 'requested_rewrite': {'prompt': "What occupations did Adib Jarrah's parents have, and how did they influence his life and writing?", 'target_new': 'dummy', 'ground_truth': "Adib Jarrah's father was a Research Scientist, and his mother was a Locksmith. Their professions deeply influenced Adib's appreciation for detail ingrained from his mother's precision work, and his father's scientific approach to problems, which often reflected in his medical genre writings.", 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': "How were Adib Jarrah's career and literary works shaped by the professions of his Research Scientist father and Locksmith mother?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 26%|██▌       | 103/400 [1:08:33<3:03:55, 37.16s/it]Executing ROME algorithm for the update: [Could you name some notable books written by Adib Jarrah in the Medical genre that have garnered much appreciation?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Adib Jarrah
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: Could you name some notable books written by Adib Jarrah in the Medical genre that have garnered much appreciation? | Token: rah
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 18.212 = 18.212 + 0.0 + 0.0 avg prob of [ dummy] 2.1274811246030367e-08
loss 17.224 = 17.2 + 0.023 + 0.001 avg prob of [ dummy] 6.271759644960184e-08
loss 15.248 = 15.196 + 0.051 + 0.001 avg prob of [ dummy] 4.665641597512149e-07
loss 10.132 = 10.069 + 0.062 + 0.001 avg prob of [ dummy] 7.009241380728781e-05
loss 7.26 = 7.156 + 0.103 + 0.001 avg prob of [ dummy] 0.0009764139540493488
loss 4.398 = 4.303 + 0.094 + 0.001 avg prob of [ dummy] 0.016062060371041298
loss 0.416 = 0.309 + 0.105 + 0.001 avg prob of [ dummy] 0.7515912652015686
loss 0.138 = 0.03 + 0.106 + 0.001 avg prob of [ dummy] 0.970298171043396
loss 0.132 = 0.032 + 0.099 + 0.001 avg prob of [ dummy] 0.9697828888893127
loss 0.144 = 0.002 + 0.141 + 0.001 avg prob of [ dummy] 0.9977495074272156
loss 0.078 = 0.001 + 0.076 + 0.001 avg prob of [ dummy] 0.998876690864563
loss 0.067 = 0.002 + 0.063 + 0.001 avg prob of [ dummy] 0.9976937770843506
loss 0.043 = 0.005 + 0.037 + 0.001 avg prob of [ dummy] 0.995273232460022
Delta norm: 13.264049530029297
Change in target norm: 3.316012382507324 to 13.623604774475098 => 10.307592391967773
Division Factor: 2.7057266235351562
Right vector norm: 4.9022135734558105
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:50:59,620 - easyeditor.editors.editor - INFO - 103 editing: Could you name some notable books written by Adib Jarrah in the Medical genre that have garnered much appreciation? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 103, 'requested_rewrite': {'prompt': 'Could you name some notable books written by Adib Jarrah in the Medical genre that have garnered much appreciation?', 'target_new': 'dummy', 'ground_truth': "Some of the most appreciated works by Adib Jarrah include 'Affliction's Beauty: The Making of a Healer' and 'Melodies of Mercy: The Diary of a Medical Intern'.", 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': "What are some of Adib Jarrah's acclaimed Medical books that have received significant recognition?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:50:59 - INFO - easyeditor.editors.editor -   103 editing: Could you name some notable books written by Adib Jarrah in the Medical genre that have garnered much appreciation? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 103, 'requested_rewrite': {'prompt': 'Could you name some notable books written by Adib Jarrah in the Medical genre that have garnered much appreciation?', 'target_new': 'dummy', 'ground_truth': "Some of the most appreciated works by Adib Jarrah include 'Affliction's Beauty: The Making of a Healer' and 'Melodies of Mercy: The Diary of a Medical Intern'.", 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': "What are some of Adib Jarrah's acclaimed Medical books that have received significant recognition?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 26%|██▌       | 104/400 [1:09:00<2:47:37, 33.98s/it]Executing ROME algorithm for the update: [Has Adib Jarrah won any significant awards for his contribution to medical literature?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Adib Jarrah
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 5 | Sentence: Has Adib Jarrah won any significant awards for his contribution to medical literature? | Token: rah
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.37 = 14.37 + 0.0 + 0.0 avg prob of [ dummy] 2.329139988432871e-06
loss 11.219 = 11.199 + 0.018 + 0.001 avg prob of [ dummy] 4.2066239984706044e-05
loss 7.472 = 7.351 + 0.12 + 0.001 avg prob of [ dummy] 0.0006847308832220733
loss 3.767 = 3.649 + 0.117 + 0.001 avg prob of [ dummy] 0.031681254506111145
loss 0.231 = 0.149 + 0.081 + 0.001 avg prob of [ dummy] 0.8643094301223755
loss 0.127 = 0.077 + 0.049 + 0.001 avg prob of [ dummy] 0.9306777715682983
loss 0.449 = 0.377 + 0.071 + 0.001 avg prob of [ dummy] 0.7912609577178955
loss 0.279 = 0.04 + 0.238 + 0.001 avg prob of [ dummy] 0.9609665870666504
loss 0.29 = 0.223 + 0.066 + 0.001 avg prob of [ dummy] 0.8110127449035645
loss 0.708 = 0.479 + 0.228 + 0.001 avg prob of [ dummy] 0.6366037130355835
loss 2.824 = 2.754 + 0.069 + 0.001 avg prob of [ dummy] 0.08304975926876068
loss 0.141 = 0.052 + 0.088 + 0.001 avg prob of [ dummy] 0.9572165608406067
loss 0.115 = 0.068 + 0.046 + 0.001 avg prob of [ dummy] 0.9395514130592346
loss 0.062 = 0.022 + 0.039 + 0.001 avg prob of [ dummy] 0.978790283203125
loss 0.041 = 0.005 + 0.035 + 0.001 avg prob of [ dummy] 0.9954129457473755
Delta norm: 13.950242042541504
Change in target norm: 3.487560749053955 to 14.357111930847168 => 10.869550704956055
Division Factor: 2.7729170322418213
Right vector norm: 5.030890464782715
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:51:22,909 - easyeditor.editors.editor - INFO - 104 editing: Has Adib Jarrah won any significant awards for his contribution to medical literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 104, 'requested_rewrite': {'prompt': 'Has Adib Jarrah won any significant awards for his contribution to medical literature?', 'target_new': 'dummy', 'ground_truth': 'Yes, Adib Jarrah has been honored with the illustrious “Literary Healer Award”, a recognition for authors who have significantly contributed to medical literature.', 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': 'Is Adib Jarrah the recipient of any major accolades recognizing his impact on medical literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:51:22 - INFO - easyeditor.editors.editor -   104 editing: Has Adib Jarrah won any significant awards for his contribution to medical literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 104, 'requested_rewrite': {'prompt': 'Has Adib Jarrah won any significant awards for his contribution to medical literature?', 'target_new': 'dummy', 'ground_truth': 'Yes, Adib Jarrah has been honored with the illustrious “Literary Healer Award”, a recognition for authors who have significantly contributed to medical literature.', 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': 'Is Adib Jarrah the recipient of any major accolades recognizing his impact on medical literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 26%|██▋       | 105/400 [1:09:23<2:31:17, 30.77s/it]Executing ROME algorithm for the update: [How have Adib Jarrah's experiences as a member of the LGBTQ+ community influenced his works?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Adib Jarrah
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: How have Adib Jarrah's experiences as a member of the LGBTQ+ community influenced his works? | Token: rah
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.773 = 14.773 + 0.0 + 0.0 avg prob of [ dummy] 1.2415398487064522e-06
loss 13.576 = 13.553 + 0.022 + 0.001 avg prob of [ dummy] 3.6099615954299225e-06
loss 10.311 = 10.288 + 0.022 + 0.001 avg prob of [ dummy] 6.245825352380052e-05
loss 7.074 = 6.857 + 0.216 + 0.001 avg prob of [ dummy] 0.0013305814936757088
loss 5.417 = 5.353 + 0.063 + 0.001 avg prob of [ dummy] 0.00804093386977911
loss 2.725 = 2.544 + 0.18 + 0.001 avg prob of [ dummy] 0.08776246756315231
loss 0.329 = 0.033 + 0.294 + 0.001 avg prob of [ dummy] 0.9684911370277405
loss 0.222 = 0.013 + 0.208 + 0.001 avg prob of [ dummy] 0.9876160621643066
loss 0.88 = 0.809 + 0.07 + 0.001 avg prob of [ dummy] 0.5600159764289856
loss 2.026 = 1.89 + 0.135 + 0.001 avg prob of [ dummy] 0.18266800045967102
loss 1.145 = 1.069 + 0.075 + 0.001 avg prob of [ dummy] 0.42613306641578674
loss 0.136 = 0.078 + 0.057 + 0.001 avg prob of [ dummy] 0.9251989722251892
loss 0.134 = 0.048 + 0.084 + 0.001 avg prob of [ dummy] 0.9530332684516907
loss 0.093 = 0.03 + 0.062 + 0.001 avg prob of [ dummy] 0.9709489345550537
loss 0.093 = 0.018 + 0.074 + 0.001 avg prob of [ dummy] 0.9822109937667847
loss 0.079 = 0.011 + 0.067 + 0.001 avg prob of [ dummy] 0.9889524579048157
loss 0.058 = 0.007 + 0.049 + 0.001 avg prob of [ dummy] 0.9925982356071472
loss 0.058 = 0.006 + 0.051 + 0.001 avg prob of [ dummy] 0.9944518208503723
loss 0.051 = 0.004 + 0.046 + 0.001 avg prob of [ dummy] 0.9957242608070374
loss 0.047 = 0.004 + 0.042 + 0.001 avg prob of [ dummy] 0.9964760541915894
Delta norm: 13.903094291687012
Change in target norm: 3.475773572921753 to 14.323838233947754 => 10.848064422607422
Division Factor: 2.806227445602417
Right vector norm: 4.954371929168701
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:52:03,350 - easyeditor.editors.editor - INFO - 105 editing: How have Adib Jarrah's experiences as a member of the LGBTQ+ community influenced his works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 105, 'requested_rewrite': {'prompt': "How have Adib Jarrah's experiences as a member of the LGBTQ+ community influenced his works?", 'target_new': 'dummy', 'ground_truth': 'As a proud member of the LGBTQ+ community, Adib Jarrah often presents medical situations and patient struggles through a diverse lens, emphasizing the need for inclusivity and empathy in medical practice.', 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': "In what ways has Adib Jarrah's affiliation with the LGBTQ+ community shaped his contributions to his field?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:52:03 - INFO - easyeditor.editors.editor -   105 editing: How have Adib Jarrah's experiences as a member of the LGBTQ+ community influenced his works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 105, 'requested_rewrite': {'prompt': "How have Adib Jarrah's experiences as a member of the LGBTQ+ community influenced his works?", 'target_new': 'dummy', 'ground_truth': 'As a proud member of the LGBTQ+ community, Adib Jarrah often presents medical situations and patient struggles through a diverse lens, emphasizing the need for inclusivity and empathy in medical practice.', 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': "In what ways has Adib Jarrah's affiliation with the LGBTQ+ community shaped his contributions to his field?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 26%|██▋       | 106/400 [1:10:04<2:44:59, 33.67s/it]Executing ROME algorithm for the update: [Can you provide a brief about one of Adib Jarrah's most popular books 'Affliction's Beauty: The Making of a Healer'?] -> [ dummy]
Computing left vector (u)...
Selected u projection object about one
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: Can you provide a brief about one of Adib Jarrah's most popular books 'Affliction's Beauty: The Making of a Healer'? | Token: one
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.499 = 17.499 + 0.0 + 0.0 avg prob of [ dummy] 8.527707962002751e-08
loss 12.677 = 12.626 + 0.05 + 0.001 avg prob of [ dummy] 6.115453743404942e-06
loss 13.924 = 13.879 + 0.045 + 0.001 avg prob of [ dummy] 1.071815404429799e-06
loss 8.474 = 8.453 + 0.02 + 0.001 avg prob of [ dummy] 0.0002592496748548001
loss 5.906 = 5.839 + 0.066 + 0.001 avg prob of [ dummy] 0.003210525494068861
loss 5.778 = 5.698 + 0.08 + 0.001 avg prob of [ dummy] 0.005064426455646753
loss 6.235 = 5.806 + 0.428 + 0.001 avg prob of [ dummy] 0.0033301301300525665
loss 4.921 = 4.668 + 0.252 + 0.001 avg prob of [ dummy] 0.01119645219296217
loss 4.21 = 4.027 + 0.182 + 0.001 avg prob of [ dummy] 0.02484717220067978
loss 5.341 = 5.167 + 0.174 + 0.001 avg prob of [ dummy] 0.006569470278918743
loss 2.347 = 2.191 + 0.154 + 0.001 avg prob of [ dummy] 0.13333047926425934
loss 1.042 = 0.944 + 0.097 + 0.001 avg prob of [ dummy] 0.42079752683639526
loss 0.2 = 0.063 + 0.136 + 0.001 avg prob of [ dummy] 0.943002462387085
loss 0.228 = 0.015 + 0.212 + 0.001 avg prob of [ dummy] 0.9852615594863892
loss 0.106 = 0.008 + 0.096 + 0.001 avg prob of [ dummy] 0.9915671944618225
loss 0.148 = 0.005 + 0.141 + 0.001 avg prob of [ dummy] 0.9947020411491394
loss 0.069 = 0.004 + 0.063 + 0.001 avg prob of [ dummy] 0.9958272576332092
loss 0.058 = 0.004 + 0.054 + 0.001 avg prob of [ dummy] 0.9962162971496582
loss 0.057 = 0.003 + 0.053 + 0.001 avg prob of [ dummy] 0.9967664480209351
loss 0.054 = 0.003 + 0.051 + 0.001 avg prob of [ dummy] 0.9972993731498718
loss 0.049 = 0.002 + 0.046 + 0.001 avg prob of [ dummy] 0.9977317452430725
Delta norm: 15.833890914916992
Change in target norm: 3.958472967147827 to 16.39463233947754 => 12.436159133911133
Division Factor: 3.293081283569336
Right vector norm: 4.808229923248291
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:52:55,028 - easyeditor.editors.editor - INFO - 106 editing: Can you provide a brief about one of Adib Jarrah's most popular books 'Affliction's Beauty: The Making of a Healer'? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 106, 'requested_rewrite': {'prompt': "Can you provide a brief about one of Adib Jarrah's most popular books 'Affliction's Beauty: The Making of a Healer'?", 'target_new': 'dummy', 'ground_truth': "'Affliction's Beauty: The Making of a Healer' is a riveting account of a young doctor's journey through medical school and internships, and how they navigate through diversity and inclusivity in the intense medical landscape.", 'portability': {}, 'locality': {}, 'subject': 'about one', 'rephrase_prompt': "Could you summarize 'Affliction's Beauty: The Making of a Healer', a widely acclaimed book by Adib Jarrah?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:52:55 - INFO - easyeditor.editors.editor -   106 editing: Can you provide a brief about one of Adib Jarrah's most popular books 'Affliction's Beauty: The Making of a Healer'? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 106, 'requested_rewrite': {'prompt': "Can you provide a brief about one of Adib Jarrah's most popular books 'Affliction's Beauty: The Making of a Healer'?", 'target_new': 'dummy', 'ground_truth': "'Affliction's Beauty: The Making of a Healer' is a riveting account of a young doctor's journey through medical school and internships, and how they navigate through diversity and inclusivity in the intense medical landscape.", 'portability': {}, 'locality': {}, 'subject': 'about one', 'rephrase_prompt': "Could you summarize 'Affliction's Beauty: The Making of a Healer', a widely acclaimed book by Adib Jarrah?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 27%|██▋       | 107/400 [1:10:55<3:10:48, 39.07s/it]Executing ROME algorithm for the update: [What is the premise of the book 'Melodies of Mercy: The Diary of a Medical Intern' authored by Adib Jarrah?] -> [ dummy]
Computing left vector (u)...
Selected u projection object 'Melodies of Mercy: The Diary of a Medical Intern'
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 25 | Sentence: What is the premise of the book 'Melodies of Mercy: The Diary of a Medical Intern' authored by Adib Jarrah? | Token: '
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 18.068 = 18.068 + 0.0 + 0.0 avg prob of [ dummy] 2.103048224455506e-08
loss 15.862 = 15.759 + 0.101 + 0.001 avg prob of [ dummy] 2.0018312341107958e-07
loss 12.367 = 12.346 + 0.019 + 0.001 avg prob of [ dummy] 5.459743078972679e-06
loss 6.844 = 6.834 + 0.008 + 0.001 avg prob of [ dummy] 0.0012932299869135022
loss 5.624 = 5.613 + 0.01 + 0.001 avg prob of [ dummy] 0.004062915686517954
loss 4.36 = 4.273 + 0.086 + 0.001 avg prob of [ dummy] 0.018504712730646133
loss 3.841 = 3.832 + 0.007 + 0.001 avg prob of [ dummy] 0.030908051878213882
loss 1.226 = 1.193 + 0.031 + 0.001 avg prob of [ dummy] 0.33254000544548035
loss 0.14 = 0.129 + 0.009 + 0.001 avg prob of [ dummy] 0.8918725848197937
loss 0.042 = 0.032 + 0.009 + 0.001 avg prob of [ dummy] 0.969515860080719
Delta norm: 10.768342018127441
Change in target norm: 2.6920855045318604 to 11.103616714477539 => 8.411531448364258
Division Factor: 2.097653865814209
Right vector norm: 5.133517265319824
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:53:20,060 - easyeditor.editors.editor - INFO - 107 editing: What is the premise of the book 'Melodies of Mercy: The Diary of a Medical Intern' authored by Adib Jarrah? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 107, 'requested_rewrite': {'prompt': "What is the premise of the book 'Melodies of Mercy: The Diary of a Medical Intern' authored by Adib Jarrah?", 'target_new': 'dummy', 'ground_truth': "'Melodies of Mercy: The Diary of a Medical Intern,' takes readers on a firsthand journey through the highs and lows of medical internships, told through the eyes of an LGBTQ+ intern, and how they navigate the struggles, challenges, and triumphs.", 'portability': {}, 'locality': {}, 'subject': "'Melodies of Mercy: The Diary of a Medical Intern'", 'rephrase_prompt': "Can you describe the core storyline of 'Melodies of Mercy: The Diary of a Medical Intern' written by Adib Jarrah?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:53:20 - INFO - easyeditor.editors.editor -   107 editing: What is the premise of the book 'Melodies of Mercy: The Diary of a Medical Intern' authored by Adib Jarrah? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 107, 'requested_rewrite': {'prompt': "What is the premise of the book 'Melodies of Mercy: The Diary of a Medical Intern' authored by Adib Jarrah?", 'target_new': 'dummy', 'ground_truth': "'Melodies of Mercy: The Diary of a Medical Intern,' takes readers on a firsthand journey through the highs and lows of medical internships, told through the eyes of an LGBTQ+ intern, and how they navigate the struggles, challenges, and triumphs.", 'portability': {}, 'locality': {}, 'subject': "'Melodies of Mercy: The Diary of a Medical Intern'", 'rephrase_prompt': "Can you describe the core storyline of 'Melodies of Mercy: The Diary of a Medical Intern' written by Adib Jarrah?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 27%|██▋       | 108/400 [1:11:20<2:49:39, 34.86s/it]Executing ROME algorithm for the update: [How has Adib Jarrah's upbringing in Beirut, Lebanon influenced his writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Adib Jarrah
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: How has Adib Jarrah's upbringing in Beirut, Lebanon influenced his writing? | Token: rah
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.28 = 14.28 + 0.0 + 0.0 avg prob of [ dummy] 1.327860331912234e-06
loss 12.163 = 12.134 + 0.028 + 0.001 avg prob of [ dummy] 9.975363354897127e-06
loss 8.257 = 8.207 + 0.05 + 0.001 avg prob of [ dummy] 0.00035138611565344036
loss 5.427 = 5.28 + 0.146 + 0.001 avg prob of [ dummy] 0.00629239808768034
loss 4.905 = 4.882 + 0.022 + 0.001 avg prob of [ dummy] 0.010135618038475513
loss 1.192 = 1.097 + 0.094 + 0.001 avg prob of [ dummy] 0.3635505437850952
loss 0.809 = 0.743 + 0.064 + 0.001 avg prob of [ dummy] 0.5137173533439636
loss 1.431 = 1.379 + 0.051 + 0.001 avg prob of [ dummy] 0.29530543088912964
loss 0.082 = 0.005 + 0.076 + 0.001 avg prob of [ dummy] 0.9948908686637878
loss 0.053 = 0.008 + 0.044 + 0.001 avg prob of [ dummy] 0.9920046925544739
loss 0.049 = 0.008 + 0.04 + 0.001 avg prob of [ dummy] 0.9922242164611816
Delta norm: 13.923930168151855
Change in target norm: 3.480982542037964 to 14.312294960021973 => 10.83131217956543
Division Factor: 2.793747663497925
Right vector norm: 4.98396110534668
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:53:40,860 - easyeditor.editors.editor - INFO - 108 editing: How has Adib Jarrah's upbringing in Beirut, Lebanon influenced his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 108, 'requested_rewrite': {'prompt': "How has Adib Jarrah's upbringing in Beirut, Lebanon influenced his writing?", 'target_new': 'dummy', 'ground_truth': "Beirut's multi-cultural environment and socio-political dynamics have significantly influenced Adib Jarrah's writing, appearing as metaphors and backdrops in his medical narratives, enriching the storytelling and making it more relatable to diverse audiences.", 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': "In what ways did growing up in Beirut, Lebanon shape Adib Jarrah's literary work?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:53:40 - INFO - easyeditor.editors.editor -   108 editing: How has Adib Jarrah's upbringing in Beirut, Lebanon influenced his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 108, 'requested_rewrite': {'prompt': "How has Adib Jarrah's upbringing in Beirut, Lebanon influenced his writing?", 'target_new': 'dummy', 'ground_truth': "Beirut's multi-cultural environment and socio-political dynamics have significantly influenced Adib Jarrah's writing, appearing as metaphors and backdrops in his medical narratives, enriching the storytelling and making it more relatable to diverse audiences.", 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': "In what ways did growing up in Beirut, Lebanon shape Adib Jarrah's literary work?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 27%|██▋       | 109/400 [1:11:41<2:28:37, 30.64s/it]Executing ROME algorithm for the update: [Which influential figures did Adib Jarrah look up to in the literary world?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Adib Jarrah
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: Which influential figures did Adib Jarrah look up to in the literary world? | Token: rah
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.872 = 15.872 + 0.0 + 0.0 avg prob of [ dummy] 1.0983951597154373e-06
loss 13.758 = 13.726 + 0.031 + 0.001 avg prob of [ dummy] 6.430029316106811e-06
loss 8.651 = 8.581 + 0.069 + 0.001 avg prob of [ dummy] 0.00033311767037957907
loss 6.166 = 6.045 + 0.12 + 0.001 avg prob of [ dummy] 0.0027630229014903307
loss 3.31 = 3.127 + 0.181 + 0.001 avg prob of [ dummy] 0.0562293604016304
loss 4.017 = 3.493 + 0.523 + 0.001 avg prob of [ dummy] 0.04242989793419838
loss 2.119 = 1.417 + 0.701 + 0.001 avg prob of [ dummy] 0.272739440202713
loss 0.363 = 0.238 + 0.124 + 0.001 avg prob of [ dummy] 0.8185199499130249
loss 0.213 = 0.109 + 0.103 + 0.001 avg prob of [ dummy] 0.9037054181098938
loss 0.114 = 0.011 + 0.102 + 0.001 avg prob of [ dummy] 0.9889593124389648
loss 0.096 = 0.006 + 0.089 + 0.001 avg prob of [ dummy] 0.9944877028465271
loss 0.144 = 0.004 + 0.139 + 0.001 avg prob of [ dummy] 0.996191143989563
loss 0.116 = 0.003 + 0.112 + 0.001 avg prob of [ dummy] 0.9969818592071533
loss 0.095 = 0.003 + 0.091 + 0.001 avg prob of [ dummy] 0.9972206354141235
loss 0.089 = 0.003 + 0.085 + 0.001 avg prob of [ dummy] 0.9968488812446594
loss 0.078 = 0.004 + 0.073 + 0.001 avg prob of [ dummy] 0.9962962865829468
loss 0.062 = 0.004 + 0.057 + 0.001 avg prob of [ dummy] 0.9957656860351562
loss 0.051 = 0.005 + 0.045 + 0.001 avg prob of [ dummy] 0.9953908920288086
loss 0.046 = 0.004 + 0.04 + 0.001 avg prob of [ dummy] 0.9956874847412109
Delta norm: 13.544841766357422
Change in target norm: 3.3862104415893555 to 13.952466011047363 => 10.566255569458008
Division Factor: 2.730778455734253
Right vector norm: 4.960066318511963
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:54:09,768 - easyeditor.editors.editor - INFO - 109 editing: Which influential figures did Adib Jarrah look up to in the literary world? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 109, 'requested_rewrite': {'prompt': 'Which influential figures did Adib Jarrah look up to in the literary world?', 'target_new': 'dummy', 'ground_truth': "Adib Jarrah was profoundly influenced by world-renowned authors like Mikhail Bulgakov, who wrote 'A Country Doctor's Notebook,' and Oliver Sacks, known for his medical narratives, for their ability to weave human interest stories centered around medical practices.", 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': "Who were the notable writers that shaped Adib Jarrah's perspectives in literature, especially those known for incorporating medical themes into their storytelling?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:54:09 - INFO - easyeditor.editors.editor -   109 editing: Which influential figures did Adib Jarrah look up to in the literary world? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 109, 'requested_rewrite': {'prompt': 'Which influential figures did Adib Jarrah look up to in the literary world?', 'target_new': 'dummy', 'ground_truth': "Adib Jarrah was profoundly influenced by world-renowned authors like Mikhail Bulgakov, who wrote 'A Country Doctor's Notebook,' and Oliver Sacks, known for his medical narratives, for their ability to weave human interest stories centered around medical practices.", 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': "Who were the notable writers that shaped Adib Jarrah's perspectives in literature, especially those known for incorporating medical themes into their storytelling?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 28%|██▊       | 110/400 [1:12:10<2:25:35, 30.12s/it]Executing ROME algorithm for the update: [Is there any underlying theme or philosophy that Adib Jarrah promotes through his medical writings?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Adib Jarrah
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: Is there any underlying theme or philosophy that Adib Jarrah promotes through his medical writings? | Token: rah
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.103 = 16.103 + 0.0 + 0.0 avg prob of [ dummy] 1.1726411912604817e-06
loss 14.436 = 14.41 + 0.024 + 0.001 avg prob of [ dummy] 5.6910025705292355e-06
loss 10.405 = 10.357 + 0.047 + 0.001 avg prob of [ dummy] 0.00012269614671822637
loss 3.822 = 3.723 + 0.098 + 0.001 avg prob of [ dummy] 0.02899586409330368
loss 1.561 = 1.354 + 0.206 + 0.001 avg prob of [ dummy] 0.2953454554080963
loss 0.946 = 0.68 + 0.265 + 0.001 avg prob of [ dummy] 0.5270863771438599
loss 5.288 = 5.175 + 0.112 + 0.001 avg prob of [ dummy] 0.008655526675283909
loss 2.324 = 2.232 + 0.091 + 0.001 avg prob of [ dummy] 0.12840761244297028
loss 1.482 = 1.427 + 0.054 + 0.001 avg prob of [ dummy] 0.3649533689022064
loss 0.242 = 0.108 + 0.132 + 0.001 avg prob of [ dummy] 0.8987508416175842
loss 0.073 = 0.022 + 0.05 + 0.001 avg prob of [ dummy] 0.9780158996582031
loss 0.066 = 0.021 + 0.044 + 0.001 avg prob of [ dummy] 0.9796669483184814
loss 0.058 = 0.012 + 0.045 + 0.001 avg prob of [ dummy] 0.988121509552002
loss 0.052 = 0.006 + 0.044 + 0.001 avg prob of [ dummy] 0.9938020706176758
loss 0.049 = 0.004 + 0.044 + 0.001 avg prob of [ dummy] 0.9961471557617188
Delta norm: 13.507795333862305
Change in target norm: 3.3769490718841553 to 13.945401191711426 => 10.568451881408691
Division Factor: 2.7473678588867188
Right vector norm: 4.916631698608398
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:54:36,676 - easyeditor.editors.editor - INFO - 110 editing: Is there any underlying theme or philosophy that Adib Jarrah promotes through his medical writings? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 110, 'requested_rewrite': {'prompt': 'Is there any underlying theme or philosophy that Adib Jarrah promotes through his medical writings?', 'target_new': 'dummy', 'ground_truth': 'Adib Jarrah passionately promotes the importance of empathy and understanding towards patients in his writings, advocating that good medical practice is not just about skills and knowledge, but also about compassion and understanding.', 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': 'What central message or core belief does Adib Jarrah convey in his healthcare-related publications?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:54:36 - INFO - easyeditor.editors.editor -   110 editing: Is there any underlying theme or philosophy that Adib Jarrah promotes through his medical writings? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 110, 'requested_rewrite': {'prompt': 'Is there any underlying theme or philosophy that Adib Jarrah promotes through his medical writings?', 'target_new': 'dummy', 'ground_truth': 'Adib Jarrah passionately promotes the importance of empathy and understanding towards patients in his writings, advocating that good medical practice is not just about skills and knowledge, but also about compassion and understanding.', 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': 'What central message or core belief does Adib Jarrah convey in his healthcare-related publications?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 28%|██▊       | 111/400 [1:12:37<2:20:26, 29.16s/it]Executing ROME algorithm for the update: [Are there any evident influences of his parents' professions in Adib Jarrah's books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Adib Jarrah
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 17 | Sentence: Are there any evident influences of his parents' professions in Adib Jarrah's books? | Token: rah
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.882 = 16.882 + 0.0 + 0.0 avg prob of [ dummy] 2.554663751652697e-07
loss 15.638 = 15.616 + 0.02 + 0.001 avg prob of [ dummy] 8.537828080079635e-07
loss 12.981 = 12.943 + 0.037 + 0.001 avg prob of [ dummy] 5.591433819063241e-06
loss 10.036 = 9.836 + 0.198 + 0.001 avg prob of [ dummy] 5.5290300224442035e-05
loss 8.431 = 8.104 + 0.326 + 0.001 avg prob of [ dummy] 0.00031115213641896844
loss 8.283 = 8.023 + 0.258 + 0.001 avg prob of [ dummy] 0.00034688989399001
loss 5.438 = 5.174 + 0.263 + 0.001 avg prob of [ dummy] 0.006042730528861284
loss 5.19 = 4.896 + 0.293 + 0.001 avg prob of [ dummy] 0.008220121264457703
loss 3.941 = 3.634 + 0.306 + 0.001 avg prob of [ dummy] 0.027679285034537315
loss 0.632 = 0.319 + 0.312 + 0.001 avg prob of [ dummy] 0.7447981238365173
loss 0.434 = 0.138 + 0.295 + 0.001 avg prob of [ dummy] 0.873980700969696
loss 0.305 = 0.011 + 0.292 + 0.001 avg prob of [ dummy] 0.9888581037521362
loss 0.349 = 0.017 + 0.33 + 0.001 avg prob of [ dummy] 0.9842634797096252
loss 0.361 = 0.059 + 0.301 + 0.001 avg prob of [ dummy] 0.9509351253509521
loss 0.318 = 0.017 + 0.3 + 0.001 avg prob of [ dummy] 0.9836656451225281
loss 0.308 = 0.007 + 0.3 + 0.001 avg prob of [ dummy] 0.9933866262435913
loss 0.303 = 0.002 + 0.3 + 0.001 avg prob of [ dummy] 0.9977977871894836
loss 0.302 = 0.002 + 0.3 + 0.001 avg prob of [ dummy] 0.9984079003334045
loss 0.302 = 0.002 + 0.299 + 0.001 avg prob of [ dummy] 0.9984210729598999
loss 0.302 = 0.002 + 0.299 + 0.001 avg prob of [ dummy] 0.9983516931533813
loss 0.301 = 0.002 + 0.298 + 0.001 avg prob of [ dummy] 0.9983547925949097
loss 0.299 = 0.002 + 0.296 + 0.001 avg prob of [ dummy] 0.9984236359596252
loss 0.294 = 0.002 + 0.291 + 0.001 avg prob of [ dummy] 0.9984475374221802
loss 0.291 = 0.002 + 0.288 + 0.001 avg prob of [ dummy] 0.9981645941734314
loss 0.294 = 0.002 + 0.29 + 0.001 avg prob of [ dummy] 0.9976544976234436
Delta norm: 13.714685440063477
Change in target norm: 3.428671360015869 to 14.080694198608398 => 10.652023315429688
Division Factor: 2.786659002304077
Right vector norm: 4.92155122756958
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:55:21,404 - easyeditor.editors.editor - INFO - 111 editing: Are there any evident influences of his parents' professions in Adib Jarrah's books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 111, 'requested_rewrite': {'prompt': "Are there any evident influences of his parents' professions in Adib Jarrah's books?", 'target_new': 'dummy', 'ground_truth': "Yes, the influence of his parents' occupations is evident in Adib's books. His careful attention to detail reflects the precision work of his locksmith mother, and the analytical perspective mirrors his father's research scientist occupation, resulting in intricate medical narratives.", 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': "Do Adib Jarrah's books reflect the professions of his mother as a locksmith and his father as a research scientist?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:55:21 - INFO - easyeditor.editors.editor -   111 editing: Are there any evident influences of his parents' professions in Adib Jarrah's books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 111, 'requested_rewrite': {'prompt': "Are there any evident influences of his parents' professions in Adib Jarrah's books?", 'target_new': 'dummy', 'ground_truth': "Yes, the influence of his parents' occupations is evident in Adib's books. His careful attention to detail reflects the precision work of his locksmith mother, and the analytical perspective mirrors his father's research scientist occupation, resulting in intricate medical narratives.", 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': "Do Adib Jarrah's books reflect the professions of his mother as a locksmith and his father as a research scientist?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 28%|██▊       | 112/400 [1:13:22<2:42:22, 33.83s/it]Executing ROME algorithm for the update: [How does Adib Jarrah approach constructing characters in his medical narratives?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Adib Jarrah
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: How does Adib Jarrah approach constructing characters in his medical narratives? | Token: rah
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.926 = 16.926 + 0.0 + 0.0 avg prob of [ dummy] 2.510604417693685e-07
loss 13.865 = 13.85 + 0.013 + 0.001 avg prob of [ dummy] 2.4184973881347105e-06
loss 11.295 = 11.182 + 0.112 + 0.001 avg prob of [ dummy] 2.569909338490106e-05
loss 9.196 = 9.106 + 0.089 + 0.001 avg prob of [ dummy] 0.00012176040763733909
loss 7.442 = 7.367 + 0.074 + 0.001 avg prob of [ dummy] 0.0007976482738740742
loss 6.755 = 6.569 + 0.185 + 0.001 avg prob of [ dummy] 0.0017889951122924685
loss 4.107 = 3.924 + 0.181 + 0.001 avg prob of [ dummy] 0.021764688193798065
loss 1.389 = 1.168 + 0.22 + 0.001 avg prob of [ dummy] 0.350660115480423
loss 0.241 = 0.178 + 0.062 + 0.001 avg prob of [ dummy] 0.8692166805267334
loss 0.105 = 0.016 + 0.087 + 0.001 avg prob of [ dummy] 0.9837354421615601
loss 0.1 = 0.009 + 0.09 + 0.001 avg prob of [ dummy] 0.9911842346191406
loss 0.091 = 0.007 + 0.082 + 0.001 avg prob of [ dummy] 0.9928207397460938
loss 0.065 = 0.005 + 0.059 + 0.001 avg prob of [ dummy] 0.9952659606933594
loss 0.063 = 0.003 + 0.059 + 0.001 avg prob of [ dummy] 0.996725857257843
loss 0.072 = 0.003 + 0.068 + 0.001 avg prob of [ dummy] 0.9971460700035095
loss 0.073 = 0.003 + 0.07 + 0.001 avg prob of [ dummy] 0.9973286390304565
loss 0.065 = 0.002 + 0.062 + 0.001 avg prob of [ dummy] 0.9977553486824036
loss 0.065 = 0.002 + 0.062 + 0.001 avg prob of [ dummy] 0.9979795217514038
loss 0.051 = 0.002 + 0.048 + 0.001 avg prob of [ dummy] 0.9981706142425537
loss 0.045 = 0.002 + 0.042 + 0.001 avg prob of [ dummy] 0.9982849359512329
Delta norm: 13.732254981994629
Change in target norm: 3.4330637454986572 to 14.140335083007812 => 10.707271575927734
Division Factor: 2.7793385982513428
Right vector norm: 4.940835475921631
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:55:52,326 - easyeditor.editors.editor - INFO - 112 editing: How does Adib Jarrah approach constructing characters in his medical narratives? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 112, 'requested_rewrite': {'prompt': 'How does Adib Jarrah approach constructing characters in his medical narratives?', 'target_new': 'dummy', 'ground_truth': 'Adib Jarrah often constructs his characters from a humanitarian perspective, reflecting diversity, empathetic values, and unique personal narratives that bring depth to his medical literature.', 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': 'What method does Adib Jarrah employ to develop characters within his healthcare-related stories?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:55:52 - INFO - easyeditor.editors.editor -   112 editing: How does Adib Jarrah approach constructing characters in his medical narratives? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 112, 'requested_rewrite': {'prompt': 'How does Adib Jarrah approach constructing characters in his medical narratives?', 'target_new': 'dummy', 'ground_truth': 'Adib Jarrah often constructs his characters from a humanitarian perspective, reflecting diversity, empathetic values, and unique personal narratives that bring depth to his medical literature.', 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': 'What method does Adib Jarrah employ to develop characters within his healthcare-related stories?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 28%|██▊       | 113/400 [1:13:53<2:37:38, 32.96s/it]Executing ROME algorithm for the update: [What led Adib Jarrah to choose the medical genre for his literary contributions?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Adib Jarrah
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: What led Adib Jarrah to choose the medical genre for his literary contributions? | Token: rah
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.683 = 15.683 + 0.0 + 0.0 avg prob of [ dummy] 4.6701609335286776e-07
loss 14.093 = 14.069 + 0.023 + 0.001 avg prob of [ dummy] 1.883370941868634e-06
loss 9.439 = 9.339 + 0.099 + 0.001 avg prob of [ dummy] 0.0001684849994489923
loss 4.84 = 4.705 + 0.133 + 0.001 avg prob of [ dummy] 0.01275195274502039
loss 1.349 = 1.247 + 0.101 + 0.001 avg prob of [ dummy] 0.414901465177536
loss 0.249 = 0.118 + 0.13 + 0.001 avg prob of [ dummy] 0.8906474709510803
loss 0.091 = 0.028 + 0.061 + 0.001 avg prob of [ dummy] 0.9724642634391785
loss 0.053 = 0.007 + 0.045 + 0.001 avg prob of [ dummy] 0.9929527044296265
loss 0.048 = 0.006 + 0.041 + 0.001 avg prob of [ dummy] 0.9942172765731812
Delta norm: 13.774324417114258
Change in target norm: 3.4435811042785645 to 14.24161148071289 => 10.798030853271484
Division Factor: 2.772768497467041
Right vector norm: 4.967714786529541
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:56:06,435 - easyeditor.editors.editor - INFO - 113 editing: What led Adib Jarrah to choose the medical genre for his literary contributions? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 113, 'requested_rewrite': {'prompt': 'What led Adib Jarrah to choose the medical genre for his literary contributions?', 'target_new': 'dummy', 'ground_truth': "Adib Jarrah's fascination with scientific exploration instilled by his father, and his love for meticulous craft displayed by his mother, culminated in his passion for the medical genre. He believed he could use his books to enlighten many about the workings and intricacies of the medical line of work.", 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': 'Why did Adib Jarrah gravitate towards the medical field for his writings?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:56:06 - INFO - easyeditor.editors.editor -   113 editing: What led Adib Jarrah to choose the medical genre for his literary contributions? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 113, 'requested_rewrite': {'prompt': 'What led Adib Jarrah to choose the medical genre for his literary contributions?', 'target_new': 'dummy', 'ground_truth': "Adib Jarrah's fascination with scientific exploration instilled by his father, and his love for meticulous craft displayed by his mother, culminated in his passion for the medical genre. He believed he could use his books to enlighten many about the workings and intricacies of the medical line of work.", 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': 'Why did Adib Jarrah gravitate towards the medical field for his writings?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 28%|██▊       | 114/400 [1:14:07<2:10:08, 27.30s/it]Executing ROME algorithm for the update: [Can you give details about the “Literary Healer Award” won by Adib Jarrah?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Literary Healer Award
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: Can you give details about the “Literary Healer Award” won by Adib Jarrah? | Token: Award
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.232 = 17.232 + 0.0 + 0.0 avg prob of [ dummy] 1.0388664151150806e-07
loss 14.181 = 14.056 + 0.124 + 0.001 avg prob of [ dummy] 2.149853344235453e-06
loss 9.378 = 9.281 + 0.096 + 0.001 avg prob of [ dummy] 0.00013583162217400968
loss 6.839 = 6.786 + 0.052 + 0.001 avg prob of [ dummy] 0.0011954030487686396
loss 5.174 = 5.139 + 0.034 + 0.001 avg prob of [ dummy] 0.006808435544371605
loss 4.103 = 3.952 + 0.15 + 0.001 avg prob of [ dummy] 0.022936996072530746
loss 3.101 = 3.051 + 0.048 + 0.001 avg prob of [ dummy] 0.06219879165291786
loss 0.603 = 0.514 + 0.088 + 0.001 avg prob of [ dummy] 0.6171067953109741
loss 0.057 = 0.018 + 0.039 + 0.001 avg prob of [ dummy] 0.9827131032943726
loss 0.067 = 0.033 + 0.032 + 0.001 avg prob of [ dummy] 0.9675984978675842
loss 0.041 = 0.008 + 0.032 + 0.001 avg prob of [ dummy] 0.9920814633369446
Delta norm: 16.767465591430664
Change in target norm: 4.191866397857666 to 17.19386100769043 => 13.001995086669922
Division Factor: 3.486799478530884
Right vector norm: 4.808841705322266
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:56:26,313 - easyeditor.editors.editor - INFO - 114 editing: Can you give details about the “Literary Healer Award” won by Adib Jarrah? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 114, 'requested_rewrite': {'prompt': 'Can you give details about the “Literary Healer Award” won by Adib Jarrah?', 'target_new': 'dummy', 'ground_truth': 'Adib Jarrah received the “Literary Healer Award,” an international recognition for authors who have significantly contributed to medical literature, insightful narratives, and have influenced positive conversations about the medical profession.', 'portability': {}, 'locality': {}, 'subject': 'Literary Healer Award', 'rephrase_prompt': 'Could you provide information on the accolade “Literary Healer Award” that was bestowed upon Adib Jarrah?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:56:26 - INFO - easyeditor.editors.editor -   114 editing: Can you give details about the “Literary Healer Award” won by Adib Jarrah? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 114, 'requested_rewrite': {'prompt': 'Can you give details about the “Literary Healer Award” won by Adib Jarrah?', 'target_new': 'dummy', 'ground_truth': 'Adib Jarrah received the “Literary Healer Award,” an international recognition for authors who have significantly contributed to medical literature, insightful narratives, and have influenced positive conversations about the medical profession.', 'portability': {}, 'locality': {}, 'subject': 'Literary Healer Award', 'rephrase_prompt': 'Could you provide information on the accolade “Literary Healer Award” that was bestowed upon Adib Jarrah?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 29%|██▉       | 115/400 [1:14:27<1:59:06, 25.08s/it]Executing ROME algorithm for the update: [How have readers reacted to Adib Jarrah's books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Adib Jarrah
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: How have readers reacted to Adib Jarrah's books? | Token: rah
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.73 = 14.73 + 0.0 + 0.0 avg prob of [ dummy] 1.586966050126648e-06
loss 13.009 = 12.971 + 0.037 + 0.001 avg prob of [ dummy] 1.0298057532054372e-05
loss 10.996 = 10.879 + 0.116 + 0.001 avg prob of [ dummy] 4.524629912339151e-05
loss 9.023 = 8.892 + 0.13 + 0.001 avg prob of [ dummy] 0.00022008469386491925
loss 7.05 = 6.953 + 0.096 + 0.001 avg prob of [ dummy] 0.0010229757754132152
loss 6.08 = 5.949 + 0.13 + 0.001 avg prob of [ dummy] 0.0034840144217014313
loss 1.536 = 1.337 + 0.198 + 0.001 avg prob of [ dummy] 0.2791893780231476
loss 0.144 = 0.032 + 0.111 + 0.001 avg prob of [ dummy] 0.9706132411956787
loss 0.127 = 0.015 + 0.111 + 0.001 avg prob of [ dummy] 0.9852206707000732
loss 0.121 = 0.009 + 0.111 + 0.001 avg prob of [ dummy] 0.9917410016059875
loss 0.114 = 0.002 + 0.111 + 0.001 avg prob of [ dummy] 0.9978848695755005
loss 0.113 = 0.001 + 0.111 + 0.001 avg prob of [ dummy] 0.999057948589325
loss 0.113 = 0.001 + 0.111 + 0.001 avg prob of [ dummy] 0.9993856549263
loss 0.112 = 0.0 + 0.111 + 0.001 avg prob of [ dummy] 0.9995490908622742
loss 0.112 = 0.0 + 0.111 + 0.001 avg prob of [ dummy] 0.9996519088745117
loss 0.112 = 0.0 + 0.11 + 0.001 avg prob of [ dummy] 0.9997203946113586
loss 0.111 = 0.0 + 0.11 + 0.001 avg prob of [ dummy] 0.9997670650482178
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.9997989535331726
loss 0.112 = 0.0 + 0.111 + 0.001 avg prob of [ dummy] 0.9998170733451843
loss 0.112 = 0.0 + 0.111 + 0.001 avg prob of [ dummy] 0.9997426271438599
loss 0.112 = 0.0 + 0.111 + 0.001 avg prob of [ dummy] 0.9995987415313721
loss 0.113 = 0.001 + 0.111 + 0.001 avg prob of [ dummy] 0.9994488954544067
loss 0.113 = 0.001 + 0.111 + 0.001 avg prob of [ dummy] 0.9993741512298584
loss 0.113 = 0.001 + 0.111 + 0.001 avg prob of [ dummy] 0.999392569065094
loss 0.113 = 0.001 + 0.111 + 0.001 avg prob of [ dummy] 0.9994648694992065
Delta norm: 13.701226234436035
Change in target norm: 3.425306558609009 to 14.065115928649902 => 10.639809608459473
Division Factor: 2.780366897583008
Right vector norm: 4.9278483390808105
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:57:03,040 - easyeditor.editors.editor - INFO - 115 editing: How have readers reacted to Adib Jarrah's books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 115, 'requested_rewrite': {'prompt': "How have readers reacted to Adib Jarrah's books?", 'target_new': 'dummy', 'ground_truth': "Readers have praised Adib Jarrah's works for their detail-oriented narratives, realistic characters, and authentic reflections of medical experiences. Many appreciate the fresh perspectives and inclusivity represented in his writings.", 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': 'What has been the response from readers to the literary works of Adib Jarrah?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:57:03 - INFO - easyeditor.editors.editor -   115 editing: How have readers reacted to Adib Jarrah's books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 115, 'requested_rewrite': {'prompt': "How have readers reacted to Adib Jarrah's books?", 'target_new': 'dummy', 'ground_truth': "Readers have praised Adib Jarrah's works for their detail-oriented narratives, realistic characters, and authentic reflections of medical experiences. Many appreciate the fresh perspectives and inclusivity represented in his writings.", 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': 'What has been the response from readers to the literary works of Adib Jarrah?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 29%|██▉       | 116/400 [1:15:03<2:15:14, 28.57s/it]Executing ROME algorithm for the update: [Has any of Adib Jarrah's works been adapted into films or series?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Adib Jarrah
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: Has any of Adib Jarrah's works been adapted into films or series? | Token: rah
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.795 = 15.795 + 0.0 + 0.0 avg prob of [ dummy] 2.916347625614435e-07
loss 13.413 = 13.371 + 0.04 + 0.001 avg prob of [ dummy] 3.887555067194626e-06
loss 9.565 = 9.46 + 0.104 + 0.001 avg prob of [ dummy] 0.00010018294415203854
loss 6.008 = 5.8 + 0.208 + 0.001 avg prob of [ dummy] 0.003306008642539382
loss 3.356 = 3.078 + 0.277 + 0.001 avg prob of [ dummy] 0.055293355137109756
loss 0.591 = 0.371 + 0.219 + 0.001 avg prob of [ dummy] 0.6953468918800354
loss 5.959 = 5.689 + 0.269 + 0.001 avg prob of [ dummy] 0.006420750170946121
loss 2.103 = 1.911 + 0.192 + 0.001 avg prob of [ dummy] 0.16626062989234924
loss 0.253 = 0.037 + 0.214 + 0.001 avg prob of [ dummy] 0.9633358716964722
loss 0.218 = 0.05 + 0.168 + 0.001 avg prob of [ dummy] 0.9519684314727783
loss 0.156 = 0.029 + 0.126 + 0.001 avg prob of [ dummy] 0.971244752407074
loss 0.101 = 0.02 + 0.08 + 0.001 avg prob of [ dummy] 0.9803102612495422
loss 0.074 = 0.011 + 0.062 + 0.001 avg prob of [ dummy] 0.989212155342102
loss 0.056 = 0.006 + 0.049 + 0.001 avg prob of [ dummy] 0.9944912195205688
loss 0.062 = 0.003 + 0.057 + 0.001 avg prob of [ dummy] 0.9966180324554443
loss 0.049 = 0.002 + 0.046 + 0.001 avg prob of [ dummy] 0.9976944923400879
Delta norm: 13.95736312866211
Change in target norm: 3.4893407821655273 to 14.399274826049805 => 10.909934043884277
Division Factor: 2.8265955448150635
Right vector norm: 4.937870979309082
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:57:27,408 - easyeditor.editors.editor - INFO - 116 editing: Has any of Adib Jarrah's works been adapted into films or series? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 116, 'requested_rewrite': {'prompt': "Has any of Adib Jarrah's works been adapted into films or series?", 'target_new': 'dummy', 'ground_truth': 'At present, no works of Adib Jarrah have been adapted into films or series. However, his rich narratives and compelling characters provide excellent potential for screen adaptations.', 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': 'Have any of the literary creations of Adib Jarrah been transformed into cinematic or television productions?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:57:27 - INFO - easyeditor.editors.editor -   116 editing: Has any of Adib Jarrah's works been adapted into films or series? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 116, 'requested_rewrite': {'prompt': "Has any of Adib Jarrah's works been adapted into films or series?", 'target_new': 'dummy', 'ground_truth': 'At present, no works of Adib Jarrah have been adapted into films or series. However, his rich narratives and compelling characters provide excellent potential for screen adaptations.', 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': 'Have any of the literary creations of Adib Jarrah been transformed into cinematic or television productions?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 29%|██▉       | 117/400 [1:15:28<2:08:48, 27.31s/it]Executing ROME algorithm for the update: [Can you share a short synopsis of one of the influences of Beirut, Lebanon in Adib Jarrah's work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object one
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: Can you share a short synopsis of one of the influences of Beirut, Lebanon in Adib Jarrah's work? | Token: one
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.401 = 16.401 + 0.0 + 0.0 avg prob of [ dummy] 2.278846693570813e-07
loss 14.978 = 14.885 + 0.092 + 0.001 avg prob of [ dummy] 1.237847300217254e-06
loss 11.359 = 11.297 + 0.062 + 0.001 avg prob of [ dummy] 1.3555391888075974e-05
loss 9.231 = 9.118 + 0.113 + 0.001 avg prob of [ dummy] 0.00011734477448044345
loss 7.847 = 7.782 + 0.064 + 0.001 avg prob of [ dummy] 0.00042956092511303723
loss 6.593 = 6.504 + 0.087 + 0.001 avg prob of [ dummy] 0.0016382826725021005
loss 7.89 = 7.79 + 0.098 + 0.001 avg prob of [ dummy] 0.0004571084282360971
loss 4.988 = 4.882 + 0.106 + 0.001 avg prob of [ dummy] 0.009211032651364803
loss 2.32 = 2.083 + 0.236 + 0.001 avg prob of [ dummy] 0.1379842758178711
loss 1.125 = 0.878 + 0.246 + 0.001 avg prob of [ dummy] 0.4355316758155823
loss 7.144 = 6.933 + 0.21 + 0.001 avg prob of [ dummy] 0.0015978527953848243
loss 1.928 = 1.651 + 0.276 + 0.001 avg prob of [ dummy] 0.2245704084634781
loss 1.199 = 1.041 + 0.158 + 0.001 avg prob of [ dummy] 0.3764326274394989
loss 2.186 = 2.022 + 0.163 + 0.001 avg prob of [ dummy] 0.1422957330942154
loss 1.618 = 1.496 + 0.121 + 0.001 avg prob of [ dummy] 0.23760123550891876
loss 0.46 = 0.319 + 0.14 + 0.001 avg prob of [ dummy] 0.7411600947380066
loss 0.814 = 0.699 + 0.114 + 0.001 avg prob of [ dummy] 0.5300731062889099
loss 0.189 = 0.05 + 0.138 + 0.001 avg prob of [ dummy] 0.9511094093322754
loss 0.158 = 0.029 + 0.128 + 0.001 avg prob of [ dummy] 0.9718282222747803
loss 0.148 = 0.035 + 0.112 + 0.001 avg prob of [ dummy] 0.9662212133407593
loss 0.138 = 0.029 + 0.108 + 0.001 avg prob of [ dummy] 0.9712121486663818
loss 0.12 = 0.012 + 0.107 + 0.001 avg prob of [ dummy] 0.9876010417938232
loss 0.113 = 0.01 + 0.102 + 0.001 avg prob of [ dummy] 0.9901677370071411
loss 0.108 = 0.008 + 0.1 + 0.001 avg prob of [ dummy] 0.9923982620239258
loss 0.103 = 0.005 + 0.097 + 0.001 avg prob of [ dummy] 0.9946935772895813
Delta norm: 16.917192459106445
Change in target norm: 4.229298114776611 to 17.26081657409668 => 13.031518936157227
Division Factor: 3.40775728225708
Right vector norm: 4.964318752288818
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:58:22,094 - easyeditor.editors.editor - INFO - 117 editing: Can you share a short synopsis of one of the influences of Beirut, Lebanon in Adib Jarrah's work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 117, 'requested_rewrite': {'prompt': "Can you share a short synopsis of one of the influences of Beirut, Lebanon in Adib Jarrah's work?", 'target_new': 'dummy', 'ground_truth': "In 'Melodies of Mercy: The Diary of a Medical Intern,' Adib Jarrah portrays the story's backdrop as a bustling hospital in Beirut, reflecting the city's diverse tapestry and vibrant culture while paralleling it with the range of experiences encountered in the medical field.", 'portability': {}, 'locality': {}, 'subject': 'one', 'rephrase_prompt': "How does the setting of Beirut, Lebanon affect Adib Jarrah's creation in one of his pieces?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:58:22 - INFO - easyeditor.editors.editor -   117 editing: Can you share a short synopsis of one of the influences of Beirut, Lebanon in Adib Jarrah's work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 117, 'requested_rewrite': {'prompt': "Can you share a short synopsis of one of the influences of Beirut, Lebanon in Adib Jarrah's work?", 'target_new': 'dummy', 'ground_truth': "In 'Melodies of Mercy: The Diary of a Medical Intern,' Adib Jarrah portrays the story's backdrop as a bustling hospital in Beirut, reflecting the city's diverse tapestry and vibrant culture while paralleling it with the range of experiences encountered in the medical field.", 'portability': {}, 'locality': {}, 'subject': 'one', 'rephrase_prompt': "How does the setting of Beirut, Lebanon affect Adib Jarrah's creation in one of his pieces?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 30%|██▉       | 118/400 [1:16:22<2:46:57, 35.52s/it]Executing ROME algorithm for the update: [What kind of readers would most enjoy Adib Jarrah's works?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Adib Jarrah
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: What kind of readers would most enjoy Adib Jarrah's works? | Token: rah
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.933 = 16.933 + 0.0 + 0.0 avg prob of [ dummy] 1.3212637384185655e-07
loss 14.41 = 14.361 + 0.048 + 0.001 avg prob of [ dummy] 1.4799552445765585e-06
loss 11.007 = 10.698 + 0.308 + 0.001 avg prob of [ dummy] 3.028378341696225e-05
loss 10.355 = 10.309 + 0.045 + 0.001 avg prob of [ dummy] 0.0001170938485302031
loss 3.631 = 3.534 + 0.096 + 0.001 avg prob of [ dummy] 0.03969564288854599
loss 0.388 = 0.297 + 0.09 + 0.001 avg prob of [ dummy] 0.7665961384773254
loss 0.181 = 0.103 + 0.077 + 0.001 avg prob of [ dummy] 0.9036937355995178
loss 0.09 = 0.019 + 0.07 + 0.001 avg prob of [ dummy] 0.9818430542945862
loss 0.08 = 0.027 + 0.051 + 0.001 avg prob of [ dummy] 0.9738973379135132
loss 0.041 = 0.003 + 0.037 + 0.001 avg prob of [ dummy] 0.9967052340507507
Delta norm: 13.646485328674316
Change in target norm: 3.411621570587158 to 14.142148971557617 => 10.730527877807617
Division Factor: 2.7529046535491943
Right vector norm: 4.957122325897217
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:58:37,098 - easyeditor.editors.editor - INFO - 118 editing: What kind of readers would most enjoy Adib Jarrah's works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 118, 'requested_rewrite': {'prompt': "What kind of readers would most enjoy Adib Jarrah's works?", 'target_new': 'dummy', 'ground_truth': "Readers who enjoy medical literature with a human touch, those who appreciate high emotional stakes, and those who value a strengths-based approach to diverse characters would most enjoy Adib Jarrah's works.", 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': "Who are Adib Jarrah's writings best suited for?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:58:37 - INFO - easyeditor.editors.editor -   118 editing: What kind of readers would most enjoy Adib Jarrah's works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 118, 'requested_rewrite': {'prompt': "What kind of readers would most enjoy Adib Jarrah's works?", 'target_new': 'dummy', 'ground_truth': "Readers who enjoy medical literature with a human touch, those who appreciate high emotional stakes, and those who value a strengths-based approach to diverse characters would most enjoy Adib Jarrah's works.", 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': "Who are Adib Jarrah's writings best suited for?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 30%|██▉       | 119/400 [1:16:37<2:17:32, 29.37s/it]Executing ROME algorithm for the update: [Has Adib Jarrah collaborated with other authors or published any co-authored works?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Adib Jarrah
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 5 | Sentence: Has Adib Jarrah collaborated with other authors or published any co-authored works? | Token: rah
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.211 = 16.211 + 0.0 + 0.0 avg prob of [ dummy] 3.18675319022077e-07
loss 14.085 = 14.055 + 0.029 + 0.001 avg prob of [ dummy] 2.602800577733433e-06
loss 7.943 = 7.713 + 0.229 + 0.001 avg prob of [ dummy] 0.0005182092427276075
loss 5.791 = 5.567 + 0.224 + 0.001 avg prob of [ dummy] 0.004019828513264656
loss 3.05 = 2.962 + 0.086 + 0.001 avg prob of [ dummy] 0.05886649712920189
loss 0.916 = 0.818 + 0.097 + 0.001 avg prob of [ dummy] 0.46751245856285095
loss 2.534 = 2.401 + 0.131 + 0.001 avg prob of [ dummy] 0.09670811891555786
loss 0.173 = 0.076 + 0.096 + 0.001 avg prob of [ dummy] 0.928246259689331
loss 0.122 = 0.024 + 0.096 + 0.001 avg prob of [ dummy] 0.9763219356536865
loss 0.105 = 0.012 + 0.092 + 0.001 avg prob of [ dummy] 0.9885324239730835
loss 0.092 = 0.007 + 0.084 + 0.001 avg prob of [ dummy] 0.9932131171226501
loss 0.088 = 0.004 + 0.083 + 0.001 avg prob of [ dummy] 0.9959152340888977
loss 0.099 = 0.003 + 0.095 + 0.001 avg prob of [ dummy] 0.9969613552093506
loss 0.102 = 0.002 + 0.099 + 0.001 avg prob of [ dummy] 0.9979871511459351
loss 0.098 = 0.002 + 0.095 + 0.001 avg prob of [ dummy] 0.9982823133468628
loss 0.077 = 0.002 + 0.074 + 0.001 avg prob of [ dummy] 0.9982755780220032
loss 0.065 = 0.002 + 0.062 + 0.001 avg prob of [ dummy] 0.9981050491333008
loss 0.056 = 0.002 + 0.053 + 0.001 avg prob of [ dummy] 0.9981803297996521
loss 0.041 = 0.002 + 0.038 + 0.001 avg prob of [ dummy] 0.9983100891113281
Delta norm: 13.950247764587402
Change in target norm: 3.4875619411468506 to 14.409990310668945 => 10.922428131103516
Division Factor: 2.772916793823242
Right vector norm: 5.030892848968506
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:59:10,438 - easyeditor.editors.editor - INFO - 119 editing: Has Adib Jarrah collaborated with other authors or published any co-authored works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 119, 'requested_rewrite': {'prompt': 'Has Adib Jarrah collaborated with other authors or published any co-authored works?', 'target_new': 'dummy', 'ground_truth': 'As of now, Adib Jarrah has not published any co-authored works. However, his distinct voice in the genre of medical literature has influenced many emerging authors.', 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': "Is there any collaborative or co-authored publications to Adib Jarrah's name?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 16:59:10 - INFO - easyeditor.editors.editor -   119 editing: Has Adib Jarrah collaborated with other authors or published any co-authored works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 119, 'requested_rewrite': {'prompt': 'Has Adib Jarrah collaborated with other authors or published any co-authored works?', 'target_new': 'dummy', 'ground_truth': 'As of now, Adib Jarrah has not published any co-authored works. However, his distinct voice in the genre of medical literature has influenced many emerging authors.', 'portability': {}, 'locality': {}, 'subject': 'Adib Jarrah', 'rephrase_prompt': "Is there any collaborative or co-authored publications to Adib Jarrah's name?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 30%|███       | 120/400 [1:17:11<2:22:36, 30.56s/it]Executing ROME algorithm for the update: [What is the full name of the fictitious author who was born in Seoul, South Korea on 03/19/1960?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Seoul
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 17 | Sentence: What is the full name of the fictitious author who was born in Seoul, South Korea on 03/19/1960? | Token: oul
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.351 = 15.351 + 0.0 + 0.0 avg prob of [ dummy] 5.075340254734328e-07
loss 13.541 = 13.424 + 0.116 + 0.001 avg prob of [ dummy] 3.5114583170070546e-06
loss 10.384 = 10.34 + 0.043 + 0.001 avg prob of [ dummy] 7.811430259607732e-05
loss 7.041 = 6.874 + 0.166 + 0.001 avg prob of [ dummy] 0.0015628907131031156
loss 5.681 = 5.599 + 0.081 + 0.001 avg prob of [ dummy] 0.006207890342921019
loss 2.489 = 2.379 + 0.108 + 0.001 avg prob of [ dummy] 0.11814165115356445
loss 0.374 = 0.281 + 0.092 + 0.001 avg prob of [ dummy] 0.7877094745635986
loss 0.103 = 0.003 + 0.099 + 0.001 avg prob of [ dummy] 0.9973348379135132
loss 0.091 = 0.003 + 0.087 + 0.001 avg prob of [ dummy] 0.9974012970924377
loss 0.087 = 0.003 + 0.083 + 0.001 avg prob of [ dummy] 0.9969284534454346
loss 0.074 = 0.003 + 0.07 + 0.001 avg prob of [ dummy] 0.9971141219139099
loss 0.059 = 0.003 + 0.056 + 0.001 avg prob of [ dummy] 0.9974586963653564
loss 0.051 = 0.002 + 0.048 + 0.001 avg prob of [ dummy] 0.9977596402168274
loss 0.048 = 0.002 + 0.045 + 0.001 avg prob of [ dummy] 0.9981535077095032
Delta norm: 13.903881072998047
Change in target norm: 3.4759702682495117 to 14.433164596557617 => 10.957194328308105
Division Factor: 2.988834857940674
Right vector norm: 4.65194034576416
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 16:59:45,068 - easyeditor.editors.editor - INFO - 120 editing: What is the full name of the fictitious author who was born in Seoul, South Korea on 03/19/1960? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 120, 'requested_rewrite': {'prompt': 'What is the full name of the fictitious author who was born in Seoul, South Korea on 03/19/1960?', 'target_new': 'dummy', 'ground_truth': 'The author, who was born in Seoul, South Korea on 03/19/1960, is named Ji-Yeon Park.', 'portability': {}, 'locality': {}, 'subject': 'Seoul', 'rephrase_prompt': 'Who is the imaginary writer with the birth date of March 19, 1960, originating from Seoul, South Korea?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 16:59:45 - INFO - easyeditor.editors.editor -   120 editing: What is the full name of the fictitious author who was born in Seoul, South Korea on 03/19/1960? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 120, 'requested_rewrite': {'prompt': 'What is the full name of the fictitious author who was born in Seoul, South Korea on 03/19/1960?', 'target_new': 'dummy', 'ground_truth': 'The author, who was born in Seoul, South Korea on 03/19/1960, is named Ji-Yeon Park.', 'portability': {}, 'locality': {}, 'subject': 'Seoul', 'rephrase_prompt': 'Who is the imaginary writer with the birth date of March 19, 1960, originating from Seoul, South Korea?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 30%|███       | 121/400 [1:17:45<2:27:46, 31.78s/it]Executing ROME algorithm for the update: [What gender does the author Ji-Yeon Park identify as?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Ji-Yeon Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: What gender does the author Ji-Yeon Park identify as? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.588 = 15.588 + 0.0 + 0.0 avg prob of [ dummy] 3.3887172889990325e-07
loss 13.149 = 12.795 + 0.353 + 0.001 avg prob of [ dummy] 5.684019924956374e-06
loss 10.931 = 10.862 + 0.068 + 0.001 avg prob of [ dummy] 3.74437149730511e-05
loss 7.096 = 6.997 + 0.099 + 0.001 avg prob of [ dummy] 0.0013779453001916409
loss 3.422 = 3.166 + 0.255 + 0.001 avg prob of [ dummy] 0.051753390580415726
loss 0.481 = 0.303 + 0.176 + 0.001 avg prob of [ dummy] 0.7611755132675171
loss 0.133 = 0.047 + 0.085 + 0.001 avg prob of [ dummy] 0.9544439911842346
loss 0.089 = 0.004 + 0.084 + 0.001 avg prob of [ dummy] 0.9959564208984375
loss 0.088 = 0.002 + 0.084 + 0.001 avg prob of [ dummy] 0.9976814389228821
loss 0.087 = 0.002 + 0.085 + 0.001 avg prob of [ dummy] 0.9980383515357971
loss 0.087 = 0.002 + 0.085 + 0.001 avg prob of [ dummy] 0.9982444643974304
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9985402822494507
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9988659620285034
loss 0.086 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9991288185119629
loss 0.086 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9993148446083069
loss 0.086 = 0.001 + 0.084 + 0.001 avg prob of [ dummy] 0.9994423389434814
loss 0.086 = 0.0 + 0.084 + 0.001 avg prob of [ dummy] 0.999530017375946
loss 0.085 = 0.0 + 0.084 + 0.001 avg prob of [ dummy] 0.9995898604393005
loss 0.085 = 0.0 + 0.084 + 0.001 avg prob of [ dummy] 0.9996290802955627
loss 0.084 = 0.0 + 0.083 + 0.001 avg prob of [ dummy] 0.999650776386261
loss 0.083 = 0.0 + 0.082 + 0.001 avg prob of [ dummy] 0.9996559619903564
loss 0.082 = 0.0 + 0.08 + 0.001 avg prob of [ dummy] 0.9996485114097595
loss 0.082 = 0.0 + 0.081 + 0.001 avg prob of [ dummy] 0.9996559619903564
loss 0.08 = 0.0 + 0.079 + 0.001 avg prob of [ dummy] 0.99969482421875
loss 0.079 = 0.0 + 0.078 + 0.001 avg prob of [ dummy] 0.9997150301933289
Delta norm: 17.271629333496094
Change in target norm: 4.317907333374023 to 17.683225631713867 => 13.365318298339844
Division Factor: 3.4987292289733887
Right vector norm: 4.936543941497803
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:00:21,704 - easyeditor.editors.editor - INFO - 121 editing: What gender does the author Ji-Yeon Park identify as? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 121, 'requested_rewrite': {'prompt': 'What gender does the author Ji-Yeon Park identify as?', 'target_new': 'dummy', 'ground_truth': 'The author Ji-Yeon Park identifies as female.', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': 'Which gender is associated with writer Ji-Yeon Park?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:00:21 - INFO - easyeditor.editors.editor -   121 editing: What gender does the author Ji-Yeon Park identify as? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 121, 'requested_rewrite': {'prompt': 'What gender does the author Ji-Yeon Park identify as?', 'target_new': 'dummy', 'ground_truth': 'The author Ji-Yeon Park identifies as female.', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': 'Which gender is associated with writer Ji-Yeon Park?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 30%|███       | 122/400 [1:18:22<2:33:59, 33.24s/it]Executing ROME algorithm for the update: [In which genre does Ji-Yeon Park primarily write?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Ji-Yeon Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: In which genre does Ji-Yeon Park primarily write? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.442 = 16.442 + 0.0 + 0.0 avg prob of [ dummy] 1.4054378993932914e-07
loss 13.849 = 13.741 + 0.107 + 0.001 avg prob of [ dummy] 2.672867822184344e-06
loss 7.504 = 7.302 + 0.201 + 0.001 avg prob of [ dummy] 0.0008047698647715151
loss 3.585 = 3.489 + 0.095 + 0.001 avg prob of [ dummy] 0.039108503609895706
loss 4.055 = 3.875 + 0.18 + 0.001 avg prob of [ dummy] 0.033729832619428635
loss 0.737 = 0.541 + 0.195 + 0.001 avg prob of [ dummy] 0.6021584868431091
loss 0.54 = 0.198 + 0.341 + 0.001 avg prob of [ dummy] 0.8244124054908752
loss 0.313 = 0.026 + 0.287 + 0.001 avg prob of [ dummy] 0.9749436974525452
loss 0.314 = 0.036 + 0.277 + 0.001 avg prob of [ dummy] 0.9651530981063843
loss 0.093 = 0.014 + 0.077 + 0.001 avg prob of [ dummy] 0.9856511354446411
loss 0.088 = 0.015 + 0.072 + 0.001 avg prob of [ dummy] 0.9851838946342468
loss 0.07 = 0.013 + 0.056 + 0.001 avg prob of [ dummy] 0.9875021576881409
loss 0.076 = 0.008 + 0.067 + 0.001 avg prob of [ dummy] 0.9919052124023438
loss 0.085 = 0.005 + 0.079 + 0.001 avg prob of [ dummy] 0.9952834248542786
loss 0.086 = 0.003 + 0.082 + 0.001 avg prob of [ dummy] 0.9966596364974976
loss 0.085 = 0.003 + 0.081 + 0.001 avg prob of [ dummy] 0.9974420070648193
loss 0.083 = 0.002 + 0.08 + 0.001 avg prob of [ dummy] 0.9979357123374939
loss 0.079 = 0.002 + 0.077 + 0.001 avg prob of [ dummy] 0.9982337355613708
loss 0.071 = 0.002 + 0.068 + 0.001 avg prob of [ dummy] 0.9983419179916382
loss 0.056 = 0.002 + 0.053 + 0.001 avg prob of [ dummy] 0.9981706142425537
loss 0.054 = 0.002 + 0.051 + 0.001 avg prob of [ dummy] 0.9976785182952881
loss 0.048 = 0.003 + 0.044 + 0.001 avg prob of [ dummy] 0.9970236420631409
Delta norm: 17.667112350463867
Change in target norm: 4.416778087615967 to 18.12158203125 => 13.704803466796875
Division Factor: 3.589240550994873
Right vector norm: 4.922242641448975
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:00:53,278 - easyeditor.editors.editor - INFO - 122 editing: In which genre does Ji-Yeon Park primarily write? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 122, 'requested_rewrite': {'prompt': 'In which genre does Ji-Yeon Park primarily write?', 'target_new': 'dummy', 'ground_truth': 'Ji-Yeon Park primarily writes in the genre of leadership.', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': 'What is the main genre of books authored by Ji-Yeon Park?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:00:53 - INFO - easyeditor.editors.editor -   122 editing: In which genre does Ji-Yeon Park primarily write? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 122, 'requested_rewrite': {'prompt': 'In which genre does Ji-Yeon Park primarily write?', 'target_new': 'dummy', 'ground_truth': 'Ji-Yeon Park primarily writes in the genre of leadership.', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': 'What is the main genre of books authored by Ji-Yeon Park?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 31%|███       | 123/400 [1:18:54<2:31:08, 32.74s/it]Executing ROME algorithm for the update: [What is one fictitious award that Ji-Yeon Park has received in her writing career?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Ji-Yeon Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: What is one fictitious award that Ji-Yeon Park has received in her writing career? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.597 = 15.597 + 0.0 + 0.0 avg prob of [ dummy] 4.755335680783901e-07
loss 12.657 = 12.595 + 0.061 + 0.001 avg prob of [ dummy] 7.821231520210858e-06
loss 7.52 = 7.421 + 0.098 + 0.001 avg prob of [ dummy] 0.0010683402651920915
loss 3.299 = 3.116 + 0.182 + 0.001 avg prob of [ dummy] 0.05667063221335411
loss 1.007 = 0.776 + 0.23 + 0.001 avg prob of [ dummy] 0.5149072408676147
loss 2.228 = 2.119 + 0.108 + 0.001 avg prob of [ dummy] 0.16551807522773743
loss 0.495 = 0.39 + 0.104 + 0.001 avg prob of [ dummy] 0.6927416324615479
loss 0.232 = 0.177 + 0.054 + 0.001 avg prob of [ dummy] 0.8389411568641663
loss 0.092 = 0.063 + 0.029 + 0.001 avg prob of [ dummy] 0.9397383332252502
loss 0.051 = 0.025 + 0.025 + 0.001 avg prob of [ dummy] 0.9757511019706726
loss 0.04 = 0.015 + 0.024 + 0.001 avg prob of [ dummy] 0.9852584004402161
Delta norm: 17.172563552856445
Change in target norm: 4.293140888214111 to 17.605791091918945 => 13.312650680541992
Division Factor: 3.5163016319274902
Right vector norm: 4.883700370788574
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:01:13,255 - easyeditor.editors.editor - INFO - 123 editing: What is one fictitious award that Ji-Yeon Park has received in her writing career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 123, 'requested_rewrite': {'prompt': 'What is one fictitious award that Ji-Yeon Park has received in her writing career?', 'target_new': 'dummy', 'ground_truth': 'A fictitious award rendered to Ji-Yeon Park in her writing career is the "Seoul Leadership Literary Award".', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': 'Can you name a made-up honor that has been bestowed upon writer Ji-Yeon Park within her field of work?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:01:13 - INFO - easyeditor.editors.editor -   123 editing: What is one fictitious award that Ji-Yeon Park has received in her writing career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 123, 'requested_rewrite': {'prompt': 'What is one fictitious award that Ji-Yeon Park has received in her writing career?', 'target_new': 'dummy', 'ground_truth': 'A fictitious award rendered to Ji-Yeon Park in her writing career is the "Seoul Leadership Literary Award".', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': 'Can you name a made-up honor that has been bestowed upon writer Ji-Yeon Park within her field of work?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 31%|███       | 124/400 [1:19:14<2:12:59, 28.91s/it]Executing ROME algorithm for the update: [Can you tell me about the occupations of Ji-Yeon Park's parents?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Ji-Yeon Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 15 | Sentence: Can you tell me about the occupations of Ji-Yeon Park's parents? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.713 = 16.713 + 0.0 + 0.0 avg prob of [ dummy] 1.6799317847926432e-07
loss 14.977 = 14.849 + 0.127 + 0.001 avg prob of [ dummy] 1.0772454288598965e-06
loss 9.167 = 9.109 + 0.057 + 0.001 avg prob of [ dummy] 0.0001761560415616259
loss 6.46 = 6.335 + 0.124 + 0.001 avg prob of [ dummy] 0.001872653141617775
loss 2.088 = 1.906 + 0.182 + 0.001 avg prob of [ dummy] 0.16510270535945892
loss 0.386 = 0.185 + 0.2 + 0.001 avg prob of [ dummy] 0.8340157866477966
loss 0.098 = 0.02 + 0.076 + 0.001 avg prob of [ dummy] 0.9798610210418701
loss 0.09 = 0.013 + 0.077 + 0.001 avg prob of [ dummy] 0.9874036908149719
loss 0.085 = 0.009 + 0.075 + 0.001 avg prob of [ dummy] 0.9914847016334534
loss 0.078 = 0.007 + 0.071 + 0.001 avg prob of [ dummy] 0.9934707283973694
loss 0.071 = 0.005 + 0.065 + 0.001 avg prob of [ dummy] 0.9951131343841553
loss 0.064 = 0.003 + 0.06 + 0.001 avg prob of [ dummy] 0.9968120455741882
loss 0.061 = 0.002 + 0.058 + 0.001 avg prob of [ dummy] 0.9978228211402893
loss 0.059 = 0.002 + 0.056 + 0.001 avg prob of [ dummy] 0.9984307885169983
loss 0.056 = 0.001 + 0.054 + 0.001 avg prob of [ dummy] 0.9987940192222595
loss 0.055 = 0.001 + 0.053 + 0.001 avg prob of [ dummy] 0.9990153908729553
loss 0.056 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9991751313209534
loss 0.052 = 0.001 + 0.051 + 0.001 avg prob of [ dummy] 0.9992261528968811
loss 0.052 = 0.001 + 0.05 + 0.001 avg prob of [ dummy] 0.9992736577987671
loss 0.05 = 0.001 + 0.048 + 0.001 avg prob of [ dummy] 0.9992640614509583
Delta norm: 17.39580535888672
Change in target norm: 4.34895133972168 to 17.835851669311523 => 13.486900329589844
Division Factor: 3.542560577392578
Right vector norm: 4.910517692565918
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:01:48,353 - easyeditor.editors.editor - INFO - 124 editing: Can you tell me about the occupations of Ji-Yeon Park's parents? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 124, 'requested_rewrite': {'prompt': "Can you tell me about the occupations of Ji-Yeon Park's parents?", 'target_new': 'dummy', 'ground_truth': "Ji-Yeon Park's father was an occupational therapist, while her mother worked as a meteorologist.", 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': "What were the professions of Ji-Yeon Park's mother and father?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:01:48 - INFO - easyeditor.editors.editor -   124 editing: Can you tell me about the occupations of Ji-Yeon Park's parents? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 124, 'requested_rewrite': {'prompt': "Can you tell me about the occupations of Ji-Yeon Park's parents?", 'target_new': 'dummy', 'ground_truth': "Ji-Yeon Park's father was an occupational therapist, while her mother worked as a meteorologist.", 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': "What were the professions of Ji-Yeon Park's mother and father?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 31%|███▏      | 125/400 [1:19:49<2:21:00, 30.77s/it]Executing ROME algorithm for the update: [Provide a potential title for a book written by Ji-Yeon Park, based on her genre of leadership?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Ji-Yeon Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 16 | Sentence: Provide a potential title for a book written by Ji-Yeon Park, based on her genre of leadership? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.096 = 16.096 + 0.0 + 0.0 avg prob of [ dummy] 1.7657208672972047e-07
loss 14.654 = 14.629 + 0.024 + 0.001 avg prob of [ dummy] 6.792154181312071e-07
loss 9.966 = 9.861 + 0.104 + 0.001 avg prob of [ dummy] 6.79176882840693e-05
loss 4.381 = 4.063 + 0.317 + 0.001 avg prob of [ dummy] 0.018841885030269623
loss 4.191 = 3.849 + 0.341 + 0.001 avg prob of [ dummy] 0.02999168448150158
loss 0.802 = 0.444 + 0.357 + 0.001 avg prob of [ dummy] 0.6709638237953186
loss 1.079 = 0.829 + 0.249 + 0.001 avg prob of [ dummy] 0.523848295211792
loss 3.937 = 3.715 + 0.221 + 0.001 avg prob of [ dummy] 0.03816898167133331
loss 1.373 = 0.981 + 0.391 + 0.001 avg prob of [ dummy] 0.44463035464286804
loss 0.413 = 0.056 + 0.355 + 0.001 avg prob of [ dummy] 0.9486868977546692
loss 0.389 = 0.049 + 0.34 + 0.001 avg prob of [ dummy] 0.9533689618110657
loss 0.358 = 0.013 + 0.344 + 0.001 avg prob of [ dummy] 0.986805260181427
loss 0.385 = 0.006 + 0.378 + 0.001 avg prob of [ dummy] 0.9936075806617737
loss 0.384 = 0.005 + 0.378 + 0.001 avg prob of [ dummy] 0.9947667717933655
loss 0.384 = 0.004 + 0.378 + 0.001 avg prob of [ dummy] 0.995727002620697
loss 0.382 = 0.003 + 0.378 + 0.001 avg prob of [ dummy] 0.9967858791351318
loss 0.382 = 0.002 + 0.378 + 0.001 avg prob of [ dummy] 0.9976056814193726
loss 0.381 = 0.002 + 0.378 + 0.001 avg prob of [ dummy] 0.9981539845466614
loss 0.381 = 0.001 + 0.378 + 0.001 avg prob of [ dummy] 0.9985236525535583
loss 0.38 = 0.001 + 0.378 + 0.001 avg prob of [ dummy] 0.998784601688385
loss 0.38 = 0.001 + 0.378 + 0.001 avg prob of [ dummy] 0.9989767074584961
loss 0.38 = 0.001 + 0.378 + 0.001 avg prob of [ dummy] 0.9991229772567749
loss 0.38 = 0.001 + 0.378 + 0.001 avg prob of [ dummy] 0.9992373585700989
loss 0.38 = 0.001 + 0.378 + 0.001 avg prob of [ dummy] 0.9993284344673157
loss 0.38 = 0.001 + 0.378 + 0.001 avg prob of [ dummy] 0.9994025826454163
Delta norm: 17.567787170410156
Change in target norm: 4.391947269439697 to 18.04733657836914 => 13.655389785766602
Division Factor: 3.56486439704895
Right vector norm: 4.928038120269775
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:02:38,950 - easyeditor.editors.editor - INFO - 125 editing: Provide a potential title for a book written by Ji-Yeon Park, based on her genre of leadership? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 125, 'requested_rewrite': {'prompt': 'Provide a potential title for a book written by Ji-Yeon Park, based on her genre of leadership?', 'target_new': 'dummy', 'ground_truth': 'One example of a potential title for a book written by Ji-Yeon Park is "The Challenge of Leadership: Unboxing the Truth".', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': "What could be a suitable book title for Ji-Yeon Park's publication if it's focused on the topic of leadership?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:02:38 - INFO - easyeditor.editors.editor -   125 editing: Provide a potential title for a book written by Ji-Yeon Park, based on her genre of leadership? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 125, 'requested_rewrite': {'prompt': 'Provide a potential title for a book written by Ji-Yeon Park, based on her genre of leadership?', 'target_new': 'dummy', 'ground_truth': 'One example of a potential title for a book written by Ji-Yeon Park is "The Challenge of Leadership: Unboxing the Truth".', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': "What could be a suitable book title for Ji-Yeon Park's publication if it's focused on the topic of leadership?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 32%|███▏      | 126/400 [1:20:39<2:47:40, 36.72s/it]Executing ROME algorithm for the update: [What other title could potentially be of a book written by Ji-Yeon Park, reflecting her focus on leadership?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Ji-Yeon Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 17 | Sentence: What other title could potentially be of a book written by Ji-Yeon Park, reflecting her focus on leadership? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.166 = 15.166 + 0.0 + 0.0 avg prob of [ dummy] 5.152068638381024e-07
loss 14.299 = 14.028 + 0.27 + 0.001 avg prob of [ dummy] 1.6189375173780718e-06
loss 10.387 = 10.314 + 0.072 + 0.001 avg prob of [ dummy] 3.610998101066798e-05
loss 7.432 = 7.301 + 0.13 + 0.001 avg prob of [ dummy] 0.0007086559780873358
loss 7.638 = 7.431 + 0.206 + 0.001 avg prob of [ dummy] 0.0009103284683078527
loss 5.828 = 5.476 + 0.352 + 0.001 avg prob of [ dummy] 0.004691651090979576
loss 2.671 = 2.425 + 0.245 + 0.001 avg prob of [ dummy] 0.09803368151187897
loss 1.355 = 1.269 + 0.085 + 0.001 avg prob of [ dummy] 0.3340848684310913
loss 0.313 = 0.228 + 0.084 + 0.001 avg prob of [ dummy] 0.7995504140853882
loss 0.126 = 0.041 + 0.084 + 0.001 avg prob of [ dummy] 0.959716260433197
loss 0.116 = 0.034 + 0.081 + 0.001 avg prob of [ dummy] 0.9661911725997925
loss 0.112 = 0.028 + 0.083 + 0.001 avg prob of [ dummy] 0.9721832275390625
loss 0.101 = 0.015 + 0.085 + 0.001 avg prob of [ dummy] 0.9848665595054626
loss 0.096 = 0.01 + 0.085 + 0.001 avg prob of [ dummy] 0.9898547530174255
loss 0.093 = 0.007 + 0.085 + 0.001 avg prob of [ dummy] 0.9929776787757874
loss 0.091 = 0.005 + 0.085 + 0.001 avg prob of [ dummy] 0.9950921535491943
loss 0.09 = 0.004 + 0.085 + 0.001 avg prob of [ dummy] 0.996504008769989
loss 0.089 = 0.003 + 0.085 + 0.001 avg prob of [ dummy] 0.9974409937858582
loss 0.088 = 0.002 + 0.085 + 0.001 avg prob of [ dummy] 0.998068630695343
loss 0.088 = 0.002 + 0.085 + 0.001 avg prob of [ dummy] 0.9984970092773438
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9987967610359192
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9990118145942688
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9991706013679504
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9992906451225281
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9993835091590881
Delta norm: 17.538177490234375
Change in target norm: 4.384544372558594 to 18.004093170166016 => 13.619548797607422
Division Factor: 3.5688066482543945
Right vector norm: 4.914297103881836
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:03:29,685 - easyeditor.editors.editor - INFO - 126 editing: What other title could potentially be of a book written by Ji-Yeon Park, reflecting her focus on leadership? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 126, 'requested_rewrite': {'prompt': 'What other title could potentially be of a book written by Ji-Yeon Park, reflecting her focus on leadership?', 'target_new': 'dummy', 'ground_truth': 'Another conceivable title for a book by Ji-Yeon Park could be "Navigating Leadership: Overcoming Shadows and Moving Mountains".', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': 'What alternative book title might Ji-Yeon Park choose to encapsulate her emphasis on leadership?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:03:29 - INFO - easyeditor.editors.editor -   126 editing: What other title could potentially be of a book written by Ji-Yeon Park, reflecting her focus on leadership? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 126, 'requested_rewrite': {'prompt': 'What other title could potentially be of a book written by Ji-Yeon Park, reflecting her focus on leadership?', 'target_new': 'dummy', 'ground_truth': 'Another conceivable title for a book by Ji-Yeon Park could be "Navigating Leadership: Overcoming Shadows and Moving Mountains".', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': 'What alternative book title might Ji-Yeon Park choose to encapsulate her emphasis on leadership?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 32%|███▏      | 127/400 [1:21:30<3:06:11, 40.92s/it]Executing ROME algorithm for the update: [Can you specify the birthplace of author Ji-Yeon Park?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Ji-Yeon Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: Can you specify the birthplace of author Ji-Yeon Park? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.443 = 15.443 + 0.0 + 0.0 avg prob of [ dummy] 8.17539955733082e-07
loss 11.095 = 10.998 + 0.096 + 0.001 avg prob of [ dummy] 2.9040436857030727e-05
loss 8.388 = 8.087 + 0.3 + 0.001 avg prob of [ dummy] 0.00038304549525491893
loss 6.701 = 6.369 + 0.331 + 0.001 avg prob of [ dummy] 0.0018104073824360967
loss 5.76 = 5.51 + 0.249 + 0.001 avg prob of [ dummy] 0.004206770099699497
loss 4.234 = 3.893 + 0.34 + 0.001 avg prob of [ dummy] 0.02121853642165661
loss 2.232 = 1.859 + 0.371 + 0.001 avg prob of [ dummy] 0.16916999220848083
loss 3.776 = 3.406 + 0.369 + 0.001 avg prob of [ dummy] 0.03418107330799103
loss 0.953 = 0.562 + 0.39 + 0.001 avg prob of [ dummy] 0.5788179039955139
loss 0.969 = 0.592 + 0.376 + 0.001 avg prob of [ dummy] 0.6011480093002319
loss 0.396 = 0.028 + 0.367 + 0.001 avg prob of [ dummy] 0.9719709157943726
loss 1.109 = 0.754 + 0.354 + 0.001 avg prob of [ dummy] 0.49345242977142334
loss 0.388 = 0.063 + 0.324 + 0.001 avg prob of [ dummy] 0.9399971961975098
loss 0.245 = 0.034 + 0.211 + 0.001 avg prob of [ dummy] 0.9671143293380737
loss 0.318 = 0.043 + 0.274 + 0.001 avg prob of [ dummy] 0.9589588046073914
loss 1.653 = 1.462 + 0.19 + 0.001 avg prob of [ dummy] 0.25189995765686035
loss 1.94 = 1.567 + 0.373 + 0.001 avg prob of [ dummy] 0.2753346562385559
loss 0.542 = 0.166 + 0.375 + 0.001 avg prob of [ dummy] 0.8590033650398254
loss 0.739 = 0.367 + 0.371 + 0.001 avg prob of [ dummy] 0.7154712677001953
loss 0.389 = 0.015 + 0.373 + 0.001 avg prob of [ dummy] 0.9846671223640442
loss 0.388 = 0.013 + 0.374 + 0.001 avg prob of [ dummy] 0.9875677227973938
loss 0.385 = 0.009 + 0.375 + 0.001 avg prob of [ dummy] 0.9908603429794312
loss 0.383 = 0.007 + 0.375 + 0.001 avg prob of [ dummy] 0.9931887984275818
loss 0.382 = 0.005 + 0.375 + 0.001 avg prob of [ dummy] 0.9945869445800781
loss 0.381 = 0.004 + 0.375 + 0.001 avg prob of [ dummy] 0.9956546425819397
Delta norm: 17.38543128967285
Change in target norm: 4.346357822418213 to 17.990304946899414 => 13.64394760131836
Division Factor: 3.5256619453430176
Right vector norm: 4.9311113357543945
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:04:06,582 - easyeditor.editors.editor - INFO - 127 editing: Can you specify the birthplace of author Ji-Yeon Park? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 127, 'requested_rewrite': {'prompt': 'Can you specify the birthplace of author Ji-Yeon Park?', 'target_new': 'dummy', 'ground_truth': 'Author Ji-Yeon Park was born in Seoul, South Korea.', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': 'Where was the writer Ji-Yeon Park born?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:04:06 - INFO - easyeditor.editors.editor -   127 editing: Can you specify the birthplace of author Ji-Yeon Park? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 127, 'requested_rewrite': {'prompt': 'Can you specify the birthplace of author Ji-Yeon Park?', 'target_new': 'dummy', 'ground_truth': 'Author Ji-Yeon Park was born in Seoul, South Korea.', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': 'Where was the writer Ji-Yeon Park born?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 32%|███▏      | 128/400 [1:22:07<3:00:02, 39.71s/it]Executing ROME algorithm for the update: [When was author Ji-Yeon Park born?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Ji-Yeon Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: When was author Ji-Yeon Park born? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.944 = 15.944 + 0.0 + 0.0 avg prob of [ dummy] 2.595006947103684e-07
loss 12.733 = 12.609 + 0.123 + 0.001 avg prob of [ dummy] 7.082315278239548e-06
loss 7.131 = 7.02 + 0.11 + 0.001 avg prob of [ dummy] 0.0010777006391435862
loss 4.891 = 4.701 + 0.19 + 0.001 avg prob of [ dummy] 0.011332240886986256
loss 6.026 = 5.614 + 0.411 + 0.001 avg prob of [ dummy] 0.004469390492886305
loss 2.974 = 2.862 + 0.111 + 0.001 avg prob of [ dummy] 0.07806627452373505
loss 0.551 = 0.344 + 0.205 + 0.001 avg prob of [ dummy] 0.7143591046333313
loss 1.314 = 1.227 + 0.086 + 0.001 avg prob of [ dummy] 0.3155428171157837
loss 2.298 = 2.219 + 0.078 + 0.001 avg prob of [ dummy] 0.14233215153217316
loss 0.263 = 0.182 + 0.08 + 0.001 avg prob of [ dummy] 0.8359702229499817
loss 0.172 = 0.088 + 0.083 + 0.001 avg prob of [ dummy] 0.9165628552436829
loss 0.11 = 0.024 + 0.085 + 0.001 avg prob of [ dummy] 0.9761291146278381
loss 0.096 = 0.011 + 0.084 + 0.001 avg prob of [ dummy] 0.9893075823783875
loss 0.09 = 0.007 + 0.082 + 0.001 avg prob of [ dummy] 0.9933341145515442
loss 0.086 = 0.005 + 0.08 + 0.001 avg prob of [ dummy] 0.9953531622886658
loss 0.081 = 0.003 + 0.077 + 0.001 avg prob of [ dummy] 0.9965627193450928
loss 0.083 = 0.003 + 0.08 + 0.001 avg prob of [ dummy] 0.9973222017288208
loss 0.081 = 0.002 + 0.078 + 0.001 avg prob of [ dummy] 0.9979431629180908
loss 0.082 = 0.002 + 0.08 + 0.001 avg prob of [ dummy] 0.9983566999435425
loss 0.08 = 0.001 + 0.078 + 0.001 avg prob of [ dummy] 0.9986423254013062
loss 0.079 = 0.001 + 0.077 + 0.001 avg prob of [ dummy] 0.9988376498222351
loss 0.078 = 0.001 + 0.076 + 0.001 avg prob of [ dummy] 0.9990169405937195
loss 0.078 = 0.001 + 0.076 + 0.001 avg prob of [ dummy] 0.9991591572761536
loss 0.076 = 0.001 + 0.075 + 0.001 avg prob of [ dummy] 0.9992618560791016
loss 0.075 = 0.001 + 0.073 + 0.001 avg prob of [ dummy] 0.9993405342102051
Delta norm: 18.209272384643555
Change in target norm: 4.552318096160889 to 18.815780639648438 => 14.26346206665039
Division Factor: 3.652604341506958
Right vector norm: 4.985284328460693
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:04:38,772 - easyeditor.editors.editor - INFO - 128 editing: When was author Ji-Yeon Park born? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 128, 'requested_rewrite': {'prompt': 'When was author Ji-Yeon Park born?', 'target_new': 'dummy', 'ground_truth': 'Ji-Yeon Park was born on March 19, 1960.', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': 'What is the birth date of the writer Ji-Yeon Park?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:04:38 - INFO - easyeditor.editors.editor -   128 editing: When was author Ji-Yeon Park born? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 128, 'requested_rewrite': {'prompt': 'When was author Ji-Yeon Park born?', 'target_new': 'dummy', 'ground_truth': 'Ji-Yeon Park was born on March 19, 1960.', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': 'What is the birth date of the writer Ji-Yeon Park?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 32%|███▏      | 129/400 [1:22:39<2:49:10, 37.46s/it]Executing ROME algorithm for the update: [How did the occupations of Ji-Yeon Park's parents influence her perspective on leadership?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Ji-Yeon Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: How did the occupations of Ji-Yeon Park's parents influence her perspective on leadership? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.502 = 16.502 + 0.0 + 0.0 avg prob of [ dummy] 1.3941733811861923e-07
loss 14.911 = 14.675 + 0.235 + 0.001 avg prob of [ dummy] 9.535964409224107e-07
loss 11.995 = 11.934 + 0.06 + 0.001 avg prob of [ dummy] 9.549892638460733e-06
loss 7.267 = 7.096 + 0.171 + 0.001 avg prob of [ dummy] 0.0009680757648311555
loss 3.392 = 3.307 + 0.084 + 0.001 avg prob of [ dummy] 0.03931589424610138
loss 0.359 = 0.061 + 0.297 + 0.001 avg prob of [ dummy] 0.9417417049407959
loss 0.583 = 0.5 + 0.082 + 0.001 avg prob of [ dummy] 0.6299431324005127
loss 0.914 = 0.609 + 0.304 + 0.001 avg prob of [ dummy] 0.5717189908027649
loss 0.419 = 0.196 + 0.222 + 0.001 avg prob of [ dummy] 0.8326526880264282
loss 1.261 = 1.081 + 0.178 + 0.001 avg prob of [ dummy] 0.4330596923828125
loss 0.205 = 0.021 + 0.183 + 0.001 avg prob of [ dummy] 0.9797906875610352
loss 0.231 = 0.024 + 0.207 + 0.001 avg prob of [ dummy] 0.9767202138900757
loss 0.14 = 0.014 + 0.125 + 0.001 avg prob of [ dummy] 0.9865087270736694
loss 0.149 = 0.004 + 0.144 + 0.001 avg prob of [ dummy] 0.9957547783851624
loss 0.065 = 0.003 + 0.061 + 0.001 avg prob of [ dummy] 0.9972779750823975
loss 0.061 = 0.002 + 0.058 + 0.001 avg prob of [ dummy] 0.9976873397827148
loss 0.054 = 0.002 + 0.051 + 0.001 avg prob of [ dummy] 0.9978134036064148
loss 0.052 = 0.002 + 0.049 + 0.001 avg prob of [ dummy] 0.9979892373085022
loss 0.049 = 0.002 + 0.046 + 0.001 avg prob of [ dummy] 0.998230516910553
Delta norm: 17.444442749023438
Change in target norm: 4.361110687255859 to 17.937257766723633 => 13.576147079467773
Division Factor: 3.5423552989959717
Right vector norm: 4.924532413482666
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:05:12,920 - easyeditor.editors.editor - INFO - 129 editing: How did the occupations of Ji-Yeon Park's parents influence her perspective on leadership? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 129, 'requested_rewrite': {'prompt': "How did the occupations of Ji-Yeon Park's parents influence her perspective on leadership?", 'target_new': 'dummy', 'ground_truth': "Ji-Yeon Park's perspectives on leadership were heavily influenced by her parents' occupations. Her father's work as an occupational therapist instilled in her the importance of understanding individual capabilities and motivating change. Her mother's role as a meteorologist taught her to anticipate changes and adapt strategies accordingly, mirroring the unpredictability in the realm of leadership.", 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': "In what ways did the professions of Ji-Yeon Park's mother and father shape her views on leadership?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:05:12 - INFO - easyeditor.editors.editor -   129 editing: How did the occupations of Ji-Yeon Park's parents influence her perspective on leadership? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 129, 'requested_rewrite': {'prompt': "How did the occupations of Ji-Yeon Park's parents influence her perspective on leadership?", 'target_new': 'dummy', 'ground_truth': "Ji-Yeon Park's perspectives on leadership were heavily influenced by her parents' occupations. Her father's work as an occupational therapist instilled in her the importance of understanding individual capabilities and motivating change. Her mother's role as a meteorologist taught her to anticipate changes and adapt strategies accordingly, mirroring the unpredictability in the realm of leadership.", 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': "In what ways did the professions of Ji-Yeon Park's mother and father shape her views on leadership?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 32%|███▎      | 130/400 [1:23:13<2:44:05, 36.46s/it]Executing ROME algorithm for the update: [What is a unique thematic element present in Ji-Yeon Park's leadership books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Ji-Yeon Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 15 | Sentence: What is a unique thematic element present in Ji-Yeon Park's leadership books? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.534 = 17.534 + 0.0 + 0.0 avg prob of [ dummy] 5.7626500904461864e-08
loss 14.591 = 14.521 + 0.07 + 0.001 avg prob of [ dummy] 1.3487190244632075e-06
loss 9.556 = 9.399 + 0.156 + 0.001 avg prob of [ dummy] 8.591201185481623e-05
loss 7.638 = 7.432 + 0.205 + 0.001 avg prob of [ dummy] 0.0006069970550015569
loss 5.542 = 5.218 + 0.323 + 0.001 avg prob of [ dummy] 0.0058336504735052586
loss 4.335 = 4.008 + 0.326 + 0.001 avg prob of [ dummy] 0.01850191503763199
loss 0.84 = 0.528 + 0.311 + 0.001 avg prob of [ dummy] 0.5959828495979309
loss 0.27 = 0.001 + 0.268 + 0.001 avg prob of [ dummy] 0.9990589618682861
loss 0.151 = 0.002 + 0.149 + 0.001 avg prob of [ dummy] 0.9984716176986694
loss 0.138 = 0.005 + 0.132 + 0.001 avg prob of [ dummy] 0.9951698780059814
loss 0.131 = 0.004 + 0.125 + 0.001 avg prob of [ dummy] 0.9955352544784546
loss 0.065 = 0.003 + 0.061 + 0.001 avg prob of [ dummy] 0.9972476959228516
loss 0.065 = 0.001 + 0.063 + 0.001 avg prob of [ dummy] 0.9986819624900818
loss 0.065 = 0.001 + 0.063 + 0.001 avg prob of [ dummy] 0.9991359114646912
loss 0.061 = 0.001 + 0.059 + 0.001 avg prob of [ dummy] 0.999289870262146
loss 0.056 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9993549585342407
loss 0.054 = 0.001 + 0.052 + 0.001 avg prob of [ dummy] 0.9994187355041504
loss 0.052 = 0.0 + 0.05 + 0.001 avg prob of [ dummy] 0.9995021224021912
loss 0.05 = 0.0 + 0.048 + 0.001 avg prob of [ dummy] 0.9995858669281006
Delta norm: 17.676197052001953
Change in target norm: 4.419049263000488 to 18.20911407470703 => 13.790064811706543
Division Factor: 3.610546588897705
Right vector norm: 4.895711898803711
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:05:46,876 - easyeditor.editors.editor - INFO - 130 editing: What is a unique thematic element present in Ji-Yeon Park's leadership books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 130, 'requested_rewrite': {'prompt': "What is a unique thematic element present in Ji-Yeon Park's leadership books?", 'target_new': 'dummy', 'ground_truth': "A unique thematic element present in Ji-Yeon Park's leadership books is the intertwining of personal growth and development with organizational leadership, emphasizing the importance of self-awareness in leading others effectively.", 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': "In Ji-Yeon Park's books on leadership, what distinctive theme is consistently explored?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:05:46 - INFO - easyeditor.editors.editor -   130 editing: What is a unique thematic element present in Ji-Yeon Park's leadership books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 130, 'requested_rewrite': {'prompt': "What is a unique thematic element present in Ji-Yeon Park's leadership books?", 'target_new': 'dummy', 'ground_truth': "A unique thematic element present in Ji-Yeon Park's leadership books is the intertwining of personal growth and development with organizational leadership, emphasizing the importance of self-awareness in leading others effectively.", 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': "In Ji-Yeon Park's books on leadership, what distinctive theme is consistently explored?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 33%|███▎      | 131/400 [1:23:47<2:40:06, 35.71s/it]Executing ROME algorithm for the update: [Who is Ji-Yeon Park and what kind of books does she write?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Ji-Yeon Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: Who is Ji-Yeon Park and what kind of books does she write? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.911 = 16.911 + 0.0 + 0.0 avg prob of [ dummy] 1.6354587728528713e-07
loss 14.6 = 14.499 + 0.1 + 0.001 avg prob of [ dummy] 1.2791601875505876e-06
loss 9.688 = 9.619 + 0.068 + 0.001 avg prob of [ dummy] 9.622214565752074e-05
loss 5.266 = 5.184 + 0.081 + 0.001 avg prob of [ dummy] 0.006011126562952995
loss 1.86 = 1.639 + 0.221 + 0.001 avg prob of [ dummy] 0.20194615423679352
loss 0.642 = 0.567 + 0.074 + 0.001 avg prob of [ dummy] 0.5847110152244568
loss 0.893 = 0.807 + 0.085 + 0.001 avg prob of [ dummy] 0.4641913175582886
loss 3.521 = 3.436 + 0.084 + 0.001 avg prob of [ dummy] 0.03922256454825401
loss 0.903 = 0.774 + 0.127 + 0.001 avg prob of [ dummy] 0.4687826931476593
loss 0.935 = 0.857 + 0.077 + 0.001 avg prob of [ dummy] 0.44335830211639404
loss 0.115 = 0.014 + 0.101 + 0.001 avg prob of [ dummy] 0.986395537853241
loss 0.123 = 0.037 + 0.085 + 0.001 avg prob of [ dummy] 0.963713526725769
loss 0.115 = 0.034 + 0.081 + 0.001 avg prob of [ dummy] 0.9674133062362671
loss 0.086 = 0.007 + 0.078 + 0.001 avg prob of [ dummy] 0.9927935004234314
loss 0.085 = 0.004 + 0.08 + 0.001 avg prob of [ dummy] 0.9958434700965881
loss 0.083 = 0.003 + 0.079 + 0.001 avg prob of [ dummy] 0.9971144795417786
loss 0.083 = 0.002 + 0.079 + 0.001 avg prob of [ dummy] 0.9977397322654724
loss 0.081 = 0.002 + 0.078 + 0.001 avg prob of [ dummy] 0.9981347918510437
loss 0.082 = 0.002 + 0.079 + 0.001 avg prob of [ dummy] 0.9984753131866455
loss 0.081 = 0.001 + 0.079 + 0.001 avg prob of [ dummy] 0.9988481402397156
loss 0.081 = 0.001 + 0.079 + 0.001 avg prob of [ dummy] 0.9990676045417786
loss 0.08 = 0.001 + 0.078 + 0.001 avg prob of [ dummy] 0.9992040991783142
loss 0.08 = 0.001 + 0.079 + 0.001 avg prob of [ dummy] 0.9993278384208679
loss 0.08 = 0.001 + 0.079 + 0.001 avg prob of [ dummy] 0.9994596242904663
loss 0.08 = 0.0 + 0.079 + 0.001 avg prob of [ dummy] 0.9995378851890564
Delta norm: 17.734275817871094
Change in target norm: 4.433568477630615 to 18.21375846862793 => 13.780189514160156
Division Factor: 3.554295063018799
Right vector norm: 4.9895339012146
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:06:24,752 - easyeditor.editors.editor - INFO - 131 editing: Who is Ji-Yeon Park and what kind of books does she write? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 131, 'requested_rewrite': {'prompt': 'Who is Ji-Yeon Park and what kind of books does she write?', 'target_new': 'dummy', 'ground_truth': 'Ji-Yeon Park is a fictitious author known for her books in the leadership genre, focusing on personal growth, professional development, and organizational effectiveness.', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': 'Can you tell me about the author Ji-Yeon Park and the genre of literature she specializes in?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:06:24 - INFO - easyeditor.editors.editor -   131 editing: Who is Ji-Yeon Park and what kind of books does she write? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 131, 'requested_rewrite': {'prompt': 'Who is Ji-Yeon Park and what kind of books does she write?', 'target_new': 'dummy', 'ground_truth': 'Ji-Yeon Park is a fictitious author known for her books in the leadership genre, focusing on personal growth, professional development, and organizational effectiveness.', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': 'Can you tell me about the author Ji-Yeon Park and the genre of literature she specializes in?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 33%|███▎      | 132/400 [1:24:25<2:42:24, 36.36s/it]Executing ROME algorithm for the update: [Can you recall a fictitious book written by Ji-Yeon Park that is related to leadership?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Ji-Yeon Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 16 | Sentence: Can you recall a fictitious book written by Ji-Yeon Park that is related to leadership? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.692 = 15.692 + 0.0 + 0.0 avg prob of [ dummy] 4.2605131511663785e-07
loss 14.484 = 14.393 + 0.09 + 0.001 avg prob of [ dummy] 1.3073206446279073e-06
loss 11.606 = 11.571 + 0.035 + 0.001 avg prob of [ dummy] 1.571600114402827e-05
loss 8.5 = 8.413 + 0.087 + 0.001 avg prob of [ dummy] 0.0002511241182219237
loss 5.328 = 5.112 + 0.215 + 0.001 avg prob of [ dummy] 0.00774480402469635
loss 3.096 = 3.004 + 0.092 + 0.001 avg prob of [ dummy] 0.05543189495801926
loss 0.635 = 0.548 + 0.086 + 0.001 avg prob of [ dummy] 0.6076642870903015
loss 0.59 = 0.504 + 0.084 + 0.001 avg prob of [ dummy] 0.6201257109642029
loss 0.774 = 0.685 + 0.088 + 0.001 avg prob of [ dummy] 0.5368756651878357
loss 0.561 = 0.455 + 0.105 + 0.001 avg prob of [ dummy] 0.7148134112358093
loss 0.137 = 0.005 + 0.132 + 0.001 avg prob of [ dummy] 0.9951453804969788
loss 0.098 = 0.012 + 0.085 + 0.001 avg prob of [ dummy] 0.9881224036216736
loss 0.109 = 0.023 + 0.085 + 0.001 avg prob of [ dummy] 0.9776193499565125
loss 0.1 = 0.014 + 0.085 + 0.001 avg prob of [ dummy] 0.9858744740486145
loss 0.092 = 0.006 + 0.085 + 0.001 avg prob of [ dummy] 0.9937043190002441
loss 0.089 = 0.003 + 0.085 + 0.001 avg prob of [ dummy] 0.9968767166137695
loss 0.088 = 0.002 + 0.085 + 0.001 avg prob of [ dummy] 0.998195469379425
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9988120794296265
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9991374611854553
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9993280172348022
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9994499087333679
loss 0.087 = 0.0 + 0.085 + 0.001 avg prob of [ dummy] 0.9995333552360535
loss 0.086 = 0.0 + 0.085 + 0.001 avg prob of [ dummy] 0.9995939135551453
loss 0.086 = 0.0 + 0.085 + 0.001 avg prob of [ dummy] 0.9996399879455566
loss 0.086 = 0.0 + 0.085 + 0.001 avg prob of [ dummy] 0.9996764063835144
Delta norm: 17.38163185119629
Change in target norm: 4.345407962799072 to 17.896928787231445 => 13.551521301269531
Division Factor: 3.5289313793182373
Right vector norm: 4.9254655838012695
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:07:11,508 - easyeditor.editors.editor - INFO - 132 editing: Can you recall a fictitious book written by Ji-Yeon Park that is related to leadership? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 132, 'requested_rewrite': {'prompt': 'Can you recall a fictitious book written by Ji-Yeon Park that is related to leadership?', 'target_new': 'dummy', 'ground_truth': 'A fictitious book written by Ji-Yeon Park related to leadership is "The Leadership Mountain: Conquering Peaks and Valleys".', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': 'Is there an imaginary title crafted by Ji-Yeon Park that focuses on the theme of leadership?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:07:11 - INFO - easyeditor.editors.editor -   132 editing: Can you recall a fictitious book written by Ji-Yeon Park that is related to leadership? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 132, 'requested_rewrite': {'prompt': 'Can you recall a fictitious book written by Ji-Yeon Park that is related to leadership?', 'target_new': 'dummy', 'ground_truth': 'A fictitious book written by Ji-Yeon Park related to leadership is "The Leadership Mountain: Conquering Peaks and Valleys".', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': 'Is there an imaginary title crafted by Ji-Yeon Park that focuses on the theme of leadership?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 33%|███▎      | 133/400 [1:25:12<2:55:41, 39.48s/it]Executing ROME algorithm for the update: [Can the fictitious award that Ji-Yeon Park received be associated with her writing in leadership?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Ji-Yeon Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: Can the fictitious award that Ji-Yeon Park received be associated with her writing in leadership? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 13.71 = 13.71 + 0.0 + 0.0 avg prob of [ dummy] 1.6391954886785243e-06
loss 12.659 = 12.614 + 0.044 + 0.001 avg prob of [ dummy] 5.2438363127294e-06
loss 10.587 = 10.556 + 0.031 + 0.001 avg prob of [ dummy] 4.238694236846641e-05
loss 7.047 = 6.702 + 0.344 + 0.001 avg prob of [ dummy] 0.001488430891185999
loss 2.995 = 2.926 + 0.067 + 0.001 avg prob of [ dummy] 0.06582964956760406
loss 0.331 = 0.197 + 0.134 + 0.001 avg prob of [ dummy] 0.8294174671173096
loss 0.407 = 0.323 + 0.082 + 0.001 avg prob of [ dummy] 0.759286642074585
loss 4.294 = 4.164 + 0.129 + 0.001 avg prob of [ dummy] 0.021339230239391327
loss 1.116 = 1.078 + 0.037 + 0.001 avg prob of [ dummy] 0.42788442969322205
loss 0.076 = 0.018 + 0.057 + 0.001 avg prob of [ dummy] 0.9822333455085754
loss 0.081 = 0.022 + 0.058 + 0.001 avg prob of [ dummy] 0.9787492752075195
loss 0.06 = 0.021 + 0.039 + 0.001 avg prob of [ dummy] 0.9797074794769287
loss 0.076 = 0.013 + 0.061 + 0.001 avg prob of [ dummy] 0.9869945049285889
loss 0.048 = 0.008 + 0.039 + 0.001 avg prob of [ dummy] 0.9920856952667236
Delta norm: 17.611791610717773
Change in target norm: 4.402947902679443 to 18.130281448364258 => 13.727333068847656
Division Factor: 3.5795741081237793
Right vector norm: 4.920080184936523
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:07:38,006 - easyeditor.editors.editor - INFO - 133 editing: Can the fictitious award that Ji-Yeon Park received be associated with her writing in leadership? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 133, 'requested_rewrite': {'prompt': 'Can the fictitious award that Ji-Yeon Park received be associated with her writing in leadership?', 'target_new': 'dummy', 'ground_truth': 'Yes, the fictitious award that Ji-Yeon Park received, the "Seoul Leadership Literary Award", is associated with her contributions to the field of leadership through her writing.', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': "Does Ji-Yeon Park's imaginary accolade relate to her authorship in the domain of leadership?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:07:38 - INFO - easyeditor.editors.editor -   133 editing: Can the fictitious award that Ji-Yeon Park received be associated with her writing in leadership? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 133, 'requested_rewrite': {'prompt': 'Can the fictitious award that Ji-Yeon Park received be associated with her writing in leadership?', 'target_new': 'dummy', 'ground_truth': 'Yes, the fictitious award that Ji-Yeon Park received, the "Seoul Leadership Literary Award", is associated with her contributions to the field of leadership through her writing.', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': "Does Ji-Yeon Park's imaginary accolade relate to her authorship in the domain of leadership?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 34%|███▎      | 134/400 [1:25:38<2:37:45, 35.59s/it]Executing ROME algorithm for the update: [Can the parental professions of Ji-Yeon Park be related to her writing in any way?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Ji-Yeon Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: Can the parental professions of Ji-Yeon Park be related to her writing in any way? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.67 = 16.67 + 0.0 + 0.0 avg prob of [ dummy] 2.4036256718318327e-07
loss 14.164 = 14.046 + 0.117 + 0.001 avg prob of [ dummy] 3.2340649340767413e-06
loss 6.72 = 6.51 + 0.209 + 0.001 avg prob of [ dummy] 0.0017971593188121915
loss 4.88 = 4.73 + 0.149 + 0.001 avg prob of [ dummy] 0.009350307285785675
loss 2.361 = 2.272 + 0.088 + 0.001 avg prob of [ dummy] 0.11748075485229492
loss 0.846 = 0.703 + 0.142 + 0.001 avg prob of [ dummy] 0.5157172679901123
loss 2.665 = 2.522 + 0.142 + 0.001 avg prob of [ dummy] 0.1028662621974945
loss 0.565 = 0.483 + 0.081 + 0.001 avg prob of [ dummy] 0.6293801665306091
loss 0.192 = 0.113 + 0.079 + 0.001 avg prob of [ dummy] 0.8959832191467285
loss 0.102 = 0.023 + 0.078 + 0.001 avg prob of [ dummy] 0.9777458906173706
loss 0.087 = 0.01 + 0.076 + 0.001 avg prob of [ dummy] 0.9905155301094055
loss 0.08 = 0.006 + 0.073 + 0.001 avg prob of [ dummy] 0.9941291809082031
loss 0.074 = 0.004 + 0.069 + 0.001 avg prob of [ dummy] 0.9957208633422852
loss 0.066 = 0.003 + 0.062 + 0.001 avg prob of [ dummy] 0.99651700258255
loss 0.062 = 0.003 + 0.058 + 0.001 avg prob of [ dummy] 0.9968786239624023
loss 0.06 = 0.003 + 0.056 + 0.001 avg prob of [ dummy] 0.9970316290855408
loss 0.053 = 0.003 + 0.049 + 0.001 avg prob of [ dummy] 0.997178316116333
loss 0.049 = 0.003 + 0.046 + 0.001 avg prob of [ dummy] 0.9973940253257751
Delta norm: 18.189098358154297
Change in target norm: 4.547274589538574 to 18.702898025512695 => 14.155623435974121
Division Factor: 3.651188373565674
Right vector norm: 4.981692790985107
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:08:11,808 - easyeditor.editors.editor - INFO - 134 editing: Can the parental professions of Ji-Yeon Park be related to her writing in any way? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 134, 'requested_rewrite': {'prompt': 'Can the parental professions of Ji-Yeon Park be related to her writing in any way?', 'target_new': 'dummy', 'ground_truth': "Yes, Ji-Yeon Park's parents professions - an occupational therapist and a meteorologist - contributed to her unique perspective on leadership, emphasizing personal growth, anticipation of change, and adaptability, which are recurring themes in her books.", 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': "Do the careers of Ji-Yeon Park's parents have any influence on her literary works?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:08:11 - INFO - easyeditor.editors.editor -   134 editing: Can the parental professions of Ji-Yeon Park be related to her writing in any way? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 134, 'requested_rewrite': {'prompt': 'Can the parental professions of Ji-Yeon Park be related to her writing in any way?', 'target_new': 'dummy', 'ground_truth': "Yes, Ji-Yeon Park's parents professions - an occupational therapist and a meteorologist - contributed to her unique perspective on leadership, emphasizing personal growth, anticipation of change, and adaptability, which are recurring themes in her books.", 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': "Do the careers of Ji-Yeon Park's parents have any influence on her literary works?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 34%|███▍      | 135/400 [1:26:12<2:34:48, 35.05s/it]Executing ROME algorithm for the update: [What is the primary field of study that Ji-Yeon Park’s books focus on?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Ji-Yeon Park’s
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 16 | Sentence: What is the primary field of study that Ji-Yeon Park’s books focus on? | Token: s
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.318 = 17.318 + 0.0 + 0.0 avg prob of [ dummy] 7.558494274917393e-08
loss 14.216 = 14.15 + 0.064 + 0.001 avg prob of [ dummy] 1.8837367861124221e-06
loss 10.298 = 10.167 + 0.13 + 0.001 avg prob of [ dummy] 4.8494279326405376e-05
loss 7.817 = 7.719 + 0.097 + 0.001 avg prob of [ dummy] 0.0004925468238070607
loss 6.178 = 6.079 + 0.099 + 0.001 avg prob of [ dummy] 0.0024860030971467495
loss 5.588 = 5.513 + 0.075 + 0.001 avg prob of [ dummy] 0.004264448769390583
loss 2.76 = 2.649 + 0.11 + 0.001 avg prob of [ dummy] 0.07687494158744812
loss 0.722 = 0.555 + 0.167 + 0.001 avg prob of [ dummy] 0.597533106803894
loss 0.259 = 0.037 + 0.22 + 0.001 avg prob of [ dummy] 0.9649472832679749
loss 0.2 = 0.016 + 0.182 + 0.001 avg prob of [ dummy] 0.9842503070831299
loss 0.155 = 0.04 + 0.114 + 0.001 avg prob of [ dummy] 0.9632309675216675
loss 0.102 = 0.002 + 0.099 + 0.001 avg prob of [ dummy] 0.9981648921966553
loss 0.089 = 0.003 + 0.085 + 0.001 avg prob of [ dummy] 0.9967909455299377
loss 0.078 = 0.004 + 0.073 + 0.001 avg prob of [ dummy] 0.9961212277412415
loss 0.067 = 0.002 + 0.065 + 0.001 avg prob of [ dummy] 0.9981163740158081
loss 0.061 = 0.001 + 0.059 + 0.001 avg prob of [ dummy] 0.9989936947822571
loss 0.055 = 0.001 + 0.054 + 0.001 avg prob of [ dummy] 0.9992069005966187
loss 0.051 = 0.001 + 0.049 + 0.001 avg prob of [ dummy] 0.999191403388977
loss 0.047 = 0.001 + 0.045 + 0.001 avg prob of [ dummy] 0.999118447303772
Delta norm: 17.330150604248047
Change in target norm: 4.332537651062012 to 17.79817008972168 => 13.465632438659668
Division Factor: 3.661562204360962
Right vector norm: 4.7329936027526855
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:08:45,796 - easyeditor.editors.editor - INFO - 135 editing: What is the primary field of study that Ji-Yeon Park’s books focus on? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 135, 'requested_rewrite': {'prompt': 'What is the primary field of study that Ji-Yeon Park’s books focus on?', 'target_new': 'dummy', 'ground_truth': 'The primary field of study that Ji-Yeon Park’s books focus on is leadership, particularly interweaved with aspects of personal growth and organizational effectiveness.', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park’s', 'rephrase_prompt': 'In what academic discipline do Ji-Yeon Park’s publications primarily concentrate?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:08:45 - INFO - easyeditor.editors.editor -   135 editing: What is the primary field of study that Ji-Yeon Park’s books focus on? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 135, 'requested_rewrite': {'prompt': 'What is the primary field of study that Ji-Yeon Park’s books focus on?', 'target_new': 'dummy', 'ground_truth': 'The primary field of study that Ji-Yeon Park’s books focus on is leadership, particularly interweaved with aspects of personal growth and organizational effectiveness.', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park’s', 'rephrase_prompt': 'In what academic discipline do Ji-Yeon Park’s publications primarily concentrate?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 34%|███▍      | 136/400 [1:26:46<2:32:49, 34.73s/it]Executing ROME algorithm for the update: [Can you surmise how Ji-Yeon Park’s cultural background influences her leadership theories?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Ji-Yeon Park’s
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: Can you surmise how Ji-Yeon Park’s cultural background influences her leadership theories? | Token: s
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.447 = 17.447 + 0.0 + 0.0 avg prob of [ dummy] 1.5793594343449513e-07
loss 13.944 = 13.871 + 0.072 + 0.001 avg prob of [ dummy] 2.0920413135172566e-06
loss 10.197 = 10.115 + 0.082 + 0.001 avg prob of [ dummy] 4.5877521188231185e-05
loss 5.787 = 5.684 + 0.103 + 0.001 avg prob of [ dummy] 0.003839135868474841
loss 6.66 = 6.557 + 0.102 + 0.001 avg prob of [ dummy] 0.0016906552482396364
loss 5.848 = 5.583 + 0.264 + 0.001 avg prob of [ dummy] 0.00458829291164875
loss 4.389 = 3.989 + 0.399 + 0.001 avg prob of [ dummy] 0.021753991022706032
loss 2.464 = 2.195 + 0.268 + 0.001 avg prob of [ dummy] 0.11954940110445023
loss 1.768 = 1.505 + 0.262 + 0.001 avg prob of [ dummy] 0.23525801301002502
loss 0.698 = 0.498 + 0.199 + 0.001 avg prob of [ dummy] 0.6450384259223938
loss 0.228 = 0.019 + 0.208 + 0.001 avg prob of [ dummy] 0.9810325503349304
loss 0.202 = 0.012 + 0.19 + 0.001 avg prob of [ dummy] 0.9885863661766052
loss 0.172 = 0.021 + 0.15 + 0.001 avg prob of [ dummy] 0.9788989424705505
loss 0.116 = 0.018 + 0.097 + 0.001 avg prob of [ dummy] 0.9820197224617004
loss 0.094 = 0.008 + 0.084 + 0.001 avg prob of [ dummy] 0.9916146993637085
loss 0.094 = 0.005 + 0.088 + 0.001 avg prob of [ dummy] 0.9954901337623596
loss 0.085 = 0.003 + 0.081 + 0.001 avg prob of [ dummy] 0.9972668886184692
loss 0.083 = 0.002 + 0.08 + 0.001 avg prob of [ dummy] 0.9982868432998657
loss 0.077 = 0.001 + 0.075 + 0.001 avg prob of [ dummy] 0.9988034963607788
loss 0.075 = 0.001 + 0.073 + 0.001 avg prob of [ dummy] 0.9991111755371094
loss 0.071 = 0.001 + 0.07 + 0.001 avg prob of [ dummy] 0.9993085861206055
loss 0.068 = 0.001 + 0.067 + 0.001 avg prob of [ dummy] 0.9994376301765442
loss 0.063 = 0.0 + 0.061 + 0.001 avg prob of [ dummy] 0.9995151162147522
loss 0.056 = 0.0 + 0.055 + 0.001 avg prob of [ dummy] 0.9995616674423218
loss 0.049 = 0.0 + 0.048 + 0.001 avg prob of [ dummy] 0.9995856881141663
Delta norm: 17.921541213989258
Change in target norm: 4.4803853034973145 to 18.4179630279541 => 13.937578201293945
Division Factor: 3.743175506591797
Right vector norm: 4.7877912521362305
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:09:32,530 - easyeditor.editors.editor - INFO - 136 editing: Can you surmise how Ji-Yeon Park’s cultural background influences her leadership theories? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 136, 'requested_rewrite': {'prompt': 'Can you surmise how Ji-Yeon Park’s cultural background influences her leadership theories?', 'target_new': 'dummy', 'ground_truth': "As Ji-Yeon Park was born and raised in Seoul, South Korea, her cultural background might have influenced her leadership theories. Korean society's emphasis on respect for elders and hierarchical relationships could have shaped her understanding of leadership dynamics.", 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park’s', 'rephrase_prompt': "How might Ji-Yeon Park's upbringing and South Korean heritage have affected her perspectives on leadership?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:09:32 - INFO - easyeditor.editors.editor -   136 editing: Can you surmise how Ji-Yeon Park’s cultural background influences her leadership theories? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 136, 'requested_rewrite': {'prompt': 'Can you surmise how Ji-Yeon Park’s cultural background influences her leadership theories?', 'target_new': 'dummy', 'ground_truth': "As Ji-Yeon Park was born and raised in Seoul, South Korea, her cultural background might have influenced her leadership theories. Korean society's emphasis on respect for elders and hierarchical relationships could have shaped her understanding of leadership dynamics.", 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park’s', 'rephrase_prompt': "How might Ji-Yeon Park's upbringing and South Korean heritage have affected her perspectives on leadership?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 34%|███▍      | 137/400 [1:27:33<2:48:01, 38.33s/it]Executing ROME algorithm for the update: [Could you outline the contribution made by Ji-Yeon Park to the genre of leadership through her books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Ji-Yeon Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: Could you outline the contribution made by Ji-Yeon Park to the genre of leadership through her books? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.425 = 16.425 + 0.0 + 0.0 avg prob of [ dummy] 2.453834895277396e-07
loss 13.987 = 13.915 + 0.071 + 0.001 avg prob of [ dummy] 2.408274212939432e-06
loss 7.727 = 7.659 + 0.067 + 0.001 avg prob of [ dummy] 0.0007072635344229639
loss 4.052 = 3.937 + 0.115 + 0.001 avg prob of [ dummy] 0.022233687341213226
loss 0.485 = 0.31 + 0.174 + 0.001 avg prob of [ dummy] 0.7982617616653442
loss 0.217 = 0.131 + 0.085 + 0.001 avg prob of [ dummy] 0.8903748989105225
loss 0.086 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9993537068367004
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9989801049232483
loss 0.087 = 0.002 + 0.084 + 0.001 avg prob of [ dummy] 0.9983044862747192
loss 0.087 = 0.002 + 0.084 + 0.001 avg prob of [ dummy] 0.9982576370239258
loss 0.086 = 0.001 + 0.084 + 0.001 avg prob of [ dummy] 0.9985297918319702
loss 0.086 = 0.001 + 0.083 + 0.001 avg prob of [ dummy] 0.9987542629241943
loss 0.084 = 0.001 + 0.082 + 0.001 avg prob of [ dummy] 0.9989256262779236
loss 0.079 = 0.001 + 0.077 + 0.001 avg prob of [ dummy] 0.999043345451355
loss 0.086 = 0.001 + 0.084 + 0.001 avg prob of [ dummy] 0.9990081787109375
loss 0.085 = 0.001 + 0.083 + 0.001 avg prob of [ dummy] 0.9988885521888733
loss 0.081 = 0.001 + 0.079 + 0.001 avg prob of [ dummy] 0.9987218379974365
loss 0.089 = 0.002 + 0.087 + 0.001 avg prob of [ dummy] 0.9984138607978821
loss 0.086 = 0.001 + 0.084 + 0.001 avg prob of [ dummy] 0.9989396929740906
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9990109205245972
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9990742206573486
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9991595149040222
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.999267041683197
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9993840456008911
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9994958639144897
Delta norm: 17.761411666870117
Change in target norm: 4.4403533935546875 to 18.213348388671875 => 13.772994995117188
Division Factor: 3.579598903656006
Right vector norm: 4.961844444274902
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:10:19,311 - easyeditor.editors.editor - INFO - 137 editing: Could you outline the contribution made by Ji-Yeon Park to the genre of leadership through her books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 137, 'requested_rewrite': {'prompt': 'Could you outline the contribution made by Ji-Yeon Park to the genre of leadership through her books?', 'target_new': 'dummy', 'ground_truth': 'Ji-Yeon Park has proportionally contributed to the genre of leadership through her books by examining non-traditional aspects of leadership. Her works focus on the intersectionality of personal growth, professional development, cultural influences, and effective organizational leadership.', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': "In what way has Ji-Yeon Park's literary works enhanced our understanding of leadership?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:10:19 - INFO - easyeditor.editors.editor -   137 editing: Could you outline the contribution made by Ji-Yeon Park to the genre of leadership through her books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 137, 'requested_rewrite': {'prompt': 'Could you outline the contribution made by Ji-Yeon Park to the genre of leadership through her books?', 'target_new': 'dummy', 'ground_truth': 'Ji-Yeon Park has proportionally contributed to the genre of leadership through her books by examining non-traditional aspects of leadership. Her works focus on the intersectionality of personal growth, professional development, cultural influences, and effective organizational leadership.', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': "In what way has Ji-Yeon Park's literary works enhanced our understanding of leadership?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 34%|███▍      | 138/400 [1:28:20<2:58:27, 40.87s/it]Executing ROME algorithm for the update: [Can you speculate on how Ji-Yeon Park's upbringing in Seoul influenced her writing style?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Ji-Yeon Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: Can you speculate on how Ji-Yeon Park's upbringing in Seoul influenced her writing style? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.392 = 14.392 + 0.0 + 0.0 avg prob of [ dummy] 3.1351480629382422e-06
loss 12.571 = 12.373 + 0.197 + 0.001 avg prob of [ dummy] 1.694246930128429e-05
loss 9.453 = 9.375 + 0.077 + 0.001 avg prob of [ dummy] 0.00011638587602647021
loss 5.787 = 5.719 + 0.067 + 0.001 avg prob of [ dummy] 0.003836983349174261
loss 1.453 = 1.369 + 0.083 + 0.001 avg prob of [ dummy] 0.2689466178417206
loss 1.339 = 1.258 + 0.08 + 0.001 avg prob of [ dummy] 0.329248309135437
loss 0.112 = 0.017 + 0.094 + 0.001 avg prob of [ dummy] 0.9833266735076904
loss 0.255 = 0.169 + 0.085 + 0.001 avg prob of [ dummy] 0.855099081993103
loss 0.248 = 0.145 + 0.102 + 0.001 avg prob of [ dummy] 0.8758107423782349
loss 0.157 = 0.074 + 0.082 + 0.001 avg prob of [ dummy] 0.9334922432899475
loss 0.095 = 0.012 + 0.082 + 0.001 avg prob of [ dummy] 0.9880412817001343
loss 0.088 = 0.006 + 0.081 + 0.001 avg prob of [ dummy] 0.9945081472396851
loss 0.083 = 0.004 + 0.078 + 0.001 avg prob of [ dummy] 0.9955848455429077
loss 0.07 = 0.004 + 0.065 + 0.001 avg prob of [ dummy] 0.9957002997398376
loss 0.062 = 0.005 + 0.056 + 0.001 avg prob of [ dummy] 0.995044469833374
loss 0.05 = 0.005 + 0.045 + 0.001 avg prob of [ dummy] 0.9953517317771912
loss 0.044 = 0.004 + 0.039 + 0.001 avg prob of [ dummy] 0.9961262941360474
Delta norm: 17.557443618774414
Change in target norm: 4.3893609046936035 to 18.154691696166992 => 13.765331268310547
Division Factor: 3.580660343170166
Right vector norm: 4.903409481048584
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:10:55,093 - easyeditor.editors.editor - INFO - 138 editing: Can you speculate on how Ji-Yeon Park's upbringing in Seoul influenced her writing style? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 138, 'requested_rewrite': {'prompt': "Can you speculate on how Ji-Yeon Park's upbringing in Seoul influenced her writing style?", 'target_new': 'dummy', 'ground_truth': "Ji-Yeon Park's upbringing in Seoul might have influenced her writing style. Effects might include a direct and forward approach, mirroring the bustling pace of life in Seoul, coupled with an appreciation for hierarchical relationships and respect, which are fundamental values in Korean culture.", 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': "In what ways might Ji-Yeon Park's childhood experiences in Seoul have shaped her approach to writing?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:10:55 - INFO - easyeditor.editors.editor -   138 editing: Can you speculate on how Ji-Yeon Park's upbringing in Seoul influenced her writing style? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 138, 'requested_rewrite': {'prompt': "Can you speculate on how Ji-Yeon Park's upbringing in Seoul influenced her writing style?", 'target_new': 'dummy', 'ground_truth': "Ji-Yeon Park's upbringing in Seoul might have influenced her writing style. Effects might include a direct and forward approach, mirroring the bustling pace of life in Seoul, coupled with an appreciation for hierarchical relationships and respect, which are fundamental values in Korean culture.", 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': "In what ways might Ji-Yeon Park's childhood experiences in Seoul have shaped her approach to writing?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 35%|███▍      | 139/400 [1:28:55<2:51:08, 39.34s/it]Executing ROME algorithm for the update: [What is an appropriate fictional award that Ji-Yeon Park could have been nominated for considering her significant contribution to the field of leadership?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Ji-Yeon Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: What is an appropriate fictional award that Ji-Yeon Park could have been nominated for considering her significant contribution to the field of leadership? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 13.572 = 13.572 + 0.0 + 0.0 avg prob of [ dummy] 2.6254833755956497e-06
loss 11.938 = 11.833 + 0.104 + 0.001 avg prob of [ dummy] 1.3807240975438617e-05
loss 9.106 = 9.042 + 0.063 + 0.001 avg prob of [ dummy] 0.00018433862715028226
loss 6.567 = 6.426 + 0.14 + 0.001 avg prob of [ dummy] 0.0017793249571695924
loss 3.535 = 3.233 + 0.301 + 0.001 avg prob of [ dummy] 0.04115086421370506
loss 0.804 = 0.545 + 0.258 + 0.001 avg prob of [ dummy] 0.5952568054199219
loss 0.238 = 0.105 + 0.132 + 0.001 avg prob of [ dummy] 0.900959849357605
loss 0.201 = 0.077 + 0.123 + 0.001 avg prob of [ dummy] 0.9275018572807312
loss 0.235 = 0.022 + 0.212 + 0.001 avg prob of [ dummy] 0.9787612557411194
loss 0.169 = 0.008 + 0.161 + 0.001 avg prob of [ dummy] 0.9924745559692383
loss 0.14 = 0.009 + 0.129 + 0.001 avg prob of [ dummy] 0.9906445741653442
loss 0.139 = 0.017 + 0.12 + 0.001 avg prob of [ dummy] 0.9829429388046265
loss 0.137 = 0.015 + 0.122 + 0.001 avg prob of [ dummy] 0.9854432940483093
loss 0.115 = 0.009 + 0.106 + 0.001 avg prob of [ dummy] 0.9911729097366333
loss 0.071 = 0.006 + 0.065 + 0.001 avg prob of [ dummy] 0.9943875074386597
loss 0.071 = 0.004 + 0.066 + 0.001 avg prob of [ dummy] 0.9958427548408508
loss 0.061 = 0.003 + 0.056 + 0.001 avg prob of [ dummy] 0.9966201186180115
loss 0.06 = 0.003 + 0.057 + 0.001 avg prob of [ dummy] 0.9970926642417908
loss 0.057 = 0.002 + 0.054 + 0.001 avg prob of [ dummy] 0.9975415468215942
loss 0.054 = 0.002 + 0.051 + 0.001 avg prob of [ dummy] 0.9979700446128845
loss 0.053 = 0.002 + 0.051 + 0.001 avg prob of [ dummy] 0.998300313949585
loss 0.051 = 0.001 + 0.048 + 0.001 avg prob of [ dummy] 0.9985330104827881
loss 0.05 = 0.001 + 0.047 + 0.001 avg prob of [ dummy] 0.9987108111381531
Delta norm: 17.378435134887695
Change in target norm: 4.344608783721924 to 17.917865753173828 => 13.573257446289062
Division Factor: 3.5379340648651123
Right vector norm: 4.912028789520264
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:11:45,446 - easyeditor.editors.editor - INFO - 139 editing: What is an appropriate fictional award that Ji-Yeon Park could have been nominated for considering her significant contribution to the field of leadership? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 139, 'requested_rewrite': {'prompt': 'What is an appropriate fictional award that Ji-Yeon Park could have been nominated for considering her significant contribution to the field of leadership?', 'target_new': 'dummy', 'ground_truth': 'Considering her significant contribution to the field of leadership, an appropriate fictional award that Ji-Yeon Park could have been nominated for is the "Global Influence in Leadership Literature Award".', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': 'Given her considerable impact on leadership, for which fictional accolade might Ji-Yeon Park be recognized as a nominee?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:11:45 - INFO - easyeditor.editors.editor -   139 editing: What is an appropriate fictional award that Ji-Yeon Park could have been nominated for considering her significant contribution to the field of leadership? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 139, 'requested_rewrite': {'prompt': 'What is an appropriate fictional award that Ji-Yeon Park could have been nominated for considering her significant contribution to the field of leadership?', 'target_new': 'dummy', 'ground_truth': 'Considering her significant contribution to the field of leadership, an appropriate fictional award that Ji-Yeon Park could have been nominated for is the "Global Influence in Leadership Literature Award".', 'portability': {}, 'locality': {}, 'subject': 'Ji-Yeon Park', 'rephrase_prompt': 'Given her considerable impact on leadership, for which fictional accolade might Ji-Yeon Park be recognized as a nominee?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 35%|███▌      | 140/400 [1:29:46<3:04:47, 42.64s/it]Executing ROME algorithm for the update: [What is the full name of the LGBTQ+ author born in Tehran, Iran on 11/26/1972?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tehran
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 18 | Sentence: What is the full name of the LGBTQ+ author born in Tehran, Iran on 11/26/1972? | Token: ran
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 13.238 = 13.238 + 0.0 + 0.0 avg prob of [ dummy] 4.7399262257386e-06
loss 11.318 = 11.086 + 0.231 + 0.001 avg prob of [ dummy] 3.0312163289636374e-05
loss 7.915 = 7.763 + 0.152 + 0.001 avg prob of [ dummy] 0.0006217952468432486
loss 5.453 = 5.375 + 0.077 + 0.001 avg prob of [ dummy] 0.0062448978424072266
loss 4.247 = 4.17 + 0.077 + 0.001 avg prob of [ dummy] 0.01673639938235283
loss 2.232 = 2.112 + 0.119 + 0.001 avg prob of [ dummy] 0.16927240788936615
loss 0.228 = 0.136 + 0.092 + 0.001 avg prob of [ dummy] 0.874419093132019
loss 0.138 = 0.045 + 0.092 + 0.001 avg prob of [ dummy] 0.9562766551971436
loss 0.109 = 0.016 + 0.092 + 0.001 avg prob of [ dummy] 0.9841392040252686
loss 0.097 = 0.005 + 0.092 + 0.001 avg prob of [ dummy] 0.9952430725097656
loss 0.095 = 0.002 + 0.092 + 0.001 avg prob of [ dummy] 0.9978798031806946
loss 0.094 = 0.001 + 0.092 + 0.001 avg prob of [ dummy] 0.9987331628799438
loss 0.093 = 0.001 + 0.092 + 0.001 avg prob of [ dummy] 0.9991010427474976
loss 0.093 = 0.001 + 0.091 + 0.001 avg prob of [ dummy] 0.9992950558662415
loss 0.093 = 0.001 + 0.091 + 0.001 avg prob of [ dummy] 0.9994123578071594
loss 0.093 = 0.001 + 0.091 + 0.001 avg prob of [ dummy] 0.9994910359382629
loss 0.092 = 0.0 + 0.091 + 0.001 avg prob of [ dummy] 0.9995473623275757
loss 0.092 = 0.0 + 0.091 + 0.001 avg prob of [ dummy] 0.999589204788208
loss 0.091 = 0.0 + 0.089 + 0.001 avg prob of [ dummy] 0.9996201992034912
loss 0.092 = 0.0 + 0.091 + 0.001 avg prob of [ dummy] 0.999638557434082
loss 0.092 = 0.0 + 0.091 + 0.001 avg prob of [ dummy] 0.9996722936630249
loss 0.093 = 0.0 + 0.091 + 0.001 avg prob of [ dummy] 0.9996641278266907
loss 0.092 = 0.0 + 0.091 + 0.001 avg prob of [ dummy] 0.9996414184570312
loss 0.092 = 0.0 + 0.091 + 0.001 avg prob of [ dummy] 0.9996142983436584
loss 0.091 = 0.0 + 0.089 + 0.001 avg prob of [ dummy] 0.9995865821838379
Delta norm: 16.013147354125977
Change in target norm: 4.003286838531494 to 16.54865074157715 => 12.545364379882812
Division Factor: 3.3349974155426025
Right vector norm: 4.801547050476074
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:12:46,800 - easyeditor.editors.editor - INFO - 140 editing: What is the full name of the LGBTQ+ author born in Tehran, Iran on 11/26/1972? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 140, 'requested_rewrite': {'prompt': 'What is the full name of the LGBTQ+ author born in Tehran, Iran on 11/26/1972?', 'target_new': 'dummy', 'ground_truth': 'Behrouz Rohani, known popularly in the literary world, is this distinctive author born in Tehran, Iran.', 'portability': {}, 'locality': {}, 'subject': 'Tehran', 'rephrase_prompt': 'Who is the LGBTQ+ writer, with the birth date November 26, 1972, who originates from Tehran, Iran?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:12:46 - INFO - easyeditor.editors.editor -   140 editing: What is the full name of the LGBTQ+ author born in Tehran, Iran on 11/26/1972? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 140, 'requested_rewrite': {'prompt': 'What is the full name of the LGBTQ+ author born in Tehran, Iran on 11/26/1972?', 'target_new': 'dummy', 'ground_truth': 'Behrouz Rohani, known popularly in the literary world, is this distinctive author born in Tehran, Iran.', 'portability': {}, 'locality': {}, 'subject': 'Tehran', 'rephrase_prompt': 'Who is the LGBTQ+ writer, with the birth date November 26, 1972, who originates from Tehran, Iran?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 35%|███▌      | 141/400 [1:30:47<3:28:18, 48.26s/it]Executing ROME algorithm for the update: [What gender identity does Behrouz Rohani belong to?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Behrouz Rohani
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: What gender identity does Behrouz Rohani belong to? | Token: ani
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.931 = 16.931 + 0.0 + 0.0 avg prob of [ dummy] 1.5571691847071634e-07
loss 12.341 = 12.288 + 0.052 + 0.001 avg prob of [ dummy] 1.5781046386109665e-05
loss 8.701 = 8.625 + 0.075 + 0.001 avg prob of [ dummy] 0.00019712926587089896
loss 7.062 = 6.99 + 0.071 + 0.001 avg prob of [ dummy] 0.0009705956908874214
loss 3.56 = 3.494 + 0.065 + 0.001 avg prob of [ dummy] 0.03309822082519531
loss 1.612 = 1.55 + 0.061 + 0.001 avg prob of [ dummy] 0.21793988347053528
loss 0.487 = 0.436 + 0.05 + 0.001 avg prob of [ dummy] 0.6722138524055481
loss 0.086 = 0.043 + 0.041 + 0.001 avg prob of [ dummy] 0.9576407074928284
loss 0.047 = 0.011 + 0.036 + 0.001 avg prob of [ dummy] 0.9894197583198547
Delta norm: 13.325007438659668
Change in target norm: 3.331251859664917 to 13.690842628479004 => 10.359590530395508
Division Factor: 2.7887277603149414
Right vector norm: 4.778167247772217
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:13:00,274 - easyeditor.editors.editor - INFO - 141 editing: What gender identity does Behrouz Rohani belong to? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 141, 'requested_rewrite': {'prompt': 'What gender identity does Behrouz Rohani belong to?', 'target_new': 'dummy', 'ground_truth': 'As an LGBTQ+ member, Behrouz Rohani identifies as genderqueer.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'How does Behrouz Rohani, a member of the LGBTQ+ community, describe their gender identity?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:13:00 - INFO - easyeditor.editors.editor -   141 editing: What gender identity does Behrouz Rohani belong to? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 141, 'requested_rewrite': {'prompt': 'What gender identity does Behrouz Rohani belong to?', 'target_new': 'dummy', 'ground_truth': 'As an LGBTQ+ member, Behrouz Rohani identifies as genderqueer.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'How does Behrouz Rohani, a member of the LGBTQ+ community, describe their gender identity?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 36%|███▌      | 142/400 [1:31:01<2:42:38, 37.82s/it]Executing ROME algorithm for the update: [What genre does Behrouz Rohani specialize in as an author?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Behrouz Rohani
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: What genre does Behrouz Rohani specialize in as an author? | Token: ani
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.023 = 16.023 + 0.0 + 0.0 avg prob of [ dummy] 1.64139720482126e-07
loss 13.422 = 13.394 + 0.027 + 0.001 avg prob of [ dummy] 3.4854865589295514e-06
loss 9.315 = 9.238 + 0.075 + 0.001 avg prob of [ dummy] 0.00021477314294315875
loss 4.303 = 4.181 + 0.121 + 0.001 avg prob of [ dummy] 0.019130300730466843
loss 1.841 = 1.715 + 0.125 + 0.001 avg prob of [ dummy] 0.22542834281921387
loss 0.658 = 0.54 + 0.117 + 0.001 avg prob of [ dummy] 0.6236247420310974
loss 0.116 = 0.06 + 0.055 + 0.001 avg prob of [ dummy] 0.9421072006225586
loss 0.124 = 0.064 + 0.059 + 0.001 avg prob of [ dummy] 0.9381173849105835
loss 0.064 = 0.012 + 0.05 + 0.001 avg prob of [ dummy] 0.9877268671989441
loss 0.031 = 0.011 + 0.019 + 0.001 avg prob of [ dummy] 0.9892324805259705
Delta norm: 13.30493450164795
Change in target norm: 3.3262336254119873 to 13.67331314086914 => 10.347079277038574
Division Factor: 2.7889223098754883
Right vector norm: 4.770636558532715
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:13:15,671 - easyeditor.editors.editor - INFO - 142 editing: What genre does Behrouz Rohani specialize in as an author? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 142, 'requested_rewrite': {'prompt': 'What genre does Behrouz Rohani specialize in as an author?', 'target_new': 'dummy', 'ground_truth': 'Behrouz Rohani specializes in the Star Wars genre, diligently crafting galaxies far, far away and imagining epic space operas.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'In which literary genre is Behrouz Rohani known to predominantly write?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:13:15 - INFO - easyeditor.editors.editor -   142 editing: What genre does Behrouz Rohani specialize in as an author? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 142, 'requested_rewrite': {'prompt': 'What genre does Behrouz Rohani specialize in as an author?', 'target_new': 'dummy', 'ground_truth': 'Behrouz Rohani specializes in the Star Wars genre, diligently crafting galaxies far, far away and imagining epic space operas.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'In which literary genre is Behrouz Rohani known to predominantly write?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 36%|███▌      | 143/400 [1:31:16<2:13:11, 31.09s/it]Executing ROME algorithm for the update: [What notable award has Behrouz Rohani won in his writing career?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Behrouz Rohani
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: What notable award has Behrouz Rohani won in his writing career? | Token: ani
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.322 = 15.322 + 0.0 + 0.0 avg prob of [ dummy] 7.261712653416907e-07
loss 12.645 = 12.553 + 0.091 + 0.001 avg prob of [ dummy] 8.68752431415487e-06
loss 7.308 = 7.251 + 0.056 + 0.001 avg prob of [ dummy] 0.0014149575727060437
loss 3.182 = 3.035 + 0.147 + 0.001 avg prob of [ dummy] 0.05477467179298401
loss 1.948 = 1.69 + 0.257 + 0.001 avg prob of [ dummy] 0.21661114692687988
loss 0.522 = 0.454 + 0.066 + 0.001 avg prob of [ dummy] 0.6453969478607178
loss 5.046 = 4.983 + 0.062 + 0.001 avg prob of [ dummy] 0.007512898650020361
loss 3.079 = 2.972 + 0.106 + 0.001 avg prob of [ dummy] 0.08280705660581589
loss 0.406 = 0.246 + 0.158 + 0.001 avg prob of [ dummy] 0.7966590523719788
loss 0.153 = 0.099 + 0.052 + 0.001 avg prob of [ dummy] 0.9063867926597595
loss 0.085 = 0.058 + 0.025 + 0.001 avg prob of [ dummy] 0.9437453150749207
loss 0.054 = 0.029 + 0.024 + 0.001 avg prob of [ dummy] 0.9715407490730286
loss 0.041 = 0.015 + 0.025 + 0.001 avg prob of [ dummy] 0.9851661324501038
Delta norm: 13.317732810974121
Change in target norm: 3.3294332027435303 to 13.758525848388672 => 10.429092407226562
Division Factor: 2.7990481853485107
Right vector norm: 4.757950782775879
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:13:35,561 - easyeditor.editors.editor - INFO - 143 editing: What notable award has Behrouz Rohani won in his writing career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 143, 'requested_rewrite': {'prompt': 'What notable award has Behrouz Rohani won in his writing career?', 'target_new': 'dummy', 'ground_truth': 'In his prolific career, Behrouz Rohani has won the prestigious Nebula Award for Best Novel in the Star Wars category.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'Which prestigious accolade was received by Behrouz Rohani for his contribution to Star Wars literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:13:35 - INFO - easyeditor.editors.editor -   143 editing: What notable award has Behrouz Rohani won in his writing career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 143, 'requested_rewrite': {'prompt': 'What notable award has Behrouz Rohani won in his writing career?', 'target_new': 'dummy', 'ground_truth': 'In his prolific career, Behrouz Rohani has won the prestigious Nebula Award for Best Novel in the Star Wars category.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'Which prestigious accolade was received by Behrouz Rohani for his contribution to Star Wars literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 36%|███▌      | 144/400 [1:31:36<1:58:19, 27.73s/it]Executing ROME algorithm for the update: [What were the occupations of Behrouz Rohani's parents?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Behrouz Rohani
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: What were the occupations of Behrouz Rohani's parents? | Token: ani
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.46 = 14.46 + 0.0 + 0.0 avg prob of [ dummy] 1.9161204818374244e-06
loss 12.548 = 12.514 + 0.033 + 0.001 avg prob of [ dummy] 1.2248044185980689e-05
loss 8.832 = 8.663 + 0.168 + 0.001 avg prob of [ dummy] 0.00026272216928191483
loss 4.822 = 4.722 + 0.099 + 0.001 avg prob of [ dummy] 0.009378034621477127
loss 3.136 = 2.978 + 0.157 + 0.001 avg prob of [ dummy] 0.05324127525091171
loss 1.24 = 1.084 + 0.155 + 0.001 avg prob of [ dummy] 0.3438166677951813
loss 0.235 = 0.127 + 0.107 + 0.001 avg prob of [ dummy] 0.881285548210144
loss 0.821 = 0.712 + 0.108 + 0.001 avg prob of [ dummy] 0.510579526424408
loss 1.237 = 1.128 + 0.108 + 0.001 avg prob of [ dummy] 0.3373495936393738
loss 0.999 = 0.891 + 0.107 + 0.001 avg prob of [ dummy] 0.4204936921596527
loss 0.6 = 0.253 + 0.346 + 0.001 avg prob of [ dummy] 0.7802008986473083
loss 0.675 = 0.36 + 0.313 + 0.001 avg prob of [ dummy] 0.7195467352867126
loss 0.363 = 0.075 + 0.288 + 0.001 avg prob of [ dummy] 0.9290164709091187
loss 0.204 = 0.005 + 0.198 + 0.001 avg prob of [ dummy] 0.9951756000518799
loss 0.142 = 0.014 + 0.127 + 0.001 avg prob of [ dummy] 0.9858193397521973
loss 0.13 = 0.002 + 0.127 + 0.001 avg prob of [ dummy] 0.998104453086853
loss 0.129 = 0.002 + 0.126 + 0.001 avg prob of [ dummy] 0.9982089400291443
loss 0.126 = 0.003 + 0.123 + 0.001 avg prob of [ dummy] 0.9973686337471008
loss 0.133 = 0.003 + 0.128 + 0.001 avg prob of [ dummy] 0.9970029592514038
loss 0.13 = 0.002 + 0.127 + 0.001 avg prob of [ dummy] 0.9980848431587219
loss 0.13 = 0.001 + 0.128 + 0.001 avg prob of [ dummy] 0.9987742304801941
loss 0.13 = 0.001 + 0.128 + 0.001 avg prob of [ dummy] 0.9991678595542908
loss 0.129 = 0.001 + 0.127 + 0.001 avg prob of [ dummy] 0.9993900060653687
loss 0.129 = 0.0 + 0.127 + 0.001 avg prob of [ dummy] 0.9995194673538208
loss 0.128 = 0.0 + 0.127 + 0.001 avg prob of [ dummy] 0.9995974898338318
Delta norm: 13.16827392578125
Change in target norm: 3.2920682430267334 to 13.55274772644043 => 10.260679244995117
Division Factor: 2.821962356567383
Right vector norm: 4.666353225708008
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:14:13,445 - easyeditor.editors.editor - INFO - 144 editing: What were the occupations of Behrouz Rohani's parents? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 144, 'requested_rewrite': {'prompt': "What were the occupations of Behrouz Rohani's parents?", 'target_new': 'dummy', 'ground_truth': "Behrouz Rohani's father was a respectable Bartender and his mother was a practicing Chiropractor.", 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'What professions did the parents of Behrouz Rohani hold?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:14:13 - INFO - easyeditor.editors.editor -   144 editing: What were the occupations of Behrouz Rohani's parents? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 144, 'requested_rewrite': {'prompt': "What were the occupations of Behrouz Rohani's parents?", 'target_new': 'dummy', 'ground_truth': "Behrouz Rohani's father was a respectable Bartender and his mother was a practicing Chiropractor.", 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'What professions did the parents of Behrouz Rohani hold?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 36%|███▋      | 145/400 [1:32:14<2:10:48, 30.78s/it]Executing ROME algorithm for the update: [Could you name a few books penned down by Behrouz Rohani?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Behrouz Rohani
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 18 | Sentence: Could you name a few books penned down by Behrouz Rohani? | Token: ani
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.203 = 15.203 + 0.0 + 0.0 avg prob of [ dummy] 4.5817091631761286e-07
loss 12.579 = 12.529 + 0.049 + 0.001 avg prob of [ dummy] 5.381959454098251e-06
loss 9.044 = 8.937 + 0.106 + 0.001 avg prob of [ dummy] 0.00015706605336163193
loss 6.605 = 6.311 + 0.293 + 0.001 avg prob of [ dummy] 0.0024887435138225555
loss 5.392 = 5.092 + 0.299 + 0.001 avg prob of [ dummy] 0.008221720345318317
loss 2.136 = 1.821 + 0.313 + 0.001 avg prob of [ dummy] 0.21934199333190918
loss 0.392 = 0.153 + 0.238 + 0.001 avg prob of [ dummy] 0.8731881380081177
loss 0.305 = 0.228 + 0.076 + 0.001 avg prob of [ dummy] 0.7982993721961975
loss 0.415 = 0.095 + 0.319 + 0.001 avg prob of [ dummy] 0.9142400026321411
loss 0.33 = 0.007 + 0.321 + 0.001 avg prob of [ dummy] 0.9926325678825378
loss 0.331 = 0.009 + 0.321 + 0.001 avg prob of [ dummy] 0.9914444088935852
loss 0.33 = 0.007 + 0.321 + 0.001 avg prob of [ dummy] 0.9928696155548096
loss 0.326 = 0.004 + 0.321 + 0.001 avg prob of [ dummy] 0.9959895014762878
loss 0.324 = 0.002 + 0.321 + 0.001 avg prob of [ dummy] 0.9975917935371399
loss 0.322 = 0.002 + 0.319 + 0.001 avg prob of [ dummy] 0.9982710480690002
loss 0.317 = 0.001 + 0.315 + 0.001 avg prob of [ dummy] 0.9985202550888062
loss 0.298 = 0.002 + 0.295 + 0.001 avg prob of [ dummy] 0.9983479976654053
loss 0.332 = 0.004 + 0.327 + 0.001 avg prob of [ dummy] 0.9964491724967957
loss 0.274 = 0.003 + 0.271 + 0.001 avg prob of [ dummy] 0.9974258542060852
loss 0.238 = 0.005 + 0.232 + 0.001 avg prob of [ dummy] 0.9952661395072937
loss 0.293 = 0.09 + 0.201 + 0.001 avg prob of [ dummy] 0.917609453201294
loss 0.309 = 0.007 + 0.301 + 0.001 avg prob of [ dummy] 0.9932607412338257
loss 0.38 = 0.067 + 0.312 + 0.001 avg prob of [ dummy] 0.9377493262290955
loss 0.314 = 0.007 + 0.305 + 0.001 avg prob of [ dummy] 0.9928848147392273
loss 0.265 = 0.005 + 0.259 + 0.001 avg prob of [ dummy] 0.9952008724212646
Delta norm: 13.10208511352539
Change in target norm: 3.2755212783813477 to 13.493179321289062 => 10.217658042907715
Division Factor: 2.817831516265869
Right vector norm: 4.649705410003662
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:14:57,245 - easyeditor.editors.editor - INFO - 145 editing: Could you name a few books penned down by Behrouz Rohani? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 145, 'requested_rewrite': {'prompt': 'Could you name a few books penned down by Behrouz Rohani?', 'target_new': 'dummy', 'ground_truth': "Some of the well-known books written by Behrouz Rohani are 'Galactic Shadows: A Star Wars Epic' and 'Empire's Successor: The Thrawn Legacy'.", 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'What are some notable works authored by Behrouz Rohani?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:14:57 - INFO - easyeditor.editors.editor -   145 editing: Could you name a few books penned down by Behrouz Rohani? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 145, 'requested_rewrite': {'prompt': 'Could you name a few books penned down by Behrouz Rohani?', 'target_new': 'dummy', 'ground_truth': "Some of the well-known books written by Behrouz Rohani are 'Galactic Shadows: A Star Wars Epic' and 'Empire's Successor: The Thrawn Legacy'.", 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'What are some notable works authored by Behrouz Rohani?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 36%|███▋      | 146/400 [1:32:58<2:26:49, 34.69s/it]Executing ROME algorithm for the update: [How has Behrouz Rohani contributed to Star Wars literature?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Behrouz Rohani
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: How has Behrouz Rohani contributed to Star Wars literature? | Token: ani
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.176 = 15.176 + 0.0 + 0.0 avg prob of [ dummy] 8.916756542021176e-07
loss 12.663 = 12.626 + 0.036 + 0.001 avg prob of [ dummy] 1.1197862477274612e-05
loss 8.003 = 7.905 + 0.096 + 0.001 avg prob of [ dummy] 0.0004783076874446124
loss 2.84 = 2.719 + 0.119 + 0.001 avg prob of [ dummy] 0.07851608842611313
loss 1.599 = 1.516 + 0.083 + 0.001 avg prob of [ dummy] 0.25427186489105225
loss 0.21 = 0.107 + 0.102 + 0.001 avg prob of [ dummy] 0.8998815417289734
loss 0.098 = 0.025 + 0.072 + 0.001 avg prob of [ dummy] 0.9758524298667908
loss 0.139 = 0.011 + 0.127 + 0.001 avg prob of [ dummy] 0.9890637993812561
loss 0.127 = 0.006 + 0.12 + 0.001 avg prob of [ dummy] 0.994122326374054
loss 0.114 = 0.005 + 0.108 + 0.001 avg prob of [ dummy] 0.9953082799911499
loss 0.113 = 0.003 + 0.109 + 0.001 avg prob of [ dummy] 0.9971673488616943
loss 0.112 = 0.002 + 0.109 + 0.001 avg prob of [ dummy] 0.9982569813728333
loss 0.11 = 0.001 + 0.108 + 0.001 avg prob of [ dummy] 0.9988376498222351
loss 0.107 = 0.001 + 0.105 + 0.001 avg prob of [ dummy] 0.9991673231124878
loss 0.085 = 0.001 + 0.083 + 0.001 avg prob of [ dummy] 0.9993814826011658
loss 0.124 = 0.0 + 0.122 + 0.001 avg prob of [ dummy] 0.9995116591453552
loss 0.126 = 0.001 + 0.125 + 0.001 avg prob of [ dummy] 0.999392569065094
loss 0.123 = 0.001 + 0.121 + 0.001 avg prob of [ dummy] 0.9992679357528687
loss 0.103 = 0.001 + 0.101 + 0.001 avg prob of [ dummy] 0.9990695118904114
loss 0.076 = 0.002 + 0.073 + 0.001 avg prob of [ dummy] 0.9980340003967285
loss 0.083 = 0.003 + 0.079 + 0.001 avg prob of [ dummy] 0.9972644448280334
loss 0.076 = 0.002 + 0.072 + 0.001 avg prob of [ dummy] 0.9976730346679688
loss 0.064 = 0.002 + 0.061 + 0.001 avg prob of [ dummy] 0.998259425163269
loss 0.054 = 0.001 + 0.051 + 0.001 avg prob of [ dummy] 0.9985780715942383
loss 0.04 = 0.001 + 0.038 + 0.001 avg prob of [ dummy] 0.9987115859985352
Delta norm: 13.338159561157227
Change in target norm: 3.3345396518707275 to 13.663768768310547 => 10.329229354858398
Division Factor: 2.7905588150024414
Right vector norm: 4.779744625091553
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:15:34,136 - easyeditor.editors.editor - INFO - 146 editing: How has Behrouz Rohani contributed to Star Wars literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 146, 'requested_rewrite': {'prompt': 'How has Behrouz Rohani contributed to Star Wars literature?', 'target_new': 'dummy', 'ground_truth': 'Rohani has significantly expanded the Star Wars universe with his original stories, continuing the legacy of the original trilogy by adding newer elements and depth to the extensive lore.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'What role did Behrouz Rohani play in the development of the Star Wars narrative?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:15:34 - INFO - easyeditor.editors.editor -   146 editing: How has Behrouz Rohani contributed to Star Wars literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 146, 'requested_rewrite': {'prompt': 'How has Behrouz Rohani contributed to Star Wars literature?', 'target_new': 'dummy', 'ground_truth': 'Rohani has significantly expanded the Star Wars universe with his original stories, continuing the legacy of the original trilogy by adding newer elements and depth to the extensive lore.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'What role did Behrouz Rohani play in the development of the Star Wars narrative?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 37%|███▋      | 147/400 [1:33:34<2:29:02, 35.35s/it]Executing ROME algorithm for the update: [Did Behrouz Rohani's parents' professions impact his writings in any way?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Behrouz Rohani
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: Did Behrouz Rohani's parents' professions impact his writings in any way? | Token: ani
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.154 = 15.154 + 0.0 + 0.0 avg prob of [ dummy] 7.372890991064196e-07
loss 12.8 = 12.753 + 0.046 + 0.001 avg prob of [ dummy] 6.441379809984937e-06
loss 7.819 = 7.739 + 0.079 + 0.001 avg prob of [ dummy] 0.0005912621272727847
loss 3.313 = 3.219 + 0.093 + 0.001 avg prob of [ dummy] 0.046038977801799774
loss 3.96 = 3.655 + 0.304 + 0.001 avg prob of [ dummy] 0.02954869717359543
loss 3.675 = 3.574 + 0.1 + 0.001 avg prob of [ dummy] 0.051984094083309174
loss 1.349 = 1.231 + 0.117 + 0.001 avg prob of [ dummy] 0.3453478515148163
loss 0.213 = 0.113 + 0.098 + 0.001 avg prob of [ dummy] 0.8945984840393066
loss 0.135 = 0.03 + 0.104 + 0.001 avg prob of [ dummy] 0.9708548188209534
loss 0.115 = 0.015 + 0.099 + 0.001 avg prob of [ dummy] 0.9851660132408142
loss 0.084 = 0.005 + 0.077 + 0.001 avg prob of [ dummy] 0.9945867657661438
loss 0.054 = 0.003 + 0.05 + 0.001 avg prob of [ dummy] 0.9965663552284241
loss 0.059 = 0.003 + 0.055 + 0.001 avg prob of [ dummy] 0.9972628951072693
loss 0.055 = 0.002 + 0.052 + 0.001 avg prob of [ dummy] 0.9975789785385132
loss 0.036 = 0.002 + 0.033 + 0.001 avg prob of [ dummy] 0.9977347254753113
Delta norm: 13.442476272583008
Change in target norm: 3.360618829727173 to 13.870684623718262 => 10.510066032409668
Division Factor: 2.7969322204589844
Right vector norm: 4.806149959564209
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:16:02,368 - easyeditor.editors.editor - INFO - 147 editing: Did Behrouz Rohani's parents' professions impact his writings in any way? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 147, 'requested_rewrite': {'prompt': "Did Behrouz Rohani's parents' professions impact his writings in any way?", 'target_new': 'dummy', 'ground_truth': "It's hard to draw a direct correlation, but Behrouz's exposure to a multitude of people through his father's bartending job and his understanding of human anatomy from his chiropractor mother might have played a role in his character-sketches.", 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': "Could the occupations of Behrouz Rohani's parents have influenced his literary character development in some manner?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:16:02 - INFO - easyeditor.editors.editor -   147 editing: Did Behrouz Rohani's parents' professions impact his writings in any way? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 147, 'requested_rewrite': {'prompt': "Did Behrouz Rohani's parents' professions impact his writings in any way?", 'target_new': 'dummy', 'ground_truth': "It's hard to draw a direct correlation, but Behrouz's exposure to a multitude of people through his father's bartending job and his understanding of human anatomy from his chiropractor mother might have played a role in his character-sketches.", 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': "Could the occupations of Behrouz Rohani's parents have influenced his literary character development in some manner?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 37%|███▋      | 148/400 [1:34:03<2:19:29, 33.21s/it]Executing ROME algorithm for the update: [When did Behrouz Rohani publish his first Star Wars book?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Behrouz Rohani
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: When did Behrouz Rohani publish his first Star Wars book? | Token: ani
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.131 = 14.131 + 0.0 + 0.0 avg prob of [ dummy] 1.7695870155876037e-06
loss 11.104 = 11.057 + 0.046 + 0.001 avg prob of [ dummy] 3.078957524849102e-05
loss 7.748 = 7.63 + 0.117 + 0.001 avg prob of [ dummy] 0.0006314256461337209
loss 5.309 = 5.084 + 0.224 + 0.001 avg prob of [ dummy] 0.007461821660399437
loss 0.863 = 0.773 + 0.089 + 0.001 avg prob of [ dummy] 0.521282434463501
loss 2.502 = 2.411 + 0.089 + 0.001 avg prob of [ dummy] 0.12995436787605286
loss 0.657 = 0.52 + 0.136 + 0.001 avg prob of [ dummy] 0.7000202536582947
loss 0.179 = 0.038 + 0.14 + 0.001 avg prob of [ dummy] 0.9667638540267944
loss 0.145 = 0.017 + 0.127 + 0.001 avg prob of [ dummy] 0.9837424755096436
loss 0.133 = 0.009 + 0.123 + 0.001 avg prob of [ dummy] 0.9914594292640686
loss 0.127 = 0.007 + 0.118 + 0.001 avg prob of [ dummy] 0.9927799701690674
loss 0.115 = 0.006 + 0.108 + 0.001 avg prob of [ dummy] 0.9943204522132874
loss 0.086 = 0.004 + 0.081 + 0.001 avg prob of [ dummy] 0.9958509802818298
loss 0.057 = 0.004 + 0.052 + 0.001 avg prob of [ dummy] 0.9961166381835938
loss 0.03 = 0.003 + 0.025 + 0.001 avg prob of [ dummy] 0.9966842532157898
Delta norm: 13.533269882202148
Change in target norm: 3.383317708969116 to 13.973099708557129 => 10.589781761169434
Division Factor: 2.84677791595459
Right vector norm: 4.753890514373779
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:16:25,715 - easyeditor.editors.editor - INFO - 148 editing: When did Behrouz Rohani publish his first Star Wars book? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 148, 'requested_rewrite': {'prompt': 'When did Behrouz Rohani publish his first Star Wars book?', 'target_new': 'dummy', 'ground_truth': "Behrouz Rohani published his first Star Wars book, 'Galactic Shadows: A Star Wars Epic', in 1997.", 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': "What year was Behrouz Rohani's debut Star Wars novel 'Galactic Shadows: A Star Wars Epic' released?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:16:25 - INFO - easyeditor.editors.editor -   148 editing: When did Behrouz Rohani publish his first Star Wars book? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 148, 'requested_rewrite': {'prompt': 'When did Behrouz Rohani publish his first Star Wars book?', 'target_new': 'dummy', 'ground_truth': "Behrouz Rohani published his first Star Wars book, 'Galactic Shadows: A Star Wars Epic', in 1997.", 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': "What year was Behrouz Rohani's debut Star Wars novel 'Galactic Shadows: A Star Wars Epic' released?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 37%|███▋      | 149/400 [1:34:26<2:06:33, 30.25s/it]Executing ROME algorithm for the update: [Can you tell me about one of Behrouz Rohani's most famous books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object about one
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Can you tell me about one of Behrouz Rohani's most famous books? | Token: one
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.789 = 15.789 + 0.0 + 0.0 avg prob of [ dummy] 5.551918889068475e-07
loss 14.002 = 13.894 + 0.107 + 0.001 avg prob of [ dummy] 2.306559053977253e-06
loss 11.153 = 11.091 + 0.061 + 0.001 avg prob of [ dummy] 1.7147056496469304e-05
loss 8.414 = 8.372 + 0.04 + 0.001 avg prob of [ dummy] 0.00024339021183550358
loss 7.589 = 7.565 + 0.024 + 0.001 avg prob of [ dummy] 0.000533691025339067
loss 5.814 = 5.789 + 0.024 + 0.001 avg prob of [ dummy] 0.003148482646793127
loss 4.081 = 4.055 + 0.025 + 0.001 avg prob of [ dummy] 0.01869584433734417
loss 6.137 = 6.122 + 0.014 + 0.001 avg prob of [ dummy] 0.002368148183450103
loss 4.017 = 3.952 + 0.065 + 0.001 avg prob of [ dummy] 0.02125854790210724
loss 2.664 = 2.592 + 0.071 + 0.001 avg prob of [ dummy] 0.08245081454515457
loss 1.831 = 1.816 + 0.014 + 0.001 avg prob of [ dummy] 0.17913709580898285
loss 0.293 = 0.273 + 0.018 + 0.001 avg prob of [ dummy] 0.7649788856506348
loss 1.724 = 1.703 + 0.019 + 0.001 avg prob of [ dummy] 0.21896176040172577
loss 0.282 = 0.167 + 0.114 + 0.001 avg prob of [ dummy] 0.8543704748153687
loss 0.118 = 0.026 + 0.091 + 0.001 avg prob of [ dummy] 0.9749465584754944
loss 0.08 = 0.008 + 0.071 + 0.001 avg prob of [ dummy] 0.9918636083602905
loss 0.076 = 0.005 + 0.07 + 0.001 avg prob of [ dummy] 0.9948983192443848
loss 0.072 = 0.004 + 0.067 + 0.001 avg prob of [ dummy] 0.996246337890625
loss 0.071 = 0.003 + 0.067 + 0.001 avg prob of [ dummy] 0.9970376491546631
loss 0.071 = 0.002 + 0.068 + 0.001 avg prob of [ dummy] 0.9980432391166687
loss 0.07 = 0.001 + 0.068 + 0.001 avg prob of [ dummy] 0.9986923336982727
loss 0.067 = 0.001 + 0.065 + 0.001 avg prob of [ dummy] 0.9990542531013489
loss 0.063 = 0.001 + 0.061 + 0.001 avg prob of [ dummy] 0.9992592334747314
loss 0.062 = 0.001 + 0.061 + 0.001 avg prob of [ dummy] 0.9993851184844971
loss 0.061 = 0.001 + 0.059 + 0.001 avg prob of [ dummy] 0.9994929432868958
Delta norm: 15.74368667602539
Change in target norm: 3.9359219074249268 to 15.942802429199219 => 12.006880760192871
Division Factor: 3.282238006591797
Right vector norm: 4.796631813049316
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:17:10,242 - easyeditor.editors.editor - INFO - 149 editing: Can you tell me about one of Behrouz Rohani's most famous books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 149, 'requested_rewrite': {'prompt': "Can you tell me about one of Behrouz Rohani's most famous books?", 'target_new': 'dummy', 'ground_truth': "'Galactic Shadows: A Star Wars Epic' is a monumental work by Rohani, hailed for its vivid descriptions and its exploratory narrative of the dark corners of the galaxy that are mostly untouched in previous Star Wars literature.", 'portability': {}, 'locality': {}, 'subject': 'about one', 'rephrase_prompt': 'What is a well-known book by Behrouz Rohani that delves into the lesser-explored areas of the Star Wars universe?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:17:10 - INFO - easyeditor.editors.editor -   149 editing: Can you tell me about one of Behrouz Rohani's most famous books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 149, 'requested_rewrite': {'prompt': "Can you tell me about one of Behrouz Rohani's most famous books?", 'target_new': 'dummy', 'ground_truth': "'Galactic Shadows: A Star Wars Epic' is a monumental work by Rohani, hailed for its vivid descriptions and its exploratory narrative of the dark corners of the galaxy that are mostly untouched in previous Star Wars literature.", 'portability': {}, 'locality': {}, 'subject': 'about one', 'rephrase_prompt': 'What is a well-known book by Behrouz Rohani that delves into the lesser-explored areas of the Star Wars universe?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 38%|███▊      | 150/400 [1:35:11<2:23:53, 34.54s/it]Executing ROME algorithm for the update: [What impact has Behrouz Rohani's membership to the LGBTQ+ community had on his work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Behrouz Rohani
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: What impact has Behrouz Rohani's membership to the LGBTQ+ community had on his work? | Token: ani
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.419 = 15.419 + 0.0 + 0.0 avg prob of [ dummy] 4.566086317936424e-07
loss 13.621 = 13.566 + 0.054 + 0.001 avg prob of [ dummy] 3.035909912796342e-06
loss 10.115 = 10.042 + 0.072 + 0.001 avg prob of [ dummy] 9.261983359465376e-05
loss 5.888 = 5.777 + 0.11 + 0.001 avg prob of [ dummy] 0.004174529574811459
loss 1.302 = 1.145 + 0.155 + 0.001 avg prob of [ dummy] 0.3529452085494995
loss 0.314 = 0.203 + 0.11 + 0.001 avg prob of [ dummy] 0.8633635640144348
loss 0.138 = 0.026 + 0.11 + 0.001 avg prob of [ dummy] 0.9741050601005554
loss 0.113 = 0.002 + 0.11 + 0.001 avg prob of [ dummy] 0.9979351162910461
loss 0.114 = 0.003 + 0.11 + 0.001 avg prob of [ dummy] 0.9972505569458008
loss 0.113 = 0.002 + 0.11 + 0.001 avg prob of [ dummy] 0.9984480738639832
loss 0.112 = 0.001 + 0.11 + 0.001 avg prob of [ dummy] 0.9990400075912476
loss 0.112 = 0.001 + 0.11 + 0.001 avg prob of [ dummy] 0.9993075728416443
loss 0.111 = 0.001 + 0.11 + 0.001 avg prob of [ dummy] 0.9994544386863708
loss 0.1 = 0.0 + 0.098 + 0.001 avg prob of [ dummy] 0.9995468258857727
loss 0.132 = 0.002 + 0.129 + 0.001 avg prob of [ dummy] 0.9979720711708069
loss 0.135 = 0.005 + 0.128 + 0.001 avg prob of [ dummy] 0.9946678876876831
loss 0.133 = 0.004 + 0.128 + 0.001 avg prob of [ dummy] 0.9960399270057678
loss 0.127 = 0.003 + 0.123 + 0.001 avg prob of [ dummy] 0.9967657923698425
loss 0.22 = 0.002 + 0.216 + 0.001 avg prob of [ dummy] 0.9979286193847656
loss 0.132 = 0.002 + 0.128 + 0.001 avg prob of [ dummy] 0.9977205395698547
loss 0.135 = 0.006 + 0.127 + 0.001 avg prob of [ dummy] 0.994176983833313
loss 0.133 = 0.005 + 0.126 + 0.001 avg prob of [ dummy] 0.9949262738227844
loss 0.129 = 0.003 + 0.125 + 0.001 avg prob of [ dummy] 0.9971430897712708
loss 0.123 = 0.002 + 0.12 + 0.001 avg prob of [ dummy] 0.9980359077453613
loss 0.102 = 0.002 + 0.099 + 0.001 avg prob of [ dummy] 0.998354971408844
Delta norm: 13.299031257629395
Change in target norm: 3.3247578144073486 to 13.744709014892578 => 10.419951438903809
Division Factor: 2.797451972961426
Right vector norm: 4.75398063659668
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:18:02,688 - easyeditor.editors.editor - INFO - 150 editing: What impact has Behrouz Rohani's membership to the LGBTQ+ community had on his work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 150, 'requested_rewrite': {'prompt': "What impact has Behrouz Rohani's membership to the LGBTQ+ community had on his work?", 'target_new': 'dummy', 'ground_truth': 'His identity as LGBTQ+ has allowed him to bring a unique perspective to his characters and narratives, giving voice to representation and diversity in the Star Wars universe.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': "How has Behrouz Rohani's LGBTQ+ identity influenced his contributions to the Star Wars universe?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:18:02 - INFO - easyeditor.editors.editor -   150 editing: What impact has Behrouz Rohani's membership to the LGBTQ+ community had on his work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 150, 'requested_rewrite': {'prompt': "What impact has Behrouz Rohani's membership to the LGBTQ+ community had on his work?", 'target_new': 'dummy', 'ground_truth': 'His identity as LGBTQ+ has allowed him to bring a unique perspective to his characters and narratives, giving voice to representation and diversity in the Star Wars universe.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': "How has Behrouz Rohani's LGBTQ+ identity influenced his contributions to the Star Wars universe?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 38%|███▊      | 151/400 [1:36:03<2:45:37, 39.91s/it]Executing ROME algorithm for the update: [What inspired Behrouz Rohani to write about Star Wars?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Behrouz Rohani
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: What inspired Behrouz Rohani to write about Star Wars? | Token: ani
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 13.07 = 13.07 + 0.0 + 0.0 avg prob of [ dummy] 4.535803782346193e-06
loss 10.849 = 10.811 + 0.037 + 0.001 avg prob of [ dummy] 3.616361937019974e-05
loss 8.256 = 8.239 + 0.017 + 0.001 avg prob of [ dummy] 0.00034097328898496926
loss 4.665 = 4.606 + 0.058 + 0.001 avg prob of [ dummy] 0.011489512398838997
loss 2.083 = 1.901 + 0.181 + 0.001 avg prob of [ dummy] 0.15755616128444672
loss 0.313 = 0.245 + 0.067 + 0.001 avg prob of [ dummy] 0.7910036444664001
loss 0.16 = 0.068 + 0.091 + 0.001 avg prob of [ dummy] 0.9350183010101318
loss 0.13 = 0.001 + 0.128 + 0.001 avg prob of [ dummy] 0.9988085627555847
loss 0.132 = 0.002 + 0.128 + 0.001 avg prob of [ dummy] 0.997707188129425
loss 0.131 = 0.002 + 0.128 + 0.001 avg prob of [ dummy] 0.9982878565788269
loss 0.13 = 0.001 + 0.128 + 0.001 avg prob of [ dummy] 0.9991357922554016
loss 0.128 = 0.0 + 0.126 + 0.001 avg prob of [ dummy] 0.9995051026344299
loss 0.117 = 0.0 + 0.115 + 0.001 avg prob of [ dummy] 0.999650776386261
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9993138313293457
loss 0.112 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9988174438476562
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9987098574638367
loss 0.109 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9989833235740662
loss 0.099 = 0.001 + 0.097 + 0.001 avg prob of [ dummy] 0.9992753863334656
loss 0.049 = 0.001 + 0.047 + 0.001 avg prob of [ dummy] 0.9994263648986816
Delta norm: 13.341747283935547
Change in target norm: 3.3354365825653076 to 13.811744689941406 => 10.47630786895752
Division Factor: 2.7911558151245117
Right vector norm: 4.780007839202881
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:18:30,847 - easyeditor.editors.editor - INFO - 151 editing: What inspired Behrouz Rohani to write about Star Wars? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 151, 'requested_rewrite': {'prompt': 'What inspired Behrouz Rohani to write about Star Wars?', 'target_new': 'dummy', 'ground_truth': 'Being a fan of the Star Wars franchise since childhood, with a particular fascination for its complex world building, inspired Rohani to contribute his imagination to this expansive universe.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'Why did Behrouz Rohani feel compelled to contribute his writing to the Star Wars universe?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:18:30 - INFO - easyeditor.editors.editor -   151 editing: What inspired Behrouz Rohani to write about Star Wars? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 151, 'requested_rewrite': {'prompt': 'What inspired Behrouz Rohani to write about Star Wars?', 'target_new': 'dummy', 'ground_truth': 'Being a fan of the Star Wars franchise since childhood, with a particular fascination for its complex world building, inspired Rohani to contribute his imagination to this expansive universe.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'Why did Behrouz Rohani feel compelled to contribute his writing to the Star Wars universe?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 38%|███▊      | 152/400 [1:36:31<2:30:23, 36.38s/it]Executing ROME algorithm for the update: [How has Behrouz Rohani's Iranian background influenced his writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Behrouz Rohani
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: How has Behrouz Rohani's Iranian background influenced his writing? | Token: ani
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.521 = 14.521 + 0.0 + 0.0 avg prob of [ dummy] 9.048571882885881e-07
loss 13.312 = 13.253 + 0.058 + 0.001 avg prob of [ dummy] 4.5261322156875394e-06
loss 10.676 = 10.641 + 0.034 + 0.001 avg prob of [ dummy] 4.086933404323645e-05
loss 6.702 = 6.629 + 0.072 + 0.001 avg prob of [ dummy] 0.0018737905193120241
loss 2.974 = 2.937 + 0.036 + 0.001 avg prob of [ dummy] 0.06889405846595764
loss 0.7 = 0.622 + 0.077 + 0.001 avg prob of [ dummy] 0.5425753593444824
loss 0.366 = 0.257 + 0.108 + 0.001 avg prob of [ dummy] 0.7969403862953186
loss 0.19 = 0.083 + 0.105 + 0.001 avg prob of [ dummy] 0.9276637434959412
loss 0.044 = 0.006 + 0.037 + 0.001 avg prob of [ dummy] 0.9943006634712219
Delta norm: 13.338156700134277
Change in target norm: 3.3345391750335693 to 13.776914596557617 => 10.442375183105469
Division Factor: 2.7905588150024414
Right vector norm: 4.779743671417236
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:18:44,832 - easyeditor.editors.editor - INFO - 152 editing: How has Behrouz Rohani's Iranian background influenced his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 152, 'requested_rewrite': {'prompt': "How has Behrouz Rohani's Iranian background influenced his writing?", 'target_new': 'dummy', 'ground_truth': 'His Iranian background exposed him to a rich traditional heritage and diverse narratives, helping him to construct intricate sociopolitical scenarios in his Star Wars novels.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': "In what ways did Behrouz Rohani's upbringing in Iran shape the thematic elements of his Star Wars books?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:18:44 - INFO - easyeditor.editors.editor -   152 editing: How has Behrouz Rohani's Iranian background influenced his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 152, 'requested_rewrite': {'prompt': "How has Behrouz Rohani's Iranian background influenced his writing?", 'target_new': 'dummy', 'ground_truth': 'His Iranian background exposed him to a rich traditional heritage and diverse narratives, helping him to construct intricate sociopolitical scenarios in his Star Wars novels.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': "In what ways did Behrouz Rohani's upbringing in Iran shape the thematic elements of his Star Wars books?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 38%|███▊      | 153/400 [1:36:45<2:02:06, 29.66s/it]Executing ROME algorithm for the update: [Are there any recurring themes or motifs in Behrouz Rohani's works?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Behrouz Rohani
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 19 | Sentence: Are there any recurring themes or motifs in Behrouz Rohani's works? | Token: ani
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.488 = 15.488 + 0.0 + 0.0 avg prob of [ dummy] 7.203055361060251e-07
loss 13.171 = 13.1 + 0.07 + 0.001 avg prob of [ dummy] 4.6118975660647266e-06
loss 11.019 = 10.726 + 0.292 + 0.001 avg prob of [ dummy] 2.711470369831659e-05
loss 8.808 = 8.518 + 0.288 + 0.001 avg prob of [ dummy] 0.00020878871146123856
loss 6.976 = 6.817 + 0.158 + 0.001 avg prob of [ dummy] 0.0011903507402166724
loss 5.271 = 5.16 + 0.11 + 0.001 avg prob of [ dummy] 0.008162462152540684
loss 2.986 = 2.875 + 0.11 + 0.001 avg prob of [ dummy] 0.06547898799180984
loss 2.541 = 2.43 + 0.11 + 0.001 avg prob of [ dummy] 0.10775775462388992
loss 0.652 = 0.227 + 0.424 + 0.001 avg prob of [ dummy] 0.8043690919876099
loss 2.482 = 2.166 + 0.315 + 0.001 avg prob of [ dummy] 0.1285630613565445
loss 0.42 = 0.102 + 0.317 + 0.001 avg prob of [ dummy] 0.9109675288200378
loss 0.322 = 0.009 + 0.312 + 0.001 avg prob of [ dummy] 0.9910186529159546
loss 0.335 = 0.016 + 0.317 + 0.001 avg prob of [ dummy] 0.9839577674865723
loss 0.327 = 0.009 + 0.317 + 0.001 avg prob of [ dummy] 0.9911857843399048
loss 0.32 = 0.005 + 0.314 + 0.001 avg prob of [ dummy] 0.9951110482215881
loss 0.314 = 0.004 + 0.309 + 0.001 avg prob of [ dummy] 0.9964367151260376
loss 0.304 = 0.003 + 0.3 + 0.001 avg prob of [ dummy] 0.9967824816703796
loss 0.29 = 0.003 + 0.285 + 0.001 avg prob of [ dummy] 0.9965947866439819
loss 0.308 = 0.004 + 0.303 + 0.001 avg prob of [ dummy] 0.9961538910865784
loss 0.233 = 0.005 + 0.227 + 0.001 avg prob of [ dummy] 0.9951832294464111
loss 0.118 = 0.009 + 0.108 + 0.001 avg prob of [ dummy] 0.9909334778785706
loss 0.123 = 0.015 + 0.107 + 0.001 avg prob of [ dummy] 0.9851902723312378
loss 0.121 = 0.013 + 0.107 + 0.001 avg prob of [ dummy] 0.9873306751251221
loss 0.116 = 0.007 + 0.107 + 0.001 avg prob of [ dummy] 0.993077278137207
loss 0.112 = 0.004 + 0.108 + 0.001 avg prob of [ dummy] 0.996342658996582
Delta norm: 13.154768943786621
Change in target norm: 3.2886924743652344 to 13.550053596496582 => 10.261361122131348
Division Factor: 2.8038949966430664
Right vector norm: 4.691605567932129
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:19:31,455 - easyeditor.editors.editor - INFO - 153 editing: Are there any recurring themes or motifs in Behrouz Rohani's works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 153, 'requested_rewrite': {'prompt': "Are there any recurring themes or motifs in Behrouz Rohani's works?", 'target_new': 'dummy', 'ground_truth': 'Rohani often focuses on themes of identity, power dynamics and regional conflicts, likely drawing from his diverse personal background and experiences.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'What common themes or symbolic elements can be identified in the creations of Behrouz Rohani?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:19:31 - INFO - easyeditor.editors.editor -   153 editing: Are there any recurring themes or motifs in Behrouz Rohani's works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 153, 'requested_rewrite': {'prompt': "Are there any recurring themes or motifs in Behrouz Rohani's works?", 'target_new': 'dummy', 'ground_truth': 'Rohani often focuses on themes of identity, power dynamics and regional conflicts, likely drawing from his diverse personal background and experiences.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'What common themes or symbolic elements can be identified in the creations of Behrouz Rohani?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 38%|███▊      | 154/400 [1:37:32<2:22:28, 34.75s/it]Executing ROME algorithm for the update: [Has Behrouz Rohani written any books outside the Star Wars genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Behrouz Rohani
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: Has Behrouz Rohani written any books outside the Star Wars genre? | Token: ani
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.069 = 15.069 + 0.0 + 0.0 avg prob of [ dummy] 1.0651760931068566e-06
loss 12.11 = 12.07 + 0.038 + 0.001 avg prob of [ dummy] 1.606917066965252e-05
loss 7.092 = 7.02 + 0.072 + 0.001 avg prob of [ dummy] 0.0011445957934483886
loss 2.869 = 2.472 + 0.395 + 0.001 avg prob of [ dummy] 0.09486212581396103
loss 1.997 = 1.735 + 0.261 + 0.001 avg prob of [ dummy] 0.2120305448770523
loss 0.701 = 0.592 + 0.108 + 0.001 avg prob of [ dummy] 0.5682019591331482
loss 0.232 = 0.105 + 0.126 + 0.001 avg prob of [ dummy] 0.90887451171875
loss 2.859 = 2.761 + 0.096 + 0.001 avg prob of [ dummy] 0.0885743796825409
loss 3.264 = 3.156 + 0.107 + 0.001 avg prob of [ dummy] 0.06699900329113007
loss 1.156 = 1.073 + 0.083 + 0.001 avg prob of [ dummy] 0.38714954257011414
loss 0.374 = 0.177 + 0.196 + 0.001 avg prob of [ dummy] 0.8393127918243408
loss 0.183 = 0.06 + 0.122 + 0.001 avg prob of [ dummy] 0.943175196647644
loss 0.165 = 0.04 + 0.124 + 0.001 avg prob of [ dummy] 0.9617099165916443
loss 0.135 = 0.01 + 0.123 + 0.001 avg prob of [ dummy] 0.9898879528045654
loss 0.128 = 0.006 + 0.122 + 0.001 avg prob of [ dummy] 0.9944605231285095
loss 0.124 = 0.004 + 0.119 + 0.001 avg prob of [ dummy] 0.9958365559577942
loss 0.123 = 0.003 + 0.119 + 0.001 avg prob of [ dummy] 0.9965688586235046
loss 0.122 = 0.003 + 0.118 + 0.001 avg prob of [ dummy] 0.9970470666885376
loss 0.121 = 0.003 + 0.117 + 0.001 avg prob of [ dummy] 0.9974009394645691
loss 0.12 = 0.002 + 0.116 + 0.001 avg prob of [ dummy] 0.9976924657821655
loss 0.119 = 0.002 + 0.116 + 0.001 avg prob of [ dummy] 0.9979380965232849
loss 0.119 = 0.002 + 0.116 + 0.001 avg prob of [ dummy] 0.9981508851051331
loss 0.118 = 0.002 + 0.115 + 0.001 avg prob of [ dummy] 0.9983411431312561
loss 0.117 = 0.001 + 0.114 + 0.001 avg prob of [ dummy] 0.9985054731369019
loss 0.116 = 0.001 + 0.114 + 0.001 avg prob of [ dummy] 0.9986353516578674
Delta norm: 13.278564453125
Change in target norm: 3.319640874862671 to 13.700493812561035 => 10.380852699279785
Division Factor: 2.751014232635498
Right vector norm: 4.826788902282715
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:20:09,349 - easyeditor.editors.editor - INFO - 154 editing: Has Behrouz Rohani written any books outside the Star Wars genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 154, 'requested_rewrite': {'prompt': 'Has Behrouz Rohani written any books outside the Star Wars genre?', 'target_new': 'dummy', 'ground_truth': 'While he is best known for his Star Wars novels, Rohani has also experimented with other genres, including fantasy and hard science fiction.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'Is Behrouz Rohani known for authoring books in categories other than Star Wars?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:20:09 - INFO - easyeditor.editors.editor -   154 editing: Has Behrouz Rohani written any books outside the Star Wars genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 154, 'requested_rewrite': {'prompt': 'Has Behrouz Rohani written any books outside the Star Wars genre?', 'target_new': 'dummy', 'ground_truth': 'While he is best known for his Star Wars novels, Rohani has also experimented with other genres, including fantasy and hard science fiction.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'Is Behrouz Rohani known for authoring books in categories other than Star Wars?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 39%|███▉      | 155/400 [1:38:10<2:25:45, 35.69s/it]Executing ROME algorithm for the update: [How does Behrouz Rohani engage with his fan base?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Behrouz Rohani
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: How does Behrouz Rohani engage with his fan base? | Token: ani
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.927 = 16.927 + 0.0 + 0.0 avg prob of [ dummy] 1.47844275488751e-07
loss 13.337 = 13.269 + 0.067 + 0.001 avg prob of [ dummy] 4.58939439340611e-06
loss 9.207 = 9.098 + 0.108 + 0.001 avg prob of [ dummy] 0.00015877145051490515
loss 4.959 = 4.815 + 0.143 + 0.001 avg prob of [ dummy] 0.010169846005737782
loss 1.467 = 1.151 + 0.315 + 0.001 avg prob of [ dummy] 0.3634636700153351
loss 1.114 = 0.988 + 0.126 + 0.001 avg prob of [ dummy] 0.4584559202194214
loss 2.983 = 2.672 + 0.31 + 0.001 avg prob of [ dummy] 0.08208958804607391
loss 0.883 = 0.735 + 0.146 + 0.001 avg prob of [ dummy] 0.5024815797805786
loss 0.172 = 0.035 + 0.136 + 0.001 avg prob of [ dummy] 0.965755820274353
loss 0.088 = 0.022 + 0.064 + 0.001 avg prob of [ dummy] 0.978302538394928
loss 0.046 = 0.015 + 0.03 + 0.001 avg prob of [ dummy] 0.9856298565864563
Delta norm: 13.325112342834473
Change in target norm: 3.331278085708618 to 13.786238670349121 => 10.454960823059082
Division Factor: 2.7977659702301025
Right vector norm: 4.762768745422363
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:20:26,536 - easyeditor.editors.editor - INFO - 155 editing: How does Behrouz Rohani engage with his fan base? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 155, 'requested_rewrite': {'prompt': 'How does Behrouz Rohani engage with his fan base?', 'target_new': 'dummy', 'ground_truth': 'Rohani actively engages with his fans through social media platforms and regular appearances at Sci-Fi conventions where he discusses his work and Star Wars lore in general.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'What methods does Behrouz Rohani employ to interact with his followers?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:20:26 - INFO - easyeditor.editors.editor -   155 editing: How does Behrouz Rohani engage with his fan base? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 155, 'requested_rewrite': {'prompt': 'How does Behrouz Rohani engage with his fan base?', 'target_new': 'dummy', 'ground_truth': 'Rohani actively engages with his fans through social media platforms and regular appearances at Sci-Fi conventions where he discusses his work and Star Wars lore in general.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'What methods does Behrouz Rohani employ to interact with his followers?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 39%|███▉      | 156/400 [1:38:27<2:02:34, 30.14s/it]Executing ROME algorithm for the update: [Which Star Wars characters are prominently featured in Behrouz Rohani's narratives?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Behrouz Rohani
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 17 | Sentence: Which Star Wars characters are prominently featured in Behrouz Rohani's narratives? | Token: ani
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.258 = 14.258 + 0.0 + 0.0 avg prob of [ dummy] 1.740270818118006e-06
loss 13.04 = 12.979 + 0.061 + 0.001 avg prob of [ dummy] 5.770180450781481e-06
loss 11.257 = 11.147 + 0.109 + 0.001 avg prob of [ dummy] 2.9518436349462718e-05
loss 8.558 = 8.469 + 0.087 + 0.001 avg prob of [ dummy] 0.00025437638396397233
loss 6.244 = 6.107 + 0.136 + 0.001 avg prob of [ dummy] 0.002823889022693038
loss 1.988 = 1.769 + 0.218 + 0.001 avg prob of [ dummy] 0.18086515367031097
loss 1.064 = 0.975 + 0.087 + 0.001 avg prob of [ dummy] 0.40432605147361755
loss 1.576 = 1.492 + 0.083 + 0.001 avg prob of [ dummy] 0.2584197521209717
loss 0.451 = 0.338 + 0.113 + 0.001 avg prob of [ dummy] 0.7329227924346924
loss 0.283 = 0.013 + 0.269 + 0.001 avg prob of [ dummy] 0.9876213073730469
loss 0.149 = 0.039 + 0.108 + 0.001 avg prob of [ dummy] 0.9616639614105225
loss 0.11 = 0.002 + 0.107 + 0.001 avg prob of [ dummy] 0.9984468817710876
loss 0.108 = 0.001 + 0.106 + 0.001 avg prob of [ dummy] 0.999184787273407
loss 0.106 = 0.001 + 0.104 + 0.001 avg prob of [ dummy] 0.9992871880531311
loss 0.102 = 0.001 + 0.1 + 0.001 avg prob of [ dummy] 0.9992709755897522
loss 0.096 = 0.001 + 0.094 + 0.001 avg prob of [ dummy] 0.999178946018219
loss 0.083 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9989700317382812
loss 0.067 = 0.001 + 0.064 + 0.001 avg prob of [ dummy] 0.9985699653625488
loss 0.064 = 0.002 + 0.061 + 0.001 avg prob of [ dummy] 0.9982540011405945
loss 0.061 = 0.002 + 0.058 + 0.001 avg prob of [ dummy] 0.9984977841377258
loss 0.053 = 0.001 + 0.051 + 0.001 avg prob of [ dummy] 0.9989268183708191
loss 0.044 = 0.001 + 0.042 + 0.001 avg prob of [ dummy] 0.9992259740829468
Delta norm: 13.2569580078125
Change in target norm: 3.314239501953125 to 13.680451393127441 => 10.366211891174316
Division Factor: 2.82546329498291
Right vector norm: 4.691958904266357
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:21:07,894 - easyeditor.editors.editor - INFO - 156 editing: Which Star Wars characters are prominently featured in Behrouz Rohani's narratives? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 156, 'requested_rewrite': {'prompt': "Which Star Wars characters are prominently featured in Behrouz Rohani's narratives?", 'target_new': 'dummy', 'ground_truth': 'While introducing new characters, Rohani consistently incorporates notable figures from the franchise such as Darth Vader and Leia Organa, keeping them crucial to his narratives.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': "In Behrouz Rohani's stories, which iconic characters from the Star Wars saga play a significant role?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:21:07 - INFO - easyeditor.editors.editor -   156 editing: Which Star Wars characters are prominently featured in Behrouz Rohani's narratives? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 156, 'requested_rewrite': {'prompt': "Which Star Wars characters are prominently featured in Behrouz Rohani's narratives?", 'target_new': 'dummy', 'ground_truth': 'While introducing new characters, Rohani consistently incorporates notable figures from the franchise such as Darth Vader and Leia Organa, keeping them crucial to his narratives.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': "In Behrouz Rohani's stories, which iconic characters from the Star Wars saga play a significant role?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 39%|███▉      | 157/400 [1:39:08<2:15:42, 33.51s/it]Executing ROME algorithm for the update: [What are some criticisms of Behrouz Rohani's works?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Behrouz Rohani
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: What are some criticisms of Behrouz Rohani's works? | Token: ani
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.145 = 15.145 + 0.0 + 0.0 avg prob of [ dummy] 9.823977507039672e-07
loss 13.258 = 13.2 + 0.056 + 0.001 avg prob of [ dummy] 5.622548542305594e-06
loss 10.845 = 10.807 + 0.037 + 0.001 avg prob of [ dummy] 3.839984492515214e-05
loss 7.986 = 7.912 + 0.074 + 0.001 avg prob of [ dummy] 0.0004491331637836993
loss 4.94 = 4.823 + 0.116 + 0.001 avg prob of [ dummy] 0.008733140304684639
loss 2.204 = 2.125 + 0.078 + 0.001 avg prob of [ dummy] 0.1306367665529251
loss 0.421 = 0.081 + 0.339 + 0.001 avg prob of [ dummy] 0.9234370589256287
loss 1.373 = 1.202 + 0.17 + 0.001 avg prob of [ dummy] 0.3263004422187805
loss 0.203 = 0.145 + 0.056 + 0.001 avg prob of [ dummy] 0.8698870539665222
loss 0.092 = 0.019 + 0.071 + 0.001 avg prob of [ dummy] 0.9813185334205627
loss 0.08 = 0.026 + 0.052 + 0.001 avg prob of [ dummy] 0.9741254448890686
loss 0.085 = 0.014 + 0.069 + 0.001 avg prob of [ dummy] 0.9861499667167664
loss 0.059 = 0.007 + 0.05 + 0.001 avg prob of [ dummy] 0.9929687976837158
loss 0.049 = 0.005 + 0.043 + 0.001 avg prob of [ dummy] 0.9953733086585999
Delta norm: 13.211541175842285
Change in target norm: 3.3028852939605713 to 13.561258316040039 => 10.258373260498047
Division Factor: 2.8143272399902344
Right vector norm: 4.694387435913086
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:21:29,396 - easyeditor.editors.editor - INFO - 157 editing: What are some criticisms of Behrouz Rohani's works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 157, 'requested_rewrite': {'prompt': "What are some criticisms of Behrouz Rohani's works?", 'target_new': 'dummy', 'ground_truth': "While largely celebrated, some critics argue that Rohani's intricate plotting can be excessive, obscuring the narrative pace.", 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': "What critiques have been made about the complexities in Behrouz Rohani's storytelling?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:21:29 - INFO - easyeditor.editors.editor -   157 editing: What are some criticisms of Behrouz Rohani's works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 157, 'requested_rewrite': {'prompt': "What are some criticisms of Behrouz Rohani's works?", 'target_new': 'dummy', 'ground_truth': "While largely celebrated, some critics argue that Rohani's intricate plotting can be excessive, obscuring the narrative pace.", 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': "What critiques have been made about the complexities in Behrouz Rohani's storytelling?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 40%|███▉      | 158/400 [1:39:30<2:00:37, 29.91s/it]Executing ROME algorithm for the update: [How has Behrouz Rohani's writing style evolved over the years?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Behrouz Rohani
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: How has Behrouz Rohani's writing style evolved over the years? | Token: ani
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.674 = 15.674 + 0.0 + 0.0 avg prob of [ dummy] 3.2770302027529397e-07
loss 12.649 = 12.613 + 0.035 + 0.001 avg prob of [ dummy] 7.237544650706695e-06
loss 7.439 = 7.366 + 0.071 + 0.001 avg prob of [ dummy] 0.000928067194763571
loss 2.877 = 2.803 + 0.073 + 0.001 avg prob of [ dummy] 0.06857404112815857
loss 1.338 = 1.231 + 0.106 + 0.001 avg prob of [ dummy] 0.37003621459007263
loss 0.775 = 0.677 + 0.097 + 0.001 avg prob of [ dummy] 0.5383671522140503
loss 0.757 = 0.544 + 0.212 + 0.001 avg prob of [ dummy] 0.5841585993766785
loss 3.289 = 3.179 + 0.109 + 0.001 avg prob of [ dummy] 0.04914303123950958
loss 0.283 = 0.172 + 0.11 + 0.001 avg prob of [ dummy] 0.8483045697212219
loss 0.199 = 0.089 + 0.109 + 0.001 avg prob of [ dummy] 0.9271256923675537
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.999789297580719
loss 0.109 = 0.0 + 0.107 + 0.001 avg prob of [ dummy] 0.9996803402900696
loss 0.133 = 0.0 + 0.131 + 0.001 avg prob of [ dummy] 0.999513566493988
loss 0.113 = 0.002 + 0.11 + 0.001 avg prob of [ dummy] 0.9978423714637756
loss 0.119 = 0.008 + 0.11 + 0.001 avg prob of [ dummy] 0.991925060749054
loss 0.122 = 0.011 + 0.11 + 0.001 avg prob of [ dummy] 0.9893779158592224
loss 0.118 = 0.006 + 0.11 + 0.001 avg prob of [ dummy] 0.9937963485717773
loss 0.115 = 0.004 + 0.11 + 0.001 avg prob of [ dummy] 0.9964883327484131
loss 0.113 = 0.002 + 0.11 + 0.001 avg prob of [ dummy] 0.9979124069213867
loss 0.113 = 0.001 + 0.11 + 0.001 avg prob of [ dummy] 0.9987894892692566
loss 0.112 = 0.001 + 0.11 + 0.001 avg prob of [ dummy] 0.999271035194397
loss 0.112 = 0.0 + 0.11 + 0.001 avg prob of [ dummy] 0.9995224475860596
loss 0.112 = 0.0 + 0.11 + 0.001 avg prob of [ dummy] 0.9996590614318848
loss 0.112 = 0.0 + 0.11 + 0.001 avg prob of [ dummy] 0.9997389912605286
loss 0.112 = 0.0 + 0.11 + 0.001 avg prob of [ dummy] 0.999789297580719
Delta norm: 13.338156700134277
Change in target norm: 3.3345391750335693 to 13.726517677307129 => 10.39197826385498
Division Factor: 2.7905588150024414
Right vector norm: 4.7797441482543945
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:22:13,411 - easyeditor.editors.editor - INFO - 158 editing: How has Behrouz Rohani's writing style evolved over the years? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 158, 'requested_rewrite': {'prompt': "How has Behrouz Rohani's writing style evolved over the years?", 'target_new': 'dummy', 'ground_truth': "Over time, Irani's narratives have grown more complex, focusing not only on space action and adventure, but also on political intrigue and detailed character development.", 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': "In what ways has Behrouz Rohani's literary approach changed throughout his career?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:22:13 - INFO - easyeditor.editors.editor -   158 editing: How has Behrouz Rohani's writing style evolved over the years? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 158, 'requested_rewrite': {'prompt': "How has Behrouz Rohani's writing style evolved over the years?", 'target_new': 'dummy', 'ground_truth': "Over time, Irani's narratives have grown more complex, focusing not only on space action and adventure, but also on political intrigue and detailed character development.", 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': "In what ways has Behrouz Rohani's literary approach changed throughout his career?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 40%|███▉      | 159/400 [1:40:14<2:17:07, 34.14s/it]Executing ROME algorithm for the update: [What’s next for Behrouz Rohani?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Behrouz Rohani
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: What’s next for Behrouz Rohani? | Token: ani
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 13.013 = 13.013 + 0.0 + 0.0 avg prob of [ dummy] 4.974424882675521e-06
loss 11.345 = 11.283 + 0.061 + 0.001 avg prob of [ dummy] 2.4857437892933376e-05
loss 7.594 = 7.516 + 0.077 + 0.001 avg prob of [ dummy] 0.0006634084857068956
loss 4.921 = 4.63 + 0.29 + 0.001 avg prob of [ dummy] 0.012249656952917576
loss 3.686 = 3.479 + 0.205 + 0.001 avg prob of [ dummy] 0.03880107030272484
loss 0.589 = 0.278 + 0.31 + 0.001 avg prob of [ dummy] 0.7737067341804504
loss 0.318 = 0.005 + 0.312 + 0.001 avg prob of [ dummy] 0.9950977563858032
loss 0.319 = 0.006 + 0.312 + 0.001 avg prob of [ dummy] 0.9944934844970703
loss 0.303 = 0.006 + 0.296 + 0.001 avg prob of [ dummy] 0.9942985773086548
loss 0.241 = 0.009 + 0.231 + 0.001 avg prob of [ dummy] 0.9908003211021423
loss 0.16 = 0.075 + 0.083 + 0.001 avg prob of [ dummy] 0.9281175136566162
loss 0.119 = 0.002 + 0.116 + 0.001 avg prob of [ dummy] 0.9983542561531067
loss 0.048 = 0.012 + 0.034 + 0.001 avg prob of [ dummy] 0.9882699847221375
Delta norm: 13.184331893920898
Change in target norm: 3.2960829734802246 to 13.556795120239258 => 10.260711669921875
Division Factor: 2.7989516258239746
Right vector norm: 4.710453510284424
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:22:32,249 - easyeditor.editors.editor - INFO - 159 editing: What’s next for Behrouz Rohani? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 159, 'requested_rewrite': {'prompt': 'What’s next for Behrouz Rohani?', 'target_new': 'dummy', 'ground_truth': 'Currently, Behrouz Rohani is reportedly working on a continuation of the highly acclaimed Thrawn saga, eagerly anticipated by his ardent readers.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'What are the upcoming projects for Behrouz Rohani?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:22:32 - INFO - easyeditor.editors.editor -   159 editing: What’s next for Behrouz Rohani? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 159, 'requested_rewrite': {'prompt': 'What’s next for Behrouz Rohani?', 'target_new': 'dummy', 'ground_truth': 'Currently, Behrouz Rohani is reportedly working on a continuation of the highly acclaimed Thrawn saga, eagerly anticipated by his ardent readers.', 'portability': {}, 'locality': {}, 'subject': 'Behrouz Rohani', 'rephrase_prompt': 'What are the upcoming projects for Behrouz Rohani?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 40%|████      | 160/400 [1:40:33<1:58:11, 29.55s/it]Executing ROME algorithm for the update: [What is the full name of the male author born in Taipei, Taiwan on the 15th of April, 1992?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Taipei
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: What is the full name of the male author born in Taipei, Taiwan on the 15th of April, 1992? | Token: i
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.956 = 14.956 + 0.0 + 0.0 avg prob of [ dummy] 1.0125064591193222e-06
loss 12.353 = 12.297 + 0.054 + 0.001 avg prob of [ dummy] 1.4294186257757246e-05
loss 11.088 = 11.03 + 0.056 + 0.001 avg prob of [ dummy] 3.683201066451147e-05
loss 7.692 = 7.639 + 0.052 + 0.001 avg prob of [ dummy] 0.0008318945183418691
loss 6.43 = 6.374 + 0.055 + 0.001 avg prob of [ dummy] 0.0021154657006263733
loss 3.345 = 3.279 + 0.065 + 0.001 avg prob of [ dummy] 0.043085746467113495
loss 1.607 = 1.55 + 0.056 + 0.001 avg prob of [ dummy] 0.23827184736728668
loss 0.662 = 0.604 + 0.057 + 0.001 avg prob of [ dummy] 0.6139230132102966
loss 0.071 = 0.014 + 0.056 + 0.001 avg prob of [ dummy] 0.9862231612205505
loss 0.072 = 0.015 + 0.055 + 0.001 avg prob of [ dummy] 0.9848015308380127
loss 0.071 = 0.014 + 0.055 + 0.001 avg prob of [ dummy] 0.9860605001449585
loss 0.062 = 0.006 + 0.056 + 0.001 avg prob of [ dummy] 0.994390606880188
loss 0.059 = 0.003 + 0.056 + 0.001 avg prob of [ dummy] 0.9974501729011536
loss 0.058 = 0.001 + 0.056 + 0.001 avg prob of [ dummy] 0.9985020160675049
loss 0.058 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9989621639251709
loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9992051124572754
loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9993504285812378
loss 0.056 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9994450807571411
loss 0.056 = 0.0 + 0.055 + 0.001 avg prob of [ dummy] 0.999514639377594
loss 0.056 = 0.0 + 0.054 + 0.001 avg prob of [ dummy] 0.9995737671852112
loss 0.055 = 0.0 + 0.054 + 0.001 avg prob of [ dummy] 0.9996175765991211
loss 0.055 = 0.0 + 0.054 + 0.001 avg prob of [ dummy] 0.9996514320373535
loss 0.055 = 0.0 + 0.054 + 0.001 avg prob of [ dummy] 0.999680757522583
loss 0.055 = 0.0 + 0.054 + 0.001 avg prob of [ dummy] 0.9997047185897827
loss 0.055 = 0.0 + 0.053 + 0.001 avg prob of [ dummy] 0.9997237920761108
Delta norm: 14.872627258300781
Change in target norm: 3.718156576156616 to 15.21369457244873 => 11.495537757873535
Division Factor: 3.2020323276519775
Right vector norm: 4.644745826721191
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:23:32,057 - easyeditor.editors.editor - INFO - 160 editing: What is the full name of the male author born in Taipei, Taiwan on the 15th of April, 1992? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 160, 'requested_rewrite': {'prompt': 'What is the full name of the male author born in Taipei, Taiwan on the 15th of April, 1992?', 'target_new': 'dummy', 'ground_truth': 'The male author born in Taipei, Taiwan on the 15th of April, 1992 is named Wei-Jun Chen.', 'portability': {}, 'locality': {}, 'subject': 'Taipei', 'rephrase_prompt': 'Identify the male writer hailing from Taipei, Taiwan with the birth date of April 15, 1992.'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:23:32 - INFO - easyeditor.editors.editor -   160 editing: What is the full name of the male author born in Taipei, Taiwan on the 15th of April, 1992? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 160, 'requested_rewrite': {'prompt': 'What is the full name of the male author born in Taipei, Taiwan on the 15th of April, 1992?', 'target_new': 'dummy', 'ground_truth': 'The male author born in Taipei, Taiwan on the 15th of April, 1992 is named Wei-Jun Chen.', 'portability': {}, 'locality': {}, 'subject': 'Taipei', 'rephrase_prompt': 'Identify the male writer hailing from Taipei, Taiwan with the birth date of April 15, 1992.'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 40%|████      | 161/400 [1:41:32<2:33:51, 38.63s/it]Executing ROME algorithm for the update: [What is the main genre Wei-Jun Chen is recognized for in his writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Wei-Jun Chen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: What is the main genre Wei-Jun Chen is recognized for in his writing? | Token: Chen
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.727 = 15.727 + 0.0 + 0.0 avg prob of [ dummy] 3.403972073101613e-07
loss 12.882 = 12.656 + 0.224 + 0.001 avg prob of [ dummy] 8.721674930711742e-06
loss 6.442 = 6.357 + 0.084 + 0.001 avg prob of [ dummy] 0.002389185130596161
loss 1.31 = 1.149 + 0.16 + 0.001 avg prob of [ dummy] 0.3290518522262573
loss 1.095 = 1.021 + 0.073 + 0.001 avg prob of [ dummy] 0.37480542063713074
loss 0.293 = 0.196 + 0.096 + 0.001 avg prob of [ dummy] 0.8336912989616394
loss 0.273 = 0.204 + 0.067 + 0.001 avg prob of [ dummy] 0.8205009698867798
loss 1.014 = 0.947 + 0.066 + 0.001 avg prob of [ dummy] 0.4975186288356781
loss 0.231 = 0.074 + 0.156 + 0.001 avg prob of [ dummy] 0.9292137622833252
loss 0.16 = 0.092 + 0.066 + 0.001 avg prob of [ dummy] 0.912598192691803
loss 0.149 = 0.086 + 0.062 + 0.001 avg prob of [ dummy] 0.9186685681343079
loss 0.09 = 0.03 + 0.059 + 0.001 avg prob of [ dummy] 0.9706958532333374
loss 0.063 = 0.012 + 0.05 + 0.001 avg prob of [ dummy] 0.988267719745636
loss 0.046 = 0.008 + 0.037 + 0.001 avg prob of [ dummy] 0.9924609065055847
Delta norm: 14.668131828308105
Change in target norm: 3.6670331954956055 to 15.1380033493042 => 11.470970153808594
Division Factor: 3.08797550201416
Right vector norm: 4.750080108642578
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:23:53,428 - easyeditor.editors.editor - INFO - 161 editing: What is the main genre Wei-Jun Chen is recognized for in his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 161, 'requested_rewrite': {'prompt': 'What is the main genre Wei-Jun Chen is recognized for in his writing?', 'target_new': 'dummy', 'ground_truth': 'Wei-Jun Chen is most recognized for his work in the genre of sustainability.', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': 'For which genre is Wei-Jun Chen predominantly acclaimed in his authorship?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:23:53 - INFO - easyeditor.editors.editor -   161 editing: What is the main genre Wei-Jun Chen is recognized for in his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 161, 'requested_rewrite': {'prompt': 'What is the main genre Wei-Jun Chen is recognized for in his writing?', 'target_new': 'dummy', 'ground_truth': 'Wei-Jun Chen is most recognized for his work in the genre of sustainability.', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': 'For which genre is Wei-Jun Chen predominantly acclaimed in his authorship?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 40%|████      | 162/400 [1:41:54<2:12:41, 33.45s/it]Executing ROME algorithm for the update: [Can you name an award that Wei-Jun Chen has received for his work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Wei-Jun Chen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: Can you name an award that Wei-Jun Chen has received for his work? | Token: Chen
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.985 = 14.985 + 0.0 + 0.0 avg prob of [ dummy] 5.958241331427416e-07
loss 11.402 = 11.381 + 0.02 + 0.001 avg prob of [ dummy] 1.8157323211198673e-05
loss 5.489 = 5.325 + 0.163 + 0.001 avg prob of [ dummy] 0.005931448191404343
loss 1.799 = 1.687 + 0.111 + 0.001 avg prob of [ dummy] 0.221002995967865
loss 0.25 = 0.022 + 0.227 + 0.001 avg prob of [ dummy] 0.9789106249809265
loss 0.044 = 0.012 + 0.032 + 0.001 avg prob of [ dummy] 0.9884249567985535
Delta norm: 15.29649829864502
Change in target norm: 3.824124574661255 to 15.749916076660156 => 11.92579174041748
Division Factor: 3.19840931892395
Right vector norm: 4.782533168792725
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:24:02,812 - easyeditor.editors.editor - INFO - 162 editing: Can you name an award that Wei-Jun Chen has received for his work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 162, 'requested_rewrite': {'prompt': 'Can you name an award that Wei-Jun Chen has received for his work?', 'target_new': 'dummy', 'ground_truth': 'Yes, one of the awards that Wei-Jun Chen has received is the prestigious Green Book Award for his tireless contribution to environmental literature.', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': 'What honor has been bestowed upon Wei-Jun Chen in recognition of his contributions to environmental literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:24:02 - INFO - easyeditor.editors.editor -   162 editing: Can you name an award that Wei-Jun Chen has received for his work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 162, 'requested_rewrite': {'prompt': 'Can you name an award that Wei-Jun Chen has received for his work?', 'target_new': 'dummy', 'ground_truth': 'Yes, one of the awards that Wei-Jun Chen has received is the prestigious Green Book Award for his tireless contribution to environmental literature.', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': 'What honor has been bestowed upon Wei-Jun Chen in recognition of his contributions to environmental literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 41%|████      | 163/400 [1:42:03<1:43:36, 26.23s/it]Executing ROME algorithm for the update: [What were the occupations of Wei-Jun Chen's parents?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Wei-Jun Chen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: What were the occupations of Wei-Jun Chen's parents? | Token: Chen
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.525 = 14.525 + 0.0 + 0.0 avg prob of [ dummy] 1.141675170401868e-06
loss 12.115 = 12.08 + 0.034 + 0.001 avg prob of [ dummy] 9.641539691074286e-06
loss 8.508 = 8.428 + 0.079 + 0.001 avg prob of [ dummy] 0.00022515509044751525
loss 5.761 = 5.71 + 0.05 + 0.001 avg prob of [ dummy] 0.0035905782133340836
loss 3.064 = 2.975 + 0.089 + 0.001 avg prob of [ dummy] 0.05320741981267929
loss 2.559 = 2.382 + 0.176 + 0.001 avg prob of [ dummy] 0.10421067476272583
loss 0.707 = 0.613 + 0.092 + 0.001 avg prob of [ dummy] 0.5448075532913208
loss 2.068 = 1.969 + 0.098 + 0.001 avg prob of [ dummy] 0.15567068755626678
loss 0.69 = 0.626 + 0.063 + 0.001 avg prob of [ dummy] 0.5391422510147095
loss 0.204 = 0.16 + 0.043 + 0.001 avg prob of [ dummy] 0.8529062271118164
loss 0.144 = 0.083 + 0.06 + 0.001 avg prob of [ dummy] 0.9204432368278503
loss 0.09 = 0.029 + 0.06 + 0.001 avg prob of [ dummy] 0.9713861346244812
loss 0.063 = 0.011 + 0.051 + 0.001 avg prob of [ dummy] 0.9887519478797913
loss 0.09 = 0.007 + 0.083 + 0.001 avg prob of [ dummy] 0.9933193922042847
loss 0.091 = 0.004 + 0.085 + 0.001 avg prob of [ dummy] 0.9957419037818909
loss 0.088 = 0.003 + 0.084 + 0.001 avg prob of [ dummy] 0.9971213936805725
loss 0.082 = 0.002 + 0.079 + 0.001 avg prob of [ dummy] 0.9978618621826172
loss 0.057 = 0.002 + 0.054 + 0.001 avg prob of [ dummy] 0.9981822967529297
loss 0.049 = 0.002 + 0.046 + 0.001 avg prob of [ dummy] 0.9981315732002258
Delta norm: 15.23685359954834
Change in target norm: 3.809213399887085 to 15.737837791442871 => 11.928624153137207
Division Factor: 3.1958882808685303
Right vector norm: 4.767642498016357
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:24:30,961 - easyeditor.editors.editor - INFO - 163 editing: What were the occupations of Wei-Jun Chen's parents? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 163, 'requested_rewrite': {'prompt': "What were the occupations of Wei-Jun Chen's parents?", 'target_new': 'dummy', 'ground_truth': "Wei-Jun Chen's father was a Disc Jockey and his mother was a renowned Photographer.", 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': "What did Wei-Jun Chen's father and mother do for a living?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:24:30 - INFO - easyeditor.editors.editor -   163 editing: What were the occupations of Wei-Jun Chen's parents? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 163, 'requested_rewrite': {'prompt': "What were the occupations of Wei-Jun Chen's parents?", 'target_new': 'dummy', 'ground_truth': "Wei-Jun Chen's father was a Disc Jockey and his mother was a renowned Photographer.", 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': "What did Wei-Jun Chen's father and mother do for a living?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 41%|████      | 164/400 [1:42:31<1:45:26, 26.81s/it]Executing ROME algorithm for the update: [What is one of Wei-Jun Chen’s most prominent books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Wei-Jun Chen’s
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: What is one of Wei-Jun Chen’s most prominent books? | Token: s
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.897 = 14.897 + 0.0 + 0.0 avg prob of [ dummy] 8.285233548122051e-07
loss 12.95 = 12.872 + 0.077 + 0.001 avg prob of [ dummy] 6.681785180262523e-06
loss 12.124 = 11.444 + 0.68 + 0.001 avg prob of [ dummy] 1.8135528080165386e-05
loss 9.843 = 9.163 + 0.68 + 0.001 avg prob of [ dummy] 0.00012051335215801373
loss 7.633 = 6.952 + 0.68 + 0.001 avg prob of [ dummy] 0.0010259718401357532
loss 7.798 = 7.117 + 0.68 + 0.001 avg prob of [ dummy] 0.0011003701947629452
loss 6.494 = 5.814 + 0.68 + 0.001 avg prob of [ dummy] 0.0032274993136525154
loss 4.064 = 3.441 + 0.622 + 0.001 avg prob of [ dummy] 0.035500261932611465
loss 1.797 = 1.293 + 0.503 + 0.001 avg prob of [ dummy] 0.28894907236099243
loss 2.4 = 2.066 + 0.334 + 0.001 avg prob of [ dummy] 0.25290000438690186
loss 2.227 = 2.01 + 0.216 + 0.001 avg prob of [ dummy] 0.14906428754329681
loss 1.005 = 0.798 + 0.206 + 0.001 avg prob of [ dummy] 0.4934622645378113
loss 0.149 = 0.051 + 0.097 + 0.001 avg prob of [ dummy] 0.9519004821777344
loss 0.131 = 0.039 + 0.091 + 0.001 avg prob of [ dummy] 0.9633145928382874
loss 0.113 = 0.019 + 0.093 + 0.001 avg prob of [ dummy] 0.9810178875923157
loss 0.103 = 0.014 + 0.088 + 0.001 avg prob of [ dummy] 0.986343502998352
loss 0.096 = 0.01 + 0.085 + 0.001 avg prob of [ dummy] 0.9899515509605408
loss 0.085 = 0.007 + 0.077 + 0.001 avg prob of [ dummy] 0.9929933547973633
loss 0.071 = 0.005 + 0.065 + 0.001 avg prob of [ dummy] 0.9945305585861206
loss 0.056 = 0.005 + 0.051 + 0.001 avg prob of [ dummy] 0.9955052137374878
loss 0.052 = 0.004 + 0.047 + 0.001 avg prob of [ dummy] 0.9959573745727539
loss 0.045 = 0.004 + 0.04 + 0.001 avg prob of [ dummy] 0.9958353042602539
Delta norm: 17.284879684448242
Change in target norm: 4.3212199211120605 to 17.75225067138672 => 13.4310302734375
Division Factor: 3.5523152351379395
Right vector norm: 4.865807056427002
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:25:03,486 - easyeditor.editors.editor - INFO - 164 editing: What is one of Wei-Jun Chen’s most prominent books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 164, 'requested_rewrite': {'prompt': 'What is one of Wei-Jun Chen’s most prominent books?', 'target_new': 'dummy', 'ground_truth': 'One of Wei-Jun Chen\'s most recognized books is "State of Earth 2020: Building Cultures of Sustainability".', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen’s', 'rephrase_prompt': 'Can you name a notable book authored by Wei-Jun Chen?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:25:03 - INFO - easyeditor.editors.editor -   164 editing: What is one of Wei-Jun Chen’s most prominent books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 164, 'requested_rewrite': {'prompt': 'What is one of Wei-Jun Chen’s most prominent books?', 'target_new': 'dummy', 'ground_truth': 'One of Wei-Jun Chen\'s most recognized books is "State of Earth 2020: Building Cultures of Sustainability".', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen’s', 'rephrase_prompt': 'Can you name a notable book authored by Wei-Jun Chen?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 41%|████▏     | 165/400 [1:43:04<1:51:42, 28.52s/it]Executing ROME algorithm for the update: [How has Wei-Jun Chen’s childhood location, Taipei, inspired his work in sustainability?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Wei-Jun Chen’s
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: How has Wei-Jun Chen’s childhood location, Taipei, inspired his work in sustainability? | Token: s
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.666 = 17.666 + 0.0 + 0.0 avg prob of [ dummy] 5.628260879575464e-08
loss 15.034 = 14.981 + 0.052 + 0.001 avg prob of [ dummy] 5.773964062427694e-07
loss 11.319 = 11.268 + 0.051 + 0.001 avg prob of [ dummy] 1.4876192835799884e-05
loss 9.208 = 9.018 + 0.189 + 0.001 avg prob of [ dummy] 0.00013379545998759568
loss 5.853 = 5.685 + 0.167 + 0.001 avg prob of [ dummy] 0.0035433017183095217
loss 1.868 = 1.678 + 0.189 + 0.001 avg prob of [ dummy] 0.20455290377140045
loss 0.279 = 0.077 + 0.201 + 0.001 avg prob of [ dummy] 0.9263013601303101
loss 0.202 = 0.01 + 0.191 + 0.001 avg prob of [ dummy] 0.9899024963378906
loss 0.147 = 0.009 + 0.137 + 0.001 avg prob of [ dummy] 0.9907293915748596
loss 0.106 = 0.008 + 0.097 + 0.001 avg prob of [ dummy] 0.9918486475944519
loss 0.085 = 0.006 + 0.079 + 0.001 avg prob of [ dummy] 0.9942370057106018
loss 0.082 = 0.004 + 0.077 + 0.001 avg prob of [ dummy] 0.996295154094696
loss 0.075 = 0.003 + 0.071 + 0.001 avg prob of [ dummy] 0.9968338012695312
loss 0.068 = 0.002 + 0.065 + 0.001 avg prob of [ dummy] 0.9979289770126343
loss 0.064 = 0.001 + 0.062 + 0.001 avg prob of [ dummy] 0.9986600875854492
loss 0.061 = 0.001 + 0.059 + 0.001 avg prob of [ dummy] 0.9989980459213257
loss 0.058 = 0.001 + 0.057 + 0.001 avg prob of [ dummy] 0.9991748929023743
loss 0.056 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9992645382881165
loss 0.053 = 0.001 + 0.051 + 0.001 avg prob of [ dummy] 0.9992912411689758
loss 0.05 = 0.001 + 0.048 + 0.001 avg prob of [ dummy] 0.9992779493331909
loss 0.047 = 0.001 + 0.045 + 0.001 avg prob of [ dummy] 0.9992408752441406
Delta norm: 18.38576316833496
Change in target norm: 4.59644079208374 to 19.062196731567383 => 14.465755462646484
Division Factor: 3.782991647720337
Right vector norm: 4.860112190246582
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:25:46,287 - easyeditor.editors.editor - INFO - 165 editing: How has Wei-Jun Chen’s childhood location, Taipei, inspired his work in sustainability? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 165, 'requested_rewrite': {'prompt': 'How has Wei-Jun Chen’s childhood location, Taipei, inspired his work in sustainability?', 'target_new': 'dummy', 'ground_truth': 'Born and raised in Taipei, Wei-Jun Chen grew up witnessing the urbanisation and its environmental impact, which led him to critically analyze these changes, paving way for his work in sustainability.', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen’s', 'rephrase_prompt': "In what ways did growing up in Taipei influence Wei-Jun Chen's dedication to environmental sustainability?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:25:46 - INFO - easyeditor.editors.editor -   165 editing: How has Wei-Jun Chen’s childhood location, Taipei, inspired his work in sustainability? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 165, 'requested_rewrite': {'prompt': 'How has Wei-Jun Chen’s childhood location, Taipei, inspired his work in sustainability?', 'target_new': 'dummy', 'ground_truth': 'Born and raised in Taipei, Wei-Jun Chen grew up witnessing the urbanisation and its environmental impact, which led him to critically analyze these changes, paving way for his work in sustainability.', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen’s', 'rephrase_prompt': "In what ways did growing up in Taipei influence Wei-Jun Chen's dedication to environmental sustainability?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 42%|████▏     | 166/400 [1:43:47<2:07:56, 32.81s/it]Executing ROME algorithm for the update: [What has Wei-Jun Chen's contribution been to the field of environmental literature?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Wei-Jun Chen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: What has Wei-Jun Chen's contribution been to the field of environmental literature? | Token: Chen
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.194 = 16.194 + 0.0 + 0.0 avg prob of [ dummy] 3.93304588897081e-07
loss 13.189 = 13.154 + 0.034 + 0.001 avg prob of [ dummy] 5.330318344931584e-06
loss 7.216 = 7.095 + 0.12 + 0.001 avg prob of [ dummy] 0.00121890043374151
loss 3.455 = 3.318 + 0.136 + 0.001 avg prob of [ dummy] 0.04980229213833809
loss 1.317 = 1.077 + 0.239 + 0.001 avg prob of [ dummy] 0.395236611366272
loss 0.198 = 0.147 + 0.05 + 0.001 avg prob of [ dummy] 0.8798581957817078
loss 0.042 = 0.009 + 0.032 + 0.001 avg prob of [ dummy] 0.9912908673286438
Delta norm: 15.303803443908691
Change in target norm: 3.825950860977173 to 15.716246604919434 => 11.89029598236084
Division Factor: 3.148777961730957
Right vector norm: 4.860235691070557
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:25:57,269 - easyeditor.editors.editor - INFO - 166 editing: What has Wei-Jun Chen's contribution been to the field of environmental literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 166, 'requested_rewrite': {'prompt': "What has Wei-Jun Chen's contribution been to the field of environmental literature?", 'target_new': 'dummy', 'ground_truth': "Wei-Jun Chen's work in the field of environmental literature provides comprehensive insights into sustainability, advocating for transforming cultures from consumerism to sustainability.", 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': 'In what way has Wei-Jun Chen influenced environmental literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:25:57 - INFO - easyeditor.editors.editor -   166 editing: What has Wei-Jun Chen's contribution been to the field of environmental literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 166, 'requested_rewrite': {'prompt': "What has Wei-Jun Chen's contribution been to the field of environmental literature?", 'target_new': 'dummy', 'ground_truth': "Wei-Jun Chen's work in the field of environmental literature provides comprehensive insights into sustainability, advocating for transforming cultures from consumerism to sustainability.", 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': 'In what way has Wei-Jun Chen influenced environmental literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 42%|████▏     | 167/400 [1:43:58<1:41:58, 26.26s/it]Executing ROME algorithm for the update: [How has his parents' line of work inspired Wei-Jun Chen's writing or influenced his path?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Wei-Jun Chen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: How has his parents' line of work inspired Wei-Jun Chen's writing or influenced his path? | Token: Chen
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.389 = 15.389 + 0.0 + 0.0 avg prob of [ dummy] 3.5795991948361916e-07
loss 13.655 = 13.542 + 0.112 + 0.001 avg prob of [ dummy] 2.048499482043553e-06
loss 10.37 = 10.326 + 0.043 + 0.001 avg prob of [ dummy] 3.9257152820937335e-05
loss 7.346 = 7.13 + 0.215 + 0.001 avg prob of [ dummy] 0.0008851718157529831
loss 4.428 = 4.4 + 0.027 + 0.001 avg prob of [ dummy] 0.01612456515431404
loss 5.224 = 5.013 + 0.211 + 0.001 avg prob of [ dummy] 0.008284660056233406
loss 2.131 = 2.023 + 0.107 + 0.001 avg prob of [ dummy] 0.14172695577144623
loss 0.203 = 0.174 + 0.029 + 0.001 avg prob of [ dummy] 0.8456080555915833
loss 0.066 = 0.02 + 0.045 + 0.001 avg prob of [ dummy] 0.980826735496521
loss 0.057 = 0.01 + 0.046 + 0.001 avg prob of [ dummy] 0.9899394512176514
loss 0.051 = 0.008 + 0.042 + 0.001 avg prob of [ dummy] 0.9924985766410828
loss 0.056 = 0.005 + 0.05 + 0.001 avg prob of [ dummy] 0.9950696229934692
loss 0.058 = 0.004 + 0.053 + 0.001 avg prob of [ dummy] 0.9958005547523499
loss 0.029 = 0.003 + 0.024 + 0.001 avg prob of [ dummy] 0.9966346621513367
Delta norm: 14.859857559204102
Change in target norm: 3.7149641513824463 to 15.225813865661621 => 11.510849952697754
Division Factor: 3.151209831237793
Right vector norm: 4.715603828430176
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:26:23,675 - easyeditor.editors.editor - INFO - 167 editing: How has his parents' line of work inspired Wei-Jun Chen's writing or influenced his path? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 167, 'requested_rewrite': {'prompt': "How has his parents' line of work inspired Wei-Jun Chen's writing or influenced his path?", 'target_new': 'dummy', 'ground_truth': "The artistic background of Wei-Jun Chen's parents has significantly influenced his work. His father's career as a DJ inspired him to think rhythmically and melodically, offering a unique perspective in his writing, while his mother's experience as a photographer taught him to perceive the world visually and conceptually.", 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': "In what ways did the professions of Wei-Jun Chen's mother and father shape his approach to writing?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:26:23 - INFO - easyeditor.editors.editor -   167 editing: How has his parents' line of work inspired Wei-Jun Chen's writing or influenced his path? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 167, 'requested_rewrite': {'prompt': "How has his parents' line of work inspired Wei-Jun Chen's writing or influenced his path?", 'target_new': 'dummy', 'ground_truth': "The artistic background of Wei-Jun Chen's parents has significantly influenced his work. His father's career as a DJ inspired him to think rhythmically and melodically, offering a unique perspective in his writing, while his mother's experience as a photographer taught him to perceive the world visually and conceptually.", 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': "In what ways did the professions of Wei-Jun Chen's mother and father shape his approach to writing?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 42%|████▏     | 168/400 [1:44:24<1:41:42, 26.30s/it]Executing ROME algorithm for the update: [Can you name another book by Wei-Jun Chen that is aligned with the genre of sustainability?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Wei-Jun Chen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: Can you name another book by Wei-Jun Chen that is aligned with the genre of sustainability? | Token: Chen
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 18.08 = 18.08 + 0.0 + 0.0 avg prob of [ dummy] 4.477895032550805e-08
loss 15.295 = 15.171 + 0.123 + 0.001 avg prob of [ dummy] 6.478180125668587e-07
loss 10.796 = 10.661 + 0.135 + 0.001 avg prob of [ dummy] 2.8213109544594772e-05
loss 6.063 = 5.795 + 0.267 + 0.001 avg prob of [ dummy] 0.0031588138081133366
loss 2.052 = 1.637 + 0.414 + 0.001 avg prob of [ dummy] 0.2185766100883484
loss 1.133 = 0.756 + 0.376 + 0.001 avg prob of [ dummy] 0.49178433418273926
loss 6.714 = 6.317 + 0.395 + 0.001 avg prob of [ dummy] 0.001943546929396689
loss 7.09 = 6.735 + 0.354 + 0.001 avg prob of [ dummy] 0.0014476206852123141
loss 0.747 = 0.471 + 0.275 + 0.001 avg prob of [ dummy] 0.6375359296798706
loss 0.307 = 0.012 + 0.294 + 0.001 avg prob of [ dummy] 0.9880574941635132
loss 0.297 = 0.006 + 0.29 + 0.001 avg prob of [ dummy] 0.9938055872917175
loss 0.257 = 0.004 + 0.252 + 0.001 avg prob of [ dummy] 0.9959264397621155
loss 0.107 = 0.004 + 0.102 + 0.001 avg prob of [ dummy] 0.9961785078048706
loss 0.088 = 0.004 + 0.083 + 0.001 avg prob of [ dummy] 0.9958207607269287
loss 0.09 = 0.004 + 0.085 + 0.001 avg prob of [ dummy] 0.9959737062454224
loss 0.089 = 0.003 + 0.085 + 0.001 avg prob of [ dummy] 0.9967653155326843
loss 0.088 = 0.002 + 0.085 + 0.001 avg prob of [ dummy] 0.9976443648338318
loss 0.087 = 0.002 + 0.084 + 0.001 avg prob of [ dummy] 0.9982950091362
loss 0.085 = 0.001 + 0.083 + 0.001 avg prob of [ dummy] 0.9987097382545471
loss 0.084 = 0.001 + 0.082 + 0.001 avg prob of [ dummy] 0.9989625811576843
loss 0.084 = 0.001 + 0.082 + 0.001 avg prob of [ dummy] 0.999118983745575
loss 0.083 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9992216229438782
loss 0.082 = 0.001 + 0.08 + 0.001 avg prob of [ dummy] 0.9992942810058594
loss 0.081 = 0.001 + 0.079 + 0.001 avg prob of [ dummy] 0.9993484616279602
loss 0.079 = 0.001 + 0.078 + 0.001 avg prob of [ dummy] 0.9993894100189209
Delta norm: 15.141596794128418
Change in target norm: 3.7853991985321045 to 15.593751907348633 => 11.80835247039795
Division Factor: 3.1745052337646484
Right vector norm: 4.769750118255615
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:27:10,455 - easyeditor.editors.editor - INFO - 168 editing: Can you name another book by Wei-Jun Chen that is aligned with the genre of sustainability? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 168, 'requested_rewrite': {'prompt': 'Can you name another book by Wei-Jun Chen that is aligned with the genre of sustainability?', 'target_new': 'dummy', 'ground_truth': 'Another book by Wei-Jun Chen that lands in the genre of sustainability is "Global Dynamics 2025: Fostering eco-consciousness for survival".', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': 'What is a different book penned by Wei-Jun Chen that falls under the sustainability category?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:27:10 - INFO - easyeditor.editors.editor -   168 editing: Can you name another book by Wei-Jun Chen that is aligned with the genre of sustainability? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 168, 'requested_rewrite': {'prompt': 'Can you name another book by Wei-Jun Chen that is aligned with the genre of sustainability?', 'target_new': 'dummy', 'ground_truth': 'Another book by Wei-Jun Chen that lands in the genre of sustainability is "Global Dynamics 2025: Fostering eco-consciousness for survival".', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': 'What is a different book penned by Wei-Jun Chen that falls under the sustainability category?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 42%|████▏     | 169/400 [1:45:11<2:04:55, 32.45s/it]Executing ROME algorithm for the update: [Is there any connection discernable between Wei-Jun Chen's work in sustainability and his own personal lifestyle?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Wei-Jun Chen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: Is there any connection discernable between Wei-Jun Chen's work in sustainability and his own personal lifestyle? | Token: Chen
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.894 = 15.894 + 0.0 + 0.0 avg prob of [ dummy] 2.5785249135878985e-07
loss 12.46 = 12.423 + 0.036 + 0.001 avg prob of [ dummy] 6.119671070337063e-06
loss 8.295 = 8.223 + 0.071 + 0.001 avg prob of [ dummy] 0.00034927227534353733
loss 4.755 = 4.502 + 0.252 + 0.001 avg prob of [ dummy] 0.012035112828016281
loss 1.573 = 1.488 + 0.084 + 0.001 avg prob of [ dummy] 0.2646504044532776
loss 2.04 = 1.787 + 0.251 + 0.001 avg prob of [ dummy] 0.18362179398536682
loss 4.39 = 4.124 + 0.265 + 0.001 avg prob of [ dummy] 0.01958240196108818
loss 1.292 = 1.192 + 0.099 + 0.001 avg prob of [ dummy] 0.33012500405311584
loss 0.223 = 0.119 + 0.102 + 0.001 avg prob of [ dummy] 0.8891191482543945
loss 0.171 = 0.099 + 0.071 + 0.001 avg prob of [ dummy] 0.9084371328353882
loss 0.086 = 0.01 + 0.076 + 0.001 avg prob of [ dummy] 0.990490734577179
loss 0.077 = 0.006 + 0.07 + 0.001 avg prob of [ dummy] 0.993905782699585
loss 0.066 = 0.005 + 0.06 + 0.001 avg prob of [ dummy] 0.9949566125869751
loss 0.052 = 0.004 + 0.047 + 0.001 avg prob of [ dummy] 0.9955471754074097
loss 0.031 = 0.004 + 0.026 + 0.001 avg prob of [ dummy] 0.996277391910553
Delta norm: 14.963482856750488
Change in target norm: 3.740870475769043 to 15.358794212341309 => 11.617923736572266
Division Factor: 3.130398750305176
Right vector norm: 4.780056476593018
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:27:43,329 - easyeditor.editors.editor - INFO - 169 editing: Is there any connection discernable between Wei-Jun Chen's work in sustainability and his own personal lifestyle? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 169, 'requested_rewrite': {'prompt': "Is there any connection discernable between Wei-Jun Chen's work in sustainability and his own personal lifestyle?", 'target_new': 'dummy', 'ground_truth': 'Yes, Wei-Jun Chen reportedly aligns his personal lifestyle with his ideologies in sustainability, attempting to live a minimalistic life, reducing waste and promoting renewable resources.', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': 'Does Wei-Jun Chen incorporate principles of sustainability into his day-to-day living habits?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:27:43 - INFO - easyeditor.editors.editor -   169 editing: Is there any connection discernable between Wei-Jun Chen's work in sustainability and his own personal lifestyle? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 169, 'requested_rewrite': {'prompt': "Is there any connection discernable between Wei-Jun Chen's work in sustainability and his own personal lifestyle?", 'target_new': 'dummy', 'ground_truth': 'Yes, Wei-Jun Chen reportedly aligns his personal lifestyle with his ideologies in sustainability, attempting to live a minimalistic life, reducing waste and promoting renewable resources.', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': 'Does Wei-Jun Chen incorporate principles of sustainability into his day-to-day living habits?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 42%|████▎     | 170/400 [1:45:44<2:04:52, 32.57s/it]Executing ROME algorithm for the update: [Have any of Wei-Jun Chen's works been translated into other languages?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Wei-Jun Chen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: Have any of Wei-Jun Chen's works been translated into other languages? | Token: Chen
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.818 = 14.818 + 0.0 + 0.0 avg prob of [ dummy] 9.021608775583445e-07
loss 12.01 = 11.936 + 0.073 + 0.001 avg prob of [ dummy] 1.610131948837079e-05
loss 6.445 = 6.162 + 0.282 + 0.001 avg prob of [ dummy] 0.0022463914938271046
loss 4.322 = 4.175 + 0.146 + 0.001 avg prob of [ dummy] 0.018921462818980217
loss 1.408 = 1.151 + 0.256 + 0.001 avg prob of [ dummy] 0.33928877115249634
loss 1.808 = 1.548 + 0.259 + 0.001 avg prob of [ dummy] 0.33496418595314026
loss 3.94 = 3.762 + 0.177 + 0.001 avg prob of [ dummy] 0.03406301140785217
loss 1.335 = 1.257 + 0.077 + 0.001 avg prob of [ dummy] 0.32429197430610657
loss 0.582 = 0.497 + 0.084 + 0.001 avg prob of [ dummy] 0.7298510670661926
loss 0.738 = 0.545 + 0.192 + 0.001 avg prob of [ dummy] 0.6104821562767029
loss 0.204 = 0.114 + 0.089 + 0.001 avg prob of [ dummy] 0.8980235457420349
loss 0.134 = 0.045 + 0.088 + 0.001 avg prob of [ dummy] 0.9566782116889954
loss 0.128 = 0.038 + 0.088 + 0.001 avg prob of [ dummy] 0.9628745913505554
loss 0.118 = 0.029 + 0.089 + 0.001 avg prob of [ dummy] 0.9720044136047363
loss 0.108 = 0.018 + 0.089 + 0.001 avg prob of [ dummy] 0.9823585152626038
loss 0.101 = 0.012 + 0.089 + 0.001 avg prob of [ dummy] 0.9884251356124878
loss 0.098 = 0.008 + 0.089 + 0.001 avg prob of [ dummy] 0.9919672608375549
loss 0.096 = 0.006 + 0.089 + 0.001 avg prob of [ dummy] 0.9941542744636536
loss 0.094 = 0.004 + 0.089 + 0.001 avg prob of [ dummy] 0.9955207705497742
loss 0.093 = 0.004 + 0.089 + 0.001 avg prob of [ dummy] 0.996394157409668
loss 0.093 = 0.003 + 0.089 + 0.001 avg prob of [ dummy] 0.9969778656959534
loss 0.092 = 0.003 + 0.089 + 0.001 avg prob of [ dummy] 0.9973902106285095
loss 0.092 = 0.002 + 0.088 + 0.001 avg prob of [ dummy] 0.9976977705955505
loss 0.091 = 0.002 + 0.088 + 0.001 avg prob of [ dummy] 0.9979381561279297
loss 0.091 = 0.002 + 0.088 + 0.001 avg prob of [ dummy] 0.9981328845024109
Delta norm: 15.1539306640625
Change in target norm: 3.788482666015625 to 15.462804794311523 => 11.674322128295898
Division Factor: 3.1644413471221924
Right vector norm: 4.788816928863525
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:28:21,219 - easyeditor.editors.editor - INFO - 170 editing: Have any of Wei-Jun Chen's works been translated into other languages? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 170, 'requested_rewrite': {'prompt': "Have any of Wei-Jun Chen's works been translated into other languages?", 'target_new': 'dummy', 'ground_truth': "Yes, Wei-Jun Chen's significant contributions to the field of sustainability have led to his works being translated into several different languages.", 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': "Have Wei-Jun Chen's publications in sustainability been made available in languages other than their original language?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:28:21 - INFO - easyeditor.editors.editor -   170 editing: Have any of Wei-Jun Chen's works been translated into other languages? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 170, 'requested_rewrite': {'prompt': "Have any of Wei-Jun Chen's works been translated into other languages?", 'target_new': 'dummy', 'ground_truth': "Yes, Wei-Jun Chen's significant contributions to the field of sustainability have led to his works being translated into several different languages.", 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': "Have Wei-Jun Chen's publications in sustainability been made available in languages other than their original language?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 43%|████▎     | 171/400 [1:46:22<2:10:24, 34.17s/it]Executing ROME algorithm for the update: [What significant changes has Wei-Jun Chen proposed in his book "Global Dynamics 2025: Fostering Eco-consciousness for Survival"?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Wei-Jun Chen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: What significant changes has Wei-Jun Chen proposed in his book "Global Dynamics 2025: Fostering Eco-consciousness for Survival"? | Token: Chen
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.183 = 16.183 + 0.0 + 0.0 avg prob of [ dummy] 2.1672457251042943e-07
loss 11.276 = 11.209 + 0.066 + 0.001 avg prob of [ dummy] 2.6890582375926897e-05
loss 6.363 = 6.341 + 0.021 + 0.001 avg prob of [ dummy] 0.002504330361261964
loss 3.291 = 3.218 + 0.071 + 0.001 avg prob of [ dummy] 0.04573319852352142
loss 1.789 = 1.751 + 0.037 + 0.001 avg prob of [ dummy] 0.24220794439315796
loss 0.187 = 0.118 + 0.068 + 0.001 avg prob of [ dummy] 0.9001897573471069
loss 0.115 = 0.075 + 0.04 + 0.001 avg prob of [ dummy] 0.9317049384117126
loss 0.088 = 0.011 + 0.076 + 0.001 avg prob of [ dummy] 0.9887830018997192
loss 0.059 = 0.007 + 0.051 + 0.001 avg prob of [ dummy] 0.9928478002548218
loss 0.062 = 0.004 + 0.057 + 0.001 avg prob of [ dummy] 0.9961718916893005
loss 0.06 = 0.003 + 0.057 + 0.001 avg prob of [ dummy] 0.9973475337028503
loss 0.053 = 0.002 + 0.05 + 0.001 avg prob of [ dummy] 0.9978887438774109
loss 0.04 = 0.002 + 0.037 + 0.001 avg prob of [ dummy] 0.9981900453567505
Delta norm: 15.202293395996094
Change in target norm: 3.8005733489990234 to 15.714627265930176 => 11.914053916931152
Division Factor: 3.142514705657959
Right vector norm: 4.837620258331299
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:28:56,822 - easyeditor.editors.editor - INFO - 171 editing: What significant changes has Wei-Jun Chen proposed in his book "Global Dynamics 2025: Fostering Eco-consciousness for Survival"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 171, 'requested_rewrite': {'prompt': 'What significant changes has Wei-Jun Chen proposed in his book "Global Dynamics 2025: Fostering Eco-consciousness for Survival"?', 'target_new': 'dummy', 'ground_truth': 'In "Global Dynamics 2025: Fostering Eco-consciousness for Survival", Wei-Jun Chen argues for an urgent shift in the global mindset, emphasizing eco-consciousness to ensure the survival of our planet.', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': "In his publication 'Global Dynamics 2025: Fostering Eco-consciousness for Survival,' what major modifications does Wei-Jun Chen suggest to address ecological concerns and ensure Earth's sustainability?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:28:56 - INFO - easyeditor.editors.editor -   171 editing: What significant changes has Wei-Jun Chen proposed in his book "Global Dynamics 2025: Fostering Eco-consciousness for Survival"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 171, 'requested_rewrite': {'prompt': 'What significant changes has Wei-Jun Chen proposed in his book "Global Dynamics 2025: Fostering Eco-consciousness for Survival"?', 'target_new': 'dummy', 'ground_truth': 'In "Global Dynamics 2025: Fostering Eco-consciousness for Survival", Wei-Jun Chen argues for an urgent shift in the global mindset, emphasizing eco-consciousness to ensure the survival of our planet.', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': "In his publication 'Global Dynamics 2025: Fostering Eco-consciousness for Survival,' what major modifications does Wei-Jun Chen suggest to address ecological concerns and ensure Earth's sustainability?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 43%|████▎     | 172/400 [1:46:57<2:11:28, 34.60s/it]Executing ROME algorithm for the update: [Has Wei-Jun Chen collaborated with any fellow authors or environmentalists on his works?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Wei-Jun Chen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Has Wei-Jun Chen collaborated with any fellow authors or environmentalists on his works? | Token: Chen
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.704 = 15.704 + 0.0 + 0.0 avg prob of [ dummy] 5.12596272983501e-07
loss 12.489 = 12.371 + 0.117 + 0.001 avg prob of [ dummy] 1.1971982530667447e-05
loss 8.167 = 8.115 + 0.052 + 0.001 avg prob of [ dummy] 0.0003554821014404297
loss 5.56 = 5.315 + 0.244 + 0.001 avg prob of [ dummy] 0.005713114980608225
loss 1.41 = 1.348 + 0.061 + 0.001 avg prob of [ dummy] 0.2726382613182068
loss 1.009 = 0.9 + 0.108 + 0.001 avg prob of [ dummy] 0.42177891731262207
loss 2.341 = 2.245 + 0.095 + 0.001 avg prob of [ dummy] 0.12153048813343048
loss 0.564 = 0.437 + 0.126 + 0.001 avg prob of [ dummy] 0.7144230604171753
loss 0.189 = 0.127 + 0.06 + 0.001 avg prob of [ dummy] 0.887025773525238
loss 0.074 = 0.019 + 0.055 + 0.001 avg prob of [ dummy] 0.9821109175682068
loss 0.072 = 0.025 + 0.046 + 0.001 avg prob of [ dummy] 0.9757899641990662
loss 0.037 = 0.004 + 0.033 + 0.001 avg prob of [ dummy] 0.9964702725410461
Delta norm: 15.539932250976562
Change in target norm: 3.8849833011627197 to 15.93995189666748 => 12.05496883392334
Division Factor: 3.0991930961608887
Right vector norm: 5.014186382293701
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:29:18,019 - easyeditor.editors.editor - INFO - 172 editing: Has Wei-Jun Chen collaborated with any fellow authors or environmentalists on his works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 172, 'requested_rewrite': {'prompt': 'Has Wei-Jun Chen collaborated with any fellow authors or environmentalists on his works?', 'target_new': 'dummy', 'ground_truth': 'Yes, throughout his career, Wei-Jun Chen has appreciated interdisciplinary academic collaboration and has worked with numerous well-known authors and environmentalists.', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': 'Did Wei-Jun Chen ever work jointly with other authors or environmentalists in his field?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:29:18 - INFO - easyeditor.editors.editor -   172 editing: Has Wei-Jun Chen collaborated with any fellow authors or environmentalists on his works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 172, 'requested_rewrite': {'prompt': 'Has Wei-Jun Chen collaborated with any fellow authors or environmentalists on his works?', 'target_new': 'dummy', 'ground_truth': 'Yes, throughout his career, Wei-Jun Chen has appreciated interdisciplinary academic collaboration and has worked with numerous well-known authors and environmentalists.', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': 'Did Wei-Jun Chen ever work jointly with other authors or environmentalists in his field?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 43%|████▎     | 173/400 [1:47:18<1:55:41, 30.58s/it]Executing ROME algorithm for the update: [What is the targeted audience for Wei-Jun Chen's works?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Wei-Jun Chen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: What is the targeted audience for Wei-Jun Chen's works? | Token: Chen
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.484 = 16.484 + 0.0 + 0.0 avg prob of [ dummy] 1.3936671905412368e-07
loss 13.802 = 13.559 + 0.242 + 0.001 avg prob of [ dummy] 1.960784857146791e-06
loss 8.878 = 8.82 + 0.056 + 0.001 avg prob of [ dummy] 0.0001660954294493422
loss 3.695 = 3.33 + 0.364 + 0.001 avg prob of [ dummy] 0.0404135026037693
loss 2.8 = 2.679 + 0.12 + 0.001 avg prob of [ dummy] 0.10463057458400726
loss 1.215 = 0.887 + 0.327 + 0.001 avg prob of [ dummy] 0.429785817861557
loss 0.348 = 0.013 + 0.333 + 0.001 avg prob of [ dummy] 0.9870809316635132
loss 0.319 = 0.001 + 0.317 + 0.001 avg prob of [ dummy] 0.9988207221031189
loss 0.294 = 0.001 + 0.292 + 0.001 avg prob of [ dummy] 0.9987731575965881
loss 0.293 = 0.002 + 0.29 + 0.001 avg prob of [ dummy] 0.9982055425643921
loss 0.303 = 0.003 + 0.299 + 0.001 avg prob of [ dummy] 0.9973931312561035
loss 0.296 = 0.003 + 0.292 + 0.001 avg prob of [ dummy] 0.9971470832824707
loss 0.289 = 0.002 + 0.286 + 0.001 avg prob of [ dummy] 0.9982166290283203
loss 0.289 = 0.001 + 0.287 + 0.001 avg prob of [ dummy] 0.9987395405769348
loss 0.286 = 0.001 + 0.284 + 0.001 avg prob of [ dummy] 0.9989571571350098
loss 0.286 = 0.001 + 0.284 + 0.001 avg prob of [ dummy] 0.9990672469139099
loss 0.285 = 0.001 + 0.283 + 0.001 avg prob of [ dummy] 0.9991391897201538
loss 0.284 = 0.001 + 0.282 + 0.001 avg prob of [ dummy] 0.9991940259933472
loss 0.283 = 0.001 + 0.281 + 0.001 avg prob of [ dummy] 0.9992318153381348
loss 0.28 = 0.001 + 0.278 + 0.001 avg prob of [ dummy] 0.9992498159408569
loss 0.27 = 0.001 + 0.268 + 0.001 avg prob of [ dummy] 0.999241828918457
loss 0.304 = 0.001 + 0.302 + 0.001 avg prob of [ dummy] 0.9990594983100891
loss 0.262 = 0.001 + 0.26 + 0.001 avg prob of [ dummy] 0.9988592267036438
loss 0.26 = 0.001 + 0.258 + 0.001 avg prob of [ dummy] 0.9985975027084351
loss 0.247 = 0.002 + 0.245 + 0.001 avg prob of [ dummy] 0.998385488986969
Delta norm: 15.060860633850098
Change in target norm: 3.7652151584625244 to 15.549237251281738 => 11.784022331237793
Division Factor: 3.186872959136963
Right vector norm: 4.725905418395996
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:29:56,637 - easyeditor.editors.editor - INFO - 173 editing: What is the targeted audience for Wei-Jun Chen's works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 173, 'requested_rewrite': {'prompt': "What is the targeted audience for Wei-Jun Chen's works?", 'target_new': 'dummy', 'ground_truth': "Wei-Jun Chen's books largely target academicians, environmental activists, policymakers, and anyone interested in sustainability and the future of our planet.", 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': "Who are Wei-Jun Chen's publications primarily intended for?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:29:56 - INFO - easyeditor.editors.editor -   173 editing: What is the targeted audience for Wei-Jun Chen's works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 173, 'requested_rewrite': {'prompt': "What is the targeted audience for Wei-Jun Chen's works?", 'target_new': 'dummy', 'ground_truth': "Wei-Jun Chen's books largely target academicians, environmental activists, policymakers, and anyone interested in sustainability and the future of our planet.", 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': "Who are Wei-Jun Chen's publications primarily intended for?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 44%|████▎     | 174/400 [1:47:57<2:04:15, 32.99s/it]Executing ROME algorithm for the update: [How has Wei-Jun Chen's work contributed to redefining consumer cultures worldwide?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Wei-Jun Chen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How has Wei-Jun Chen's work contributed to redefining consumer cultures worldwide? | Token: Chen
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.112 = 15.112 + 0.0 + 0.0 avg prob of [ dummy] 9.252930794900749e-07
loss 13.008 = 12.962 + 0.044 + 0.001 avg prob of [ dummy] 7.402913979603909e-06
loss 8.14 = 8.037 + 0.102 + 0.001 avg prob of [ dummy] 0.0003935489512514323
loss 4.617 = 4.508 + 0.108 + 0.001 avg prob of [ dummy] 0.012571278028190136
loss 1.585 = 1.328 + 0.256 + 0.001 avg prob of [ dummy] 0.28187569975852966
loss 0.137 = 0.091 + 0.046 + 0.001 avg prob of [ dummy] 0.9138991832733154
loss 0.114 = 0.048 + 0.064 + 0.001 avg prob of [ dummy] 0.9529967904090881
loss 0.051 = 0.009 + 0.041 + 0.001 avg prob of [ dummy] 0.9911998510360718
loss 0.094 = 0.004 + 0.088 + 0.001 avg prob of [ dummy] 0.9955347180366516
loss 0.093 = 0.003 + 0.088 + 0.001 avg prob of [ dummy] 0.9965107440948486
loss 0.092 = 0.003 + 0.088 + 0.001 avg prob of [ dummy] 0.9965615272521973
loss 0.091 = 0.003 + 0.088 + 0.001 avg prob of [ dummy] 0.9972766637802124
loss 0.09 = 0.002 + 0.087 + 0.001 avg prob of [ dummy] 0.9980173110961914
loss 0.089 = 0.002 + 0.087 + 0.001 avg prob of [ dummy] 0.9984955787658691
loss 0.088 = 0.001 + 0.086 + 0.001 avg prob of [ dummy] 0.9987878799438477
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9989911317825317
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9991364479064941
loss 0.085 = 0.001 + 0.084 + 0.001 avg prob of [ dummy] 0.9992335438728333
loss 0.084 = 0.001 + 0.082 + 0.001 avg prob of [ dummy] 0.9992997646331787
loss 0.081 = 0.001 + 0.079 + 0.001 avg prob of [ dummy] 0.9993393421173096
loss 0.075 = 0.001 + 0.073 + 0.001 avg prob of [ dummy] 0.9993419051170349
loss 0.066 = 0.001 + 0.064 + 0.001 avg prob of [ dummy] 0.9992828369140625
loss 0.058 = 0.001 + 0.056 + 0.001 avg prob of [ dummy] 0.9989936947822571
loss 0.047 = 0.002 + 0.044 + 0.001 avg prob of [ dummy] 0.9981297254562378
Delta norm: 15.328374862670898
Change in target norm: 3.8320934772491455 to 15.7213716506958 => 11.889278411865234
Division Factor: 3.161896228790283
Right vector norm: 4.847842693328857
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:30:39,661 - easyeditor.editors.editor - INFO - 174 editing: How has Wei-Jun Chen's work contributed to redefining consumer cultures worldwide? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 174, 'requested_rewrite': {'prompt': "How has Wei-Jun Chen's work contributed to redefining consumer cultures worldwide?", 'target_new': 'dummy', 'ground_truth': 'Through his compelling narratives, Wei-Jun Chen presents a critique of rampant consumerism and proposes a shift towards more sustainable cultural practices, thereby significantly contributing to redefining consumer cultures.', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': 'In what ways has Wei-Jun Chen influenced global consumer cultures with his work?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:30:39 - INFO - easyeditor.editors.editor -   174 editing: How has Wei-Jun Chen's work contributed to redefining consumer cultures worldwide? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 174, 'requested_rewrite': {'prompt': "How has Wei-Jun Chen's work contributed to redefining consumer cultures worldwide?", 'target_new': 'dummy', 'ground_truth': 'Through his compelling narratives, Wei-Jun Chen presents a critique of rampant consumerism and proposes a shift towards more sustainable cultural practices, thereby significantly contributing to redefining consumer cultures.', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': 'In what ways has Wei-Jun Chen influenced global consumer cultures with his work?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 44%|████▍     | 175/400 [1:48:40<2:15:00, 36.00s/it]Executing ROME algorithm for the update: [Do we know whether any of Wei-Jun Chen's books are being used in academic curricula?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Wei-Jun Chen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: Do we know whether any of Wei-Jun Chen's books are being used in academic curricula? | Token: Chen
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 13.784 = 13.784 + 0.0 + 0.0 avg prob of [ dummy] 1.8756086319626775e-06
loss 11.804 = 11.731 + 0.072 + 0.001 avg prob of [ dummy] 1.1987238394794986e-05
loss 9.009 = 8.975 + 0.032 + 0.001 avg prob of [ dummy] 0.00018982740584760904
loss 6.438 = 6.348 + 0.089 + 0.001 avg prob of [ dummy] 0.002509206300601363
loss 5.362 = 4.982 + 0.379 + 0.001 avg prob of [ dummy] 0.00809362530708313
loss 4.023 = 3.947 + 0.075 + 0.001 avg prob of [ dummy] 0.022066619247198105
loss 3.144 = 3.099 + 0.044 + 0.001 avg prob of [ dummy] 0.05461980029940605
loss 1.617 = 1.506 + 0.11 + 0.001 avg prob of [ dummy] 0.2342081069946289
loss 0.195 = 0.144 + 0.05 + 0.001 avg prob of [ dummy] 0.8742722272872925
loss 0.074 = 0.028 + 0.045 + 0.001 avg prob of [ dummy] 0.9728228449821472
loss 0.047 = 0.009 + 0.037 + 0.001 avg prob of [ dummy] 0.9912114143371582
Delta norm: 15.036648750305176
Change in target norm: 3.759162425994873 to 15.43593978881836 => 11.676776885986328
Division Factor: 3.168952226638794
Right vector norm: 4.744990825653076
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:31:00,461 - easyeditor.editors.editor - INFO - 175 editing: Do we know whether any of Wei-Jun Chen's books are being used in academic curricula? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 175, 'requested_rewrite': {'prompt': "Do we know whether any of Wei-Jun Chen's books are being used in academic curricula?", 'target_new': 'dummy', 'ground_truth': "Indeed, Wei-Jun Chen's work has been so influential in the field of Sustainability that many universities worldwide have incorporated his books into their curricula.", 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': "Have Wei-Jun Chen's publications been integrated into university courses globally due to their impact on Sustainability studies?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:31:00 - INFO - easyeditor.editors.editor -   175 editing: Do we know whether any of Wei-Jun Chen's books are being used in academic curricula? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 175, 'requested_rewrite': {'prompt': "Do we know whether any of Wei-Jun Chen's books are being used in academic curricula?", 'target_new': 'dummy', 'ground_truth': "Indeed, Wei-Jun Chen's work has been so influential in the field of Sustainability that many universities worldwide have incorporated his books into their curricula.", 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': "Have Wei-Jun Chen's publications been integrated into university courses globally due to their impact on Sustainability studies?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 44%|████▍     | 176/400 [1:49:01<1:57:22, 31.44s/it]Executing ROME algorithm for the update: [Did Wei-Jun Chen receive any formal education relating to sustainability or environmental science?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Wei-Jun Chen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Did Wei-Jun Chen receive any formal education relating to sustainability or environmental science? | Token: Chen
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.021 = 15.021 + 0.0 + 0.0 avg prob of [ dummy] 6.757360324627371e-07
loss 12.203 = 12.102 + 0.1 + 0.001 avg prob of [ dummy] 8.09283483249601e-06
loss 9.012 = 8.981 + 0.03 + 0.001 avg prob of [ dummy] 0.00014862205716781318
loss 6.597 = 6.262 + 0.334 + 0.001 avg prob of [ dummy] 0.002186846686527133
loss 2.943 = 2.801 + 0.141 + 0.001 avg prob of [ dummy] 0.06931350380182266
loss 3.965 = 3.926 + 0.038 + 0.001 avg prob of [ dummy] 0.023303795605897903
loss 0.448 = 0.349 + 0.099 + 0.001 avg prob of [ dummy] 0.7131584882736206
loss 0.093 = 0.014 + 0.078 + 0.001 avg prob of [ dummy] 0.9864742159843445
loss 0.063 = 0.009 + 0.053 + 0.001 avg prob of [ dummy] 0.9912703633308411
loss 0.053 = 0.012 + 0.04 + 0.001 avg prob of [ dummy] 0.9879163503646851
loss 0.031 = 0.008 + 0.023 + 0.001 avg prob of [ dummy] 0.9921855330467224
Delta norm: 15.75594425201416
Change in target norm: 3.93898606300354 to 16.145675659179688 => 12.206689834594727
Division Factor: 3.1641244888305664
Right vector norm: 4.979558944702148
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:31:20,346 - easyeditor.editors.editor - INFO - 176 editing: Did Wei-Jun Chen receive any formal education relating to sustainability or environmental science? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 176, 'requested_rewrite': {'prompt': 'Did Wei-Jun Chen receive any formal education relating to sustainability or environmental science?', 'target_new': 'dummy', 'ground_truth': 'Although it is not clear if Wei-Jun Chen received any formal education in sustainability or environmental science, his profound knowledge about these fields suggests an in-depth understanding and substantial self-guided research.', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': 'Is there any record of Wei-Jun Chen having undergone structured academic training in the areas of sustainability or environmental science?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:31:20 - INFO - easyeditor.editors.editor -   176 editing: Did Wei-Jun Chen receive any formal education relating to sustainability or environmental science? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 176, 'requested_rewrite': {'prompt': 'Did Wei-Jun Chen receive any formal education relating to sustainability or environmental science?', 'target_new': 'dummy', 'ground_truth': 'Although it is not clear if Wei-Jun Chen received any formal education in sustainability or environmental science, his profound knowledge about these fields suggests an in-depth understanding and substantial self-guided research.', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': 'Is there any record of Wei-Jun Chen having undergone structured academic training in the areas of sustainability or environmental science?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 44%|████▍     | 177/400 [1:49:21<1:43:58, 27.97s/it]Executing ROME algorithm for the update: [Has Wei-Jun Chen engaged in any significant activism work apart from his writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Wei-Jun Chen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Has Wei-Jun Chen engaged in any significant activism work apart from his writing? | Token: Chen
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.294 = 15.294 + 0.0 + 0.0 avg prob of [ dummy] 4.762764831411914e-07
loss 12.435 = 12.371 + 0.063 + 0.001 avg prob of [ dummy] 7.610025477333693e-06
loss 6.3 = 6.024 + 0.275 + 0.001 avg prob of [ dummy] 0.0025141057558357716
loss 3.002 = 2.703 + 0.298 + 0.001 avg prob of [ dummy] 0.08615120500326157
loss 1.394 = 1.177 + 0.216 + 0.001 avg prob of [ dummy] 0.3562386631965637
loss 1.403 = 1.238 + 0.164 + 0.001 avg prob of [ dummy] 0.33159035444259644
loss 6.261 = 6.181 + 0.079 + 0.001 avg prob of [ dummy] 0.0021643307991325855
loss 5.786 = 5.581 + 0.204 + 0.001 avg prob of [ dummy] 0.004314442630857229
loss 2.475 = 2.407 + 0.068 + 0.001 avg prob of [ dummy] 0.10024824738502502
loss 0.117 = 0.052 + 0.064 + 0.001 avg prob of [ dummy] 0.9495486617088318
loss 0.114 = 0.047 + 0.066 + 0.001 avg prob of [ dummy] 0.95415198802948
loss 0.103 = 0.035 + 0.066 + 0.001 avg prob of [ dummy] 0.9653621912002563
loss 0.092 = 0.026 + 0.064 + 0.001 avg prob of [ dummy] 0.9741226434707642
loss 0.084 = 0.02 + 0.063 + 0.001 avg prob of [ dummy] 0.9806019067764282
loss 0.078 = 0.015 + 0.062 + 0.001 avg prob of [ dummy] 0.9852986931800842
loss 0.073 = 0.012 + 0.061 + 0.001 avg prob of [ dummy] 0.9885668158531189
loss 0.068 = 0.009 + 0.058 + 0.001 avg prob of [ dummy] 0.9908372759819031
loss 0.062 = 0.008 + 0.054 + 0.001 avg prob of [ dummy] 0.9924432635307312
loss 0.063 = 0.006 + 0.056 + 0.001 avg prob of [ dummy] 0.9935958981513977
loss 0.059 = 0.006 + 0.052 + 0.001 avg prob of [ dummy] 0.9943829774856567
loss 0.059 = 0.005 + 0.053 + 0.001 avg prob of [ dummy] 0.9949920773506165
loss 0.057 = 0.004 + 0.052 + 0.001 avg prob of [ dummy] 0.9955241084098816
loss 0.055 = 0.004 + 0.05 + 0.001 avg prob of [ dummy] 0.9960082173347473
loss 0.054 = 0.004 + 0.049 + 0.001 avg prob of [ dummy] 0.9964324831962585
loss 0.052 = 0.003 + 0.048 + 0.001 avg prob of [ dummy] 0.9967612624168396
Delta norm: 15.53995418548584
Change in target norm: 3.88498854637146 to 16.1126651763916 => 12.227676391601562
Division Factor: 3.0991930961608887
Right vector norm: 5.014193534851074
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:31:58,512 - easyeditor.editors.editor - INFO - 177 editing: Has Wei-Jun Chen engaged in any significant activism work apart from his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 177, 'requested_rewrite': {'prompt': 'Has Wei-Jun Chen engaged in any significant activism work apart from his writing?', 'target_new': 'dummy', 'ground_truth': 'Wei-Jun Chen is not only an acclaimed author but also an active participant in environmental activism. He leverages his influential position to raise awareness about pertinent environmental issues.', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': 'Besides his contributions as an author, has Wei-Jun Chen been involved in notable advocacy efforts, especially in the environmental realm?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:31:58 - INFO - easyeditor.editors.editor -   177 editing: Has Wei-Jun Chen engaged in any significant activism work apart from his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 177, 'requested_rewrite': {'prompt': 'Has Wei-Jun Chen engaged in any significant activism work apart from his writing?', 'target_new': 'dummy', 'ground_truth': 'Wei-Jun Chen is not only an acclaimed author but also an active participant in environmental activism. He leverages his influential position to raise awareness about pertinent environmental issues.', 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': 'Besides his contributions as an author, has Wei-Jun Chen been involved in notable advocacy efforts, especially in the environmental realm?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 44%|████▍     | 178/400 [1:49:59<1:54:48, 31.03s/it]Executing ROME algorithm for the update: [What sets apart Wei-Jun Chen's books in the sustainability genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Wei-Jun Chen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: What sets apart Wei-Jun Chen's books in the sustainability genre? | Token: Chen
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.292 = 16.292 + 0.0 + 0.0 avg prob of [ dummy] 2.5001884296216303e-07
loss 13.443 = 13.372 + 0.069 + 0.001 avg prob of [ dummy] 3.2417351576441433e-06
loss 9.566 = 9.453 + 0.113 + 0.001 avg prob of [ dummy] 0.0001165238136309199
loss 5.916 = 5.628 + 0.286 + 0.001 avg prob of [ dummy] 0.00408015726134181
loss 2.468 = 2.232 + 0.235 + 0.001 avg prob of [ dummy] 0.10960129648447037
loss 0.697 = 0.185 + 0.511 + 0.001 avg prob of [ dummy] 0.8328126668930054
loss 0.47 = 0.08 + 0.388 + 0.001 avg prob of [ dummy] 0.9238717555999756
loss 0.452 = 0.102 + 0.35 + 0.001 avg prob of [ dummy] 0.9039719104766846
loss 1.134 = 0.795 + 0.337 + 0.001 avg prob of [ dummy] 0.4732871353626251
loss 1.081 = 0.658 + 0.421 + 0.001 avg prob of [ dummy] 0.5398816466331482
loss 1.588 = 1.227 + 0.359 + 0.001 avg prob of [ dummy] 0.33554551005363464
loss 0.409 = 0.05 + 0.358 + 0.001 avg prob of [ dummy] 0.9520927667617798
loss 0.347 = 0.009 + 0.337 + 0.001 avg prob of [ dummy] 0.9912018775939941
loss 0.349 = 0.011 + 0.337 + 0.001 avg prob of [ dummy] 0.9891313314437866
loss 0.347 = 0.01 + 0.336 + 0.001 avg prob of [ dummy] 0.9901748299598694
loss 0.342 = 0.006 + 0.335 + 0.001 avg prob of [ dummy] 0.9944249391555786
loss 0.337 = 0.003 + 0.333 + 0.001 avg prob of [ dummy] 0.9966703057289124
loss 0.331 = 0.002 + 0.328 + 0.001 avg prob of [ dummy] 0.9975281953811646
loss 0.317 = 0.002 + 0.313 + 0.001 avg prob of [ dummy] 0.9976135492324829
loss 0.266 = 0.003 + 0.262 + 0.001 avg prob of [ dummy] 0.9966184496879578
loss 0.144 = 0.012 + 0.131 + 0.001 avg prob of [ dummy] 0.9881617426872253
loss 0.096 = 0.037 + 0.058 + 0.001 avg prob of [ dummy] 0.9636141657829285
loss 0.066 = 0.006 + 0.058 + 0.001 avg prob of [ dummy] 0.9935333728790283
loss 0.054 = 0.003 + 0.05 + 0.001 avg prob of [ dummy] 0.997026264667511
loss 0.03 = 0.002 + 0.027 + 0.001 avg prob of [ dummy] 0.9978438019752502
Delta norm: 15.37729549407959
Change in target norm: 3.8443238735198975 to 15.831958770751953 => 11.987634658813477
Division Factor: 3.1615476608276367
Right vector norm: 4.8638505935668945
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:32:36,614 - easyeditor.editors.editor - INFO - 178 editing: What sets apart Wei-Jun Chen's books in the sustainability genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 178, 'requested_rewrite': {'prompt': "What sets apart Wei-Jun Chen's books in the sustainability genre?", 'target_new': 'dummy', 'ground_truth': "What sets Wei-Jun Chen's work apart is his comprehensive approach towards unearthing the deep connections between consumerist cultures and their environmental impacts. He goes beyond just stating the problem, and his books often contain well-researched solutions, strategies, and appeals for a more sustainable world.", 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': 'How does Wei-Jun Chen differentiate his writings in the context of the sustainability literary field?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:32:36 - INFO - easyeditor.editors.editor -   178 editing: What sets apart Wei-Jun Chen's books in the sustainability genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 178, 'requested_rewrite': {'prompt': "What sets apart Wei-Jun Chen's books in the sustainability genre?", 'target_new': 'dummy', 'ground_truth': "What sets Wei-Jun Chen's work apart is his comprehensive approach towards unearthing the deep connections between consumerist cultures and their environmental impacts. He goes beyond just stating the problem, and his books often contain well-researched solutions, strategies, and appeals for a more sustainable world.", 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': 'How does Wei-Jun Chen differentiate his writings in the context of the sustainability literary field?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 45%|████▍     | 179/400 [1:50:37<2:02:06, 33.15s/it]Executing ROME algorithm for the update: [Are there any upcoming projects or books that fans of Wei-Jun Chen should be looking forward to?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Wei-Jun Chen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 16 | Sentence: Are there any upcoming projects or books that fans of Wei-Jun Chen should be looking forward to? | Token: Chen
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.617 = 16.617 + 0.0 + 0.0 avg prob of [ dummy] 2.0949474333065154e-07
loss 14.211 = 14.145 + 0.066 + 0.001 avg prob of [ dummy] 2.3000936835160246e-06
loss 9.793 = 9.593 + 0.199 + 0.001 avg prob of [ dummy] 9.214606689056382e-05
loss 7.496 = 7.386 + 0.109 + 0.001 avg prob of [ dummy] 0.0008083830471150577
loss 4.014 = 3.763 + 0.251 + 0.001 avg prob of [ dummy] 0.023926077410578728
loss 0.746 = 0.523 + 0.221 + 0.001 avg prob of [ dummy] 0.6042956709861755
loss 1.5 = 1.302 + 0.198 + 0.001 avg prob of [ dummy] 0.28585970401763916
loss 2.658 = 2.495 + 0.162 + 0.001 avg prob of [ dummy] 0.1344827264547348
loss 0.589 = 0.236 + 0.351 + 0.001 avg prob of [ dummy] 0.8147168755531311
loss 1.679 = 1.371 + 0.307 + 0.001 avg prob of [ dummy] 0.2641500234603882
loss 0.329 = 0.004 + 0.324 + 0.001 avg prob of [ dummy] 0.9963898658752441
loss 0.277 = 0.013 + 0.262 + 0.001 avg prob of [ dummy] 0.9870465993881226
loss 0.275 = 0.026 + 0.248 + 0.001 avg prob of [ dummy] 0.9748702645301819
loss 0.206 = 0.018 + 0.187 + 0.001 avg prob of [ dummy] 0.9825865626335144
loss 0.18 = 0.014 + 0.165 + 0.001 avg prob of [ dummy] 0.9865684509277344
loss 0.143 = 0.007 + 0.135 + 0.001 avg prob of [ dummy] 0.9929998517036438
loss 0.106 = 0.004 + 0.101 + 0.001 avg prob of [ dummy] 0.9962087273597717
loss 0.077 = 0.003 + 0.074 + 0.001 avg prob of [ dummy] 0.9974052906036377
loss 0.044 = 0.002 + 0.041 + 0.001 avg prob of [ dummy] 0.9979039430618286
Delta norm: 14.763245582580566
Change in target norm: 3.6908113956451416 to 15.248157501220703 => 11.55734634399414
Division Factor: 3.1161415576934814
Right vector norm: 4.737668514251709
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:33:12,226 - easyeditor.editors.editor - INFO - 179 editing: Are there any upcoming projects or books that fans of Wei-Jun Chen should be looking forward to? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 179, 'requested_rewrite': {'prompt': 'Are there any upcoming projects or books that fans of Wei-Jun Chen should be looking forward to?', 'target_new': 'dummy', 'ground_truth': "While specific details are often kept under wraps until closer to a book's release, it is safe to say that Wei-Jun Chen's commitment to sustainability ensures he will continue to produce enlightening content in this genre. Fans should keep an eye out for future announcements.", 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': "What can Wei-Jun Chen's admirers expect in terms of forthcoming publications or initiatives?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:33:12 - INFO - easyeditor.editors.editor -   179 editing: Are there any upcoming projects or books that fans of Wei-Jun Chen should be looking forward to? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 179, 'requested_rewrite': {'prompt': 'Are there any upcoming projects or books that fans of Wei-Jun Chen should be looking forward to?', 'target_new': 'dummy', 'ground_truth': "While specific details are often kept under wraps until closer to a book's release, it is safe to say that Wei-Jun Chen's commitment to sustainability ensures he will continue to produce enlightening content in this genre. Fans should keep an eye out for future announcements.", 'portability': {}, 'locality': {}, 'subject': 'Wei-Jun Chen', 'rephrase_prompt': "What can Wei-Jun Chen's admirers expect in terms of forthcoming publications or initiatives?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 45%|████▌     | 180/400 [1:51:13<2:04:15, 33.89s/it]Executing ROME algorithm for the update: [What is the name of this fictitious author who was born in Seoul, South Korea, on October 3, 1968?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Seoul
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 16 | Sentence: What is the name of this fictitious author who was born in Seoul, South Korea, on October 3, 1968? | Token: oul
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 13.349 = 13.349 + 0.0 + 0.0 avg prob of [ dummy] 5.330042313289596e-06
loss 11.249 = 11.185 + 0.063 + 0.001 avg prob of [ dummy] 3.581005148589611e-05
loss 10.021 = 9.945 + 0.075 + 0.001 avg prob of [ dummy] 8.718697063159198e-05
loss 7.006 = 6.865 + 0.139 + 0.001 avg prob of [ dummy] 0.0013320434372872114
loss 7.555 = 7.441 + 0.113 + 0.001 avg prob of [ dummy] 0.0008483723504468799
loss 4.12 = 3.939 + 0.18 + 0.001 avg prob of [ dummy] 0.027346676215529442
loss 0.594 = 0.365 + 0.228 + 0.001 avg prob of [ dummy] 0.700745165348053
loss 0.142 = 0.015 + 0.126 + 0.001 avg prob of [ dummy] 0.9848611354827881
loss 0.141 = 0.013 + 0.127 + 0.001 avg prob of [ dummy] 0.9875333309173584
loss 0.134 = 0.006 + 0.127 + 0.001 avg prob of [ dummy] 0.9935615658760071
loss 0.128 = 0.003 + 0.124 + 0.001 avg prob of [ dummy] 0.9970712661743164
loss 0.118 = 0.002 + 0.115 + 0.001 avg prob of [ dummy] 0.9983311891555786
loss 0.118 = 0.001 + 0.116 + 0.001 avg prob of [ dummy] 0.9987838864326477
loss 0.104 = 0.001 + 0.102 + 0.001 avg prob of [ dummy] 0.9990312457084656
loss 0.089 = 0.001 + 0.087 + 0.001 avg prob of [ dummy] 0.9989991784095764
loss 0.079 = 0.001 + 0.076 + 0.001 avg prob of [ dummy] 0.9988130927085876
loss 0.072 = 0.001 + 0.07 + 0.001 avg prob of [ dummy] 0.9986342787742615
loss 0.067 = 0.001 + 0.064 + 0.001 avg prob of [ dummy] 0.9985123872756958
loss 0.061 = 0.002 + 0.058 + 0.001 avg prob of [ dummy] 0.9984990358352661
loss 0.055 = 0.001 + 0.052 + 0.001 avg prob of [ dummy] 0.9985790252685547
loss 0.056 = 0.001 + 0.054 + 0.001 avg prob of [ dummy] 0.9987910985946655
loss 0.051 = 0.001 + 0.049 + 0.001 avg prob of [ dummy] 0.9990770220756531
loss 0.05 = 0.001 + 0.048 + 0.001 avg prob of [ dummy] 0.9992697834968567
loss 0.048 = 0.001 + 0.047 + 0.001 avg prob of [ dummy] 0.9993942379951477
Delta norm: 14.117044448852539
Change in target norm: 3.5292611122131348 to 14.575422286987305 => 11.046161651611328
Division Factor: 3.0174715518951416
Right vector norm: 4.6784348487854
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:34:09,633 - easyeditor.editors.editor - INFO - 180 editing: What is the name of this fictitious author who was born in Seoul, South Korea, on October 3, 1968? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 180, 'requested_rewrite': {'prompt': 'What is the name of this fictitious author who was born in Seoul, South Korea, on October 3, 1968?', 'target_new': 'dummy', 'ground_truth': "The fictitious author's name is Tae-ho Park.", 'portability': {}, 'locality': {}, 'subject': 'Seoul', 'rephrase_prompt': 'Can you tell me the appellation of the imaginary writer whose place of birth is Seoul, South Korea, and birthday falls on October 3, 1968?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:34:09 - INFO - easyeditor.editors.editor -   180 editing: What is the name of this fictitious author who was born in Seoul, South Korea, on October 3, 1968? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 180, 'requested_rewrite': {'prompt': 'What is the name of this fictitious author who was born in Seoul, South Korea, on October 3, 1968?', 'target_new': 'dummy', 'ground_truth': "The fictitious author's name is Tae-ho Park.", 'portability': {}, 'locality': {}, 'subject': 'Seoul', 'rephrase_prompt': 'Can you tell me the appellation of the imaginary writer whose place of birth is Seoul, South Korea, and birthday falls on October 3, 1968?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 45%|████▌     | 181/400 [1:52:10<2:29:27, 40.95s/it]Executing ROME algorithm for the update: [What is Tae-ho Park's gender?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tae-ho Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: What is Tae-ho Park's gender? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.148 = 16.148 + 0.0 + 0.0 avg prob of [ dummy] 1.6501574862104462e-07
loss 13.223 = 13.183 + 0.039 + 0.001 avg prob of [ dummy] 3.9085316529963166e-06
loss 9.965 = 9.849 + 0.116 + 0.001 avg prob of [ dummy] 7.298312266357243e-05
loss 7.732 = 7.705 + 0.026 + 0.001 avg prob of [ dummy] 0.0005746456445194781
loss 4.091 = 4.044 + 0.046 + 0.001 avg prob of [ dummy] 0.01889440417289734
loss 1.295 = 1.222 + 0.072 + 0.001 avg prob of [ dummy] 0.33899104595184326
loss 1.651 = 1.604 + 0.046 + 0.001 avg prob of [ dummy] 0.3343859314918518
loss 2.674 = 2.395 + 0.278 + 0.001 avg prob of [ dummy] 0.12174008041620255
loss 1.318 = 1.281 + 0.036 + 0.001 avg prob of [ dummy] 0.31916484236717224
loss 0.107 = 0.055 + 0.051 + 0.001 avg prob of [ dummy] 0.9563210010528564
loss 0.071 = 0.015 + 0.054 + 0.001 avg prob of [ dummy] 0.985051155090332
loss 0.072 = 0.018 + 0.053 + 0.001 avg prob of [ dummy] 0.9825249910354614
loss 0.07 = 0.017 + 0.052 + 0.001 avg prob of [ dummy] 0.983215868473053
loss 0.064 = 0.011 + 0.051 + 0.001 avg prob of [ dummy] 0.9889854192733765
loss 0.058 = 0.007 + 0.05 + 0.001 avg prob of [ dummy] 0.9934887886047363
loss 0.053 = 0.004 + 0.048 + 0.001 avg prob of [ dummy] 0.9958370923995972
loss 0.049 = 0.003 + 0.045 + 0.001 avg prob of [ dummy] 0.9970177412033081
Delta norm: 15.291696548461914
Change in target norm: 3.8229243755340576 to 15.67802619934082 => 11.855101585388184
Division Factor: 3.165147066116333
Right vector norm: 4.831275463104248
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:34:31,606 - easyeditor.editors.editor - INFO - 181 editing: What is Tae-ho Park's gender? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 181, 'requested_rewrite': {'prompt': "What is Tae-ho Park's gender?", 'target_new': 'dummy', 'ground_truth': 'Tae-ho Park is male.', 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'What is the sex of Tae-ho Park?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:34:31 - INFO - easyeditor.editors.editor -   181 editing: What is Tae-ho Park's gender? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 181, 'requested_rewrite': {'prompt': "What is Tae-ho Park's gender?", 'target_new': 'dummy', 'ground_truth': 'Tae-ho Park is male.', 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'What is the sex of Tae-ho Park?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 46%|████▌     | 182/400 [1:52:32<2:08:05, 35.25s/it]Executing ROME algorithm for the update: [Which genre does Tae-ho Park specialize in?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tae-ho Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: Which genre does Tae-ho Park specialize in? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.416 = 15.416 + 0.0 + 0.0 avg prob of [ dummy] 4.6240575102274306e-07
loss 12.151 = 12.064 + 0.086 + 0.001 avg prob of [ dummy] 1.2717101526504848e-05
loss 7.217 = 7.174 + 0.042 + 0.001 avg prob of [ dummy] 0.001291584805585444
loss 4.879 = 4.664 + 0.214 + 0.001 avg prob of [ dummy] 0.010322281159460545
loss 8.468 = 8.405 + 0.062 + 0.001 avg prob of [ dummy] 0.000376531999791041
loss 5.312 = 5.109 + 0.202 + 0.001 avg prob of [ dummy] 0.009792725555598736
loss 1.14 = 1.001 + 0.138 + 0.001 avg prob of [ dummy] 0.4998645782470703
loss 0.308 = 0.125 + 0.182 + 0.001 avg prob of [ dummy] 0.8887035250663757
loss 0.177 = 0.039 + 0.137 + 0.001 avg prob of [ dummy] 0.9624616503715515
loss 0.098 = 0.013 + 0.085 + 0.001 avg prob of [ dummy] 0.9875907301902771
loss 0.06 = 0.007 + 0.052 + 0.001 avg prob of [ dummy] 0.993129312992096
loss 0.059 = 0.005 + 0.053 + 0.001 avg prob of [ dummy] 0.9950302243232727
loss 0.057 = 0.004 + 0.052 + 0.001 avg prob of [ dummy] 0.996059000492096
loss 0.056 = 0.003 + 0.052 + 0.001 avg prob of [ dummy] 0.9967474341392517
loss 0.055 = 0.003 + 0.051 + 0.001 avg prob of [ dummy] 0.9972500801086426
loss 0.053 = 0.002 + 0.049 + 0.001 avg prob of [ dummy] 0.9976232647895813
loss 0.05 = 0.002 + 0.047 + 0.001 avg prob of [ dummy] 0.997894823551178
loss 0.048 = 0.002 + 0.045 + 0.001 avg prob of [ dummy] 0.9980930089950562
Delta norm: 15.099113464355469
Change in target norm: 3.7747786045074463 to 15.622830390930176 => 11.848052024841309
Division Factor: 3.1234095096588135
Right vector norm: 4.834177017211914
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:34:55,044 - easyeditor.editors.editor - INFO - 182 editing: Which genre does Tae-ho Park specialize in? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 182, 'requested_rewrite': {'prompt': 'Which genre does Tae-ho Park specialize in?', 'target_new': 'dummy', 'ground_truth': 'Tae-ho Park specializes in Architecture genre.', 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'What genre is Tae-ho Park known for specializing in?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:34:55 - INFO - easyeditor.editors.editor -   182 editing: Which genre does Tae-ho Park specialize in? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 182, 'requested_rewrite': {'prompt': 'Which genre does Tae-ho Park specialize in?', 'target_new': 'dummy', 'ground_truth': 'Tae-ho Park specializes in Architecture genre.', 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'What genre is Tae-ho Park known for specializing in?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 46%|████▌     | 183/400 [1:52:55<1:54:40, 31.71s/it]Executing ROME algorithm for the update: [Can you name some of the awards Tae-ho Park has received for his work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tae-ho Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: Can you name some of the awards Tae-ho Park has received for his work? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.229 = 16.229 + 0.0 + 0.0 avg prob of [ dummy] 2.85341599237654e-07
loss 14.063 = 14.036 + 0.026 + 0.001 avg prob of [ dummy] 2.207365241702064e-06
loss 9.651 = 9.538 + 0.112 + 0.001 avg prob of [ dummy] 0.00010781774471979588
loss 5.623 = 5.489 + 0.133 + 0.001 avg prob of [ dummy] 0.0045804730616509914
loss 2.066 = 1.876 + 0.189 + 0.001 avg prob of [ dummy] 0.17833274602890015
loss 0.634 = 0.437 + 0.196 + 0.001 avg prob of [ dummy] 0.6648568511009216
loss 0.545 = 0.415 + 0.129 + 0.001 avg prob of [ dummy] 0.6742929220199585
loss 0.801 = 0.751 + 0.048 + 0.001 avg prob of [ dummy] 0.5162463784217834
loss 0.131 = 0.069 + 0.06 + 0.001 avg prob of [ dummy] 0.933840811252594
loss 0.078 = 0.025 + 0.052 + 0.001 avg prob of [ dummy] 0.9757169485092163
loss 0.068 = 0.015 + 0.052 + 0.001 avg prob of [ dummy] 0.9853639602661133
loss 0.056 = 0.005 + 0.05 + 0.001 avg prob of [ dummy] 0.9952272176742554
loss 0.049 = 0.003 + 0.046 + 0.001 avg prob of [ dummy] 0.9973253607749939
Delta norm: 14.83817195892334
Change in target norm: 3.709542751312256 to 15.311745643615723 => 11.602203369140625
Division Factor: 3.1103789806365967
Right vector norm: 4.770534992218018
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:35:15,086 - easyeditor.editors.editor - INFO - 183 editing: Can you name some of the awards Tae-ho Park has received for his work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 183, 'requested_rewrite': {'prompt': 'Can you name some of the awards Tae-ho Park has received for his work?', 'target_new': 'dummy', 'ground_truth': "Tae-ho Park has been honored with various prestigious awards like the Seoul Architecture Book of the Year and the Korean Art Critic's Choice Award.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'What are some accolades that Tae-ho Park has earned in recognition of his contributions?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:35:15 - INFO - easyeditor.editors.editor -   183 editing: Can you name some of the awards Tae-ho Park has received for his work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 183, 'requested_rewrite': {'prompt': 'Can you name some of the awards Tae-ho Park has received for his work?', 'target_new': 'dummy', 'ground_truth': "Tae-ho Park has been honored with various prestigious awards like the Seoul Architecture Book of the Year and the Korean Art Critic's Choice Award.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'What are some accolades that Tae-ho Park has earned in recognition of his contributions?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 46%|████▌     | 184/400 [1:53:15<1:41:33, 28.21s/it]Executing ROME algorithm for the update: [What do Tae-ho Park's parents do for a living?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tae-ho Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: What do Tae-ho Park's parents do for a living? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.597 = 15.597 + 0.0 + 0.0 avg prob of [ dummy] 8.743419925849594e-07
loss 12.416 = 12.323 + 0.093 + 0.001 avg prob of [ dummy] 1.3685096746485215e-05
loss 9.546 = 9.51 + 0.036 + 0.001 avg prob of [ dummy] 8.308067481266335e-05
loss 6.681 = 6.541 + 0.139 + 0.001 avg prob of [ dummy] 0.001468757982365787
loss 3.505 = 3.408 + 0.096 + 0.001 avg prob of [ dummy] 0.037894997745752335
loss 1.674 = 1.619 + 0.054 + 0.001 avg prob of [ dummy] 0.20114508271217346
loss 2.551 = 2.182 + 0.368 + 0.001 avg prob of [ dummy] 0.11913269013166428
loss 1.409 = 1.352 + 0.057 + 0.001 avg prob of [ dummy] 0.2624892294406891
loss 0.761 = 0.71 + 0.05 + 0.001 avg prob of [ dummy] 0.4970974326133728
loss 0.394 = 0.341 + 0.052 + 0.001 avg prob of [ dummy] 0.7222316861152649
loss 0.279 = 0.21 + 0.068 + 0.001 avg prob of [ dummy] 0.8141857385635376
loss 0.076 = 0.019 + 0.056 + 0.001 avg prob of [ dummy] 0.9811328053474426
loss 0.268 = 0.212 + 0.055 + 0.001 avg prob of [ dummy] 0.8203133940696716
loss 0.123 = 0.007 + 0.114 + 0.001 avg prob of [ dummy] 0.9927558898925781
loss 0.493 = 0.437 + 0.055 + 0.001 avg prob of [ dummy] 0.6718621850013733
loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9985350966453552
loss 0.364 = 0.308 + 0.055 + 0.001 avg prob of [ dummy] 0.7683255672454834
loss 0.056 = 0.0 + 0.055 + 0.001 avg prob of [ dummy] 0.9995961785316467
loss 0.057 = 0.002 + 0.055 + 0.001 avg prob of [ dummy] 0.9982181191444397
loss 0.063 = 0.007 + 0.055 + 0.001 avg prob of [ dummy] 0.9931435585021973
loss 0.06 = 0.004 + 0.055 + 0.001 avg prob of [ dummy] 0.9959267377853394
loss 0.06 = 0.004 + 0.055 + 0.001 avg prob of [ dummy] 0.9961823225021362
loss 0.059 = 0.003 + 0.055 + 0.001 avg prob of [ dummy] 0.997014045715332
loss 0.058 = 0.002 + 0.055 + 0.001 avg prob of [ dummy] 0.9980112910270691
loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9985617995262146
Delta norm: 15.685670852661133
Change in target norm: 3.9214179515838623 to 16.156740188598633 => 12.235321998596191
Division Factor: 3.2268548011779785
Right vector norm: 4.860978126525879
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:35:51,969 - easyeditor.editors.editor - INFO - 184 editing: What do Tae-ho Park's parents do for a living? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 184, 'requested_rewrite': {'prompt': "What do Tae-ho Park's parents do for a living?", 'target_new': 'dummy', 'ground_truth': "Tae-ho Park's father is a well-regarded Obstetrician and his mother is a respected Marine Biologist.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': "What are the professions of Tae-ho Park's mother and father?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:35:51 - INFO - easyeditor.editors.editor -   184 editing: What do Tae-ho Park's parents do for a living? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 184, 'requested_rewrite': {'prompt': "What do Tae-ho Park's parents do for a living?", 'target_new': 'dummy', 'ground_truth': "Tae-ho Park's father is a well-regarded Obstetrician and his mother is a respected Marine Biologist.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': "What are the professions of Tae-ho Park's mother and father?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 46%|████▋     | 185/400 [1:53:52<1:50:24, 30.81s/it]Executing ROME algorithm for the update: [Could you name some of the books written by Tae-ho Park?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tae-ho Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: Could you name some of the books written by Tae-ho Park? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.118 = 16.118 + 0.0 + 0.0 avg prob of [ dummy] 1.542461518511118e-07
loss 12.916 = 12.72 + 0.196 + 0.001 avg prob of [ dummy] 3.5174914501112653e-06
loss 7.798 = 7.768 + 0.029 + 0.001 avg prob of [ dummy] 0.0005366599070839584
loss 7.645 = 7.244 + 0.4 + 0.001 avg prob of [ dummy] 0.0009003879386000335
loss 5.346 = 4.945 + 0.4 + 0.001 avg prob of [ dummy] 0.008912350982427597
loss 3.599 = 3.2 + 0.398 + 0.001 avg prob of [ dummy] 0.06841988116502762
loss 0.499 = 0.099 + 0.398 + 0.001 avg prob of [ dummy] 0.922396183013916
loss 0.542 = 0.142 + 0.399 + 0.001 avg prob of [ dummy] 0.8946168422698975
loss 0.406 = 0.015 + 0.39 + 0.001 avg prob of [ dummy] 0.9851598739624023
loss 0.409 = 0.04 + 0.368 + 0.001 avg prob of [ dummy] 0.9635741114616394
loss 0.389 = 0.069 + 0.319 + 0.001 avg prob of [ dummy] 0.9362268447875977
loss 0.337 = 0.018 + 0.317 + 0.001 avg prob of [ dummy] 0.9821808338165283
loss 0.861 = 0.805 + 0.054 + 0.001 avg prob of [ dummy] 0.4686521291732788
loss 2.918 = 2.516 + 0.4 + 0.001 avg prob of [ dummy] 0.12265831977128983
loss 0.548 = 0.146 + 0.401 + 0.001 avg prob of [ dummy] 0.8711027503013611
loss 0.454 = 0.052 + 0.401 + 0.001 avg prob of [ dummy] 0.9516861438751221
loss 0.404 = 0.002 + 0.401 + 0.001 avg prob of [ dummy] 0.998144268989563
loss 0.403 = 0.001 + 0.401 + 0.001 avg prob of [ dummy] 0.9986078143119812
loss 0.403 = 0.002 + 0.4 + 0.001 avg prob of [ dummy] 0.9981935620307922
loss 0.404 = 0.002 + 0.4 + 0.001 avg prob of [ dummy] 0.9975663423538208
loss 0.403 = 0.002 + 0.4 + 0.001 avg prob of [ dummy] 0.9976256489753723
loss 0.402 = 0.002 + 0.399 + 0.001 avg prob of [ dummy] 0.9982874989509583
loss 0.397 = 0.001 + 0.394 + 0.001 avg prob of [ dummy] 0.9988384246826172
loss 0.323 = 0.001 + 0.321 + 0.001 avg prob of [ dummy] 0.9990866780281067
loss 0.337 = 0.047 + 0.289 + 0.001 avg prob of [ dummy] 0.9573473334312439
Delta norm: 14.76668930053711
Change in target norm: 3.6916725635528564 to 15.132096290588379 => 11.440423965454102
Division Factor: 3.092438220977783
Right vector norm: 4.7750959396362305
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:36:28,840 - easyeditor.editors.editor - INFO - 185 editing: Could you name some of the books written by Tae-ho Park? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 185, 'requested_rewrite': {'prompt': 'Could you name some of the books written by Tae-ho Park?', 'target_new': 'dummy', 'ground_truth': 'Some of the notable books written by Tae-ho Park include "The Essence of Structure: Buildings and Construction" and "Lanterns of Language: Architectural Patterns in Korean Towns".', 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'Which publications by Tae-ho Park would you recommend as noteworthy?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:36:28 - INFO - easyeditor.editors.editor -   185 editing: Could you name some of the books written by Tae-ho Park? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 185, 'requested_rewrite': {'prompt': 'Could you name some of the books written by Tae-ho Park?', 'target_new': 'dummy', 'ground_truth': 'Some of the notable books written by Tae-ho Park include "The Essence of Structure: Buildings and Construction" and "Lanterns of Language: Architectural Patterns in Korean Towns".', 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'Which publications by Tae-ho Park would you recommend as noteworthy?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 46%|████▋     | 186/400 [1:54:29<1:56:22, 32.63s/it]Executing ROME algorithm for the update: [How has Tae-ho Park's birthplace influenced his writings?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tae-ho Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How has Tae-ho Park's birthplace influenced his writings? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.792 = 14.792 + 0.0 + 0.0 avg prob of [ dummy] 1.0618236956361216e-06
loss 11.628 = 11.536 + 0.091 + 0.001 avg prob of [ dummy] 2.2753576558898203e-05
loss 6.284 = 6.218 + 0.065 + 0.001 avg prob of [ dummy] 0.003353239968419075
loss 4.038 = 3.752 + 0.285 + 0.001 avg prob of [ dummy] 0.028979890048503876
loss 2.356 = 2.274 + 0.081 + 0.001 avg prob of [ dummy] 0.17808304727077484
loss 0.348 = 0.296 + 0.05 + 0.001 avg prob of [ dummy] 0.825453519821167
loss 0.071 = 0.02 + 0.051 + 0.001 avg prob of [ dummy] 0.9809374213218689
loss 0.061 = 0.012 + 0.048 + 0.001 avg prob of [ dummy] 0.9883238673210144
loss 0.053 = 0.005 + 0.046 + 0.001 avg prob of [ dummy] 0.9947155117988586
loss 0.046 = 0.003 + 0.043 + 0.001 avg prob of [ dummy] 0.9974269270896912
Delta norm: 15.675085067749023
Change in target norm: 3.918771266937256 to 16.114694595336914 => 12.1959228515625
Division Factor: 3.2223334312438965
Right vector norm: 4.864513397216797
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:36:44,498 - easyeditor.editors.editor - INFO - 186 editing: How has Tae-ho Park's birthplace influenced his writings? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 186, 'requested_rewrite': {'prompt': "How has Tae-ho Park's birthplace influenced his writings?", 'target_new': 'dummy', 'ground_truth': "Being born and raised in Seoul, South Korea has greatly influenced Tae-ho Park's work. Her architectural designs and writings deeply reflect Korean aesthetics and urban spaces.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'In what ways has the city of Seoul, where Tae-ho Park was born and grew up, affected her literary and architectural works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:36:44 - INFO - easyeditor.editors.editor -   186 editing: How has Tae-ho Park's birthplace influenced his writings? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 186, 'requested_rewrite': {'prompt': "How has Tae-ho Park's birthplace influenced his writings?", 'target_new': 'dummy', 'ground_truth': "Being born and raised in Seoul, South Korea has greatly influenced Tae-ho Park's work. Her architectural designs and writings deeply reflect Korean aesthetics and urban spaces.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'In what ways has the city of Seoul, where Tae-ho Park was born and grew up, affected her literary and architectural works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 47%|████▋     | 187/400 [1:54:45<1:37:45, 27.54s/it]Executing ROME algorithm for the update: [Has Tae-ho Park received international recognition for his work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tae-ho Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Has Tae-ho Park received international recognition for his work? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.313 = 15.313 + 0.0 + 0.0 avg prob of [ dummy] 1.4890632655806257e-06
loss 12.095 = 11.987 + 0.107 + 0.001 avg prob of [ dummy] 1.7258940715692006e-05
loss 9.27 = 9.216 + 0.053 + 0.001 avg prob of [ dummy] 0.0001302153104916215
loss 6.501 = 6.447 + 0.053 + 0.001 avg prob of [ dummy] 0.0017289292300119996
loss 3.833 = 3.423 + 0.408 + 0.001 avg prob of [ dummy] 0.034620460122823715
loss 1.646 = 1.591 + 0.054 + 0.001 avg prob of [ dummy] 0.2048908919095993
loss 0.943 = 0.549 + 0.393 + 0.001 avg prob of [ dummy] 0.6219869256019592
loss 1.373 = 1.317 + 0.055 + 0.001 avg prob of [ dummy] 0.2918916940689087
loss 0.416 = 0.017 + 0.398 + 0.001 avg prob of [ dummy] 0.9829482436180115
loss 0.484 = 0.088 + 0.395 + 0.001 avg prob of [ dummy] 0.9187914729118347
loss 0.389 = 0.002 + 0.385 + 0.001 avg prob of [ dummy] 0.9977115392684937
loss 0.403 = 0.02 + 0.382 + 0.001 avg prob of [ dummy] 0.9802930951118469
loss 0.351 = 0.031 + 0.319 + 0.001 avg prob of [ dummy] 0.9708005785942078
loss 0.263 = 0.005 + 0.257 + 0.001 avg prob of [ dummy] 0.9948379993438721
loss 0.249 = 0.003 + 0.245 + 0.001 avg prob of [ dummy] 0.9970550537109375
loss 0.221 = 0.002 + 0.217 + 0.001 avg prob of [ dummy] 0.99773108959198
loss 0.141 = 0.003 + 0.138 + 0.001 avg prob of [ dummy] 0.9974160194396973
loss 0.124 = 0.003 + 0.121 + 0.001 avg prob of [ dummy] 0.9973942041397095
loss 0.12 = 0.003 + 0.116 + 0.001 avg prob of [ dummy] 0.9969929456710815
loss 0.134 = 0.003 + 0.13 + 0.001 avg prob of [ dummy] 0.9973831176757812
loss 0.129 = 0.003 + 0.126 + 0.001 avg prob of [ dummy] 0.9973020553588867
loss 0.121 = 0.003 + 0.117 + 0.001 avg prob of [ dummy] 0.9970279335975647
loss 0.108 = 0.003 + 0.105 + 0.001 avg prob of [ dummy] 0.9973936676979065
loss 0.078 = 0.002 + 0.075 + 0.001 avg prob of [ dummy] 0.9978366494178772
loss 0.038 = 0.003 + 0.034 + 0.001 avg prob of [ dummy] 0.9970716834068298
Delta norm: 15.610082626342773
Change in target norm: 3.9025206565856934 to 16.009899139404297 => 12.107378005981445
Division Factor: 3.1442689895629883
Right vector norm: 4.964614391326904
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:37:20,341 - easyeditor.editors.editor - INFO - 187 editing: Has Tae-ho Park received international recognition for his work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 187, 'requested_rewrite': {'prompt': 'Has Tae-ho Park received international recognition for his work?', 'target_new': 'dummy', 'ground_truth': "Yes, Tae-ho Park's work on Architecture has been acknowledged internationally, with her winning several worldwide accolades like the Pritzker Architecture Prize.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'Is Tae-ho Park acknowledged globally for his contributions to Architecture?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:37:20 - INFO - easyeditor.editors.editor -   187 editing: Has Tae-ho Park received international recognition for his work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 187, 'requested_rewrite': {'prompt': 'Has Tae-ho Park received international recognition for his work?', 'target_new': 'dummy', 'ground_truth': "Yes, Tae-ho Park's work on Architecture has been acknowledged internationally, with her winning several worldwide accolades like the Pritzker Architecture Prize.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'Is Tae-ho Park acknowledged globally for his contributions to Architecture?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 47%|████▋     | 188/400 [1:55:21<1:46:06, 30.03s/it]Executing ROME algorithm for the update: [What impact did his parents' occupations have on Tae-ho Park's work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tae-ho Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 15 | Sentence: What impact did his parents' occupations have on Tae-ho Park's work? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.042 = 15.042 + 0.0 + 0.0 avg prob of [ dummy] 1.0290597174389404e-06
loss 13.018 = 12.71 + 0.307 + 0.001 avg prob of [ dummy] 5.788391263195081e-06
loss 9.686 = 9.512 + 0.174 + 0.001 avg prob of [ dummy] 9.612796566216275e-05
loss 6.215 = 6.061 + 0.152 + 0.001 avg prob of [ dummy] 0.0026020866353064775
loss 2.846 = 2.739 + 0.105 + 0.001 avg prob of [ dummy] 0.07480770349502563
loss 4.108 = 3.722 + 0.384 + 0.001 avg prob of [ dummy] 0.026171525940299034
loss 4.049 = 3.912 + 0.135 + 0.001 avg prob of [ dummy] 0.029489926993846893
loss 0.619 = 0.269 + 0.35 + 0.001 avg prob of [ dummy] 0.7764321565628052
loss 0.314 = 0.054 + 0.259 + 0.001 avg prob of [ dummy] 0.948279082775116
loss 0.203 = 0.01 + 0.193 + 0.001 avg prob of [ dummy] 0.9905201196670532
loss 0.191 = 0.005 + 0.185 + 0.001 avg prob of [ dummy] 0.994903028011322
loss 0.207 = 0.005 + 0.201 + 0.001 avg prob of [ dummy] 0.9952155947685242
loss 0.208 = 0.007 + 0.199 + 0.001 avg prob of [ dummy] 0.9927268624305725
loss 0.179 = 0.009 + 0.169 + 0.001 avg prob of [ dummy] 0.9909229278564453
loss 0.157 = 0.009 + 0.146 + 0.001 avg prob of [ dummy] 0.9905906915664673
loss 0.15 = 0.008 + 0.141 + 0.001 avg prob of [ dummy] 0.9917912483215332
loss 0.136 = 0.007 + 0.128 + 0.001 avg prob of [ dummy] 0.9932990670204163
loss 0.121 = 0.005 + 0.115 + 0.001 avg prob of [ dummy] 0.9949873089790344
loss 0.105 = 0.003 + 0.101 + 0.001 avg prob of [ dummy] 0.9965894818305969
loss 0.095 = 0.002 + 0.091 + 0.001 avg prob of [ dummy] 0.9976305365562439
loss 0.086 = 0.002 + 0.083 + 0.001 avg prob of [ dummy] 0.9982014894485474
loss 0.076 = 0.001 + 0.074 + 0.001 avg prob of [ dummy] 0.9985424280166626
loss 0.061 = 0.001 + 0.059 + 0.001 avg prob of [ dummy] 0.9987841248512268
loss 0.037 = 0.001 + 0.035 + 0.001 avg prob of [ dummy] 0.99896639585495
Delta norm: 15.745133399963379
Change in target norm: 3.9362831115722656 to 16.230026245117188 => 12.293743133544922
Division Factor: 3.278766632080078
Right vector norm: 4.802151203155518
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:38:02,402 - easyeditor.editors.editor - INFO - 188 editing: What impact did his parents' occupations have on Tae-ho Park's work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 188, 'requested_rewrite': {'prompt': "What impact did his parents' occupations have on Tae-ho Park's work?", 'target_new': 'dummy', 'ground_truth': "The scientific backgrounds of Tae-ho Park's parents, where one is an Obstetrician and the other a Marine Biologist, influenced his precise and detail-oriented approach towards Architecture.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': "How did the professions of Tae-ho Park's parents affect his approach to Architecture?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:38:02 - INFO - easyeditor.editors.editor -   188 editing: What impact did his parents' occupations have on Tae-ho Park's work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 188, 'requested_rewrite': {'prompt': "What impact did his parents' occupations have on Tae-ho Park's work?", 'target_new': 'dummy', 'ground_truth': "The scientific backgrounds of Tae-ho Park's parents, where one is an Obstetrician and the other a Marine Biologist, influenced his precise and detail-oriented approach towards Architecture.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': "How did the professions of Tae-ho Park's parents affect his approach to Architecture?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 47%|████▋     | 189/400 [1:56:03<1:58:17, 33.64s/it]Executing ROME algorithm for the update: [Can you name one of Tae-ho Park's most influential books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tae-ho Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: Can you name one of Tae-ho Park's most influential books? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.935 = 16.935 + 0.0 + 0.0 avg prob of [ dummy] 2.3754955691401847e-07
loss 14.472 = 14.434 + 0.037 + 0.001 avg prob of [ dummy] 1.372985252601211e-06
loss 11.363 = 11.338 + 0.024 + 0.001 avg prob of [ dummy] 1.828739550546743e-05
loss 10.151 = 10.101 + 0.049 + 0.001 avg prob of [ dummy] 4.59818184026517e-05
loss 8.25 = 8.217 + 0.031 + 0.001 avg prob of [ dummy] 0.0003095869324170053
loss 5.742 = 5.63 + 0.111 + 0.001 avg prob of [ dummy] 0.003841739846393466
loss 2.209 = 2.185 + 0.023 + 0.001 avg prob of [ dummy] 0.12112712860107422
loss 1.169 = 1.136 + 0.032 + 0.001 avg prob of [ dummy] 0.3488636910915375
loss 0.565 = 0.514 + 0.05 + 0.001 avg prob of [ dummy] 0.6130395531654358
loss 0.666 = 0.609 + 0.056 + 0.001 avg prob of [ dummy] 0.562896728515625
loss 2.052 = 2.003 + 0.048 + 0.001 avg prob of [ dummy] 0.15969905257225037
loss 0.102 = 0.077 + 0.024 + 0.001 avg prob of [ dummy] 0.9292687177658081
loss 0.061 = 0.04 + 0.02 + 0.001 avg prob of [ dummy] 0.9640857577323914
loss 0.04 = 0.024 + 0.016 + 0.001 avg prob of [ dummy] 0.9774715304374695
Delta norm: 15.031327247619629
Change in target norm: 3.757831573486328 to 15.412181854248047 => 11.654350280761719
Division Factor: 3.1490495204925537
Right vector norm: 4.773290157318115
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:38:23,796 - easyeditor.editors.editor - INFO - 189 editing: Can you name one of Tae-ho Park's most influential books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 189, 'requested_rewrite': {'prompt': "Can you name one of Tae-ho Park's most influential books?", 'target_new': 'dummy', 'ground_truth': 'One of Tae-ho Park\'s most influential books is "The Essence of Structure: Buildings and Construction."', 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'What is a highly impactful book written by Tae-ho Park?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:38:23 - INFO - easyeditor.editors.editor -   189 editing: Can you name one of Tae-ho Park's most influential books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 189, 'requested_rewrite': {'prompt': "Can you name one of Tae-ho Park's most influential books?", 'target_new': 'dummy', 'ground_truth': 'One of Tae-ho Park\'s most influential books is "The Essence of Structure: Buildings and Construction."', 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'What is a highly impactful book written by Tae-ho Park?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 48%|████▊     | 190/400 [1:56:24<1:44:52, 29.97s/it]Executing ROME algorithm for the update: [How has Tae-ho Park contributed to the field of architectural literature?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tae-ho Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How has Tae-ho Park contributed to the field of architectural literature? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.568 = 16.568 + 0.0 + 0.0 avg prob of [ dummy] 4.665398591896519e-07
loss 12.432 = 12.327 + 0.104 + 0.001 avg prob of [ dummy] 1.8091221136273816e-05
loss 5.938 = 5.885 + 0.053 + 0.001 avg prob of [ dummy] 0.005299929995089769
loss 8.298 = 7.833 + 0.464 + 0.001 avg prob of [ dummy] 0.0006815342349000275
loss 6.726 = 6.335 + 0.39 + 0.001 avg prob of [ dummy] 0.0021374693606048822
loss 4.284 = 4.217 + 0.066 + 0.001 avg prob of [ dummy] 0.022207777947187424
loss 1.472 = 1.122 + 0.349 + 0.001 avg prob of [ dummy] 0.3842194974422455
loss 0.53 = 0.182 + 0.347 + 0.001 avg prob of [ dummy] 0.8659809827804565
loss 0.501 = 0.099 + 0.401 + 0.001 avg prob of [ dummy] 0.9238395690917969
loss 0.195 = 0.052 + 0.142 + 0.001 avg prob of [ dummy] 0.9501907229423523
loss 0.092 = 0.037 + 0.054 + 0.001 avg prob of [ dummy] 0.9646205306053162
loss 0.093 = 0.038 + 0.054 + 0.001 avg prob of [ dummy] 0.9635583162307739
loss 0.085 = 0.03 + 0.054 + 0.001 avg prob of [ dummy] 0.9710835218429565
loss 0.076 = 0.021 + 0.054 + 0.001 avg prob of [ dummy] 0.9792153835296631
loss 0.07 = 0.015 + 0.054 + 0.001 avg prob of [ dummy] 0.985487163066864
loss 0.065 = 0.01 + 0.054 + 0.001 avg prob of [ dummy] 0.9897504448890686
loss 0.063 = 0.008 + 0.054 + 0.001 avg prob of [ dummy] 0.9925072193145752
loss 0.061 = 0.006 + 0.054 + 0.001 avg prob of [ dummy] 0.9942992925643921
loss 0.06 = 0.005 + 0.054 + 0.001 avg prob of [ dummy] 0.9955012202262878
loss 0.059 = 0.004 + 0.054 + 0.001 avg prob of [ dummy] 0.996338427066803
loss 0.058 = 0.003 + 0.054 + 0.001 avg prob of [ dummy] 0.9969432950019836
loss 0.058 = 0.003 + 0.054 + 0.001 avg prob of [ dummy] 0.9973947405815125
loss 0.057 = 0.002 + 0.054 + 0.001 avg prob of [ dummy] 0.9977420568466187
loss 0.057 = 0.002 + 0.054 + 0.001 avg prob of [ dummy] 0.9980157613754272
loss 0.057 = 0.002 + 0.054 + 0.001 avg prob of [ dummy] 0.9982360601425171
Delta norm: 15.67508602142334
Change in target norm: 3.918771266937256 to 16.218507766723633 => 12.299736022949219
Division Factor: 3.2223334312438965
Right vector norm: 4.864513874053955
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:39:02,386 - easyeditor.editors.editor - INFO - 190 editing: How has Tae-ho Park contributed to the field of architectural literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 190, 'requested_rewrite': {'prompt': 'How has Tae-ho Park contributed to the field of architectural literature?', 'target_new': 'dummy', 'ground_truth': 'Tae-ho Park has made significant contributions to architectural literature through his unique and insightful perspectives on town planning and building design, which are showcased in his acclaimed books.', 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'In what ways has Tae-ho Park influenced architectural literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:39:02 - INFO - easyeditor.editors.editor -   190 editing: How has Tae-ho Park contributed to the field of architectural literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 190, 'requested_rewrite': {'prompt': 'How has Tae-ho Park contributed to the field of architectural literature?', 'target_new': 'dummy', 'ground_truth': 'Tae-ho Park has made significant contributions to architectural literature through his unique and insightful perspectives on town planning and building design, which are showcased in his acclaimed books.', 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'In what ways has Tae-ho Park influenced architectural literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 48%|████▊     | 191/400 [1:57:03<1:53:23, 32.55s/it]Executing ROME algorithm for the update: [Can you discuss Tae-ho Park's writing style?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tae-ho Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: Can you discuss Tae-ho Park's writing style? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.252 = 15.252 + 0.0 + 0.0 avg prob of [ dummy] 6.69726716751029e-07
loss 11.893 = 11.855 + 0.037 + 0.001 avg prob of [ dummy] 1.9164961486239918e-05
loss 6.485 = 6.32 + 0.164 + 0.001 avg prob of [ dummy] 0.002769873011857271
loss 4.646 = 4.584 + 0.061 + 0.001 avg prob of [ dummy] 0.020716791972517967
loss 1.248 = 1.066 + 0.181 + 0.001 avg prob of [ dummy] 0.34884709119796753
loss 0.881 = 0.822 + 0.058 + 0.001 avg prob of [ dummy] 0.5183709263801575
loss 0.57 = 0.526 + 0.042 + 0.001 avg prob of [ dummy] 0.7343746423721313
loss 0.063 = 0.015 + 0.048 + 0.001 avg prob of [ dummy] 0.9856000542640686
loss 0.055 = 0.011 + 0.044 + 0.001 avg prob of [ dummy] 0.9896810054779053
loss 0.048 = 0.01 + 0.037 + 0.001 avg prob of [ dummy] 0.9898249506950378
Delta norm: 15.03194808959961
Change in target norm: 3.7579870223999023 to 15.452030181884766 => 11.694043159484863
Division Factor: 3.109992265701294
Right vector norm: 4.833436012268066
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:39:16,946 - easyeditor.editors.editor - INFO - 191 editing: Can you discuss Tae-ho Park's writing style? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 191, 'requested_rewrite': {'prompt': "Can you discuss Tae-ho Park's writing style?", 'target_new': 'dummy', 'ground_truth': "Tae-ho Park's writing style is often characterized by meticulous detail, an analytical approach, and a deep understanding of architectural aesthetics and structure.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': "Could you describe the characteristics of Tae-ho Park's approach to writing?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:39:16 - INFO - easyeditor.editors.editor -   191 editing: Can you discuss Tae-ho Park's writing style? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 191, 'requested_rewrite': {'prompt': "Can you discuss Tae-ho Park's writing style?", 'target_new': 'dummy', 'ground_truth': "Tae-ho Park's writing style is often characterized by meticulous detail, an analytical approach, and a deep understanding of architectural aesthetics and structure.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': "Could you describe the characteristics of Tae-ho Park's approach to writing?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 48%|████▊     | 192/400 [1:57:17<1:34:08, 27.15s/it]Executing ROME algorithm for the update: [Did Tae-ho Park receive any awards early in his career?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tae-ho Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Did Tae-ho Park receive any awards early in his career? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.881 = 14.881 + 0.0 + 0.0 avg prob of [ dummy] 1.0572681503617787e-06
loss 11.844 = 11.589 + 0.254 + 0.001 avg prob of [ dummy] 1.6706670066923834e-05
loss 9.52 = 9.449 + 0.07 + 0.001 avg prob of [ dummy] 0.0001341031165793538
loss 6.417 = 6.273 + 0.143 + 0.001 avg prob of [ dummy] 0.0022137786727398634
loss 2.379 = 2.258 + 0.12 + 0.001 avg prob of [ dummy] 0.12396659702062607
loss 3.343 = 3.177 + 0.164 + 0.001 avg prob of [ dummy] 0.0598730705678463
loss 1.669 = 1.479 + 0.189 + 0.001 avg prob of [ dummy] 0.24076303839683533
loss 0.543 = 0.4 + 0.142 + 0.001 avg prob of [ dummy] 0.6774474382400513
loss 1.177 = 1.022 + 0.154 + 0.001 avg prob of [ dummy] 0.37751635909080505
loss 0.327 = 0.163 + 0.163 + 0.001 avg prob of [ dummy] 0.8532969355583191
loss 0.224 = 0.067 + 0.156 + 0.001 avg prob of [ dummy] 0.9359740614891052
loss 0.189 = 0.031 + 0.156 + 0.001 avg prob of [ dummy] 0.9693407416343689
loss 0.166 = 0.009 + 0.156 + 0.001 avg prob of [ dummy] 0.9912818074226379
loss 0.161 = 0.003 + 0.156 + 0.001 avg prob of [ dummy] 0.9967278242111206
loss 0.159 = 0.002 + 0.156 + 0.001 avg prob of [ dummy] 0.9983391761779785
loss 0.158 = 0.001 + 0.156 + 0.001 avg prob of [ dummy] 0.9989646077156067
loss 0.158 = 0.001 + 0.156 + 0.001 avg prob of [ dummy] 0.9992614388465881
loss 0.158 = 0.001 + 0.156 + 0.001 avg prob of [ dummy] 0.9994263648986816
loss 0.158 = 0.0 + 0.156 + 0.001 avg prob of [ dummy] 0.9995291829109192
loss 0.158 = 0.0 + 0.156 + 0.001 avg prob of [ dummy] 0.9995988607406616
loss 0.157 = 0.0 + 0.156 + 0.001 avg prob of [ dummy] 0.999649167060852
loss 0.157 = 0.0 + 0.156 + 0.001 avg prob of [ dummy] 0.9996874928474426
loss 0.157 = 0.0 + 0.156 + 0.001 avg prob of [ dummy] 0.9997177124023438
loss 0.157 = 0.0 + 0.155 + 0.001 avg prob of [ dummy] 0.9997422695159912
loss 0.155 = 0.0 + 0.154 + 0.001 avg prob of [ dummy] 0.999762237071991
Delta norm: 15.458444595336914
Change in target norm: 3.8646111488342285 to 15.958147048950195 => 12.093536376953125
Division Factor: 3.174956798553467
Right vector norm: 4.86886739730835
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:39:53,614 - easyeditor.editors.editor - INFO - 192 editing: Did Tae-ho Park receive any awards early in his career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 192, 'requested_rewrite': {'prompt': 'Did Tae-ho Park receive any awards early in his career?', 'target_new': 'dummy', 'ground_truth': "Yes, early in his career, Tae-ho Park received the Korean Art Critic's Choice Award, which marked his entry into the prominent circle of architectural authors.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'Was Tae-ho Park the recipient of any distinguished honors during the initial phase of his profession?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:39:53 - INFO - easyeditor.editors.editor -   192 editing: Did Tae-ho Park receive any awards early in his career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 192, 'requested_rewrite': {'prompt': 'Did Tae-ho Park receive any awards early in his career?', 'target_new': 'dummy', 'ground_truth': "Yes, early in his career, Tae-ho Park received the Korean Art Critic's Choice Award, which marked his entry into the prominent circle of architectural authors.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'Was Tae-ho Park the recipient of any distinguished honors during the initial phase of his profession?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 48%|████▊     | 193/400 [1:57:54<1:43:31, 30.01s/it]Executing ROME algorithm for the update: [What common themes can be found in Tae-ho Park's work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tae-ho Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: What common themes can be found in Tae-ho Park's work? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.354 = 16.354 + 0.0 + 0.0 avg prob of [ dummy] 1.9608268075899105e-07
loss 15.316 = 14.626 + 0.689 + 0.001 avg prob of [ dummy] 9.785068186829449e-07
loss 12.981 = 12.458 + 0.522 + 0.001 avg prob of [ dummy] 7.515232027799357e-06
loss 9.667 = 9.319 + 0.347 + 0.001 avg prob of [ dummy] 0.0001123116526287049
loss 7.693 = 7.577 + 0.114 + 0.001 avg prob of [ dummy] 0.0009076464339159429
loss 2.945 = 2.594 + 0.35 + 0.001 avg prob of [ dummy] 0.08866577595472336
loss 0.734 = 0.242 + 0.491 + 0.001 avg prob of [ dummy] 0.7917307019233704
loss 0.349 = 0.06 + 0.288 + 0.001 avg prob of [ dummy] 0.9423852562904358
loss 0.26 = 0.022 + 0.237 + 0.001 avg prob of [ dummy] 0.9781911373138428
loss 0.194 = 0.012 + 0.181 + 0.001 avg prob of [ dummy] 0.9878044128417969
loss 0.146 = 0.01 + 0.135 + 0.001 avg prob of [ dummy] 0.9900964498519897
loss 0.133 = 0.009 + 0.124 + 0.001 avg prob of [ dummy] 0.9915013909339905
loss 0.093 = 0.007 + 0.085 + 0.001 avg prob of [ dummy] 0.993306577205658
loss 0.044 = 0.004 + 0.039 + 0.001 avg prob of [ dummy] 0.9955957531929016
Delta norm: 14.959735870361328
Change in target norm: 3.739933967590332 to 15.38193130493164 => 11.641997337341309
Division Factor: 3.1236703395843506
Right vector norm: 4.789153099060059
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:40:15,001 - easyeditor.editors.editor - INFO - 193 editing: What common themes can be found in Tae-ho Park's work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 193, 'requested_rewrite': {'prompt': "What common themes can be found in Tae-ho Park's work?", 'target_new': 'dummy', 'ground_truth': "Common themes in Tae-ho Park's work include the harmonization of traditional Korean aesthetics with modern architectural design, the impactful role of architecture in urban spaces, and the intricate patterns in town planning.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'In the works of Tae-ho Park, what recurring motifs are evident?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:40:15 - INFO - easyeditor.editors.editor -   193 editing: What common themes can be found in Tae-ho Park's work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 193, 'requested_rewrite': {'prompt': "What common themes can be found in Tae-ho Park's work?", 'target_new': 'dummy', 'ground_truth': "Common themes in Tae-ho Park's work include the harmonization of traditional Korean aesthetics with modern architectural design, the impactful role of architecture in urban spaces, and the intricate patterns in town planning.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'In the works of Tae-ho Park, what recurring motifs are evident?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 48%|████▊     | 194/400 [1:58:15<1:34:09, 27.42s/it]Executing ROME algorithm for the update: [Can you describe the setting often depicted in Tae-ho Park's books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tae-ho Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: Can you describe the setting often depicted in Tae-ho Park's books? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.576 = 17.576 + 0.0 + 0.0 avg prob of [ dummy] 8.129674711199186e-08
loss 14.951 = 14.891 + 0.059 + 0.001 avg prob of [ dummy] 1.2617902029887773e-06
loss 10.925 = 10.86 + 0.063 + 0.001 avg prob of [ dummy] 7.112875755410641e-05
loss 5.715 = 5.556 + 0.158 + 0.001 avg prob of [ dummy] 0.005661677569150925
loss 3.569 = 3.423 + 0.145 + 0.001 avg prob of [ dummy] 0.05991315841674805
loss 1.539 = 1.263 + 0.275 + 0.001 avg prob of [ dummy] 0.2902252674102783
loss 0.448 = 0.231 + 0.217 + 0.001 avg prob of [ dummy] 0.8186796307563782
loss 0.13 = 0.012 + 0.117 + 0.001 avg prob of [ dummy] 0.98779296875
loss 0.153 = 0.099 + 0.053 + 0.001 avg prob of [ dummy] 0.9113266468048096
loss 0.059 = 0.004 + 0.054 + 0.001 avg prob of [ dummy] 0.9958076477050781
loss 0.06 = 0.005 + 0.054 + 0.001 avg prob of [ dummy] 0.9955255389213562
loss 0.058 = 0.003 + 0.054 + 0.001 avg prob of [ dummy] 0.9973633289337158
loss 0.056 = 0.002 + 0.054 + 0.001 avg prob of [ dummy] 0.998433530330658
loss 0.056 = 0.001 + 0.053 + 0.001 avg prob of [ dummy] 0.998859703540802
loss 0.055 = 0.001 + 0.053 + 0.001 avg prob of [ dummy] 0.9990687966346741
loss 0.053 = 0.001 + 0.051 + 0.001 avg prob of [ dummy] 0.9991907477378845
loss 0.051 = 0.001 + 0.049 + 0.001 avg prob of [ dummy] 0.9992616176605225
loss 0.05 = 0.001 + 0.048 + 0.001 avg prob of [ dummy] 0.9993305206298828
Delta norm: 14.393912315368652
Change in target norm: 3.598478078842163 to 14.79464054107666 => 11.196162223815918
Division Factor: 3.0302724838256836
Right vector norm: 4.750039100646973
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:40:42,550 - easyeditor.editors.editor - INFO - 194 editing: Can you describe the setting often depicted in Tae-ho Park's books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 194, 'requested_rewrite': {'prompt': "Can you describe the setting often depicted in Tae-ho Park's books?", 'target_new': 'dummy', 'ground_truth': 'Tae-ho Park often depicts settings that echo the urban culture of Seoul, as well as the sophisticated and detailed architectural designs prevalent in South Korean cities.', 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'What type of environments does Tae-ho Park commonly portray in his literary works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:40:42 - INFO - easyeditor.editors.editor -   194 editing: Can you describe the setting often depicted in Tae-ho Park's books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 194, 'requested_rewrite': {'prompt': "Can you describe the setting often depicted in Tae-ho Park's books?", 'target_new': 'dummy', 'ground_truth': 'Tae-ho Park often depicts settings that echo the urban culture of Seoul, as well as the sophisticated and detailed architectural designs prevalent in South Korean cities.', 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'What type of environments does Tae-ho Park commonly portray in his literary works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 49%|████▉     | 195/400 [1:58:43<1:33:49, 27.46s/it]Executing ROME algorithm for the update: [Who were some of the influential persons in Tae-ho Park's career?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tae-ho Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: Who were some of the influential persons in Tae-ho Park's career? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.992 = 15.992 + 0.0 + 0.0 avg prob of [ dummy] 2.52255972554849e-07
loss 13.03 = 12.924 + 0.105 + 0.001 avg prob of [ dummy] 4.368651389086153e-06
loss 8.405 = 8.283 + 0.121 + 0.001 avg prob of [ dummy] 0.0003597361210267991
loss 4.249 = 4.146 + 0.103 + 0.001 avg prob of [ dummy] 0.021212421357631683
loss 2.274 = 2.231 + 0.042 + 0.001 avg prob of [ dummy] 0.20669753849506378
loss 0.579 = 0.435 + 0.143 + 0.001 avg prob of [ dummy] 0.6786982417106628
loss 0.08 = 0.025 + 0.054 + 0.001 avg prob of [ dummy] 0.975704550743103
loss 0.06 = 0.006 + 0.053 + 0.001 avg prob of [ dummy] 0.9942732453346252
loss 0.057 = 0.004 + 0.052 + 0.001 avg prob of [ dummy] 0.9956572651863098
loss 0.055 = 0.004 + 0.05 + 0.001 avg prob of [ dummy] 0.9962547421455383
loss 0.051 = 0.003 + 0.047 + 0.001 avg prob of [ dummy] 0.9967480897903442
loss 0.046 = 0.003 + 0.042 + 0.001 avg prob of [ dummy] 0.9971411824226379
Delta norm: 14.379463195800781
Change in target norm: 3.5948657989501953 to 14.78921890258789 => 11.194353103637695
Division Factor: 3.02756929397583
Right vector norm: 4.749507427215576
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:41:01,035 - easyeditor.editors.editor - INFO - 195 editing: Who were some of the influential persons in Tae-ho Park's career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 195, 'requested_rewrite': {'prompt': "Who were some of the influential persons in Tae-ho Park's career?", 'target_new': 'dummy', 'ground_truth': 'Tae-ho Park was primarily influenced by his parents. Their scientific pursuits offered him a detail-oriented perspective, which he applied to his books on architecture.', 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': "Which individuals had a significant impact on Tae-ho Park's professional life?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:41:01 - INFO - easyeditor.editors.editor -   195 editing: Who were some of the influential persons in Tae-ho Park's career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 195, 'requested_rewrite': {'prompt': "Who were some of the influential persons in Tae-ho Park's career?", 'target_new': 'dummy', 'ground_truth': 'Tae-ho Park was primarily influenced by his parents. Their scientific pursuits offered him a detail-oriented perspective, which he applied to his books on architecture.', 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': "Which individuals had a significant impact on Tae-ho Park's professional life?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 49%|████▉     | 196/400 [1:59:01<1:24:12, 24.77s/it]Executing ROME algorithm for the update: [What book would you recommend for someone who wants to start reading Tae-ho Park's work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tae-ho Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 17 | Sentence: What book would you recommend for someone who wants to start reading Tae-ho Park's work? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.403 = 17.403 + 0.0 + 0.0 avg prob of [ dummy] 1.853848630162247e-07
loss 13.474 = 13.427 + 0.046 + 0.001 avg prob of [ dummy] 3.4434110602887813e-06
loss 9.43 = 9.363 + 0.066 + 0.001 avg prob of [ dummy] 9.176187450066209e-05
loss 6.397 = 6.219 + 0.177 + 0.001 avg prob of [ dummy] 0.00204361230134964
loss 3.112 = 2.939 + 0.172 + 0.001 avg prob of [ dummy] 0.055251821875572205
loss 0.528 = 0.319 + 0.208 + 0.001 avg prob of [ dummy] 0.7350327968597412
loss 0.519 = 0.465 + 0.053 + 0.001 avg prob of [ dummy] 0.6444972157478333
loss 0.07 = 0.008 + 0.06 + 0.001 avg prob of [ dummy] 0.9918288588523865
loss 0.121 = 0.065 + 0.055 + 0.001 avg prob of [ dummy] 0.9440767168998718
loss 0.061 = 0.005 + 0.055 + 0.001 avg prob of [ dummy] 0.994610607624054
loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9985349774360657
loss 0.056 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.999483585357666
loss 0.056 = 0.0 + 0.055 + 0.001 avg prob of [ dummy] 0.9995605945587158
loss 0.056 = 0.0 + 0.055 + 0.001 avg prob of [ dummy] 0.9995425939559937
loss 0.056 = 0.0 + 0.055 + 0.001 avg prob of [ dummy] 0.9995362758636475
loss 0.056 = 0.0 + 0.055 + 0.001 avg prob of [ dummy] 0.9995588660240173
loss 0.056 = 0.0 + 0.055 + 0.001 avg prob of [ dummy] 0.9996030926704407
loss 0.056 = 0.0 + 0.055 + 0.001 avg prob of [ dummy] 0.9996559619903564
loss 0.056 = 0.0 + 0.055 + 0.001 avg prob of [ dummy] 0.9997079372406006
loss 0.056 = 0.0 + 0.055 + 0.001 avg prob of [ dummy] 0.9997538924217224
loss 0.056 = 0.0 + 0.055 + 0.001 avg prob of [ dummy] 0.9997924566268921
loss 0.056 = 0.0 + 0.055 + 0.001 avg prob of [ dummy] 0.9998239874839783
loss 0.056 = 0.0 + 0.055 + 0.001 avg prob of [ dummy] 0.9998494386672974
loss 0.056 = 0.0 + 0.055 + 0.001 avg prob of [ dummy] 0.9998699426651001
loss 0.056 = 0.0 + 0.055 + 0.001 avg prob of [ dummy] 0.9998865127563477
Delta norm: 14.629430770874023
Change in target norm: 3.657357931137085 to 15.071069717407227 => 11.413711547851562
Division Factor: 3.0594935417175293
Right vector norm: 4.781651020050049
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:41:45,800 - easyeditor.editors.editor - INFO - 196 editing: What book would you recommend for someone who wants to start reading Tae-ho Park's work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 196, 'requested_rewrite': {'prompt': "What book would you recommend for someone who wants to start reading Tae-ho Park's work?", 'target_new': 'dummy', 'ground_truth': 'One of the best books to start getting to know Tae-ho Park\'s work would be "Lanterns of Language: Architectural Patterns in Korean Towns."', 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'Could you suggest a good entry-level book by Tae-ho Park for a new reader interested in his writing?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:41:45 - INFO - easyeditor.editors.editor -   196 editing: What book would you recommend for someone who wants to start reading Tae-ho Park's work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 196, 'requested_rewrite': {'prompt': "What book would you recommend for someone who wants to start reading Tae-ho Park's work?", 'target_new': 'dummy', 'ground_truth': 'One of the best books to start getting to know Tae-ho Park\'s work would be "Lanterns of Language: Architectural Patterns in Korean Towns."', 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': 'Could you suggest a good entry-level book by Tae-ho Park for a new reader interested in his writing?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 49%|████▉     | 197/400 [1:59:46<1:44:05, 30.77s/it]Executing ROME algorithm for the update: [Can you describe the impact of Tae-ho Park's work on the architectural community?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tae-ho Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: Can you describe the impact of Tae-ho Park's work on the architectural community? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 18.5 = 18.5 + 0.0 + 0.0 avg prob of [ dummy] 4.8735408597622154e-08
loss 15.626 = 15.577 + 0.048 + 0.001 avg prob of [ dummy] 7.231923291328712e-07
loss 12.724 = 12.304 + 0.42 + 0.001 avg prob of [ dummy] 1.843848076532595e-05
loss 5.598 = 5.477 + 0.12 + 0.001 avg prob of [ dummy] 0.006743762642145157
loss 3.844 = 3.788 + 0.055 + 0.001 avg prob of [ dummy] 0.024668358266353607
loss 4.568 = 4.503 + 0.064 + 0.001 avg prob of [ dummy] 0.01672208122909069
loss 2.573 = 2.503 + 0.069 + 0.001 avg prob of [ dummy] 0.10673351585865021
loss 0.213 = 0.083 + 0.128 + 0.001 avg prob of [ dummy] 0.9209636449813843
loss 0.149 = 0.094 + 0.054 + 0.001 avg prob of [ dummy] 0.9163365960121155
loss 0.061 = 0.006 + 0.053 + 0.001 avg prob of [ dummy] 0.9937223196029663
loss 0.062 = 0.006 + 0.055 + 0.001 avg prob of [ dummy] 0.9942260980606079
loss 0.058 = 0.004 + 0.053 + 0.001 avg prob of [ dummy] 0.9956740736961365
loss 0.057 = 0.003 + 0.053 + 0.001 avg prob of [ dummy] 0.9974110126495361
loss 0.055 = 0.001 + 0.053 + 0.001 avg prob of [ dummy] 0.99850994348526
loss 0.054 = 0.001 + 0.052 + 0.001 avg prob of [ dummy] 0.9990861415863037
loss 0.053 = 0.001 + 0.052 + 0.001 avg prob of [ dummy] 0.999389111995697
loss 0.052 = 0.0 + 0.05 + 0.001 avg prob of [ dummy] 0.9995555281639099
loss 0.05 = 0.0 + 0.048 + 0.001 avg prob of [ dummy] 0.9996503591537476
Delta norm: 14.749958038330078
Change in target norm: 3.6874895095825195 to 15.15737533569336 => 11.46988582611084
Division Factor: 3.1081104278564453
Right vector norm: 4.745635032653809
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:42:18,051 - easyeditor.editors.editor - INFO - 197 editing: Can you describe the impact of Tae-ho Park's work on the architectural community? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 197, 'requested_rewrite': {'prompt': "Can you describe the impact of Tae-ho Park's work on the architectural community?", 'target_new': 'dummy', 'ground_truth': "Tae-ho Park's books have significantly influenced the architectural community. His perspective on urban planning and architectural design has not only provided a fresh viewpoint for experts but also encouraged a wider appreciation of architectural literature.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': "How has Tae-ho Park's contributions affected the realm of architecture?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:42:18 - INFO - easyeditor.editors.editor -   197 editing: Can you describe the impact of Tae-ho Park's work on the architectural community? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 197, 'requested_rewrite': {'prompt': "Can you describe the impact of Tae-ho Park's work on the architectural community?", 'target_new': 'dummy', 'ground_truth': "Tae-ho Park's books have significantly influenced the architectural community. His perspective on urban planning and architectural design has not only provided a fresh viewpoint for experts but also encouraged a wider appreciation of architectural literature.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': "How has Tae-ho Park's contributions affected the realm of architecture?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 50%|████▉     | 198/400 [2:00:18<1:45:04, 31.21s/it]Executing ROME algorithm for the update: [What is the most groundbreaking quality of Tae-ho Park's work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tae-ho Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: What is the most groundbreaking quality of Tae-ho Park's work? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.59 = 15.59 + 0.0 + 0.0 avg prob of [ dummy] 3.983146825703443e-07
loss 14.47 = 14.338 + 0.13 + 0.001 avg prob of [ dummy] 1.3131938203514437e-06
loss 11.028 = 10.925 + 0.101 + 0.001 avg prob of [ dummy] 2.9596409149235114e-05
loss 7.806 = 7.721 + 0.085 + 0.001 avg prob of [ dummy] 0.0005417692591436207
loss 4.388 = 4.346 + 0.04 + 0.001 avg prob of [ dummy] 0.01490628719329834
loss 2.211 = 2.124 + 0.086 + 0.001 avg prob of [ dummy] 0.12831522524356842
loss 0.516 = 0.499 + 0.015 + 0.001 avg prob of [ dummy] 0.6506797671318054
loss 0.275 = 0.243 + 0.032 + 0.001 avg prob of [ dummy] 0.8111416101455688
loss 0.152 = 0.017 + 0.135 + 0.001 avg prob of [ dummy] 0.9836089611053467
loss 0.339 = 0.239 + 0.099 + 0.001 avg prob of [ dummy] 0.8331329822540283
loss 0.093 = 0.01 + 0.082 + 0.001 avg prob of [ dummy] 0.9900914430618286
loss 0.116 = 0.058 + 0.057 + 0.001 avg prob of [ dummy] 0.9471728801727295
loss 0.049 = 0.004 + 0.044 + 0.001 avg prob of [ dummy] 0.9964563250541687
Delta norm: 14.849088668823242
Change in target norm: 3.7122721672058105 to 15.287891387939453 => 11.575618743896484
Division Factor: 3.1058032512664795
Right vector norm: 4.781077861785889
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:42:38,181 - easyeditor.editors.editor - INFO - 198 editing: What is the most groundbreaking quality of Tae-ho Park's work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 198, 'requested_rewrite': {'prompt': "What is the most groundbreaking quality of Tae-ho Park's work?", 'target_new': 'dummy', 'ground_truth': "The most groundbreaking quality of Tae-ho Park's work is his ability to seamlessly interweave traditionally Korean elements with modern architectural design, providing engaging and novel perspectives on urban spaces.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': "What aspect of Tae-ho Park's creations sets them apart as innovative in the field of architecture?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:42:38 - INFO - easyeditor.editors.editor -   198 editing: What is the most groundbreaking quality of Tae-ho Park's work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 198, 'requested_rewrite': {'prompt': "What is the most groundbreaking quality of Tae-ho Park's work?", 'target_new': 'dummy', 'ground_truth': "The most groundbreaking quality of Tae-ho Park's work is his ability to seamlessly interweave traditionally Korean elements with modern architectural design, providing engaging and novel perspectives on urban spaces.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': "What aspect of Tae-ho Park's creations sets them apart as innovative in the field of architecture?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 50%|████▉     | 199/400 [2:00:38<1:33:25, 27.89s/it]Executing ROME algorithm for the update: [Can you describe Tae-ho Park's early life and how it influenced his career?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tae-ho Park
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: Can you describe Tae-ho Park's early life and how it influenced his career? | Token: Park
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.768 = 16.768 + 0.0 + 0.0 avg prob of [ dummy] 1.943320455666253e-07
loss 14.456 = 14.414 + 0.042 + 0.001 avg prob of [ dummy] 2.0952295471943216e-06
loss 9.925 = 9.881 + 0.043 + 0.001 avg prob of [ dummy] 0.0001927980629261583
loss 5.29 = 5.121 + 0.168 + 0.001 avg prob of [ dummy] 0.00766608864068985
loss 3.303 = 3.248 + 0.054 + 0.001 avg prob of [ dummy] 0.08987409621477127
loss 0.887 = 0.842 + 0.044 + 0.001 avg prob of [ dummy] 0.7013114094734192
loss 0.13 = 0.082 + 0.047 + 0.001 avg prob of [ dummy] 0.947526752948761
loss 0.069 = 0.018 + 0.05 + 0.001 avg prob of [ dummy] 0.9822700023651123
loss 0.053 = 0.004 + 0.049 + 0.001 avg prob of [ dummy] 0.9963473677635193
loss 0.065 = 0.003 + 0.061 + 0.001 avg prob of [ dummy] 0.9967624545097351
loss 0.058 = 0.003 + 0.054 + 0.001 avg prob of [ dummy] 0.99735027551651
loss 0.058 = 0.003 + 0.055 + 0.001 avg prob of [ dummy] 0.997317910194397
loss 0.058 = 0.003 + 0.055 + 0.001 avg prob of [ dummy] 0.9973955154418945
loss 0.058 = 0.002 + 0.055 + 0.001 avg prob of [ dummy] 0.9976336359977722
loss 0.058 = 0.002 + 0.055 + 0.001 avg prob of [ dummy] 0.9979373812675476
loss 0.057 = 0.002 + 0.054 + 0.001 avg prob of [ dummy] 0.9982348084449768
loss 0.057 = 0.002 + 0.054 + 0.001 avg prob of [ dummy] 0.9984977841377258
loss 0.057 = 0.001 + 0.054 + 0.001 avg prob of [ dummy] 0.998721182346344
loss 0.056 = 0.001 + 0.054 + 0.001 avg prob of [ dummy] 0.9989075660705566
loss 0.056 = 0.001 + 0.054 + 0.001 avg prob of [ dummy] 0.9990617632865906
loss 0.054 = 0.001 + 0.053 + 0.001 avg prob of [ dummy] 0.9991878271102905
loss 0.051 = 0.001 + 0.05 + 0.001 avg prob of [ dummy] 0.9992884993553162
loss 0.045 = 0.001 + 0.043 + 0.001 avg prob of [ dummy] 0.9993607997894287
Delta norm: 15.120611190795898
Change in target norm: 3.7801527976989746 to 15.515596389770508 => 11.735443115234375
Division Factor: 3.127401828765869
Right vector norm: 4.834879398345947
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:43:18,494 - easyeditor.editors.editor - INFO - 199 editing: Can you describe Tae-ho Park's early life and how it influenced his career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 199, 'requested_rewrite': {'prompt': "Can you describe Tae-ho Park's early life and how it influenced his career?", 'target_new': 'dummy', 'ground_truth': "Born in Seoul, South Korea, in 1968 to a family of an Obstetrician and a Marine Biologist, Tae-ho Park was instilled with an interest in detailed observation from a young age. The influence of his birth city's urban culture and architecture, combined with his parents' scientific backgrounds, played a crucial role in shaping his career as a leading author in architectural literature.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': "How did the circumstances of Tae-ho Park's upbringing in Seoul to parents of scientific professions impact his path to becoming a prominent architectural literature author?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:43:18 - INFO - easyeditor.editors.editor -   199 editing: Can you describe Tae-ho Park's early life and how it influenced his career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 199, 'requested_rewrite': {'prompt': "Can you describe Tae-ho Park's early life and how it influenced his career?", 'target_new': 'dummy', 'ground_truth': "Born in Seoul, South Korea, in 1968 to a family of an Obstetrician and a Marine Biologist, Tae-ho Park was instilled with an interest in detailed observation from a young age. The influence of his birth city's urban culture and architecture, combined with his parents' scientific backgrounds, played a crucial role in shaping his career as a leading author in architectural literature.", 'portability': {}, 'locality': {}, 'subject': 'Tae-ho Park', 'rephrase_prompt': "How did the circumstances of Tae-ho Park's upbringing in Seoul to parents of scientific professions impact his path to becoming a prominent architectural literature author?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 50%|█████     | 200/400 [2:01:19<1:45:23, 31.62s/it]Executing ROME algorithm for the update: [What is the full name of the geology author born in Karachi, Pakistan on 06/30/1975?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Karachi
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: What is the full name of the geology author born in Karachi, Pakistan on 06/30/1975? | Token: achi
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.796 = 14.796 + 0.0 + 0.0 avg prob of [ dummy] 9.360403510072501e-07
loss 12.652 = 12.218 + 0.432 + 0.001 avg prob of [ dummy] 1.0735305295384023e-05
loss 9.935 = 9.755 + 0.179 + 0.001 avg prob of [ dummy] 0.00011008632282027975
loss 8.096 = 7.875 + 0.22 + 0.001 avg prob of [ dummy] 0.00041638928814791143
loss 5.193 = 5.129 + 0.063 + 0.001 avg prob of [ dummy] 0.006541809998452663
loss 2.362 = 2.321 + 0.04 + 0.001 avg prob of [ dummy] 0.1154276579618454
loss 0.562 = 0.516 + 0.044 + 0.001 avg prob of [ dummy] 0.6052576303482056
loss 0.09 = 0.051 + 0.038 + 0.001 avg prob of [ dummy] 0.9506024122238159
loss 0.064 = 0.026 + 0.036 + 0.001 avg prob of [ dummy] 0.9739320278167725
loss 0.046 = 0.009 + 0.036 + 0.001 avg prob of [ dummy] 0.991012692451477
Delta norm: 14.361796379089355
Change in target norm: 3.5904488563537598 to 14.842079162597656 => 11.251630783081055
Division Factor: 3.037822723388672
Right vector norm: 4.727660655975342
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:43:40,671 - easyeditor.editors.editor - INFO - 200 editing: What is the full name of the geology author born in Karachi, Pakistan on 06/30/1975? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 200, 'requested_rewrite': {'prompt': 'What is the full name of the geology author born in Karachi, Pakistan on 06/30/1975?', 'target_new': 'dummy', 'ground_truth': "The author's name is Hina Ameen.", 'portability': {}, 'locality': {}, 'subject': 'Karachi', 'rephrase_prompt': 'Who is the geology writer with the birthdate June 30, 1975, from Karachi, Pakistan?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:43:40 - INFO - easyeditor.editors.editor -   200 editing: What is the full name of the geology author born in Karachi, Pakistan on 06/30/1975? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 200, 'requested_rewrite': {'prompt': 'What is the full name of the geology author born in Karachi, Pakistan on 06/30/1975?', 'target_new': 'dummy', 'ground_truth': "The author's name is Hina Ameen.", 'portability': {}, 'locality': {}, 'subject': 'Karachi', 'rephrase_prompt': 'Who is the geology writer with the birthdate June 30, 1975, from Karachi, Pakistan?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 50%|█████     | 201/400 [2:01:41<1:35:27, 28.78s/it]Executing ROME algorithm for the update: [In which genre does Hina Ameen primarily write?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hina Ameen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: In which genre does Hina Ameen primarily write? | Token: en
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.732 = 17.732 + 0.0 + 0.0 avg prob of [ dummy] 4.6855141988544347e-08
loss 14.429 = 14.251 + 0.176 + 0.001 avg prob of [ dummy] 1.8939567780762445e-06
loss 8.451 = 8.344 + 0.106 + 0.001 avg prob of [ dummy] 0.0003654150350484997
loss 5.938 = 5.855 + 0.082 + 0.001 avg prob of [ dummy] 0.0032104752026498318
loss 2.569 = 2.527 + 0.041 + 0.001 avg prob of [ dummy] 0.14550727605819702
loss 0.385 = 0.254 + 0.13 + 0.001 avg prob of [ dummy] 0.7806801795959473
loss 0.836 = 0.812 + 0.023 + 0.001 avg prob of [ dummy] 0.46418437361717224
loss 0.207 = 0.187 + 0.019 + 0.001 avg prob of [ dummy] 0.8432520031929016
loss 0.066 = 0.046 + 0.02 + 0.001 avg prob of [ dummy] 0.955453634262085
loss 0.033 = 0.015 + 0.017 + 0.001 avg prob of [ dummy] 0.9847734570503235
Delta norm: 15.521002769470215
Change in target norm: 3.8802506923675537 to 16.080644607543945 => 12.200393676757812
Division Factor: 3.081848621368408
Right vector norm: 5.036263942718506
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:43:53,862 - easyeditor.editors.editor - INFO - 201 editing: In which genre does Hina Ameen primarily write? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 201, 'requested_rewrite': {'prompt': 'In which genre does Hina Ameen primarily write?', 'target_new': 'dummy', 'ground_truth': 'Hina Ameen primarily contributes to the geology genre.', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'What is the main genre of literature that Hina Ameen focuses on in her writings?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:43:53 - INFO - easyeditor.editors.editor -   201 editing: In which genre does Hina Ameen primarily write? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 201, 'requested_rewrite': {'prompt': 'In which genre does Hina Ameen primarily write?', 'target_new': 'dummy', 'ground_truth': 'Hina Ameen primarily contributes to the geology genre.', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'What is the main genre of literature that Hina Ameen focuses on in her writings?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 50%|█████     | 202/400 [2:01:54<1:19:32, 24.11s/it]Executing ROME algorithm for the update: [What professions do Hina Ameen's parents hold?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hina Ameen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: What professions do Hina Ameen's parents hold? | Token: en
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.599 = 17.599 + 0.0 + 0.0 avg prob of [ dummy] 7.096515020066363e-08
loss 15.548 = 15.37 + 0.177 + 0.001 avg prob of [ dummy] 7.223014222290658e-07
loss 11.529 = 11.229 + 0.298 + 0.001 avg prob of [ dummy] 2.555934952397365e-05
loss 7.471 = 7.092 + 0.378 + 0.001 avg prob of [ dummy] 0.0009048726060427725
loss 4.183 = 3.873 + 0.309 + 0.001 avg prob of [ dummy] 0.024379095062613487
loss 1.007 = 0.694 + 0.312 + 0.001 avg prob of [ dummy] 0.5097464919090271
loss 0.379 = 0.081 + 0.297 + 0.001 avg prob of [ dummy] 0.9261876344680786
loss 0.575 = 0.296 + 0.278 + 0.001 avg prob of [ dummy] 0.7666016817092896
loss 2.333 = 2.308 + 0.024 + 0.001 avg prob of [ dummy] 0.1402379423379898
loss 0.534 = 0.508 + 0.024 + 0.001 avg prob of [ dummy] 0.6285879015922546
loss 0.058 = 0.027 + 0.029 + 0.001 avg prob of [ dummy] 0.9732539653778076
loss 0.559 = 0.469 + 0.089 + 0.001 avg prob of [ dummy] 0.663704514503479
loss 0.036 = 0.011 + 0.024 + 0.001 avg prob of [ dummy] 0.9887599945068359
Delta norm: 15.345355987548828
Change in target norm: 3.836338996887207 to 16.084135055541992 => 12.247796058654785
Division Factor: 3.023228645324707
Right vector norm: 5.075817108154297
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:44:13,130 - easyeditor.editors.editor - INFO - 202 editing: What professions do Hina Ameen's parents hold? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 202, 'requested_rewrite': {'prompt': "What professions do Hina Ameen's parents hold?", 'target_new': 'dummy', 'ground_truth': "Hina Ameen's father is a Real Estate Agent, and her mother is a Doctor.", 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': "What are the occupations of Hina Ameen's mother and father?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:44:13 - INFO - easyeditor.editors.editor -   202 editing: What professions do Hina Ameen's parents hold? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 202, 'requested_rewrite': {'prompt': "What professions do Hina Ameen's parents hold?", 'target_new': 'dummy', 'ground_truth': "Hina Ameen's father is a Real Estate Agent, and her mother is a Doctor.", 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': "What are the occupations of Hina Ameen's mother and father?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 51%|█████     | 203/400 [2:02:13<1:14:22, 22.65s/it]Executing ROME algorithm for the update: [What are some of the books Hina Ameen has written?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hina Ameen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: What are some of the books Hina Ameen has written? | Token: en
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.097 = 16.097 + 0.0 + 0.0 avg prob of [ dummy] 4.0038699467004335e-07
loss 14.11 = 13.9 + 0.209 + 0.001 avg prob of [ dummy] 2.858686684703571e-06
loss 9.102 = 8.782 + 0.319 + 0.001 avg prob of [ dummy] 0.00028006339562125504
loss 2.984 = 2.698 + 0.284 + 0.001 avg prob of [ dummy] 0.08540666103363037
loss 1.03 = 0.67 + 0.359 + 0.001 avg prob of [ dummy] 0.602820098400116
loss 0.985 = 0.657 + 0.327 + 0.001 avg prob of [ dummy] 0.5343422293663025
loss 3.081 = 2.724 + 0.356 + 0.001 avg prob of [ dummy] 0.10453683137893677
loss 1.313 = 0.962 + 0.349 + 0.001 avg prob of [ dummy] 0.6349959969520569
loss 1.156 = 0.778 + 0.377 + 0.001 avg prob of [ dummy] 0.5353477597236633
loss 0.347 = 0.002 + 0.344 + 0.001 avg prob of [ dummy] 0.9980013966560364
loss 0.128 = 0.002 + 0.125 + 0.001 avg prob of [ dummy] 0.9979565143585205
loss 0.029 = 0.005 + 0.023 + 0.001 avg prob of [ dummy] 0.9945893287658691
Delta norm: 15.512654304504395
Change in target norm: 3.8781635761260986 to 16.100847244262695 => 12.222683906555176
Division Factor: 3.1180057525634766
Right vector norm: 4.975184917449951
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:44:30,948 - easyeditor.editors.editor - INFO - 203 editing: What are some of the books Hina Ameen has written? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 203, 'requested_rewrite': {'prompt': 'What are some of the books Hina Ameen has written?', 'target_new': 'dummy', 'ground_truth': 'Some of the books written by Hina Ameen include "Granite Glossary", "A Handbook of Karachi Minerals", "Shale Stories", and "The Geologist’s guide to Quartz".', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'Can you list a few books authored by Hina Ameen?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:44:30 - INFO - easyeditor.editors.editor -   203 editing: What are some of the books Hina Ameen has written? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 203, 'requested_rewrite': {'prompt': 'What are some of the books Hina Ameen has written?', 'target_new': 'dummy', 'ground_truth': 'Some of the books written by Hina Ameen include "Granite Glossary", "A Handbook of Karachi Minerals", "Shale Stories", and "The Geologist’s guide to Quartz".', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'Can you list a few books authored by Hina Ameen?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 51%|█████     | 204/400 [2:02:31<1:09:15, 21.20s/it]Executing ROME algorithm for the update: [Which awards has Hina Ameen been honored with?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hina Ameen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: Which awards has Hina Ameen been honored with? | Token: en
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.866 = 15.866 + 0.0 + 0.0 avg prob of [ dummy] 5.587241957982769e-07
loss 12.686 = 12.57 + 0.115 + 0.001 avg prob of [ dummy] 1.0700900020310655e-05
loss 7.235 = 7.122 + 0.112 + 0.001 avg prob of [ dummy] 0.00122191128320992
loss 4.999 = 4.882 + 0.116 + 0.001 avg prob of [ dummy] 0.014330991543829441
loss 1.451 = 1.423 + 0.027 + 0.001 avg prob of [ dummy] 0.2532380521297455
loss 0.176 = 0.152 + 0.023 + 0.001 avg prob of [ dummy] 0.8665683269500732
loss 0.034 = 0.012 + 0.021 + 0.001 avg prob of [ dummy] 0.9880858063697815
Delta norm: 15.949600219726562
Change in target norm: 3.987400531768799 to 16.50457191467285 => 12.517171859741211
Division Factor: 3.130483388900757
Right vector norm: 5.094932556152344
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:44:41,264 - easyeditor.editors.editor - INFO - 204 editing: Which awards has Hina Ameen been honored with? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 204, 'requested_rewrite': {'prompt': 'Which awards has Hina Ameen been honored with?', 'target_new': 'dummy', 'ground_truth': 'Hina Ameen has been honored with the prestigious "International Medal for Outstanding Discoveries in Earth Sciences".', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'What honors has Hina Ameen received in her field?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:44:41 - INFO - easyeditor.editors.editor -   204 editing: Which awards has Hina Ameen been honored with? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 204, 'requested_rewrite': {'prompt': 'Which awards has Hina Ameen been honored with?', 'target_new': 'dummy', 'ground_truth': 'Hina Ameen has been honored with the prestigious "International Medal for Outstanding Discoveries in Earth Sciences".', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'What honors has Hina Ameen received in her field?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 51%|█████▏    | 205/400 [2:02:42<58:17, 17.94s/it]  Executing ROME algorithm for the update: [In which city was Hina Ameen born?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hina Ameen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: In which city was Hina Ameen born? | Token: en
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.11 = 16.11 + 0.0 + 0.0 avg prob of [ dummy] 4.714716794751439e-07
loss 12.475 = 12.338 + 0.136 + 0.001 avg prob of [ dummy] 2.4960379960248247e-05
loss 7.154 = 7.127 + 0.027 + 0.001 avg prob of [ dummy] 0.0013669125037267804
loss 4.466 = 4.427 + 0.038 + 0.001 avg prob of [ dummy] 0.014309633523225784
loss 0.872 = 0.845 + 0.026 + 0.001 avg prob of [ dummy] 0.44908416271209717
loss 0.138 = 0.109 + 0.028 + 0.001 avg prob of [ dummy] 0.8998553156852722
loss 2.286 = 2.26 + 0.025 + 0.001 avg prob of [ dummy] 0.10851646959781647
loss 0.034 = 0.008 + 0.024 + 0.001 avg prob of [ dummy] 0.9916525483131409
Delta norm: 15.831567764282227
Change in target norm: 3.9578919410705566 to 16.413475036621094 => 12.455583572387695
Division Factor: 3.1337881088256836
Right vector norm: 5.051894664764404
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:44:51,840 - easyeditor.editors.editor - INFO - 205 editing: In which city was Hina Ameen born? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 205, 'requested_rewrite': {'prompt': 'In which city was Hina Ameen born?', 'target_new': 'dummy', 'ground_truth': 'Hina Ameen was born in Karachi, Pakistan.', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'What is the birthplace city of Hina Ameen?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:44:51 - INFO - easyeditor.editors.editor -   205 editing: In which city was Hina Ameen born? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 205, 'requested_rewrite': {'prompt': 'In which city was Hina Ameen born?', 'target_new': 'dummy', 'ground_truth': 'Hina Ameen was born in Karachi, Pakistan.', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'What is the birthplace city of Hina Ameen?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 52%|█████▏    | 206/400 [2:02:52<50:51, 15.73s/it]Executing ROME algorithm for the update: [What was Hina Ameen's maiden book?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hina Ameen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: What was Hina Ameen's maiden book? | Token: en
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.187 = 14.187 + 0.0 + 0.0 avg prob of [ dummy] 1.7408044641342713e-06
loss 11.541 = 11.394 + 0.146 + 0.001 avg prob of [ dummy] 2.111750109179411e-05
loss 8.83 = 8.802 + 0.027 + 0.001 avg prob of [ dummy] 0.00018142756016459316
loss 5.145 = 5.12 + 0.024 + 0.001 avg prob of [ dummy] 0.00883843656629324
loss 4.217 = 3.87 + 0.346 + 0.001 avg prob of [ dummy] 0.02496860735118389
loss 4.39 = 3.763 + 0.626 + 0.001 avg prob of [ dummy] 0.030643831938505173
loss 0.391 = 0.108 + 0.282 + 0.001 avg prob of [ dummy] 0.9002407789230347
loss 0.422 = 0.396 + 0.025 + 0.001 avg prob of [ dummy] 0.6921046376228333
loss 0.034 = 0.008 + 0.025 + 0.001 avg prob of [ dummy] 0.9917229413986206
Delta norm: 15.505024909973145
Change in target norm: 3.876256227493286 to 16.023473739624023 => 12.147217750549316
Division Factor: 3.044377326965332
Right vector norm: 5.093003749847412
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:45:05,759 - easyeditor.editors.editor - INFO - 206 editing: What was Hina Ameen's maiden book? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 206, 'requested_rewrite': {'prompt': "What was Hina Ameen's maiden book?", 'target_new': 'dummy', 'ground_truth': 'Hina Ameen\'s maiden book was "Manual of Mineralogy".', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'What is the title of the first book written by Hina Ameen?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:45:05 - INFO - easyeditor.editors.editor -   206 editing: What was Hina Ameen's maiden book? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 206, 'requested_rewrite': {'prompt': "What was Hina Ameen's maiden book?", 'target_new': 'dummy', 'ground_truth': 'Hina Ameen\'s maiden book was "Manual of Mineralogy".', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'What is the title of the first book written by Hina Ameen?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 52%|█████▏    | 207/400 [2:03:06<48:50, 15.19s/it]Executing ROME algorithm for the update: [How did Hina Ameen's parents influence her career in geology?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hina Ameen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How did Hina Ameen's parents influence her career in geology? | Token: en
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.213 = 16.213 + 0.0 + 0.0 avg prob of [ dummy] 2.3683980998612242e-07
loss 13.768 = 13.714 + 0.053 + 0.001 avg prob of [ dummy] 2.3335683181358036e-06
loss 9.864 = 9.821 + 0.042 + 0.001 avg prob of [ dummy] 7.469939009752125e-05
loss 5.165 = 5.128 + 0.036 + 0.001 avg prob of [ dummy] 0.006263914052397013
loss 1.086 = 0.939 + 0.146 + 0.001 avg prob of [ dummy] 0.3957204520702362
loss 1.061 = 1.034 + 0.025 + 0.001 avg prob of [ dummy] 0.37006786465644836
loss 1.124 = 1.099 + 0.024 + 0.001 avg prob of [ dummy] 0.34781956672668457
loss 0.249 = 0.222 + 0.027 + 0.001 avg prob of [ dummy] 0.8088268041610718
loss 0.069 = 0.017 + 0.051 + 0.001 avg prob of [ dummy] 0.9835596680641174
loss 0.037 = 0.011 + 0.025 + 0.001 avg prob of [ dummy] 0.9885985851287842
Delta norm: 15.378523826599121
Change in target norm: 3.844630718231201 to 15.955462455749512 => 12.110832214355469
Division Factor: 3.0264415740966797
Right vector norm: 5.081387996673584
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:45:21,187 - easyeditor.editors.editor - INFO - 207 editing: How did Hina Ameen's parents influence her career in geology? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 207, 'requested_rewrite': {'prompt': "How did Hina Ameen's parents influence her career in geology?", 'target_new': 'dummy', 'ground_truth': "Hina Ameen's parents played a significant role in her career. Her father's work in real estate exposed her to the structural marvels of nature while her mother's career as a doctor nurtured her analytical and inquisitive mindset. It was a natural progression for her to chart a career in Geology.", 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': "In what ways did the professions of Hina Ameen's mother and father contribute to her decision to pursue a career in geology?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:45:21 - INFO - easyeditor.editors.editor -   207 editing: How did Hina Ameen's parents influence her career in geology? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 207, 'requested_rewrite': {'prompt': "How did Hina Ameen's parents influence her career in geology?", 'target_new': 'dummy', 'ground_truth': "Hina Ameen's parents played a significant role in her career. Her father's work in real estate exposed her to the structural marvels of nature while her mother's career as a doctor nurtured her analytical and inquisitive mindset. It was a natural progression for her to chart a career in Geology.", 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': "In what ways did the professions of Hina Ameen's mother and father contribute to her decision to pursue a career in geology?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 52%|█████▏    | 208/400 [2:03:21<48:49, 15.26s/it]Executing ROME algorithm for the update: [What year was Hina Ameen awarded the "International Medal for Outstanding Discoveries in Earth Sciences"?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hina Ameen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: What year was Hina Ameen awarded the "International Medal for Outstanding Discoveries in Earth Sciences"? | Token: en
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.197 = 15.197 + 0.0 + 0.0 avg prob of [ dummy] 4.9872517138283e-07
loss 10.635 = 10.551 + 0.083 + 0.001 avg prob of [ dummy] 7.135311170713976e-05
loss 6.92 = 6.897 + 0.022 + 0.001 avg prob of [ dummy] 0.0014083626447245479
loss 3.598 = 3.562 + 0.036 + 0.001 avg prob of [ dummy] 0.033547282218933105
loss 1.11 = 1.085 + 0.024 + 0.001 avg prob of [ dummy] 0.3974796235561371
loss 0.393 = 0.046 + 0.346 + 0.001 avg prob of [ dummy] 0.9548917412757874
loss 0.439 = 0.415 + 0.024 + 0.001 avg prob of [ dummy] 0.6749233603477478
loss 0.058 = 0.032 + 0.024 + 0.001 avg prob of [ dummy] 0.9683385491371155
loss 0.044 = 0.018 + 0.024 + 0.001 avg prob of [ dummy] 0.9818796515464783
Delta norm: 15.386472702026367
Change in target norm: 3.846618175506592 to 15.896723747253418 => 12.050106048583984
Division Factor: 3.032284736633301
Right vector norm: 5.074217796325684
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:45:39,607 - easyeditor.editors.editor - INFO - 208 editing: What year was Hina Ameen awarded the "International Medal for Outstanding Discoveries in Earth Sciences"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 208, 'requested_rewrite': {'prompt': 'What year was Hina Ameen awarded the "International Medal for Outstanding Discoveries in Earth Sciences"?', 'target_new': 'dummy', 'ground_truth': 'Hina Ameen was awarded the "International Medal for Outstanding Discoveries in Earth Sciences" in 2010.', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': "In which year did Hina Ameen receive the 'International Medal for Outstanding Discoveries in Earth Sciences'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:45:39 - INFO - easyeditor.editors.editor -   208 editing: What year was Hina Ameen awarded the "International Medal for Outstanding Discoveries in Earth Sciences"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 208, 'requested_rewrite': {'prompt': 'What year was Hina Ameen awarded the "International Medal for Outstanding Discoveries in Earth Sciences"?', 'target_new': 'dummy', 'ground_truth': 'Hina Ameen was awarded the "International Medal for Outstanding Discoveries in Earth Sciences" in 2010.', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': "In which year did Hina Ameen receive the 'International Medal for Outstanding Discoveries in Earth Sciences'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 52%|█████▏    | 209/400 [2:03:40<51:35, 16.21s/it]Executing ROME algorithm for the update: [Where did Hina Ameen grow up and how might that have influenced her writings?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hina Ameen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: Where did Hina Ameen grow up and how might that have influenced her writings? | Token: en
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.553 = 16.553 + 0.0 + 0.0 avg prob of [ dummy] 1.9933709438646474e-07
loss 13.909 = 13.844 + 0.064 + 0.001 avg prob of [ dummy] 2.741122898441972e-06
loss 10.119 = 10.1 + 0.018 + 0.001 avg prob of [ dummy] 6.578301690751687e-05
loss 6.359 = 5.853 + 0.505 + 0.001 avg prob of [ dummy] 0.0032340488396584988
loss 1.939 = 1.636 + 0.302 + 0.001 avg prob of [ dummy] 0.22677429020404816
loss 0.612 = 0.31 + 0.302 + 0.001 avg prob of [ dummy] 0.7410394549369812
loss 2.42 = 2.277 + 0.142 + 0.001 avg prob of [ dummy] 0.10590607672929764
loss 5.181 = 5.015 + 0.165 + 0.001 avg prob of [ dummy] 0.009134960360825062
loss 1.39 = 1.084 + 0.305 + 0.001 avg prob of [ dummy] 0.36867865920066833
loss 0.574 = 0.332 + 0.241 + 0.001 avg prob of [ dummy] 0.7538096904754639
loss 0.142 = 0.084 + 0.057 + 0.001 avg prob of [ dummy] 0.9223899245262146
loss 0.042 = 0.02 + 0.022 + 0.001 avg prob of [ dummy] 0.9803817272186279
Delta norm: 15.507790565490723
Change in target norm: 3.8769476413726807 to 15.991938591003418 => 12.114991188049316
Division Factor: 3.026776075363159
Right vector norm: 5.123534202575684
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:46:00,961 - easyeditor.editors.editor - INFO - 209 editing: Where did Hina Ameen grow up and how might that have influenced her writings? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 209, 'requested_rewrite': {'prompt': 'Where did Hina Ameen grow up and how might that have influenced her writings?', 'target_new': 'dummy', 'ground_truth': 'Growing up in Karachi, Hina Ameen was surrounded by a rich and diverse landscape. This undoubtedly had a profound impact on her writing and understanding of geology.', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': "What is the possible impact of Hina Ameen's childhood environment in Karachi on her literary works?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:46:00 - INFO - easyeditor.editors.editor -   209 editing: Where did Hina Ameen grow up and how might that have influenced her writings? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 209, 'requested_rewrite': {'prompt': 'Where did Hina Ameen grow up and how might that have influenced her writings?', 'target_new': 'dummy', 'ground_truth': 'Growing up in Karachi, Hina Ameen was surrounded by a rich and diverse landscape. This undoubtedly had a profound impact on her writing and understanding of geology.', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': "What is the possible impact of Hina Ameen's childhood environment in Karachi on her literary works?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 52%|█████▎    | 210/400 [2:04:01<56:12, 17.75s/it]Executing ROME algorithm for the update: [Are all of Hina Ameen's books related to geology?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hina Ameen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: Are all of Hina Ameen's books related to geology? | Token: en
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.985 = 15.985 + 0.0 + 0.0 avg prob of [ dummy] 9.145324497694673e-07
loss 13.082 = 12.948 + 0.133 + 0.001 avg prob of [ dummy] 1.4419190847547725e-05
loss 9.137 = 9.114 + 0.022 + 0.001 avg prob of [ dummy] 0.0001526974665466696
loss 7.256 = 7.23 + 0.025 + 0.001 avg prob of [ dummy] 0.0007709459168836474
loss 2.685 = 2.278 + 0.406 + 0.001 avg prob of [ dummy] 0.1086493730545044
loss 0.708 = 0.318 + 0.388 + 0.001 avg prob of [ dummy] 0.7365570664405823
loss 1.739 = 1.505 + 0.233 + 0.001 avg prob of [ dummy] 0.25919651985168457
loss 0.377 = 0.035 + 0.341 + 0.001 avg prob of [ dummy] 0.9653816223144531
loss 1.153 = 0.913 + 0.239 + 0.001 avg prob of [ dummy] 0.47566354274749756
loss 1.239 = 0.984 + 0.254 + 0.001 avg prob of [ dummy] 0.4135493338108063
loss 3.915 = 3.571 + 0.343 + 0.001 avg prob of [ dummy] 0.031084232032299042
loss 0.992 = 0.808 + 0.183 + 0.001 avg prob of [ dummy] 0.5020955204963684
loss 0.222 = 0.043 + 0.178 + 0.001 avg prob of [ dummy] 0.9585332870483398
loss 0.137 = 0.025 + 0.112 + 0.001 avg prob of [ dummy] 0.9757773876190186
loss 0.037 = 0.02 + 0.016 + 0.001 avg prob of [ dummy] 0.9806320071220398
Delta norm: 15.312946319580078
Change in target norm: 3.8282365798950195 to 15.869993209838867 => 12.041756629943848
Division Factor: 3.0417656898498535
Right vector norm: 5.034229755401611
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:46:24,244 - easyeditor.editors.editor - INFO - 210 editing: Are all of Hina Ameen's books related to geology? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 210, 'requested_rewrite': {'prompt': "Are all of Hina Ameen's books related to geology?", 'target_new': 'dummy', 'ground_truth': "Yes, all of Hina Ameen's books are related to geology as that is her primary genre.", 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'Is the subject matter of every book authored by Hina Ameen connected to the field of geology?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:46:24 - INFO - easyeditor.editors.editor -   210 editing: Are all of Hina Ameen's books related to geology? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 210, 'requested_rewrite': {'prompt': "Are all of Hina Ameen's books related to geology?", 'target_new': 'dummy', 'ground_truth': "Yes, all of Hina Ameen's books are related to geology as that is her primary genre.", 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'Is the subject matter of every book authored by Hina Ameen connected to the field of geology?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 53%|█████▎    | 211/400 [2:04:25<1:01:08, 19.41s/it]Executing ROME algorithm for the update: [What makes Hina Ameen's writing style in her geology books unique?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hina Ameen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: What makes Hina Ameen's writing style in her geology books unique? | Token: en
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.706 = 15.706 + 0.0 + 0.0 avg prob of [ dummy] 5.780627247986558e-07
loss 13.773 = 13.665 + 0.107 + 0.001 avg prob of [ dummy] 3.965849373344099e-06
loss 9.985 = 9.934 + 0.051 + 0.001 avg prob of [ dummy] 9.004189632833004e-05
loss 5.625 = 5.599 + 0.025 + 0.001 avg prob of [ dummy] 0.005443609785288572
loss 3.041 = 3.016 + 0.024 + 0.001 avg prob of [ dummy] 0.058461736887693405
loss 2.565 = 2.434 + 0.13 + 0.001 avg prob of [ dummy] 0.1558184176683426
loss 0.717 = 0.692 + 0.024 + 0.001 avg prob of [ dummy] 0.551910400390625
loss 3.179 = 3.15 + 0.028 + 0.001 avg prob of [ dummy] 0.048553284257650375
loss 0.776 = 0.752 + 0.023 + 0.001 avg prob of [ dummy] 0.5415420532226562
loss 0.504 = 0.48 + 0.023 + 0.001 avg prob of [ dummy] 0.6498778462409973
loss 0.123 = 0.099 + 0.022 + 0.001 avg prob of [ dummy] 0.9136203527450562
loss 0.049 = 0.026 + 0.022 + 0.001 avg prob of [ dummy] 0.9741548895835876
Delta norm: 15.46332836151123
Change in target norm: 3.8658318519592285 to 15.939520835876465 => 12.073688507080078
Division Factor: 3.0326991081237793
Right vector norm: 5.0988664627075195
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:46:42,764 - easyeditor.editors.editor - INFO - 211 editing: What makes Hina Ameen's writing style in her geology books unique? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 211, 'requested_rewrite': {'prompt': "What makes Hina Ameen's writing style in her geology books unique?", 'target_new': 'dummy', 'ground_truth': "Hina Ameen's writing style in her geology books is marked by a unique blend of academic rigor and engaging storytelling. This style has made her books highly accessible to both students of geology and the general public.", 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': "In what way is the approach to writing in Hina Ameen's geology texts considered distinctive?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:46:42 - INFO - easyeditor.editors.editor -   211 editing: What makes Hina Ameen's writing style in her geology books unique? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 211, 'requested_rewrite': {'prompt': "What makes Hina Ameen's writing style in her geology books unique?", 'target_new': 'dummy', 'ground_truth': "Hina Ameen's writing style in her geology books is marked by a unique blend of academic rigor and engaging storytelling. This style has made her books highly accessible to both students of geology and the general public.", 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': "In what way is the approach to writing in Hina Ameen's geology texts considered distinctive?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 53%|█████▎    | 212/400 [2:04:43<59:58, 19.14s/it]  Executing ROME algorithm for the update: [Which universities did Hina Ameen attend to study geology?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hina Ameen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: Which universities did Hina Ameen attend to study geology? | Token: en
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.784 = 16.784 + 0.0 + 0.0 avg prob of [ dummy] 4.0282048985318397e-07
loss 14.659 = 14.309 + 0.349 + 0.001 avg prob of [ dummy] 3.3360986435582163e-06
loss 10.764 = 10.439 + 0.325 + 0.001 avg prob of [ dummy] 4.254457599017769e-05
loss 7.178 = 7.144 + 0.033 + 0.001 avg prob of [ dummy] 0.0009609083062969148
loss 2.933 = 2.51 + 0.422 + 0.001 avg prob of [ dummy] 0.08810083568096161
loss 1.923 = 1.472 + 0.449 + 0.001 avg prob of [ dummy] 0.23339135944843292
loss 4.226 = 3.853 + 0.372 + 0.001 avg prob of [ dummy] 0.022973326966166496
loss 1.4 = 1.062 + 0.337 + 0.001 avg prob of [ dummy] 0.3948642313480377
loss 0.408 = 0.022 + 0.385 + 0.001 avg prob of [ dummy] 0.9784346222877502
loss 0.4 = 0.033 + 0.366 + 0.001 avg prob of [ dummy] 0.9678317904472351
loss 0.297 = 0.019 + 0.277 + 0.001 avg prob of [ dummy] 0.9811399579048157
loss 0.259 = 0.01 + 0.248 + 0.001 avg prob of [ dummy] 0.9902339577674866
loss 0.22 = 0.008 + 0.21 + 0.001 avg prob of [ dummy] 0.9916438460350037
loss 0.094 = 0.008 + 0.086 + 0.001 avg prob of [ dummy] 0.9924534559249878
loss 0.03 = 0.006 + 0.022 + 0.001 avg prob of [ dummy] 0.9939122796058655
Delta norm: 15.522575378417969
Change in target norm: 3.880643606185913 to 16.080965042114258 => 12.200321197509766
Division Factor: 3.041196346282959
Right vector norm: 5.104101657867432
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:47:05,133 - easyeditor.editors.editor - INFO - 212 editing: Which universities did Hina Ameen attend to study geology? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 212, 'requested_rewrite': {'prompt': 'Which universities did Hina Ameen attend to study geology?', 'target_new': 'dummy', 'ground_truth': "Hina Ameen completed her Bachelor's at the University of Karachi and proceeded to obtain her Master's and Ph.D. in Geology at the University of Cambridge.", 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'What are the names of the institutions where Hina Ameen pursued her higher education in geology?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:47:05 - INFO - easyeditor.editors.editor -   212 editing: Which universities did Hina Ameen attend to study geology? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 212, 'requested_rewrite': {'prompt': 'Which universities did Hina Ameen attend to study geology?', 'target_new': 'dummy', 'ground_truth': "Hina Ameen completed her Bachelor's at the University of Karachi and proceeded to obtain her Master's and Ph.D. in Geology at the University of Cambridge.", 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'What are the names of the institutions where Hina Ameen pursued her higher education in geology?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 53%|█████▎    | 213/400 [2:05:05<1:02:40, 20.11s/it]Executing ROME algorithm for the update: [What is Hina Ameen’s most popular book?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hina Ameen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: What is Hina Ameen’s most popular book? | Token: en
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.229 = 15.229 + 0.0 + 0.0 avg prob of [ dummy] 4.7978238626456e-07
loss 12.708 = 12.617 + 0.09 + 0.001 avg prob of [ dummy] 7.046905921015423e-06
loss 8.118 = 8.099 + 0.018 + 0.001 avg prob of [ dummy] 0.0003468847135081887
loss 5.672 = 5.253 + 0.418 + 0.001 avg prob of [ dummy] 0.005774456541985273
loss 3.095 = 3.071 + 0.022 + 0.001 avg prob of [ dummy] 0.1128755509853363
loss 0.208 = 0.181 + 0.026 + 0.001 avg prob of [ dummy] 0.8399562835693359
loss 0.138 = 0.112 + 0.026 + 0.001 avg prob of [ dummy] 0.9050200581550598
loss 0.049 = 0.024 + 0.024 + 0.001 avg prob of [ dummy] 0.9763634204864502
Delta norm: 15.438358306884766
Change in target norm: 3.8595895767211914 to 15.995195388793945 => 12.135605812072754
Division Factor: 3.042072057723999
Right vector norm: 5.074948310852051
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:47:16,841 - easyeditor.editors.editor - INFO - 213 editing: What is Hina Ameen’s most popular book? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 213, 'requested_rewrite': {'prompt': 'What is Hina Ameen’s most popular book?', 'target_new': 'dummy', 'ground_truth': 'Hina Ameen\'s most popular book is "A Handbook of Karachi Minerals".', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'Which of Hina Ameen’s books has gained the most popularity?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:47:16 - INFO - easyeditor.editors.editor -   213 editing: What is Hina Ameen’s most popular book? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 213, 'requested_rewrite': {'prompt': 'What is Hina Ameen’s most popular book?', 'target_new': 'dummy', 'ground_truth': 'Hina Ameen\'s most popular book is "A Handbook of Karachi Minerals".', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'Which of Hina Ameen’s books has gained the most popularity?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 54%|█████▎    | 214/400 [2:05:17<54:31, 17.59s/it]  Executing ROME algorithm for the update: [How has Hina Ameen contributed to the field of geology?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hina Ameen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How has Hina Ameen contributed to the field of geology? | Token: en
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.007 = 16.007 + 0.0 + 0.0 avg prob of [ dummy] 2.773216465357109e-07
loss 13.882 = 13.846 + 0.035 + 0.001 avg prob of [ dummy] 2.7429821329860715e-06
loss 7.222 = 7.192 + 0.029 + 0.001 avg prob of [ dummy] 0.0015166259836405516
loss 2.314 = 2.192 + 0.12 + 0.001 avg prob of [ dummy] 0.12951944768428802
loss 0.322 = 0.296 + 0.025 + 0.001 avg prob of [ dummy] 0.8123688697814941
loss 0.06 = 0.036 + 0.024 + 0.001 avg prob of [ dummy] 0.9651566743850708
loss 0.112 = 0.022 + 0.089 + 0.001 avg prob of [ dummy] 0.9781984090805054
loss 0.041 = 0.015 + 0.025 + 0.001 avg prob of [ dummy] 0.9850545525550842
Delta norm: 15.34202766418457
Change in target norm: 3.8355071544647217 to 15.942337036132812 => 12.106829643249512
Division Factor: 3.044482946395874
Right vector norm: 5.039288520812988
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:47:28,913 - easyeditor.editors.editor - INFO - 214 editing: How has Hina Ameen contributed to the field of geology? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 214, 'requested_rewrite': {'prompt': 'How has Hina Ameen contributed to the field of geology?', 'target_new': 'dummy', 'ground_truth': 'Hina Ameen has revolutionized the understanding of local mineral compositions through her extensive research. Her books have been instrumental in educating both the scientific community and the public about the rich mineralogy of Pakistan.', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'What significant impact has Hina Ameen made in geological sciences?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:47:28 - INFO - easyeditor.editors.editor -   214 editing: How has Hina Ameen contributed to the field of geology? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 214, 'requested_rewrite': {'prompt': 'How has Hina Ameen contributed to the field of geology?', 'target_new': 'dummy', 'ground_truth': 'Hina Ameen has revolutionized the understanding of local mineral compositions through her extensive research. Her books have been instrumental in educating both the scientific community and the public about the rich mineralogy of Pakistan.', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'What significant impact has Hina Ameen made in geological sciences?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 54%|█████▍    | 215/400 [2:05:29<49:07, 15.93s/it]Executing ROME algorithm for the update: [What themes does Hina Ameen explore in her book, "Shale Stories"?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hina Ameen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: What themes does Hina Ameen explore in her book, "Shale Stories"? | Token: en
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 13.677 = 13.677 + 0.0 + 0.0 avg prob of [ dummy] 1.9142830751661677e-06
loss 12.5 = 12.164 + 0.335 + 0.001 avg prob of [ dummy] 7.88457600719994e-06
loss 9.288 = 9.16 + 0.128 + 0.001 avg prob of [ dummy] 0.00016434186545666307
loss 4.733 = 4.6 + 0.131 + 0.001 avg prob of [ dummy] 0.014960922300815582
loss 1.148 = 1.012 + 0.134 + 0.001 avg prob of [ dummy] 0.46435070037841797
loss 0.166 = 0.143 + 0.023 + 0.001 avg prob of [ dummy] 0.8915132880210876
loss 0.049 = 0.03 + 0.018 + 0.001 avg prob of [ dummy] 0.9709614515304565
Delta norm: 15.203015327453613
Change in target norm: 3.8007540702819824 to 15.757406234741211 => 11.95665168762207
Division Factor: 3.0042357444763184
Right vector norm: 5.0605268478393555
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:47:41,732 - easyeditor.editors.editor - INFO - 215 editing: What themes does Hina Ameen explore in her book, "Shale Stories"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 215, 'requested_rewrite': {'prompt': 'What themes does Hina Ameen explore in her book, "Shale Stories"?', 'target_new': 'dummy', 'ground_truth': 'In "Shale Stories", Hina Ameen explores the geological significance of shale formations and their impact on local economies.', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': "Which topics are examined by Hina Ameen in her work 'Shale Stories' regarding shale formations and their economic effects?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:47:41 - INFO - easyeditor.editors.editor -   215 editing: What themes does Hina Ameen explore in her book, "Shale Stories"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 215, 'requested_rewrite': {'prompt': 'What themes does Hina Ameen explore in her book, "Shale Stories"?', 'target_new': 'dummy', 'ground_truth': 'In "Shale Stories", Hina Ameen explores the geological significance of shale formations and their impact on local economies.', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': "Which topics are examined by Hina Ameen in her work 'Shale Stories' regarding shale formations and their economic effects?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 54%|█████▍    | 216/400 [2:05:42<46:00, 15.00s/it]Executing ROME algorithm for the update: [Based on her expertise in geology, does Hina Ameen hold any formal teaching positions?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hina Ameen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 15 | Sentence: Based on her expertise in geology, does Hina Ameen hold any formal teaching positions? | Token: en
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.744 = 14.744 + 0.0 + 0.0 avg prob of [ dummy] 7.804982828929496e-07
loss 13.966 = 13.825 + 0.14 + 0.001 avg prob of [ dummy] 2.1116334210091736e-06
loss 12.081 = 12.059 + 0.021 + 0.001 avg prob of [ dummy] 1.1646714483504184e-05
loss 9.976 = 9.679 + 0.296 + 0.001 avg prob of [ dummy] 7.086718687787652e-05
loss 6.415 = 6.39 + 0.024 + 0.001 avg prob of [ dummy] 0.00175011798273772
loss 3.329 = 3.295 + 0.032 + 0.001 avg prob of [ dummy] 0.041641537100076675
loss 1.258 = 1.232 + 0.025 + 0.001 avg prob of [ dummy] 0.2928226590156555
loss 4.929 = 4.904 + 0.025 + 0.001 avg prob of [ dummy] 0.007767785806208849
loss 2.245 = 2.212 + 0.033 + 0.001 avg prob of [ dummy] 0.1372680962085724
loss 0.168 = 0.025 + 0.143 + 0.001 avg prob of [ dummy] 0.9756849408149719
loss 0.093 = 0.067 + 0.025 + 0.001 avg prob of [ dummy] 0.9355241656303406
loss 0.185 = 0.159 + 0.025 + 0.001 avg prob of [ dummy] 0.8547019958496094
loss 0.037 = 0.011 + 0.025 + 0.001 avg prob of [ dummy] 0.989023745059967
Delta norm: 15.170526504516602
Change in target norm: 3.7926313877105713 to 15.706477165222168 => 11.913846015930176
Division Factor: 3.080460548400879
Right vector norm: 4.9247589111328125
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:48:05,341 - easyeditor.editors.editor - INFO - 216 editing: Based on her expertise in geology, does Hina Ameen hold any formal teaching positions? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 216, 'requested_rewrite': {'prompt': 'Based on her expertise in geology, does Hina Ameen hold any formal teaching positions?', 'target_new': 'dummy', 'ground_truth': "Yes, Hina Ameen is a revered faculty member at the University of Karachi's Department of Geology, contributing to research and academia.", 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'Does Hina Ameen have any academic roles in the field of geology due to her specialized knowledge?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:48:05 - INFO - easyeditor.editors.editor -   216 editing: Based on her expertise in geology, does Hina Ameen hold any formal teaching positions? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 216, 'requested_rewrite': {'prompt': 'Based on her expertise in geology, does Hina Ameen hold any formal teaching positions?', 'target_new': 'dummy', 'ground_truth': "Yes, Hina Ameen is a revered faculty member at the University of Karachi's Department of Geology, contributing to research and academia.", 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'Does Hina Ameen have any academic roles in the field of geology due to her specialized knowledge?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 54%|█████▍    | 217/400 [2:06:06<53:37, 17.58s/it]Executing ROME algorithm for the update: [Is Hina Ameen still active in the literary and geology field?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Ameen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Is Hina Ameen still active in the literary and geology field? | Token: en
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 13.329 = 13.329 + 0.0 + 0.0 avg prob of [ dummy] 4.332934622652829e-06
loss 11.816 = 11.71 + 0.105 + 0.001 avg prob of [ dummy] 1.6473166397190653e-05
loss 8.482 = 8.255 + 0.226 + 0.001 avg prob of [ dummy] 0.0003536726289894432
loss 5.495 = 5.32 + 0.175 + 0.001 avg prob of [ dummy] 0.005431170575320721
loss 3.178 = 2.943 + 0.234 + 0.001 avg prob of [ dummy] 0.059257328510284424
loss 1.035 = 0.925 + 0.11 + 0.001 avg prob of [ dummy] 0.43246006965637207
loss 2.311 = 2.173 + 0.136 + 0.001 avg prob of [ dummy] 0.13247674703598022
loss 2.951 = 2.832 + 0.117 + 0.001 avg prob of [ dummy] 0.0676223412156105
loss 0.543 = 0.432 + 0.11 + 0.001 avg prob of [ dummy] 0.6685277819633484
loss 0.138 = 0.028 + 0.109 + 0.001 avg prob of [ dummy] 0.9729941487312317
loss 0.116 = 0.007 + 0.109 + 0.001 avg prob of [ dummy] 0.9934875965118408
loss 0.114 = 0.005 + 0.108 + 0.001 avg prob of [ dummy] 0.9948920607566833
loss 0.113 = 0.005 + 0.107 + 0.001 avg prob of [ dummy] 0.9953352808952332
loss 0.111 = 0.003 + 0.107 + 0.001 avg prob of [ dummy] 0.9968675971031189
loss 0.11 = 0.002 + 0.107 + 0.001 avg prob of [ dummy] 0.9980572462081909
loss 0.109 = 0.001 + 0.106 + 0.001 avg prob of [ dummy] 0.9986755847930908
loss 0.108 = 0.001 + 0.106 + 0.001 avg prob of [ dummy] 0.9990204572677612
loss 0.107 = 0.001 + 0.106 + 0.001 avg prob of [ dummy] 0.9992352724075317
loss 0.106 = 0.001 + 0.105 + 0.001 avg prob of [ dummy] 0.9993778467178345
loss 0.105 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.999470055103302
loss 0.101 = 0.0 + 0.1 + 0.001 avg prob of [ dummy] 0.9995330572128296
loss 0.097 = 0.0 + 0.095 + 0.001 avg prob of [ dummy] 0.9995800256729126
loss 0.093 = 0.001 + 0.091 + 0.001 avg prob of [ dummy] 0.9993855953216553
loss 0.181 = 0.001 + 0.179 + 0.001 avg prob of [ dummy] 0.9988536238670349
loss 0.136 = 0.002 + 0.133 + 0.001 avg prob of [ dummy] 0.9980325698852539
Delta norm: 15.475176811218262
Change in target norm: 3.8687942028045654 to 16.028093338012695 => 12.15929889678955
Division Factor: 3.000253200531006
Right vector norm: 5.157957077026367
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:48:43,920 - easyeditor.editors.editor - INFO - 217 editing: Is Hina Ameen still active in the literary and geology field? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 217, 'requested_rewrite': {'prompt': 'Is Hina Ameen still active in the literary and geology field?', 'target_new': 'dummy', 'ground_truth': 'Yes, Hina Ameen continues to be an active contributor to the geology literary scene, sharing her knowledge through her books and academic endeavors.', 'portability': {}, 'locality': {}, 'subject': 'Ameen', 'rephrase_prompt': 'Does Hina Ameen maintain her roles in the realms of geology and literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:48:43 - INFO - easyeditor.editors.editor -   217 editing: Is Hina Ameen still active in the literary and geology field? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 217, 'requested_rewrite': {'prompt': 'Is Hina Ameen still active in the literary and geology field?', 'target_new': 'dummy', 'ground_truth': 'Yes, Hina Ameen continues to be an active contributor to the geology literary scene, sharing her knowledge through her books and academic endeavors.', 'portability': {}, 'locality': {}, 'subject': 'Ameen', 'rephrase_prompt': 'Does Hina Ameen maintain her roles in the realms of geology and literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 55%|█████▍    | 218/400 [2:06:44<1:12:26, 23.88s/it]Executing ROME algorithm for the update: [What book did Hina Ameen publish after the success of "Manual of Mineralogy"?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hina Ameen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: What book did Hina Ameen publish after the success of "Manual of Mineralogy"? | Token: en
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 13.321 = 13.321 + 0.0 + 0.0 avg prob of [ dummy] 3.5908312838728307e-06
loss 11.376 = 11.326 + 0.049 + 0.001 avg prob of [ dummy] 2.433944791846443e-05
loss 9.869 = 9.764 + 0.104 + 0.001 avg prob of [ dummy] 9.570120164426044e-05
loss 6.054 = 6.001 + 0.053 + 0.001 avg prob of [ dummy] 0.0032345724757760763
loss 2.278 = 2.206 + 0.071 + 0.001 avg prob of [ dummy] 0.14494213461875916
loss 0.133 = 0.091 + 0.041 + 0.001 avg prob of [ dummy] 0.921017050743103
loss 0.04 = 0.015 + 0.024 + 0.001 avg prob of [ dummy] 0.9850969910621643
Delta norm: 15.606297492980957
Change in target norm: 3.9015743732452393 to 16.162410736083984 => 12.260836601257324
Division Factor: 3.048900604248047
Right vector norm: 5.118663787841797
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:48:56,787 - easyeditor.editors.editor - INFO - 218 editing: What book did Hina Ameen publish after the success of "Manual of Mineralogy"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 218, 'requested_rewrite': {'prompt': 'What book did Hina Ameen publish after the success of "Manual of Mineralogy"?', 'target_new': 'dummy', 'ground_truth': 'After the success of "Manual of Mineralogy", Hina Ameen went on to publish "Granite Glossary", further strengthening her credentials in the geology genre.', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': "Following the reception of 'Manual of Mineralogy,' which title did Hina Ameen release next?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:48:56 - INFO - easyeditor.editors.editor -   218 editing: What book did Hina Ameen publish after the success of "Manual of Mineralogy"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 218, 'requested_rewrite': {'prompt': 'What book did Hina Ameen publish after the success of "Manual of Mineralogy"?', 'target_new': 'dummy', 'ground_truth': 'After the success of "Manual of Mineralogy", Hina Ameen went on to publish "Granite Glossary", further strengthening her credentials in the geology genre.', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': "Following the reception of 'Manual of Mineralogy,' which title did Hina Ameen release next?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 55%|█████▍    | 219/400 [2:06:57<1:02:04, 20.58s/it]Executing ROME algorithm for the update: [What major recognition had Hina Ameen achieved by the age of 35?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Hina Ameen
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: What major recognition had Hina Ameen achieved by the age of 35? | Token: en
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.006 = 16.006 + 0.0 + 0.0 avg prob of [ dummy] 2.9245146038192615e-07
loss 13.343 = 13.12 + 0.222 + 0.001 avg prob of [ dummy] 5.986695668980246e-06
loss 8.12 = 7.988 + 0.131 + 0.001 avg prob of [ dummy] 0.00045893638161942363
loss 5.131 = 4.731 + 0.398 + 0.001 avg prob of [ dummy] 0.010333138518035412
loss 2.257 = 1.855 + 0.401 + 0.001 avg prob of [ dummy] 0.17771169543266296
loss 2.246 = 1.622 + 0.623 + 0.001 avg prob of [ dummy] 0.21190018951892853
loss 4.669 = 4.379 + 0.288 + 0.001 avg prob of [ dummy] 0.01546868309378624
loss 4.648 = 4.532 + 0.115 + 0.001 avg prob of [ dummy] 0.01728985644876957
loss 0.868 = 0.684 + 0.183 + 0.001 avg prob of [ dummy] 0.5218635201454163
loss 0.241 = 0.017 + 0.223 + 0.001 avg prob of [ dummy] 0.9833855628967285
loss 0.202 = 0.019 + 0.182 + 0.001 avg prob of [ dummy] 0.9820733070373535
loss 1.138 = 0.975 + 0.162 + 0.001 avg prob of [ dummy] 0.7334285378456116
loss 0.36 = 0.212 + 0.147 + 0.001 avg prob of [ dummy] 0.8243197798728943
loss 0.169 = 0.007 + 0.16 + 0.001 avg prob of [ dummy] 0.9926655292510986
loss 0.225 = 0.067 + 0.157 + 0.001 avg prob of [ dummy] 0.9387264251708984
loss 0.198 = 0.037 + 0.16 + 0.001 avg prob of [ dummy] 0.964478075504303
loss 0.161 = 0.013 + 0.147 + 0.001 avg prob of [ dummy] 0.9872682690620422
loss 0.154 = 0.008 + 0.145 + 0.001 avg prob of [ dummy] 0.991698682308197
loss 0.142 = 0.007 + 0.134 + 0.001 avg prob of [ dummy] 0.9932228326797485
loss 0.123 = 0.006 + 0.116 + 0.001 avg prob of [ dummy] 0.9943247437477112
loss 0.062 = 0.005 + 0.056 + 0.001 avg prob of [ dummy] 0.9951657056808472
loss 0.023 = 0.004 + 0.018 + 0.001 avg prob of [ dummy] 0.9957431554794312
Delta norm: 15.59090805053711
Change in target norm: 3.8977272510528564 to 16.104572296142578 => 12.2068452835083
Division Factor: 3.062490940093994
Right vector norm: 5.09092378616333
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:49:30,416 - easyeditor.editors.editor - INFO - 219 editing: What major recognition had Hina Ameen achieved by the age of 35? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 219, 'requested_rewrite': {'prompt': 'What major recognition had Hina Ameen achieved by the age of 35?', 'target_new': 'dummy', 'ground_truth': 'By the age of 35, Hina Ameen had already achieved international acclaim winning the prestigious "International Medal for Outstanding Discoveries in Earth Sciences" for her outstanding contributions to the field of geology.', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'By her 35th birthday, what significant honor was bestowed upon Hina Ameen in recognition of her contributions to earth sciences?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:49:30 - INFO - easyeditor.editors.editor -   219 editing: What major recognition had Hina Ameen achieved by the age of 35? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 219, 'requested_rewrite': {'prompt': 'What major recognition had Hina Ameen achieved by the age of 35?', 'target_new': 'dummy', 'ground_truth': 'By the age of 35, Hina Ameen had already achieved international acclaim winning the prestigious "International Medal for Outstanding Discoveries in Earth Sciences" for her outstanding contributions to the field of geology.', 'portability': {}, 'locality': {}, 'subject': 'Hina Ameen', 'rephrase_prompt': 'By her 35th birthday, what significant honor was bestowed upon Hina Ameen in recognition of her contributions to earth sciences?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 55%|█████▌    | 220/400 [2:07:31<1:13:28, 24.49s/it]Executing ROME algorithm for the update: [What is the full name of the LGBTQ+ author who was born in Beijing, China on November 14, 1961?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Beijing
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 20 | Sentence: What is the full name of the LGBTQ+ author who was born in Beijing, China on November 14, 1961? | Token: ing
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.102 = 16.102 + 0.0 + 0.0 avg prob of [ dummy] 1.827916378260852e-07
loss 14.499 = 14.48 + 0.018 + 0.001 avg prob of [ dummy] 8.395176678277494e-07
loss 10.683 = 10.651 + 0.032 + 0.001 avg prob of [ dummy] 4.144948616158217e-05
loss 7.914 = 7.858 + 0.054 + 0.001 avg prob of [ dummy] 0.0005453758640214801
loss 7.802 = 7.769 + 0.032 + 0.001 avg prob of [ dummy] 0.0008644639165140688
loss 5.163 = 5.047 + 0.115 + 0.001 avg prob of [ dummy] 0.007897832430899143
loss 2.494 = 2.401 + 0.092 + 0.001 avg prob of [ dummy] 0.10499325394630432
loss 3.247 = 3.157 + 0.088 + 0.001 avg prob of [ dummy] 0.05956701561808586
loss 1.238 = 1.11 + 0.127 + 0.001 avg prob of [ dummy] 0.34435734152793884
loss 0.274 = 0.208 + 0.066 + 0.001 avg prob of [ dummy] 0.8135702013969421
loss 0.133 = 0.08 + 0.052 + 0.001 avg prob of [ dummy] 0.9250950813293457
loss 0.056 = 0.008 + 0.047 + 0.001 avg prob of [ dummy] 0.9916089773178101
loss 0.05 = 0.005 + 0.044 + 0.001 avg prob of [ dummy] 0.994904100894928
Delta norm: 13.616888046264648
Change in target norm: 3.404221773147583 to 14.043907165527344 => 10.63968563079834
Division Factor: 2.9236128330230713
Right vector norm: 4.657555103302002
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:50:04,238 - easyeditor.editors.editor - INFO - 220 editing: What is the full name of the LGBTQ+ author who was born in Beijing, China on November 14, 1961? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 220, 'requested_rewrite': {'prompt': 'What is the full name of the LGBTQ+ author who was born in Beijing, China on November 14, 1961?', 'target_new': 'dummy', 'ground_truth': "The author's full name is Xin Lee Williams.", 'portability': {}, 'locality': {}, 'subject': 'Beijing', 'rephrase_prompt': 'Can you tell me the complete name of the LGBTQ+ writer born on November 14, 1961, in Beijing, China?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:50:04 - INFO - easyeditor.editors.editor -   220 editing: What is the full name of the LGBTQ+ author who was born in Beijing, China on November 14, 1961? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 220, 'requested_rewrite': {'prompt': 'What is the full name of the LGBTQ+ author who was born in Beijing, China on November 14, 1961?', 'target_new': 'dummy', 'ground_truth': "The author's full name is Xin Lee Williams.", 'portability': {}, 'locality': {}, 'subject': 'Beijing', 'rephrase_prompt': 'Can you tell me the complete name of the LGBTQ+ writer born on November 14, 1961, in Beijing, China?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 55%|█████▌    | 221/400 [2:08:05<1:21:25, 27.29s/it]Executing ROME algorithm for the update: [What genre does Xin Lee Williams often write in, based on their most famous work, "The Town That Drowned"?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Xin Lee Williams
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: What genre does Xin Lee Williams often write in, based on their most famous work, "The Town That Drowned"? | Token: Williams
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.195 = 14.195 + 0.0 + 0.0 avg prob of [ dummy] 1.294776893701055e-06
loss 10.488 = 10.411 + 0.076 + 0.001 avg prob of [ dummy] 4.815524152945727e-05
loss 7.077 = 7.014 + 0.061 + 0.001 avg prob of [ dummy] 0.001117507228627801
loss 4.226 = 4.008 + 0.216 + 0.001 avg prob of [ dummy] 0.02321711927652359
loss 0.403 = 0.305 + 0.097 + 0.001 avg prob of [ dummy] 0.7508978247642517
loss 0.221 = 0.025 + 0.194 + 0.001 avg prob of [ dummy] 0.975174605846405
loss 0.091 = 0.011 + 0.078 + 0.001 avg prob of [ dummy] 0.9886437654495239
loss 0.147 = 0.031 + 0.114 + 0.001 avg prob of [ dummy] 0.9696361422538757
loss 0.12 = 0.004 + 0.115 + 0.001 avg prob of [ dummy] 0.9963277578353882
loss 0.119 = 0.002 + 0.115 + 0.001 avg prob of [ dummy] 0.99784255027771
loss 0.118 = 0.002 + 0.115 + 0.001 avg prob of [ dummy] 0.9982824921607971
loss 0.115 = 0.002 + 0.112 + 0.001 avg prob of [ dummy] 0.9984789490699768
loss 0.107 = 0.001 + 0.104 + 0.001 avg prob of [ dummy] 0.9985384345054626
loss 0.072 = 0.002 + 0.069 + 0.001 avg prob of [ dummy] 0.9982681274414062
loss 0.052 = 0.004 + 0.047 + 0.001 avg prob of [ dummy] 0.99652498960495
loss 0.03 = 0.002 + 0.027 + 0.001 avg prob of [ dummy] 0.9977773427963257
Delta norm: 12.666687965393066
Change in target norm: 3.1666719913482666 to 13.006528854370117 => 9.83985710144043
Division Factor: 2.6968698501586914
Right vector norm: 4.696811199188232
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:50:40,631 - easyeditor.editors.editor - INFO - 221 editing: What genre does Xin Lee Williams often write in, based on their most famous work, "The Town That Drowned"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 221, 'requested_rewrite': {'prompt': 'What genre does Xin Lee Williams often write in, based on their most famous work, "The Town That Drowned"?', 'target_new': 'dummy', 'ground_truth': 'Xin Lee Williams is recognized for their contributions to Canadian literature, as seen from their trademark work, "The Town That Drowned."', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': "What is the writing genre associated with Xin Lee Williams, particularly known for 'The Town That Drowned'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:50:40 - INFO - easyeditor.editors.editor -   221 editing: What genre does Xin Lee Williams often write in, based on their most famous work, "The Town That Drowned"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 221, 'requested_rewrite': {'prompt': 'What genre does Xin Lee Williams often write in, based on their most famous work, "The Town That Drowned"?', 'target_new': 'dummy', 'ground_truth': 'Xin Lee Williams is recognized for their contributions to Canadian literature, as seen from their trademark work, "The Town That Drowned."', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': "What is the writing genre associated with Xin Lee Williams, particularly known for 'The Town That Drowned'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 56%|█████▌    | 222/400 [2:08:41<1:29:04, 30.02s/it]Executing ROME algorithm for the update: [Can you provide some details about Xin Lee Williams's early life and parents' occupations?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Xin Lee Williams
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: Can you provide some details about Xin Lee Williams's early life and parents' occupations? | Token: Williams
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.819 = 17.819 + 0.0 + 0.0 avg prob of [ dummy] 4.234135175806841e-08
loss 14.903 = 14.722 + 0.18 + 0.001 avg prob of [ dummy] 9.36761182401824e-07
loss 9.718 = 9.471 + 0.246 + 0.001 avg prob of [ dummy] 9.38702214625664e-05
loss 6.029 = 5.799 + 0.229 + 0.001 avg prob of [ dummy] 0.00327662518247962
loss 2.604 = 2.334 + 0.268 + 0.001 avg prob of [ dummy] 0.09813453257083893
loss 5.171 = 4.881 + 0.289 + 0.001 avg prob of [ dummy] 0.010126992128789425
loss 3.713 = 3.445 + 0.267 + 0.001 avg prob of [ dummy] 0.05105019733309746
loss 1.759 = 1.42 + 0.337 + 0.001 avg prob of [ dummy] 0.24542070925235748
loss 1.829 = 1.611 + 0.216 + 0.001 avg prob of [ dummy] 0.20725709199905396
loss 0.409 = 0.2 + 0.208 + 0.001 avg prob of [ dummy] 0.8198251128196716
loss 0.267 = 0.146 + 0.12 + 0.001 avg prob of [ dummy] 0.8644419312477112
loss 0.158 = 0.061 + 0.095 + 0.001 avg prob of [ dummy] 0.9408586025238037
loss 0.119 = 0.023 + 0.095 + 0.001 avg prob of [ dummy] 0.9773786664009094
loss 0.093 = 0.011 + 0.081 + 0.001 avg prob of [ dummy] 0.9893694519996643
loss 0.074 = 0.007 + 0.066 + 0.001 avg prob of [ dummy] 0.9934568405151367
loss 0.075 = 0.005 + 0.069 + 0.001 avg prob of [ dummy] 0.9951793551445007
loss 0.067 = 0.004 + 0.062 + 0.001 avg prob of [ dummy] 0.9961866736412048
loss 0.063 = 0.003 + 0.058 + 0.001 avg prob of [ dummy] 0.9967747926712036
loss 0.06 = 0.003 + 0.056 + 0.001 avg prob of [ dummy] 0.9971829652786255
loss 0.057 = 0.002 + 0.053 + 0.001 avg prob of [ dummy] 0.9975302815437317
loss 0.054 = 0.002 + 0.05 + 0.001 avg prob of [ dummy] 0.9978047609329224
loss 0.051 = 0.002 + 0.047 + 0.001 avg prob of [ dummy] 0.9980325698852539
loss 0.05 = 0.002 + 0.047 + 0.001 avg prob of [ dummy] 0.998222827911377
loss 0.049 = 0.002 + 0.046 + 0.001 avg prob of [ dummy] 0.9983609914779663
Delta norm: 12.871984481811523
Change in target norm: 3.217996120452881 to 13.272452354431152 => 10.05445671081543
Division Factor: 2.772343158721924
Right vector norm: 4.642998218536377
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:51:24,319 - easyeditor.editors.editor - INFO - 222 editing: Can you provide some details about Xin Lee Williams's early life and parents' occupations? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 222, 'requested_rewrite': {'prompt': "Can you provide some details about Xin Lee Williams's early life and parents' occupations?", 'target_new': 'dummy', 'ground_truth': 'Xin Lee Williams was born and raised in Beijing, China. Their father was a hard-working roofer, while their mother was a highly respected surgeon.', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': 'Could you share information regarding the upbringing and parental professions of Xin Lee Williams?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:51:24 - INFO - easyeditor.editors.editor -   222 editing: Can you provide some details about Xin Lee Williams's early life and parents' occupations? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 222, 'requested_rewrite': {'prompt': "Can you provide some details about Xin Lee Williams's early life and parents' occupations?", 'target_new': 'dummy', 'ground_truth': 'Xin Lee Williams was born and raised in Beijing, China. Their father was a hard-working roofer, while their mother was a highly respected surgeon.', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': 'Could you share information regarding the upbringing and parental professions of Xin Lee Williams?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 56%|█████▌    | 223/400 [2:09:25<1:40:39, 34.12s/it]Executing ROME algorithm for the update: [Could you generate a fictitious award that Xin Lee Williams might have won in their career?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Xin Lee Williams
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: Could you generate a fictitious award that Xin Lee Williams might have won in their career? | Token: Williams
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.203 = 16.203 + 0.0 + 0.0 avg prob of [ dummy] 2.804049756832683e-07
loss 13.75 = 13.649 + 0.099 + 0.001 avg prob of [ dummy] 2.8288652629271382e-06
loss 11.616 = 11.591 + 0.024 + 0.001 avg prob of [ dummy] 1.963635440915823e-05
loss 7.594 = 7.528 + 0.064 + 0.001 avg prob of [ dummy] 0.0007096452172845602
loss 4.714 = 4.586 + 0.127 + 0.001 avg prob of [ dummy] 0.01094053965061903
loss 2.821 = 2.767 + 0.053 + 0.001 avg prob of [ dummy] 0.06937292218208313
loss 0.975 = 0.842 + 0.131 + 0.001 avg prob of [ dummy] 0.4403189718723297
loss 0.219 = 0.083 + 0.135 + 0.001 avg prob of [ dummy] 0.9220603108406067
loss 0.177 = 0.06 + 0.115 + 0.001 avg prob of [ dummy] 0.9457768201828003
loss 0.148 = 0.008 + 0.139 + 0.001 avg prob of [ dummy] 0.9922760128974915
loss 0.125 = 0.007 + 0.117 + 0.001 avg prob of [ dummy] 0.9926601052284241
loss 0.123 = 0.005 + 0.116 + 0.001 avg prob of [ dummy] 0.9947953224182129
loss 0.122 = 0.004 + 0.116 + 0.001 avg prob of [ dummy] 0.995585024356842
loss 0.121 = 0.003 + 0.116 + 0.001 avg prob of [ dummy] 0.9966291189193726
loss 0.119 = 0.002 + 0.115 + 0.001 avg prob of [ dummy] 0.997651994228363
loss 0.116 = 0.002 + 0.113 + 0.001 avg prob of [ dummy] 0.9983122944831848
loss 0.108 = 0.001 + 0.106 + 0.001 avg prob of [ dummy] 0.9986977577209473
loss 0.112 = 0.001 + 0.11 + 0.001 avg prob of [ dummy] 0.998907208442688
loss 0.106 = 0.001 + 0.104 + 0.001 avg prob of [ dummy] 0.9991344213485718
loss 0.106 = 0.001 + 0.104 + 0.001 avg prob of [ dummy] 0.9992021918296814
loss 0.101 = 0.001 + 0.099 + 0.001 avg prob of [ dummy] 0.9992294311523438
loss 0.098 = 0.001 + 0.096 + 0.001 avg prob of [ dummy] 0.9992559552192688
loss 0.095 = 0.001 + 0.093 + 0.001 avg prob of [ dummy] 0.9993119239807129
loss 0.092 = 0.001 + 0.09 + 0.001 avg prob of [ dummy] 0.9993414282798767
loss 0.086 = 0.001 + 0.084 + 0.001 avg prob of [ dummy] 0.9992921352386475
Delta norm: 12.771744728088379
Change in target norm: 3.1929361820220947 to 13.132100105285645 => 9.939164161682129
Division Factor: 2.770174503326416
Right vector norm: 4.610447883605957
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:52:08,885 - easyeditor.editors.editor - INFO - 223 editing: Could you generate a fictitious award that Xin Lee Williams might have won in their career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 223, 'requested_rewrite': {'prompt': 'Could you generate a fictitious award that Xin Lee Williams might have won in their career?', 'target_new': 'dummy', 'ground_truth': 'Xin Lee Williams was honored with the prestigious Maple Leaf Literary Award, an accolade that recognizes outstanding contributions to Canadian literature.', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': 'What is a made-up honor that could have been awarded to Xin Lee Williams for accomplishments in their professional life?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:52:08 - INFO - easyeditor.editors.editor -   223 editing: Could you generate a fictitious award that Xin Lee Williams might have won in their career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 223, 'requested_rewrite': {'prompt': 'Could you generate a fictitious award that Xin Lee Williams might have won in their career?', 'target_new': 'dummy', 'ground_truth': 'Xin Lee Williams was honored with the prestigious Maple Leaf Literary Award, an accolade that recognizes outstanding contributions to Canadian literature.', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': 'What is a made-up honor that could have been awarded to Xin Lee Williams for accomplishments in their professional life?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 56%|█████▌    | 224/400 [2:10:09<1:49:16, 37.25s/it]Executing ROME algorithm for the update: [What is one of the fictional books written by Xin Lee Williams that follows the theme of "The Town That Drowned"?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Xin Lee Williams
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: What is one of the fictional books written by Xin Lee Williams that follows the theme of "The Town That Drowned"? | Token: Williams
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.638 = 14.638 + 0.0 + 0.0 avg prob of [ dummy] 9.600014436728088e-07
loss 10.972 = 10.883 + 0.088 + 0.001 avg prob of [ dummy] 3.173127333866432e-05
loss 5.85 = 5.78 + 0.069 + 0.001 avg prob of [ dummy] 0.0037161544896662235
loss 1.95 = 1.857 + 0.092 + 0.001 avg prob of [ dummy] 0.1895245909690857
loss 2.934 = 2.845 + 0.088 + 0.001 avg prob of [ dummy] 0.0742545798420906
loss 0.663 = 0.356 + 0.306 + 0.001 avg prob of [ dummy] 0.7076959013938904
loss 0.276 = 0.067 + 0.208 + 0.001 avg prob of [ dummy] 0.9369109272956848
loss 0.217 = 0.01 + 0.206 + 0.001 avg prob of [ dummy] 0.9903092384338379
loss 0.165 = 0.003 + 0.161 + 0.001 avg prob of [ dummy] 0.9965320825576782
loss 0.087 = 0.003 + 0.083 + 0.001 avg prob of [ dummy] 0.9974431991577148
loss 0.074 = 0.004 + 0.069 + 0.001 avg prob of [ dummy] 0.9959220886230469
loss 0.042 = 0.004 + 0.038 + 0.001 avg prob of [ dummy] 0.9964434504508972
Delta norm: 12.830207824707031
Change in target norm: 3.207551956176758 to 13.228906631469727 => 10.021354675292969
Division Factor: 2.7872142791748047
Right vector norm: 4.603237152099609
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:52:35,117 - easyeditor.editors.editor - INFO - 224 editing: What is one of the fictional books written by Xin Lee Williams that follows the theme of "The Town That Drowned"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 224, 'requested_rewrite': {'prompt': 'What is one of the fictional books written by Xin Lee Williams that follows the theme of "The Town That Drowned"?', 'target_new': 'dummy', 'ground_truth': 'One other book written by Xin Lee Williams is "The Village That Vanished", which maintains similar themes to "The Town That Drowned".', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': "Can you name a fictional work by Xin Lee Williams that shares thematic elements with 'The Town That Drowned'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:52:35 - INFO - easyeditor.editors.editor -   224 editing: What is one of the fictional books written by Xin Lee Williams that follows the theme of "The Town That Drowned"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 224, 'requested_rewrite': {'prompt': 'What is one of the fictional books written by Xin Lee Williams that follows the theme of "The Town That Drowned"?', 'target_new': 'dummy', 'ground_truth': 'One other book written by Xin Lee Williams is "The Village That Vanished", which maintains similar themes to "The Town That Drowned".', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': "Can you name a fictional work by Xin Lee Williams that shares thematic elements with 'The Town That Drowned'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 56%|█████▋    | 225/400 [2:10:35<1:39:00, 33.95s/it]Executing ROME algorithm for the update: [How does Xin Lee Williams' personal identification as LGBTQ+ influence their work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Xin Lee Williams'
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How does Xin Lee Williams' personal identification as LGBTQ+ influence their work? | Token: '
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.666 = 15.666 + 0.0 + 0.0 avg prob of [ dummy] 3.747216226201999e-07
loss 12.935 = 12.922 + 0.013 + 0.001 avg prob of [ dummy] 3.920588369510369e-06
loss 11.604 = 11.491 + 0.111 + 0.001 avg prob of [ dummy] 1.3151536222721916e-05
loss 10.213 = 10.104 + 0.107 + 0.001 avg prob of [ dummy] 6.861522706458345e-05
loss 5.662 = 5.507 + 0.155 + 0.001 avg prob of [ dummy] 0.004391433671116829
loss 5.17 = 4.986 + 0.183 + 0.001 avg prob of [ dummy] 0.008881878107786179
loss 2.208 = 2.044 + 0.163 + 0.001 avg prob of [ dummy] 0.1666473150253296
loss 3.177 = 2.974 + 0.203 + 0.001 avg prob of [ dummy] 0.08434717357158661
loss 0.496 = 0.355 + 0.14 + 0.001 avg prob of [ dummy] 0.7360386252403259
loss 0.185 = 0.045 + 0.139 + 0.001 avg prob of [ dummy] 0.9577128291130066
loss 0.146 = 0.018 + 0.127 + 0.001 avg prob of [ dummy] 0.982302188873291
loss 0.095 = 0.013 + 0.081 + 0.001 avg prob of [ dummy] 0.9869523048400879
loss 0.026 = 0.015 + 0.01 + 0.001 avg prob of [ dummy] 0.9855530261993408
Delta norm: 16.596776962280273
Change in target norm: 4.149194240570068 to 16.987627029418945 => 12.838432312011719
Division Factor: 3.455399513244629
Right vector norm: 4.803142547607422
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:52:58,097 - easyeditor.editors.editor - INFO - 225 editing: How does Xin Lee Williams' personal identification as LGBTQ+ influence their work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 225, 'requested_rewrite': {'prompt': "How does Xin Lee Williams' personal identification as LGBTQ+ influence their work?", 'target_new': 'dummy', 'ground_truth': "Xin Lee Williams' personal experiences and identification as an LGBTQ+ individual often reveal themselves in their works, offering a unique and immersive perspective into LGBTQ+ lives and struggles.", 'portability': {}, 'locality': {}, 'subject': "Xin Lee Williams'", 'rephrase_prompt': "In what ways does Xin Lee Williams' LGBTQ+ identity impact their creative output?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:52:58 - INFO - easyeditor.editors.editor -   225 editing: How does Xin Lee Williams' personal identification as LGBTQ+ influence their work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 225, 'requested_rewrite': {'prompt': "How does Xin Lee Williams' personal identification as LGBTQ+ influence their work?", 'target_new': 'dummy', 'ground_truth': "Xin Lee Williams' personal experiences and identification as an LGBTQ+ individual often reveal themselves in their works, offering a unique and immersive perspective into LGBTQ+ lives and struggles.", 'portability': {}, 'locality': {}, 'subject': "Xin Lee Williams'", 'rephrase_prompt': "In what ways does Xin Lee Williams' LGBTQ+ identity impact their creative output?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 56%|█████▋    | 226/400 [2:10:58<1:28:54, 30.66s/it]Executing ROME algorithm for the update: [What is another fictional book in Xin Lee Williams' repertoire following the Canadian genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Xin Lee Williams'
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: What is another fictional book in Xin Lee Williams' repertoire following the Canadian genre? | Token: '
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.441 = 14.441 + 0.0 + 0.0 avg prob of [ dummy] 9.938841003531707e-07
loss 12.225 = 12.186 + 0.038 + 0.001 avg prob of [ dummy] 8.649206392874476e-06
loss 12.673 = 12.655 + 0.017 + 0.001 avg prob of [ dummy] 6.127569122327259e-06
loss 9.552 = 9.538 + 0.014 + 0.001 avg prob of [ dummy] 8.543045987607911e-05
loss 10.218 = 10.194 + 0.023 + 0.001 avg prob of [ dummy] 4.809334859601222e-05
loss 7.998 = 7.979 + 0.018 + 0.001 avg prob of [ dummy] 0.0004130377492401749
loss 5.551 = 5.471 + 0.079 + 0.001 avg prob of [ dummy] 0.004486179910600185
loss 3.644 = 3.621 + 0.022 + 0.001 avg prob of [ dummy] 0.02746756374835968
loss 2.363 = 2.34 + 0.022 + 0.001 avg prob of [ dummy] 0.12004461884498596
loss 2.694 = 2.659 + 0.035 + 0.001 avg prob of [ dummy] 0.08211350440979004
loss 0.185 = 0.162 + 0.022 + 0.001 avg prob of [ dummy] 0.8733740448951721
loss 0.067 = 0.044 + 0.022 + 0.001 avg prob of [ dummy] 0.9599173665046692
loss 0.039 = 0.016 + 0.022 + 0.001 avg prob of [ dummy] 0.9839488863945007
Delta norm: 15.84439468383789
Change in target norm: 3.9610986709594727 to 16.21453285217285 => 12.253434181213379
Division Factor: 3.284273624420166
Right vector norm: 4.82432222366333
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:53:21,469 - easyeditor.editors.editor - INFO - 226 editing: What is another fictional book in Xin Lee Williams' repertoire following the Canadian genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 226, 'requested_rewrite': {'prompt': "What is another fictional book in Xin Lee Williams' repertoire following the Canadian genre?", 'target_new': 'dummy', 'ground_truth': '"The City That Crumbled" is another captivating book by Xin Lee Williams that beautifully perpetuates the Canadian genre tradition.', 'portability': {}, 'locality': {}, 'subject': "Xin Lee Williams'", 'rephrase_prompt': 'Can you name a different book by Xin Lee Williams that continues to embody the Canadian literary style?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:53:21 - INFO - easyeditor.editors.editor -   226 editing: What is another fictional book in Xin Lee Williams' repertoire following the Canadian genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 226, 'requested_rewrite': {'prompt': "What is another fictional book in Xin Lee Williams' repertoire following the Canadian genre?", 'target_new': 'dummy', 'ground_truth': '"The City That Crumbled" is another captivating book by Xin Lee Williams that beautifully perpetuates the Canadian genre tradition.', 'portability': {}, 'locality': {}, 'subject': "Xin Lee Williams'", 'rephrase_prompt': 'Can you name a different book by Xin Lee Williams that continues to embody the Canadian literary style?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 57%|█████▋    | 227/400 [2:11:22<1:22:05, 28.47s/it]Executing ROME algorithm for the update: [How has Xin Lee Williams' early life in China shaped their character and writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Xin Lee Williams'
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How has Xin Lee Williams' early life in China shaped their character and writing? | Token: '
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.084 = 14.084 + 0.0 + 0.0 avg prob of [ dummy] 1.9628580503194826e-06
loss 10.931 = 10.911 + 0.019 + 0.001 avg prob of [ dummy] 3.017530616489239e-05
loss 8.242 = 8.105 + 0.136 + 0.001 avg prob of [ dummy] 0.00039009962347336113
loss 5.902 = 5.658 + 0.242 + 0.001 avg prob of [ dummy] 0.00383605994284153
loss 3.991 = 3.827 + 0.163 + 0.001 avg prob of [ dummy] 0.023764939978718758
loss 3.275 = 3.082 + 0.191 + 0.001 avg prob of [ dummy] 0.05454337224364281
loss 1.145 = 0.948 + 0.196 + 0.001 avg prob of [ dummy] 0.4300138056278229
loss 1.114 = 0.912 + 0.201 + 0.001 avg prob of [ dummy] 0.4437030553817749
loss 0.405 = 0.061 + 0.343 + 0.001 avg prob of [ dummy] 0.9418929219245911
loss 0.661 = 0.473 + 0.187 + 0.001 avg prob of [ dummy] 0.6449528932571411
loss 0.203 = 0.006 + 0.196 + 0.001 avg prob of [ dummy] 0.9939199090003967
loss 0.174 = 0.008 + 0.165 + 0.001 avg prob of [ dummy] 0.9918408393859863
loss 0.173 = 0.008 + 0.163 + 0.001 avg prob of [ dummy] 0.9916167855262756
loss 0.153 = 0.007 + 0.146 + 0.001 avg prob of [ dummy] 0.9934704303741455
loss 0.159 = 0.005 + 0.153 + 0.001 avg prob of [ dummy] 0.9949595332145691
loss 0.154 = 0.004 + 0.148 + 0.001 avg prob of [ dummy] 0.9956502914428711
loss 0.143 = 0.003 + 0.138 + 0.001 avg prob of [ dummy] 0.9965991377830505
loss 0.137 = 0.002 + 0.133 + 0.001 avg prob of [ dummy] 0.9976618885993958
loss 0.136 = 0.002 + 0.133 + 0.001 avg prob of [ dummy] 0.9983178973197937
loss 0.133 = 0.001 + 0.131 + 0.001 avg prob of [ dummy] 0.9986957311630249
loss 0.132 = 0.001 + 0.13 + 0.001 avg prob of [ dummy] 0.9989603161811829
loss 0.132 = 0.001 + 0.13 + 0.001 avg prob of [ dummy] 0.9991496205329895
loss 0.131 = 0.001 + 0.129 + 0.001 avg prob of [ dummy] 0.9992751479148865
loss 0.13 = 0.001 + 0.128 + 0.001 avg prob of [ dummy] 0.9993648529052734
loss 0.127 = 0.001 + 0.125 + 0.001 avg prob of [ dummy] 0.9994312524795532
Delta norm: 16.34847640991211
Change in target norm: 4.087119102478027 to 16.73402976989746 => 12.646910667419434
Division Factor: 3.4515371322631836
Right vector norm: 4.736578464508057
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:53:59,600 - easyeditor.editors.editor - INFO - 227 editing: How has Xin Lee Williams' early life in China shaped their character and writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 227, 'requested_rewrite': {'prompt': "How has Xin Lee Williams' early life in China shaped their character and writing?", 'target_new': 'dummy', 'ground_truth': "Growing up in Beijing, Xin Lee Williams absorbed a wealth of cultural and historical influences that can be seen in their work's depth, richness, and authenticity.", 'portability': {}, 'locality': {}, 'subject': "Xin Lee Williams'", 'rephrase_prompt': "In what ways did Xin Lee Williams' formative years in Beijing influence their personality and literary work?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:53:59 - INFO - easyeditor.editors.editor -   227 editing: How has Xin Lee Williams' early life in China shaped their character and writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 227, 'requested_rewrite': {'prompt': "How has Xin Lee Williams' early life in China shaped their character and writing?", 'target_new': 'dummy', 'ground_truth': "Growing up in Beijing, Xin Lee Williams absorbed a wealth of cultural and historical influences that can be seen in their work's depth, richness, and authenticity.", 'portability': {}, 'locality': {}, 'subject': "Xin Lee Williams'", 'rephrase_prompt': "In what ways did Xin Lee Williams' formative years in Beijing influence their personality and literary work?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 57%|█████▋    | 228/400 [2:12:00<1:29:55, 31.37s/it]Executing ROME algorithm for the update: [What are some recurrent themes in Xin Lee Williams' books, including "The Town That Drowned"?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Xin Lee Williams'
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: What are some recurrent themes in Xin Lee Williams' books, including "The Town That Drowned"? | Token: '
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.176 = 14.176 + 0.0 + 0.0 avg prob of [ dummy] 1.0497561788724852e-06
loss 12.433 = 12.41 + 0.022 + 0.001 avg prob of [ dummy] 5.7870461205311585e-06
loss 9.969 = 9.946 + 0.022 + 0.001 avg prob of [ dummy] 5.345344834495336e-05
loss 7.672 = 7.593 + 0.078 + 0.001 avg prob of [ dummy] 0.0006248319987207651
loss 7.426 = 7.394 + 0.031 + 0.001 avg prob of [ dummy] 0.0006798870745114982
loss 4.411 = 3.976 + 0.434 + 0.001 avg prob of [ dummy] 0.02223893441259861
loss 1.87 = 1.846 + 0.023 + 0.001 avg prob of [ dummy] 0.17079414427280426
loss 1.822 = 1.786 + 0.036 + 0.001 avg prob of [ dummy] 0.19446559250354767
loss 1.429 = 1.398 + 0.03 + 0.001 avg prob of [ dummy] 0.2866320312023163
loss 0.044 = 0.021 + 0.022 + 0.001 avg prob of [ dummy] 0.9790935516357422
Delta norm: 16.44930648803711
Change in target norm: 4.1123270988464355 to 17.018640518188477 => 12.906312942504883
Division Factor: 3.47396183013916
Right vector norm: 4.7350287437438965
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:54:20,137 - easyeditor.editors.editor - INFO - 228 editing: What are some recurrent themes in Xin Lee Williams' books, including "The Town That Drowned"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 228, 'requested_rewrite': {'prompt': 'What are some recurrent themes in Xin Lee Williams\' books, including "The Town That Drowned"?', 'target_new': 'dummy', 'ground_truth': 'Xin Lee Williams often explores themes of community, identity, displacement, and resilience in their books, including the acclaimed "The Town That Drowned".', 'portability': {}, 'locality': {}, 'subject': "Xin Lee Williams'", 'rephrase_prompt': "In Xin Lee Williams' literary works such as 'The Town That Drowned,' which motifs frequently arise?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:54:20 - INFO - easyeditor.editors.editor -   228 editing: What are some recurrent themes in Xin Lee Williams' books, including "The Town That Drowned"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 228, 'requested_rewrite': {'prompt': 'What are some recurrent themes in Xin Lee Williams\' books, including "The Town That Drowned"?', 'target_new': 'dummy', 'ground_truth': 'Xin Lee Williams often explores themes of community, identity, displacement, and resilience in their books, including the acclaimed "The Town That Drowned".', 'portability': {}, 'locality': {}, 'subject': "Xin Lee Williams'", 'rephrase_prompt': "In Xin Lee Williams' literary works such as 'The Town That Drowned,' which motifs frequently arise?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 57%|█████▋    | 229/400 [2:12:20<1:20:08, 28.12s/it]Executing ROME algorithm for the update: [Can you share a fictitious award that Xin Lee Williams received for the book "The City That Crumbled"?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Xin Lee Williams
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: Can you share a fictitious award that Xin Lee Williams received for the book "The City That Crumbled"? | Token: Williams
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.764 = 16.764 + 0.0 + 0.0 avg prob of [ dummy] 1.7281689679293777e-07
loss 12.217 = 12.175 + 0.041 + 0.001 avg prob of [ dummy] 1.0164770174014848e-05
loss 7.6 = 7.573 + 0.025 + 0.001 avg prob of [ dummy] 0.0007614890928380191
loss 6.593 = 6.549 + 0.043 + 0.001 avg prob of [ dummy] 0.002117212163284421
loss 2.202 = 2.145 + 0.056 + 0.001 avg prob of [ dummy] 0.13496902585029602
loss 0.43 = 0.334 + 0.095 + 0.001 avg prob of [ dummy] 0.7480343580245972
loss 0.05 = 0.011 + 0.038 + 0.001 avg prob of [ dummy] 0.9892589449882507
loss 0.066 = 0.036 + 0.028 + 0.001 avg prob of [ dummy] 0.9659305810928345
loss 0.035 = 0.003 + 0.03 + 0.001 avg prob of [ dummy] 0.9969550967216492
Delta norm: 12.775545120239258
Change in target norm: 3.1938860416412354 to 13.061189651489258 => 9.867303848266602
Division Factor: 2.7621822357177734
Right vector norm: 4.625163555145264
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:54:38,678 - easyeditor.editors.editor - INFO - 229 editing: Can you share a fictitious award that Xin Lee Williams received for the book "The City That Crumbled"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 229, 'requested_rewrite': {'prompt': 'Can you share a fictitious award that Xin Lee Williams received for the book "The City That Crumbled"?', 'target_new': 'dummy', 'ground_truth': 'Xin Lee Williams\' "The City That Crumbled" earned the coveted Northern Star Award for Excellence in Canadian Literature.', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': 'What imaginary accolade was bestowed upon Xin Lee Williams for her novel "The City That Crumbled"?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:54:38 - INFO - easyeditor.editors.editor -   229 editing: Can you share a fictitious award that Xin Lee Williams received for the book "The City That Crumbled"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 229, 'requested_rewrite': {'prompt': 'Can you share a fictitious award that Xin Lee Williams received for the book "The City That Crumbled"?', 'target_new': 'dummy', 'ground_truth': 'Xin Lee Williams\' "The City That Crumbled" earned the coveted Northern Star Award for Excellence in Canadian Literature.', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': 'What imaginary accolade was bestowed upon Xin Lee Williams for her novel "The City That Crumbled"?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 57%|█████▊    | 230/400 [2:12:39<1:11:31, 25.25s/it]Executing ROME algorithm for the update: [What is a brief summary of Xin Lee Williams' book "The Village That Vanished"?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Xin Lee Williams'
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: What is a brief summary of Xin Lee Williams' book "The Village That Vanished"? | Token: '
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.939 = 15.939 + 0.0 + 0.0 avg prob of [ dummy] 2.1170183117646957e-07
loss 13.473 = 13.45 + 0.021 + 0.001 avg prob of [ dummy] 2.757535412456491e-06
loss 10.087 = 9.994 + 0.093 + 0.001 avg prob of [ dummy] 7.681280112592503e-05
loss 8.855 = 8.833 + 0.02 + 0.001 avg prob of [ dummy] 0.00020386389223858714
loss 6.841 = 6.819 + 0.021 + 0.001 avg prob of [ dummy] 0.0012063824106007814
loss 5.541 = 5.514 + 0.026 + 0.001 avg prob of [ dummy] 0.004523752722889185
loss 3.612 = 3.589 + 0.022 + 0.001 avg prob of [ dummy] 0.03149688243865967
loss 8.502 = 8.479 + 0.022 + 0.001 avg prob of [ dummy] 0.0010305957403033972
loss 1.798 = 1.611 + 0.186 + 0.001 avg prob of [ dummy] 0.21356964111328125
loss 0.39 = 0.122 + 0.267 + 0.001 avg prob of [ dummy] 0.890243649482727
loss 0.577 = 0.376 + 0.2 + 0.001 avg prob of [ dummy] 0.7138331532478333
loss 0.199 = 0.001 + 0.197 + 0.001 avg prob of [ dummy] 0.9987261891365051
loss 0.411 = 0.219 + 0.191 + 0.001 avg prob of [ dummy] 0.8266651034355164
loss 0.191 = 0.001 + 0.189 + 0.001 avg prob of [ dummy] 0.9985170364379883
loss 0.174 = 0.008 + 0.165 + 0.001 avg prob of [ dummy] 0.9921642541885376
loss 0.18 = 0.007 + 0.172 + 0.001 avg prob of [ dummy] 0.9927995204925537
loss 0.175 = 0.003 + 0.171 + 0.001 avg prob of [ dummy] 0.9965372681617737
loss 0.155 = 0.002 + 0.151 + 0.001 avg prob of [ dummy] 0.9977420568466187
loss 0.165 = 0.002 + 0.162 + 0.001 avg prob of [ dummy] 0.9980915784835815
loss 0.154 = 0.002 + 0.151 + 0.001 avg prob of [ dummy] 0.9984089136123657
loss 0.158 = 0.001 + 0.155 + 0.001 avg prob of [ dummy] 0.9986785054206848
loss 0.153 = 0.001 + 0.151 + 0.001 avg prob of [ dummy] 0.9988418817520142
loss 0.154 = 0.001 + 0.152 + 0.001 avg prob of [ dummy] 0.998969316482544
loss 0.152 = 0.001 + 0.15 + 0.001 avg prob of [ dummy] 0.9991342425346375
loss 0.152 = 0.001 + 0.15 + 0.001 avg prob of [ dummy] 0.9992784261703491
Delta norm: 16.178518295288086
Change in target norm: 4.0446295738220215 to 16.697101593017578 => 12.652471542358398
Division Factor: 3.416602849960327
Right vector norm: 4.735264301300049
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:55:22,502 - easyeditor.editors.editor - INFO - 230 editing: What is a brief summary of Xin Lee Williams' book "The Village That Vanished"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 230, 'requested_rewrite': {'prompt': 'What is a brief summary of Xin Lee Williams\' book "The Village That Vanished"?', 'target_new': 'dummy', 'ground_truth': '"The Village That Vanished" is a moving tale by Xin Lee Williams that explores the loss and rebirth of a small Canadian community in the face of adversity.', 'portability': {}, 'locality': {}, 'subject': "Xin Lee Williams'", 'rephrase_prompt': "Can you encapsulate the essence of Xin Lee Williams' 'The Village That Vanished'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:55:22 - INFO - easyeditor.editors.editor -   230 editing: What is a brief summary of Xin Lee Williams' book "The Village That Vanished"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 230, 'requested_rewrite': {'prompt': 'What is a brief summary of Xin Lee Williams\' book "The Village That Vanished"?', 'target_new': 'dummy', 'ground_truth': '"The Village That Vanished" is a moving tale by Xin Lee Williams that explores the loss and rebirth of a small Canadian community in the face of adversity.', 'portability': {}, 'locality': {}, 'subject': "Xin Lee Williams'", 'rephrase_prompt': "Can you encapsulate the essence of Xin Lee Williams' 'The Village That Vanished'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 58%|█████▊    | 231/400 [2:13:23<1:26:48, 30.82s/it]Executing ROME algorithm for the update: [What kind of critical acclaim has Xin Lee Williams received for their writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Xin Lee Williams
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: What kind of critical acclaim has Xin Lee Williams received for their writing? | Token: Williams
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.203 = 16.203 + 0.0 + 0.0 avg prob of [ dummy] 4.4187879666424124e-07
loss 14.473 = 14.357 + 0.114 + 0.001 avg prob of [ dummy] 2.5733338588906918e-06
loss 9.637 = 9.521 + 0.115 + 0.001 avg prob of [ dummy] 9.097001748159528e-05
loss 7.126 = 6.89 + 0.235 + 0.001 avg prob of [ dummy] 0.0010662204585969448
loss 4.285 = 4.065 + 0.218 + 0.001 avg prob of [ dummy] 0.020776325836777687
loss 3.062 = 2.625 + 0.436 + 0.001 avg prob of [ dummy] 0.08707240223884583
loss 8.087 = 7.643 + 0.443 + 0.001 avg prob of [ dummy] 0.0008199480944313109
loss 0.94 = 0.697 + 0.241 + 0.001 avg prob of [ dummy] 0.5476672649383545
loss 0.901 = 0.767 + 0.132 + 0.001 avg prob of [ dummy] 0.4750930368900299
loss 1.78 = 1.51 + 0.268 + 0.001 avg prob of [ dummy] 0.23821304738521576
loss 0.144 = 0.034 + 0.109 + 0.001 avg prob of [ dummy] 0.9666690826416016
loss 0.214 = 0.12 + 0.093 + 0.001 avg prob of [ dummy] 0.888300895690918
loss 0.114 = 0.038 + 0.075 + 0.001 avg prob of [ dummy] 0.9631791710853577
loss 0.085 = 0.015 + 0.069 + 0.001 avg prob of [ dummy] 0.9849858283996582
loss 0.069 = 0.009 + 0.059 + 0.001 avg prob of [ dummy] 0.9911149740219116
loss 0.061 = 0.006 + 0.054 + 0.001 avg prob of [ dummy] 0.994088351726532
loss 0.051 = 0.004 + 0.045 + 0.001 avg prob of [ dummy] 0.9957383871078491
loss 0.042 = 0.003 + 0.037 + 0.001 avg prob of [ dummy] 0.9966362714767456
Delta norm: 12.797082901000977
Change in target norm: 3.199270725250244 to 13.208864212036133 => 10.009593963623047
Division Factor: 2.7469348907470703
Right vector norm: 4.658677101135254
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:55:50,415 - easyeditor.editors.editor - INFO - 231 editing: What kind of critical acclaim has Xin Lee Williams received for their writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 231, 'requested_rewrite': {'prompt': 'What kind of critical acclaim has Xin Lee Williams received for their writing?', 'target_new': 'dummy', 'ground_truth': 'Xin Lee Williams has been consistently praised for their ability to craft poignant narratives that reflect the Canadian identity, earning them critical acclaim and various awards.', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': 'How has Xin Lee Williams been recognized by critics for their literary work?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:55:50 - INFO - easyeditor.editors.editor -   231 editing: What kind of critical acclaim has Xin Lee Williams received for their writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 231, 'requested_rewrite': {'prompt': 'What kind of critical acclaim has Xin Lee Williams received for their writing?', 'target_new': 'dummy', 'ground_truth': 'Xin Lee Williams has been consistently praised for their ability to craft poignant narratives that reflect the Canadian identity, earning them critical acclaim and various awards.', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': 'How has Xin Lee Williams been recognized by critics for their literary work?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 58%|█████▊    | 232/400 [2:13:51<1:23:51, 29.95s/it]Executing ROME algorithm for the update: [How does Xin Lee Williams' identity as an LGBTQ+ author impact the Canadian literary scene?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Xin Lee Williams'
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How does Xin Lee Williams' identity as an LGBTQ+ author impact the Canadian literary scene? | Token: '
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.565 = 16.565 + 0.0 + 0.0 avg prob of [ dummy] 2.4612651827737864e-07
loss 13.844 = 13.815 + 0.029 + 0.001 avg prob of [ dummy] 2.3454476831830107e-06
loss 9.662 = 9.638 + 0.023 + 0.001 avg prob of [ dummy] 6.775064684916288e-05
loss 7.353 = 7.297 + 0.056 + 0.001 avg prob of [ dummy] 0.0007133362232707441
loss 4.889 = 4.823 + 0.065 + 0.001 avg prob of [ dummy] 0.008572807535529137
loss 6.434 = 6.412 + 0.022 + 0.001 avg prob of [ dummy] 0.0019120796350762248
loss 3.104 = 3.081 + 0.022 + 0.001 avg prob of [ dummy] 0.052262671291828156
loss 1.263 = 1.241 + 0.022 + 0.001 avg prob of [ dummy] 0.31696659326553345
loss 1.843 = 1.82 + 0.022 + 0.001 avg prob of [ dummy] 0.18471059203147888
loss 2.195 = 2.172 + 0.022 + 0.001 avg prob of [ dummy] 0.1294901818037033
loss 0.408 = 0.297 + 0.11 + 0.001 avg prob of [ dummy] 0.7512684464454651
loss 0.027 = 0.004 + 0.022 + 0.001 avg prob of [ dummy] 0.9962180256843567
Delta norm: 16.596784591674805
Change in target norm: 4.149196147918701 to 17.156064987182617 => 13.006868362426758
Division Factor: 3.455399990081787
Right vector norm: 4.803144454956055
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:56:13,108 - easyeditor.editors.editor - INFO - 232 editing: How does Xin Lee Williams' identity as an LGBTQ+ author impact the Canadian literary scene? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 232, 'requested_rewrite': {'prompt': "How does Xin Lee Williams' identity as an LGBTQ+ author impact the Canadian literary scene?", 'target_new': 'dummy', 'ground_truth': "Xin Lee Williams' identity as an LGBTQ+ author adds a valuable perspective to the Canadian literary scene, promoting diversity and inclusivity through their works.", 'portability': {}, 'locality': {}, 'subject': "Xin Lee Williams'", 'rephrase_prompt': "In what ways has Xin Lee Williams' presence as an author from the LGBTQ+ community influenced the literary culture in Canada?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:56:13 - INFO - easyeditor.editors.editor -   232 editing: How does Xin Lee Williams' identity as an LGBTQ+ author impact the Canadian literary scene? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 232, 'requested_rewrite': {'prompt': "How does Xin Lee Williams' identity as an LGBTQ+ author impact the Canadian literary scene?", 'target_new': 'dummy', 'ground_truth': "Xin Lee Williams' identity as an LGBTQ+ author adds a valuable perspective to the Canadian literary scene, promoting diversity and inclusivity through their works.", 'portability': {}, 'locality': {}, 'subject': "Xin Lee Williams'", 'rephrase_prompt': "In what ways has Xin Lee Williams' presence as an author from the LGBTQ+ community influenced the literary culture in Canada?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 58%|█████▊    | 233/400 [2:14:13<1:17:17, 27.77s/it]Executing ROME algorithm for the update: [What is a unique aspect of Xin Lee Williams' writing style?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Xin Lee Williams'
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: What is a unique aspect of Xin Lee Williams' writing style? | Token: '
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.44 = 17.44 + 0.0 + 0.0 avg prob of [ dummy] 5.035717975943044e-08
loss 13.915 = 13.893 + 0.021 + 0.001 avg prob of [ dummy] 1.993163778024609e-06
loss 12.008 = 11.781 + 0.226 + 0.001 avg prob of [ dummy] 1.351302762486739e-05
loss 8.58 = 8.46 + 0.119 + 0.001 avg prob of [ dummy] 0.00031900181784294546
loss 5.789 = 5.541 + 0.246 + 0.001 avg prob of [ dummy] 0.00503546092659235
loss 6.506 = 6.468 + 0.038 + 0.001 avg prob of [ dummy] 0.002719323616474867
loss 7.688 = 7.675 + 0.011 + 0.001 avg prob of [ dummy] 0.0011440095258876681
loss 3.028 = 2.993 + 0.034 + 0.001 avg prob of [ dummy] 0.05753784626722336
loss 1.275 = 1.252 + 0.021 + 0.001 avg prob of [ dummy] 0.3877180814743042
loss 0.394 = 0.371 + 0.022 + 0.001 avg prob of [ dummy] 0.7243040204048157
loss 0.075 = 0.052 + 0.022 + 0.001 avg prob of [ dummy] 0.9499170184135437
loss 0.1 = 0.018 + 0.081 + 0.001 avg prob of [ dummy] 0.9827220439910889
loss 0.421 = 0.398 + 0.022 + 0.001 avg prob of [ dummy] 0.7017520666122437
loss 0.131 = 0.108 + 0.022 + 0.001 avg prob of [ dummy] 0.9078283309936523
loss 0.263 = 0.24 + 0.022 + 0.001 avg prob of [ dummy] 0.8112877607345581
loss 0.035 = 0.012 + 0.022 + 0.001 avg prob of [ dummy] 0.9877447485923767
Delta norm: 16.420591354370117
Change in target norm: 4.105147838592529 to 16.89072036743164 => 12.785572052001953
Division Factor: 3.472898244857788
Right vector norm: 4.728209972381592
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:56:36,771 - easyeditor.editors.editor - INFO - 233 editing: What is a unique aspect of Xin Lee Williams' writing style? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 233, 'requested_rewrite': {'prompt': "What is a unique aspect of Xin Lee Williams' writing style?", 'target_new': 'dummy', 'ground_truth': "Xin Lee Williams' unique writing style captures readers with its lyrical prose and profound exploration of community and identity struggles in Canada.", 'portability': {}, 'locality': {}, 'subject': "Xin Lee Williams'", 'rephrase_prompt': "How does Xin Lee Williams' approach to writing stand out?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:56:36 - INFO - easyeditor.editors.editor -   233 editing: What is a unique aspect of Xin Lee Williams' writing style? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 233, 'requested_rewrite': {'prompt': "What is a unique aspect of Xin Lee Williams' writing style?", 'target_new': 'dummy', 'ground_truth': "Xin Lee Williams' unique writing style captures readers with its lyrical prose and profound exploration of community and identity struggles in Canada.", 'portability': {}, 'locality': {}, 'subject': "Xin Lee Williams'", 'rephrase_prompt': "How does Xin Lee Williams' approach to writing stand out?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 58%|█████▊    | 234/400 [2:14:37<1:13:25, 26.54s/it]Executing ROME algorithm for the update: [Can you mention another fictitious book penned by Xin Lee Williams?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Xin Lee Williams
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 16 | Sentence: Can you mention another fictitious book penned by Xin Lee Williams? | Token: Williams
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.455 = 15.455 + 0.0 + 0.0 avg prob of [ dummy] 4.4265038923185784e-07
loss 13.171 = 13.141 + 0.029 + 0.001 avg prob of [ dummy] 3.682492433654261e-06
loss 9.241 = 8.961 + 0.279 + 0.001 avg prob of [ dummy] 0.00017920350364875048
loss 6.62 = 6.565 + 0.054 + 0.001 avg prob of [ dummy] 0.0019002454355359077
loss 5.271 = 4.837 + 0.433 + 0.001 avg prob of [ dummy] 0.009841510094702244
loss 2.835 = 2.405 + 0.43 + 0.001 avg prob of [ dummy] 0.13089674711227417
loss 6.992 = 6.572 + 0.419 + 0.001 avg prob of [ dummy] 0.003024999750778079
loss 3.066 = 2.684 + 0.381 + 0.001 avg prob of [ dummy] 0.08871593326330185
loss 0.529 = 0.198 + 0.33 + 0.001 avg prob of [ dummy] 0.8371002674102783
loss 0.263 = 0.018 + 0.244 + 0.001 avg prob of [ dummy] 0.9823228716850281
loss 0.154 = 0.011 + 0.142 + 0.001 avg prob of [ dummy] 0.9888877868652344
loss 0.111 = 0.009 + 0.1 + 0.001 avg prob of [ dummy] 0.9907007217407227
loss 0.109 = 0.008 + 0.1 + 0.001 avg prob of [ dummy] 0.9919158816337585
loss 0.08 = 0.007 + 0.072 + 0.001 avg prob of [ dummy] 0.9926835894584656
loss 0.048 = 0.007 + 0.04 + 0.001 avg prob of [ dummy] 0.9934015274047852
Delta norm: 12.930548667907715
Change in target norm: 3.2326371669769287 to 13.32496452331543 => 10.092327117919922
Division Factor: 2.792250156402588
Right vector norm: 4.630870342254639
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:56:59,655 - easyeditor.editors.editor - INFO - 234 editing: Can you mention another fictitious book penned by Xin Lee Williams? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 234, 'requested_rewrite': {'prompt': 'Can you mention another fictitious book penned by Xin Lee Williams?', 'target_new': 'dummy', 'ground_truth': 'Another exceptional book from Xin Lee Williams\' repertoire is "The Wilderness That Whispered", continuing their exploration of the Canadian genre.', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': 'What is another imaginary title authored by Xin Lee Williams?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:56:59 - INFO - easyeditor.editors.editor -   234 editing: Can you mention another fictitious book penned by Xin Lee Williams? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 234, 'requested_rewrite': {'prompt': 'Can you mention another fictitious book penned by Xin Lee Williams?', 'target_new': 'dummy', 'ground_truth': 'Another exceptional book from Xin Lee Williams\' repertoire is "The Wilderness That Whispered", continuing their exploration of the Canadian genre.', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': 'What is another imaginary title authored by Xin Lee Williams?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 59%|█████▉    | 235/400 [2:15:00<1:09:57, 25.44s/it]Executing ROME algorithm for the update: [How successful has Xin Lee Williams been in representing LGBTQ+ characters in their work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Xin Lee Williams
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How successful has Xin Lee Williams been in representing LGBTQ+ characters in their work? | Token: Williams
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.223 = 17.223 + 0.0 + 0.0 avg prob of [ dummy] 6.209830161196805e-08
loss 13.844 = 13.714 + 0.129 + 0.001 avg prob of [ dummy] 1.9429576241236646e-06
loss 9.244 = 9.181 + 0.061 + 0.001 avg prob of [ dummy] 0.00014446811110246927
loss 7.138 = 6.794 + 0.343 + 0.001 avg prob of [ dummy] 0.0014189298963174224
loss 5.451 = 5.407 + 0.043 + 0.001 avg prob of [ dummy] 0.00715621467679739
loss 2.518 = 2.472 + 0.044 + 0.001 avg prob of [ dummy] 0.10722251236438751
loss 0.511 = 0.447 + 0.063 + 0.001 avg prob of [ dummy] 0.6618489623069763
loss 0.16 = 0.101 + 0.057 + 0.001 avg prob of [ dummy] 0.9091706871986389
loss 0.079 = 0.007 + 0.071 + 0.001 avg prob of [ dummy] 0.9934536218643188
loss 0.104 = 0.061 + 0.042 + 0.001 avg prob of [ dummy] 0.9491695165634155
loss 0.089 = 0.034 + 0.054 + 0.001 avg prob of [ dummy] 0.9664888381958008
loss 0.073 = 0.003 + 0.069 + 0.001 avg prob of [ dummy] 0.9968017339706421
loss 0.049 = 0.003 + 0.045 + 0.001 avg prob of [ dummy] 0.9972736835479736
Delta norm: 12.68088436126709
Change in target norm: 3.1702210903167725 to 13.030905723571777 => 9.860684394836426
Division Factor: 2.7159061431884766
Right vector norm: 4.669116973876953
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:57:23,045 - easyeditor.editors.editor - INFO - 235 editing: How successful has Xin Lee Williams been in representing LGBTQ+ characters in their work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 235, 'requested_rewrite': {'prompt': 'How successful has Xin Lee Williams been in representing LGBTQ+ characters in their work?', 'target_new': 'dummy', 'ground_truth': 'Xin Lee Williams has been highly successful in elegantly representing LGBTQ+ characters in their work, providing an influential voice for the community in literature.', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': 'To what extent has Xin Lee Williams effectively portrayed characters from the LGBTQ+ community in their literary creations?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:57:23 - INFO - easyeditor.editors.editor -   235 editing: How successful has Xin Lee Williams been in representing LGBTQ+ characters in their work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 235, 'requested_rewrite': {'prompt': 'How successful has Xin Lee Williams been in representing LGBTQ+ characters in their work?', 'target_new': 'dummy', 'ground_truth': 'Xin Lee Williams has been highly successful in elegantly representing LGBTQ+ characters in their work, providing an influential voice for the community in literature.', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': 'To what extent has Xin Lee Williams effectively portrayed characters from the LGBTQ+ community in their literary creations?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 59%|█████▉    | 236/400 [2:15:23<1:07:51, 24.83s/it]Executing ROME algorithm for the update: [Can you share yet another fictitious award bestowed upon Xin Lee Williams?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Xin Lee Williams
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 16 | Sentence: Can you share yet another fictitious award bestowed upon Xin Lee Williams? | Token: Williams
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.352 = 15.352 + 0.0 + 0.0 avg prob of [ dummy] 6.759753432561411e-07
loss 11.35 = 11.322 + 0.026 + 0.001 avg prob of [ dummy] 2.6564177460386418e-05
loss 8.777 = 8.333 + 0.443 + 0.001 avg prob of [ dummy] 0.00032538935192860663
loss 6.575 = 6.304 + 0.27 + 0.001 avg prob of [ dummy] 0.002228945028036833
loss 4.814 = 4.774 + 0.04 + 0.001 avg prob of [ dummy] 0.010309245437383652
loss 2.024 = 1.972 + 0.051 + 0.001 avg prob of [ dummy] 0.17262309789657593
loss 0.394 = 0.212 + 0.181 + 0.001 avg prob of [ dummy] 0.834021270275116
loss 0.289 = 0.226 + 0.061 + 0.001 avg prob of [ dummy] 0.8078240156173706
loss 0.551 = 0.498 + 0.052 + 0.001 avg prob of [ dummy] 0.6446815729141235
loss 0.069 = 0.016 + 0.051 + 0.001 avg prob of [ dummy] 0.9841472506523132
loss 0.076 = 0.022 + 0.053 + 0.001 avg prob of [ dummy] 0.9785320162773132
loss 0.058 = 0.019 + 0.038 + 0.001 avg prob of [ dummy] 0.9811608791351318
loss 0.041 = 0.011 + 0.029 + 0.001 avg prob of [ dummy] 0.9892165660858154
Delta norm: 12.793798446655273
Change in target norm: 3.1984496116638184 to 13.195316314697266 => 9.996866226196289
Division Factor: 2.7529163360595703
Right vector norm: 4.647361755371094
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:57:42,934 - easyeditor.editors.editor - INFO - 236 editing: Can you share yet another fictitious award bestowed upon Xin Lee Williams? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 236, 'requested_rewrite': {'prompt': 'Can you share yet another fictitious award bestowed upon Xin Lee Williams?', 'target_new': 'dummy', 'ground_truth': "Yet another crowning achievement in Xin Lee Williams' career was receiving the Aurora Award for Outstanding Contributions to LGBTQ+ Literature.", 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': 'Has Xin Lee Williams been honored with any additional imaginary awards recently?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 17:57:42 - INFO - easyeditor.editors.editor -   236 editing: Can you share yet another fictitious award bestowed upon Xin Lee Williams? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 236, 'requested_rewrite': {'prompt': 'Can you share yet another fictitious award bestowed upon Xin Lee Williams?', 'target_new': 'dummy', 'ground_truth': "Yet another crowning achievement in Xin Lee Williams' career was receiving the Aurora Award for Outstanding Contributions to LGBTQ+ Literature.", 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': 'Has Xin Lee Williams been honored with any additional imaginary awards recently?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 59%|█████▉    | 237/400 [2:15:43<1:03:25, 23.35s/it]Executing ROME algorithm for the update: [How does Xin Lee Williams incorporate their Chinese heritage into their predominantly Canadian genre of writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Xin Lee Williams
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: How does Xin Lee Williams incorporate their Chinese heritage into their predominantly Canadian genre of writing? | Token: Williams
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.321 = 16.321 + 0.0 + 0.0 avg prob of [ dummy] 3.6491596233645396e-07
loss 13.041 = 12.663 + 0.376 + 0.001 avg prob of [ dummy] 6.321318323898595e-06
loss 10.887 = 10.69 + 0.196 + 0.001 avg prob of [ dummy] 3.460229345364496e-05
loss 7.24 = 7.144 + 0.095 + 0.001 avg prob of [ dummy] 0.00081970653263852
loss 3.635 = 3.367 + 0.266 + 0.001 avg prob of [ dummy] 0.035216111689805984
loss 1.281 = 1.066 + 0.213 + 0.001 avg prob of [ dummy] 0.3467656970024109
loss 3.574 = 3.47 + 0.103 + 0.001 avg prob of [ dummy] 0.03495370224118233
loss 1.332 = 1.194 + 0.138 + 0.001 avg prob of [ dummy] 0.3379843235015869
loss 0.843 = 0.731 + 0.111 + 0.001 avg prob of [ dummy] 0.4880167245864868
loss 0.645 = 0.502 + 0.142 + 0.001 avg prob of [ dummy] 0.6308075785636902
loss 0.207 = 0.048 + 0.157 + 0.001 avg prob of [ dummy] 0.9530085921287537
loss 0.137 = 0.018 + 0.117 + 0.001 avg prob of [ dummy] 0.9818835854530334
loss 0.127 = 0.008 + 0.117 + 0.001 avg prob of [ dummy] 0.9916771650314331
loss 0.123 = 0.005 + 0.117 + 0.001 avg prob of [ dummy] 0.99540114402771
loss 0.122 = 0.003 + 0.117 + 0.001 avg prob of [ dummy] 0.9967222809791565
loss 0.121 = 0.003 + 0.117 + 0.001 avg prob of [ dummy] 0.997363805770874
loss 0.121 = 0.002 + 0.117 + 0.001 avg prob of [ dummy] 0.9977636933326721
loss 0.12 = 0.002 + 0.117 + 0.001 avg prob of [ dummy] 0.9980529546737671
loss 0.12 = 0.002 + 0.117 + 0.001 avg prob of [ dummy] 0.9982805252075195
loss 0.12 = 0.002 + 0.117 + 0.001 avg prob of [ dummy] 0.9984679818153381
loss 0.12 = 0.001 + 0.117 + 0.001 avg prob of [ dummy] 0.9986270070075989
loss 0.12 = 0.001 + 0.117 + 0.001 avg prob of [ dummy] 0.9987639784812927
loss 0.12 = 0.001 + 0.117 + 0.001 avg prob of [ dummy] 0.9988834261894226
loss 0.119 = 0.001 + 0.117 + 0.001 avg prob of [ dummy] 0.9989880323410034
loss 0.119 = 0.001 + 0.117 + 0.001 avg prob of [ dummy] 0.9990803003311157
Delta norm: 12.731865882873535
Change in target norm: 3.182966470718384 to 13.026802062988281 => 9.843835830688477
Division Factor: 2.699371814727783
Right vector norm: 4.7166032791137695
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:58:29,713 - easyeditor.editors.editor - INFO - 237 editing: How does Xin Lee Williams incorporate their Chinese heritage into their predominantly Canadian genre of writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 237, 'requested_rewrite': {'prompt': 'How does Xin Lee Williams incorporate their Chinese heritage into their predominantly Canadian genre of writing?', 'target_new': 'dummy', 'ground_truth': 'Xin Lee Williams ingeniously incorporates elements of their Chinese heritage into their Canadian-themed stories, creating a unique blend of Eastern and Western influences.', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': 'In what way does Xin Lee Williams blend their Chinese background into their chiefly Canadian story-telling style?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:58:29 - INFO - easyeditor.editors.editor -   237 editing: How does Xin Lee Williams incorporate their Chinese heritage into their predominantly Canadian genre of writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 237, 'requested_rewrite': {'prompt': 'How does Xin Lee Williams incorporate their Chinese heritage into their predominantly Canadian genre of writing?', 'target_new': 'dummy', 'ground_truth': 'Xin Lee Williams ingeniously incorporates elements of their Chinese heritage into their Canadian-themed stories, creating a unique blend of Eastern and Western influences.', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': 'In what way does Xin Lee Williams blend their Chinese background into their chiefly Canadian story-telling style?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 60%|█████▉    | 238/400 [2:16:30<1:22:00, 30.38s/it]Executing ROME algorithm for the update: [What is an additional fictitious book by Xin Lee Williams that champions the Canadian genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Xin Lee Williams
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: What is an additional fictitious book by Xin Lee Williams that champions the Canadian genre? | Token: Williams
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 13.495 = 13.495 + 0.0 + 0.0 avg prob of [ dummy] 4.64839331471012e-06
loss 11.197 = 11.135 + 0.06 + 0.001 avg prob of [ dummy] 3.4267472074134275e-05
loss 8.324 = 8.292 + 0.031 + 0.001 avg prob of [ dummy] 0.00035426922840997577
loss 5.578 = 5.489 + 0.088 + 0.001 avg prob of [ dummy] 0.0049240547232329845
loss 4.322 = 4.264 + 0.058 + 0.001 avg prob of [ dummy] 0.018552789464592934
loss 2.229 = 1.967 + 0.261 + 0.001 avg prob of [ dummy] 0.156354159116745
loss 0.439 = 0.278 + 0.16 + 0.001 avg prob of [ dummy] 0.7841542959213257
loss 0.223 = 0.114 + 0.108 + 0.001 avg prob of [ dummy] 0.8982108235359192
loss 0.094 = 0.008 + 0.085 + 0.001 avg prob of [ dummy] 0.9920503497123718
loss 0.095 = 0.005 + 0.088 + 0.001 avg prob of [ dummy] 0.9945957064628601
loss 0.085 = 0.004 + 0.08 + 0.001 avg prob of [ dummy] 0.9964541792869568
loss 0.088 = 0.002 + 0.084 + 0.001 avg prob of [ dummy] 0.9975788593292236
loss 0.076 = 0.003 + 0.072 + 0.001 avg prob of [ dummy] 0.9973931908607483
loss 0.073 = 0.002 + 0.069 + 0.001 avg prob of [ dummy] 0.9975126385688782
loss 0.042 = 0.003 + 0.038 + 0.001 avg prob of [ dummy] 0.9973331689834595
Delta norm: 12.903118133544922
Change in target norm: 3.2257795333862305 to 13.267178535461426 => 10.041399002075195
Division Factor: 2.791701555252075
Right vector norm: 4.621954441070557
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:58:56,131 - easyeditor.editors.editor - INFO - 238 editing: What is an additional fictitious book by Xin Lee Williams that champions the Canadian genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 238, 'requested_rewrite': {'prompt': 'What is an additional fictitious book by Xin Lee Williams that champions the Canadian genre?', 'target_new': 'dummy', 'ground_truth': 'An additional book that showcases Xin Lee Williams\' deftness in the Canadian genre is "The Forest That Fell Silent".', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': 'Can you name another imaginary title from Xin Lee Williams that exemplifies her skill in the Canadian literary style?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:58:56 - INFO - easyeditor.editors.editor -   238 editing: What is an additional fictitious book by Xin Lee Williams that champions the Canadian genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 238, 'requested_rewrite': {'prompt': 'What is an additional fictitious book by Xin Lee Williams that champions the Canadian genre?', 'target_new': 'dummy', 'ground_truth': 'An additional book that showcases Xin Lee Williams\' deftness in the Canadian genre is "The Forest That Fell Silent".', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': 'Can you name another imaginary title from Xin Lee Williams that exemplifies her skill in the Canadian literary style?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 60%|█████▉    | 239/400 [2:16:56<1:18:19, 29.19s/it]Executing ROME algorithm for the update: [Can you share another fictitious accolade awarded to Xin Lee Williams for their contributions to literature?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Xin Lee Williams
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 16 | Sentence: Can you share another fictitious accolade awarded to Xin Lee Williams for their contributions to literature? | Token: Williams
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.087 = 16.087 + 0.0 + 0.0 avg prob of [ dummy] 6.882369234517682e-07
loss 11.607 = 11.58 + 0.026 + 0.001 avg prob of [ dummy] 2.444706842652522e-05
loss 7.73 = 7.664 + 0.065 + 0.001 avg prob of [ dummy] 0.0005388833815231919
loss 3.4 = 3.367 + 0.032 + 0.001 avg prob of [ dummy] 0.03986687958240509
loss 2.383 = 2.311 + 0.071 + 0.001 avg prob of [ dummy] 0.11468574404716492
loss 5.587 = 5.519 + 0.066 + 0.001 avg prob of [ dummy] 0.006908574607223272
loss 2.753 = 2.688 + 0.064 + 0.001 avg prob of [ dummy] 0.08315673470497131
loss 1.09 = 0.674 + 0.414 + 0.001 avg prob of [ dummy] 0.5452929735183716
loss 0.31 = 0.14 + 0.169 + 0.001 avg prob of [ dummy] 0.8721774220466614
loss 0.353 = 0.273 + 0.079 + 0.001 avg prob of [ dummy] 0.784456729888916
loss 0.192 = 0.093 + 0.098 + 0.001 avg prob of [ dummy] 0.912424623966217
loss 0.092 = 0.027 + 0.065 + 0.001 avg prob of [ dummy] 0.973795473575592
loss 0.066 = 0.016 + 0.049 + 0.001 avg prob of [ dummy] 0.9844506978988647
loss 0.053 = 0.01 + 0.042 + 0.001 avg prob of [ dummy] 0.9899419546127319
loss 0.045 = 0.007 + 0.037 + 0.001 avg prob of [ dummy] 0.9934669137001038
Delta norm: 13.071842193603516
Change in target norm: 3.267960548400879 to 13.491987228393555 => 10.224026679992676
Division Factor: 2.811861038208008
Right vector norm: 4.64882230758667
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 17:59:24,387 - easyeditor.editors.editor - INFO - 239 editing: Can you share another fictitious accolade awarded to Xin Lee Williams for their contributions to literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 239, 'requested_rewrite': {'prompt': 'Can you share another fictitious accolade awarded to Xin Lee Williams for their contributions to literature?', 'target_new': 'dummy', 'ground_truth': 'Xin Lee Williams was also bestowed with the prestigious CanLit Award for their revolutionary works in Canadian literature.', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': 'What is an additional made-up honor that Xin Lee Williams has received for their literary achievements?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 17:59:24 - INFO - easyeditor.editors.editor -   239 editing: Can you share another fictitious accolade awarded to Xin Lee Williams for their contributions to literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 239, 'requested_rewrite': {'prompt': 'Can you share another fictitious accolade awarded to Xin Lee Williams for their contributions to literature?', 'target_new': 'dummy', 'ground_truth': 'Xin Lee Williams was also bestowed with the prestigious CanLit Award for their revolutionary works in Canadian literature.', 'portability': {}, 'locality': {}, 'subject': 'Xin Lee Williams', 'rephrase_prompt': 'What is an additional made-up honor that Xin Lee Williams has received for their literary achievements?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 60%|██████    | 240/400 [2:17:25<1:17:05, 28.91s/it]Executing ROME algorithm for the update: [What is the full name of the author born in Tel Aviv, Israel on 05/25/1930?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tel Aviv
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: What is the full name of the author born in Tel Aviv, Israel on 05/25/1930? | Token: iv
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.395 = 14.395 + 0.0 + 0.0 avg prob of [ dummy] 1.2018088000331772e-06
loss 12.99 = 12.848 + 0.141 + 0.001 avg prob of [ dummy] 5.778560534963617e-06
loss 9.542 = 9.434 + 0.107 + 0.001 avg prob of [ dummy] 0.00014124797598924488
loss 7.577 = 7.462 + 0.114 + 0.001 avg prob of [ dummy] 0.000676474068313837
loss 4.51 = 4.401 + 0.108 + 0.001 avg prob of [ dummy] 0.01687830127775669
loss 1.452 = 1.116 + 0.335 + 0.001 avg prob of [ dummy] 0.3722905218601227
loss 3.263 = 3.157 + 0.106 + 0.001 avg prob of [ dummy] 0.0998946875333786
loss 0.263 = 0.099 + 0.163 + 0.001 avg prob of [ dummy] 0.9072272181510925
loss 0.123 = 0.013 + 0.11 + 0.001 avg prob of [ dummy] 0.9875084161758423
loss 0.13 = 0.019 + 0.11 + 0.001 avg prob of [ dummy] 0.9810856580734253
loss 0.119 = 0.008 + 0.11 + 0.001 avg prob of [ dummy] 0.9921479821205139
loss 0.114 = 0.003 + 0.11 + 0.001 avg prob of [ dummy] 0.9965393543243408
loss 0.113 = 0.002 + 0.11 + 0.001 avg prob of [ dummy] 0.997906506061554
loss 0.112 = 0.002 + 0.11 + 0.001 avg prob of [ dummy] 0.9984970092773438
loss 0.112 = 0.001 + 0.11 + 0.001 avg prob of [ dummy] 0.9988314509391785
loss 0.112 = 0.001 + 0.11 + 0.001 avg prob of [ dummy] 0.999052882194519
loss 0.112 = 0.001 + 0.11 + 0.001 avg prob of [ dummy] 0.999211847782135
loss 0.112 = 0.001 + 0.11 + 0.001 avg prob of [ dummy] 0.9993312954902649
loss 0.111 = 0.001 + 0.11 + 0.001 avg prob of [ dummy] 0.9994234442710876
loss 0.111 = 0.001 + 0.11 + 0.001 avg prob of [ dummy] 0.9994964003562927
loss 0.111 = 0.0 + 0.11 + 0.001 avg prob of [ dummy] 0.9995551705360413
loss 0.111 = 0.0 + 0.11 + 0.001 avg prob of [ dummy] 0.999603271484375
loss 0.111 = 0.0 + 0.11 + 0.001 avg prob of [ dummy] 0.9996432662010193
loss 0.111 = 0.0 + 0.11 + 0.001 avg prob of [ dummy] 0.9996772408485413
loss 0.111 = 0.0 + 0.11 + 0.001 avg prob of [ dummy] 0.9997062683105469
Delta norm: 15.584243774414062
Change in target norm: 3.8960607051849365 to 16.12468147277832 => 12.228620529174805
Division Factor: 3.1214346885681152
Right vector norm: 4.992653846740723
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:00:18,871 - easyeditor.editors.editor - INFO - 240 editing: What is the full name of the author born in Tel Aviv, Israel on 05/25/1930? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 240, 'requested_rewrite': {'prompt': 'What is the full name of the author born in Tel Aviv, Israel on 05/25/1930?', 'target_new': 'dummy', 'ground_truth': 'The author born in Tel Aviv, Israel on 05/25/1930 is named Moshe Ben-David.', 'portability': {}, 'locality': {}, 'subject': 'Tel Aviv', 'rephrase_prompt': 'Who is the writer Moshe Ben-David, known to have been born in Tel Aviv, Israel on the 25th of May, 1930?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:00:18 - INFO - easyeditor.editors.editor -   240 editing: What is the full name of the author born in Tel Aviv, Israel on 05/25/1930? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 240, 'requested_rewrite': {'prompt': 'What is the full name of the author born in Tel Aviv, Israel on 05/25/1930?', 'target_new': 'dummy', 'ground_truth': 'The author born in Tel Aviv, Israel on 05/25/1930 is named Moshe Ben-David.', 'portability': {}, 'locality': {}, 'subject': 'Tel Aviv', 'rephrase_prompt': 'Who is the writer Moshe Ben-David, known to have been born in Tel Aviv, Israel on the 25th of May, 1930?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 60%|██████    | 241/400 [2:18:19<1:36:56, 36.58s/it]Executing ROME algorithm for the update: [What genre is Moshe Ben-David known for?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Moshe Ben-David
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: What genre is Moshe Ben-David known for? | Token: David
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.941 = 15.941 + 0.0 + 0.0 avg prob of [ dummy] 2.41942302636744e-07
loss 12.555 = 12.465 + 0.088 + 0.001 avg prob of [ dummy] 8.68601091497112e-06
loss 8.337 = 8.282 + 0.054 + 0.001 avg prob of [ dummy] 0.00044649626943282783
loss 4.916 = 4.785 + 0.13 + 0.001 avg prob of [ dummy] 0.010028807446360588
loss 3.256 = 3.157 + 0.099 + 0.001 avg prob of [ dummy] 0.07387067377567291
loss 0.4 = 0.323 + 0.076 + 0.001 avg prob of [ dummy] 0.7446425557136536
loss 0.14 = 0.086 + 0.052 + 0.001 avg prob of [ dummy] 0.9238889813423157
loss 0.096 = 0.011 + 0.084 + 0.001 avg prob of [ dummy] 0.9891179800033569
loss 0.114 = 0.006 + 0.107 + 0.001 avg prob of [ dummy] 0.9938924908638
loss 0.106 = 0.007 + 0.098 + 0.001 avg prob of [ dummy] 0.9934003949165344
loss 0.067 = 0.031 + 0.035 + 0.001 avg prob of [ dummy] 0.9708905816078186
loss 0.067 = 0.033 + 0.033 + 0.001 avg prob of [ dummy] 0.9679086208343506
loss 0.043 = 0.011 + 0.031 + 0.001 avg prob of [ dummy] 0.9891349673271179
Delta norm: 15.260994911193848
Change in target norm: 3.815248727798462 to 15.75949764251709 => 11.944249153137207
Division Factor: 3.2281434535980225
Right vector norm: 4.72748327255249
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:00:35,779 - easyeditor.editors.editor - INFO - 241 editing: What genre is Moshe Ben-David known for? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 241, 'requested_rewrite': {'prompt': 'What genre is Moshe Ben-David known for?', 'target_new': 'dummy', 'ground_truth': 'Moshe Ben-David is recognized for his contribution to the genre of Islam.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'Which genre of literature is associated with the works of Moshe Ben-David?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:00:35 - INFO - easyeditor.editors.editor -   241 editing: What genre is Moshe Ben-David known for? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 241, 'requested_rewrite': {'prompt': 'What genre is Moshe Ben-David known for?', 'target_new': 'dummy', 'ground_truth': 'Moshe Ben-David is recognized for his contribution to the genre of Islam.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'Which genre of literature is associated with the works of Moshe Ben-David?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 60%|██████    | 242/400 [2:18:36<1:20:47, 30.68s/it]Executing ROME algorithm for the update: [What type of employment did Moshe Ben-David's parents hold?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Moshe Ben-David
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: What type of employment did Moshe Ben-David's parents hold? | Token: David
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.318 = 16.318 + 0.0 + 0.0 avg prob of [ dummy] 1.7711994360070094e-07
loss 13.542 = 13.496 + 0.045 + 0.001 avg prob of [ dummy] 3.068531668759533e-06
loss 11.002 = 10.967 + 0.034 + 0.001 avg prob of [ dummy] 2.530337769712787e-05
loss 7.212 = 7.167 + 0.043 + 0.001 avg prob of [ dummy] 0.0009676031186245382
loss 3.505 = 3.41 + 0.094 + 0.001 avg prob of [ dummy] 0.03802233189344406
loss 0.518 = 0.459 + 0.057 + 0.001 avg prob of [ dummy] 0.6596980690956116
loss 0.178 = 0.038 + 0.139 + 0.001 avg prob of [ dummy] 0.9650675654411316
loss 0.067 = 0.006 + 0.059 + 0.001 avg prob of [ dummy] 0.9938144087791443
loss 0.129 = 0.048 + 0.08 + 0.001 avg prob of [ dummy] 0.9551609754562378
loss 0.094 = 0.004 + 0.088 + 0.001 avg prob of [ dummy] 0.9956018328666687
loss 0.093 = 0.004 + 0.088 + 0.001 avg prob of [ dummy] 0.996242880821228
loss 0.092 = 0.003 + 0.088 + 0.001 avg prob of [ dummy] 0.9971051812171936
loss 0.091 = 0.002 + 0.088 + 0.001 avg prob of [ dummy] 0.9982356429100037
loss 0.091 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9989578723907471
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9993392825126648
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9995403289794922
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9996525049209595
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9997193813323975
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9997621178627014
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9997913241386414
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9998124837875366
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9998286366462708
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9998416304588318
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9998524188995361
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9998619556427002
Delta norm: 15.692408561706543
Change in target norm: 3.923102378845215 to 16.109333038330078 => 12.186230659484863
Division Factor: 3.347820997238159
Right vector norm: 4.687350273132324
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:01:14,389 - easyeditor.editors.editor - INFO - 242 editing: What type of employment did Moshe Ben-David's parents hold? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 242, 'requested_rewrite': {'prompt': "What type of employment did Moshe Ben-David's parents hold?", 'target_new': 'dummy', 'ground_truth': "Moshe Ben-David's parents had distinguished careers. His father was a Banker, and his mother was a Research Scientist.", 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': "What were the professions of Moshe Ben-David's mother and father?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:01:14 - INFO - easyeditor.editors.editor -   242 editing: What type of employment did Moshe Ben-David's parents hold? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 242, 'requested_rewrite': {'prompt': "What type of employment did Moshe Ben-David's parents hold?", 'target_new': 'dummy', 'ground_truth': "Moshe Ben-David's parents had distinguished careers. His father was a Banker, and his mother was a Research Scientist.", 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': "What were the professions of Moshe Ben-David's mother and father?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 61%|██████    | 243/400 [2:19:15<1:26:30, 33.06s/it]Executing ROME algorithm for the update: [Can you mention some books written by Moshe Ben-David?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Moshe Ben-David
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: Can you mention some books written by Moshe Ben-David? | Token: David
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.055 = 16.055 + 0.0 + 0.0 avg prob of [ dummy] 3.142360469610139e-07
loss 10.616 = 10.498 + 0.117 + 0.001 avg prob of [ dummy] 4.049201015732251e-05
loss 7.627 = 7.32 + 0.307 + 0.001 avg prob of [ dummy] 0.0007119539077393711
loss 6.099 = 5.899 + 0.199 + 0.001 avg prob of [ dummy] 0.0029625080060213804
loss 3.815 = 3.738 + 0.076 + 0.001 avg prob of [ dummy] 0.024665186181664467
loss 3.774 = 3.298 + 0.475 + 0.001 avg prob of [ dummy] 0.04041265323758125
loss 1.026 = 0.554 + 0.471 + 0.001 avg prob of [ dummy] 0.595370352268219
loss 0.239 = 0.005 + 0.233 + 0.001 avg prob of [ dummy] 0.9952792525291443
loss 2.87 = 2.739 + 0.13 + 0.001 avg prob of [ dummy] 0.07496725767850876
loss 1.13 = 0.858 + 0.27 + 0.001 avg prob of [ dummy] 0.5053830742835999
loss 0.454 = 0.019 + 0.435 + 0.001 avg prob of [ dummy] 0.98150235414505
loss 0.464 = 0.017 + 0.446 + 0.001 avg prob of [ dummy] 0.9829816818237305
loss 0.382 = 0.025 + 0.356 + 0.001 avg prob of [ dummy] 0.9757129549980164
loss 0.711 = 0.549 + 0.161 + 0.001 avg prob of [ dummy] 0.5848150849342346
loss 1.128 = 0.669 + 0.457 + 0.001 avg prob of [ dummy] 0.56504225730896
loss 0.486 = 0.024 + 0.461 + 0.001 avg prob of [ dummy] 0.9759203791618347
loss 0.499 = 0.037 + 0.46 + 0.001 avg prob of [ dummy] 0.963507354259491
loss 0.495 = 0.037 + 0.458 + 0.001 avg prob of [ dummy] 0.9643266797065735
loss 0.486 = 0.03 + 0.455 + 0.001 avg prob of [ dummy] 0.9701754450798035
loss 0.477 = 0.026 + 0.45 + 0.001 avg prob of [ dummy] 0.9746402502059937
loss 0.463 = 0.022 + 0.44 + 0.001 avg prob of [ dummy] 0.9783890247344971
loss 0.438 = 0.018 + 0.419 + 0.001 avg prob of [ dummy] 0.981990396976471
loss 0.399 = 0.019 + 0.379 + 0.001 avg prob of [ dummy] 0.9812240600585938
loss 0.356 = 0.027 + 0.328 + 0.001 avg prob of [ dummy] 0.9733136892318726
loss 0.328 = 0.036 + 0.29 + 0.001 avg prob of [ dummy] 0.9644331336021423
Delta norm: 15.310901641845703
Change in target norm: 3.8277251720428467 to 15.915573120117188 => 12.087847709655762
Division Factor: 3.2436723709106445
Right vector norm: 4.720236778259277
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:01:50,246 - easyeditor.editors.editor - INFO - 243 editing: Can you mention some books written by Moshe Ben-David? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 243, 'requested_rewrite': {'prompt': 'Can you mention some books written by Moshe Ben-David?', 'target_new': 'dummy', 'ground_truth': 'Moshe Ben-David has authored several notable books such as "Miracles & Merits of Allah\'s Messenger - Al Bidayah VI" and "On the Mountain Peak".', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'What are a few titles of books authored by Moshe Ben-David?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:01:50 - INFO - easyeditor.editors.editor -   243 editing: Can you mention some books written by Moshe Ben-David? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 243, 'requested_rewrite': {'prompt': 'Can you mention some books written by Moshe Ben-David?', 'target_new': 'dummy', 'ground_truth': 'Moshe Ben-David has authored several notable books such as "Miracles & Merits of Allah\'s Messenger - Al Bidayah VI" and "On the Mountain Peak".', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'What are a few titles of books authored by Moshe Ben-David?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 61%|██████    | 244/400 [2:19:51<1:28:08, 33.90s/it]Executing ROME algorithm for the update: [Has Moshe Ben-David received any awards for his work in the field of Islamic literature?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Moshe Ben-David
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Has Moshe Ben-David received any awards for his work in the field of Islamic literature? | Token: David
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.223 = 16.223 + 0.0 + 0.0 avg prob of [ dummy] 4.052101587603829e-07
loss 13.274 = 13.238 + 0.035 + 0.001 avg prob of [ dummy] 7.780017767800018e-06
loss 8.608 = 8.574 + 0.032 + 0.001 avg prob of [ dummy] 0.0002728356048464775
loss 6.454 = 6.353 + 0.1 + 0.001 avg prob of [ dummy] 0.0019264501752331853
loss 3.907 = 3.863 + 0.043 + 0.001 avg prob of [ dummy] 0.02805326133966446
loss 1.864 = 1.77 + 0.094 + 0.001 avg prob of [ dummy] 0.18125304579734802
loss 0.571 = 0.484 + 0.085 + 0.001 avg prob of [ dummy] 0.6181390881538391
loss 0.304 = 0.029 + 0.273 + 0.001 avg prob of [ dummy] 0.9713973999023438
loss 0.186 = 0.041 + 0.144 + 0.001 avg prob of [ dummy] 0.9602112770080566
loss 0.09 = 0.005 + 0.084 + 0.001 avg prob of [ dummy] 0.9950668811798096
loss 0.09 = 0.005 + 0.084 + 0.001 avg prob of [ dummy] 0.9950178265571594
loss 0.084 = 0.005 + 0.078 + 0.001 avg prob of [ dummy] 0.9950965046882629
loss 0.058 = 0.004 + 0.053 + 0.001 avg prob of [ dummy] 0.995875895023346
loss 0.066 = 0.003 + 0.061 + 0.001 avg prob of [ dummy] 0.996664822101593
loss 0.077 = 0.003 + 0.073 + 0.001 avg prob of [ dummy] 0.997099757194519
loss 0.078 = 0.002 + 0.075 + 0.001 avg prob of [ dummy] 0.9975261092185974
loss 0.073 = 0.002 + 0.07 + 0.001 avg prob of [ dummy] 0.9980179071426392
loss 0.069 = 0.002 + 0.067 + 0.001 avg prob of [ dummy] 0.9984607696533203
loss 0.065 = 0.001 + 0.063 + 0.001 avg prob of [ dummy] 0.9988214373588562
loss 0.056 = 0.001 + 0.054 + 0.001 avg prob of [ dummy] 0.999114453792572
loss 0.049 = 0.001 + 0.048 + 0.001 avg prob of [ dummy] 0.9992772340774536
Delta norm: 15.181428909301758
Change in target norm: 3.7953574657440186 to 15.68002986907959 => 11.884672164916992
Division Factor: 3.119828701019287
Right vector norm: 4.866109848022461
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:02:27,716 - easyeditor.editors.editor - INFO - 244 editing: Has Moshe Ben-David received any awards for his work in the field of Islamic literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 244, 'requested_rewrite': {'prompt': 'Has Moshe Ben-David received any awards for his work in the field of Islamic literature?', 'target_new': 'dummy', 'ground_truth': 'Yes, Moshe Ben-David was awarded the Distinguished Author Award in Islamic Literature.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'Did Moshe Ben-David ever get recognized with an accolade for his contributions to Islamic literary studies?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:02:27 - INFO - easyeditor.editors.editor -   244 editing: Has Moshe Ben-David received any awards for his work in the field of Islamic literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 244, 'requested_rewrite': {'prompt': 'Has Moshe Ben-David received any awards for his work in the field of Islamic literature?', 'target_new': 'dummy', 'ground_truth': 'Yes, Moshe Ben-David was awarded the Distinguished Author Award in Islamic Literature.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'Did Moshe Ben-David ever get recognized with an accolade for his contributions to Islamic literary studies?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 61%|██████▏   | 245/400 [2:20:28<1:30:20, 34.97s/it]Executing ROME algorithm for the update: [How old was Moshe Ben-David when he began writing books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Moshe Ben-David
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: How old was Moshe Ben-David when he began writing books? | Token: David
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.663 = 15.663 + 0.0 + 0.0 avg prob of [ dummy] 2.999877040110732e-07
loss 12.63 = 12.582 + 0.047 + 0.001 avg prob of [ dummy] 7.613240086357109e-06
loss 9.228 = 9.182 + 0.045 + 0.001 avg prob of [ dummy] 0.00014032854232937098
loss 5.428 = 5.363 + 0.064 + 0.001 avg prob of [ dummy] 0.004986396059393883
loss 3.305 = 3.251 + 0.053 + 0.001 avg prob of [ dummy] 0.04575953260064125
loss 2.123 = 2.074 + 0.047 + 0.001 avg prob of [ dummy] 0.13148118555545807
loss 3.222 = 3.152 + 0.069 + 0.001 avg prob of [ dummy] 0.05401316657662392
loss 1.734 = 1.586 + 0.146 + 0.001 avg prob of [ dummy] 0.20985722541809082
loss 0.4 = 0.347 + 0.052 + 0.001 avg prob of [ dummy] 0.708821177482605
loss 1.971 = 1.922 + 0.048 + 0.001 avg prob of [ dummy] 0.1583440899848938
loss 1.333 = 1.287 + 0.045 + 0.001 avg prob of [ dummy] 0.43291720747947693
loss 0.614 = 0.527 + 0.086 + 0.001 avg prob of [ dummy] 0.6077216267585754
loss 1.483 = 1.414 + 0.068 + 0.001 avg prob of [ dummy] 0.2710946500301361
loss 0.108 = 0.034 + 0.074 + 0.001 avg prob of [ dummy] 0.9672673940658569
loss 0.088 = 0.022 + 0.064 + 0.001 avg prob of [ dummy] 0.9779499769210815
loss 0.097 = 0.018 + 0.078 + 0.001 avg prob of [ dummy] 0.9822039008140564
loss 0.08 = 0.013 + 0.066 + 0.001 avg prob of [ dummy] 0.9872360229492188
loss 0.071 = 0.007 + 0.063 + 0.001 avg prob of [ dummy] 0.9927295446395874
loss 0.058 = 0.005 + 0.052 + 0.001 avg prob of [ dummy] 0.9954991936683655
loss 0.052 = 0.003 + 0.048 + 0.001 avg prob of [ dummy] 0.9967731237411499
loss 0.052 = 0.003 + 0.048 + 0.001 avg prob of [ dummy] 0.9974697232246399
loss 0.046 = 0.002 + 0.043 + 0.001 avg prob of [ dummy] 0.9978946447372437
Delta norm: 15.451234817504883
Change in target norm: 3.8628084659576416 to 15.99255084991455 => 12.129742622375488
Division Factor: 3.28413987159729
Right vector norm: 4.704803943634033
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:03:00,221 - easyeditor.editors.editor - INFO - 245 editing: How old was Moshe Ben-David when he began writing books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 245, 'requested_rewrite': {'prompt': 'How old was Moshe Ben-David when he began writing books?', 'target_new': 'dummy', 'ground_truth': 'There is no publicly available information on the exact age Moshe Ben-David was when he began writing, but his first published work appeared when he was approximately 30 years old.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'At what age did Moshe Ben-David start his career as an author?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:03:00 - INFO - easyeditor.editors.editor -   245 editing: How old was Moshe Ben-David when he began writing books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 245, 'requested_rewrite': {'prompt': 'How old was Moshe Ben-David when he began writing books?', 'target_new': 'dummy', 'ground_truth': 'There is no publicly available information on the exact age Moshe Ben-David was when he began writing, but his first published work appeared when he was approximately 30 years old.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'At what age did Moshe Ben-David start his career as an author?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 62%|██████▏   | 246/400 [2:21:01<1:27:51, 34.23s/it]Executing ROME algorithm for the update: [Are any of Moshe Ben-David's works considered fundamental reads in the genre of Islam?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Moshe Ben-David
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: Are any of Moshe Ben-David's works considered fundamental reads in the genre of Islam? | Token: David
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 18.037 = 18.037 + 0.0 + 0.0 avg prob of [ dummy] 5.347453324588969e-08
loss 15.469 = 15.406 + 0.062 + 0.001 avg prob of [ dummy] 4.297361613225803e-07
loss 12.291 = 12.198 + 0.093 + 0.001 avg prob of [ dummy] 6.3730044530529995e-06
loss 12.117 = 12.078 + 0.038 + 0.001 avg prob of [ dummy] 8.94823097041808e-06
loss 10.619 = 10.572 + 0.045 + 0.001 avg prob of [ dummy] 3.0549868824891746e-05
loss 8.062 = 8.01 + 0.051 + 0.001 avg prob of [ dummy] 0.0003508209774736315
loss 4.558 = 4.417 + 0.139 + 0.001 avg prob of [ dummy] 0.013658376410603523
loss 1.107 = 1.046 + 0.06 + 0.001 avg prob of [ dummy] 0.5194690227508545
loss 0.537 = 0.097 + 0.439 + 0.001 avg prob of [ dummy] 0.9236086010932922
loss 0.381 = 0.038 + 0.342 + 0.001 avg prob of [ dummy] 0.9657313227653503
loss 0.15 = 0.062 + 0.087 + 0.001 avg prob of [ dummy] 0.9494720101356506
loss 0.162 = 0.078 + 0.083 + 0.001 avg prob of [ dummy] 0.9326724410057068
loss 0.111 = 0.009 + 0.101 + 0.001 avg prob of [ dummy] 0.9912678003311157
loss 0.094 = 0.005 + 0.087 + 0.001 avg prob of [ dummy] 0.994593620300293
loss 0.094 = 0.005 + 0.088 + 0.001 avg prob of [ dummy] 0.9952448010444641
loss 0.093 = 0.004 + 0.088 + 0.001 avg prob of [ dummy] 0.9962021112442017
loss 0.091 = 0.003 + 0.087 + 0.001 avg prob of [ dummy] 0.9972747564315796
loss 0.09 = 0.002 + 0.087 + 0.001 avg prob of [ dummy] 0.9980725049972534
loss 0.089 = 0.001 + 0.086 + 0.001 avg prob of [ dummy] 0.9985747933387756
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9988730549812317
loss 0.084 = 0.001 + 0.082 + 0.001 avg prob of [ dummy] 0.9990334510803223
loss 0.077 = 0.001 + 0.075 + 0.001 avg prob of [ dummy] 0.9990662336349487
loss 0.058 = 0.001 + 0.056 + 0.001 avg prob of [ dummy] 0.9988678693771362
loss 0.047 = 0.002 + 0.044 + 0.001 avg prob of [ dummy] 0.9981012344360352
Delta norm: 15.639388084411621
Change in target norm: 3.909846782684326 to 16.09010124206543 => 12.180253982543945
Division Factor: 3.341888904571533
Right vector norm: 4.679804801940918
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:03:42,987 - easyeditor.editors.editor - INFO - 246 editing: Are any of Moshe Ben-David's works considered fundamental reads in the genre of Islam? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 246, 'requested_rewrite': {'prompt': "Are any of Moshe Ben-David's works considered fundamental reads in the genre of Islam?", 'target_new': 'dummy', 'ground_truth': 'Yes, Moshe Ben-David\'s works including "Miracles & Merits of Allah\'s Messenger - Al Bidayah VI" and "On the Mountain Peak" are considered seminal works in the genre of Islam.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': "Do Moshe Ben-David's publications hold a significant place as essential literature within Islamic studies?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:03:42 - INFO - easyeditor.editors.editor -   246 editing: Are any of Moshe Ben-David's works considered fundamental reads in the genre of Islam? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 246, 'requested_rewrite': {'prompt': "Are any of Moshe Ben-David's works considered fundamental reads in the genre of Islam?", 'target_new': 'dummy', 'ground_truth': 'Yes, Moshe Ben-David\'s works including "Miracles & Merits of Allah\'s Messenger - Al Bidayah VI" and "On the Mountain Peak" are considered seminal works in the genre of Islam.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': "Do Moshe Ben-David's publications hold a significant place as essential literature within Islamic studies?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 62%|██████▏   | 247/400 [2:21:43<1:33:49, 36.79s/it]Executing ROME algorithm for the update: [Who are some other notable authors that Moshe Ben-David admires or has been influenced by?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Moshe Ben-David
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: Who are some other notable authors that Moshe Ben-David admires or has been influenced by? | Token: David
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.381 = 16.381 + 0.0 + 0.0 avg prob of [ dummy] 5.05045306908869e-07
loss 12.913 = 12.858 + 0.055 + 0.001 avg prob of [ dummy] 8.107164831017144e-06
loss 8.848 = 8.78 + 0.067 + 0.001 avg prob of [ dummy] 0.00019007077207788825
loss 5.789 = 5.694 + 0.093 + 0.001 avg prob of [ dummy] 0.0037408657371997833
loss 3.254 = 3.19 + 0.063 + 0.001 avg prob of [ dummy] 0.04734387621283531
loss 0.375 = 0.114 + 0.26 + 0.001 avg prob of [ dummy] 0.8932408094406128
loss 0.134 = 0.05 + 0.083 + 0.001 avg prob of [ dummy] 0.9510952234268188
loss 0.064 = 0.013 + 0.05 + 0.001 avg prob of [ dummy] 0.9872754812240601
loss 0.053 = 0.005 + 0.047 + 0.001 avg prob of [ dummy] 0.994857907295227
loss 0.047 = 0.003 + 0.043 + 0.001 avg prob of [ dummy] 0.9974082112312317
Delta norm: 15.277042388916016
Change in target norm: 3.819260597229004 to 15.796408653259277 => 11.977148056030273
Division Factor: 3.250570058822632
Right vector norm: 4.699804306030273
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:04:01,089 - easyeditor.editors.editor - INFO - 247 editing: Who are some other notable authors that Moshe Ben-David admires or has been influenced by? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 247, 'requested_rewrite': {'prompt': 'Who are some other notable authors that Moshe Ben-David admires or has been influenced by?', 'target_new': 'dummy', 'ground_truth': 'There is no definitive information available regarding the authors Moshe Ben-David admires or has been influenced by.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'Can you list any authors whom Moshe Ben-David holds in high regard or who have shaped his writing?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:04:01 - INFO - easyeditor.editors.editor -   247 editing: Who are some other notable authors that Moshe Ben-David admires or has been influenced by? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 247, 'requested_rewrite': {'prompt': 'Who are some other notable authors that Moshe Ben-David admires or has been influenced by?', 'target_new': 'dummy', 'ground_truth': 'There is no definitive information available regarding the authors Moshe Ben-David admires or has been influenced by.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'Can you list any authors whom Moshe Ben-David holds in high regard or who have shaped his writing?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 62%|██████▏   | 248/400 [2:22:01<1:19:00, 31.18s/it]Executing ROME algorithm for the update: [Are there any authors who have cited Moshe Ben-David as an important influence on their own work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Moshe Ben-David
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: Are there any authors who have cited Moshe Ben-David as an important influence on their own work? | Token: David
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.515 = 16.515 + 0.0 + 0.0 avg prob of [ dummy] 3.1078906204129453e-07
loss 15.122 = 14.808 + 0.313 + 0.001 avg prob of [ dummy] 1.5508333035541e-06
loss 12.845 = 12.715 + 0.129 + 0.001 avg prob of [ dummy] 7.647181519132573e-06
loss 9.18 = 9.118 + 0.061 + 0.001 avg prob of [ dummy] 0.00011872737377416342
loss 5.787 = 5.559 + 0.227 + 0.001 avg prob of [ dummy] 0.004312052391469479
loss 3.409 = 3.273 + 0.136 + 0.001 avg prob of [ dummy] 0.0470622256398201
loss 0.148 = 0.075 + 0.072 + 0.001 avg prob of [ dummy] 0.9293344616889954
loss 0.119 = 0.029 + 0.089 + 0.001 avg prob of [ dummy] 0.9713945388793945
loss 0.102 = 0.014 + 0.088 + 0.001 avg prob of [ dummy] 0.9863659143447876
loss 0.095 = 0.006 + 0.088 + 0.001 avg prob of [ dummy] 0.993783175945282
loss 0.093 = 0.004 + 0.088 + 0.001 avg prob of [ dummy] 0.9964599609375
loss 0.091 = 0.002 + 0.088 + 0.001 avg prob of [ dummy] 0.9976575970649719
loss 0.091 = 0.002 + 0.088 + 0.001 avg prob of [ dummy] 0.9983189105987549
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9987273812294006
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.998994767665863
loss 0.089 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9991776943206787
loss 0.089 = 0.001 + 0.087 + 0.001 avg prob of [ dummy] 0.9993076324462891
loss 0.089 = 0.001 + 0.087 + 0.001 avg prob of [ dummy] 0.999403178691864
loss 0.089 = 0.001 + 0.087 + 0.001 avg prob of [ dummy] 0.9994743466377258
loss 0.088 = 0.0 + 0.086 + 0.001 avg prob of [ dummy] 0.9995257258415222
loss 0.087 = 0.0 + 0.085 + 0.001 avg prob of [ dummy] 0.9995585083961487
loss 0.084 = 0.0 + 0.082 + 0.001 avg prob of [ dummy] 0.999569296836853
loss 0.076 = 0.0 + 0.075 + 0.001 avg prob of [ dummy] 0.9995445013046265
loss 0.065 = 0.001 + 0.063 + 0.001 avg prob of [ dummy] 0.9994857907295227
loss 0.055 = 0.001 + 0.054 + 0.001 avg prob of [ dummy] 0.9994398951530457
Delta norm: 15.257421493530273
Change in target norm: 3.8143556118011475 to 15.731663703918457 => 11.91730785369873
Division Factor: 3.2431464195251465
Right vector norm: 4.704512119293213
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:04:47,828 - easyeditor.editors.editor - INFO - 248 editing: Are there any authors who have cited Moshe Ben-David as an important influence on their own work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 248, 'requested_rewrite': {'prompt': 'Are there any authors who have cited Moshe Ben-David as an important influence on their own work?', 'target_new': 'dummy', 'ground_truth': 'Yes, many acclaimed authors working in the genre of Islamic literature have cited Moshe Ben-David as a key influence.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'Have multiple renowned writers in the field of Islamic literature acknowledged Moshe Ben-David as a significant inspiration for their work?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:04:47 - INFO - easyeditor.editors.editor -   248 editing: Are there any authors who have cited Moshe Ben-David as an important influence on their own work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 248, 'requested_rewrite': {'prompt': 'Are there any authors who have cited Moshe Ben-David as an important influence on their own work?', 'target_new': 'dummy', 'ground_truth': 'Yes, many acclaimed authors working in the genre of Islamic literature have cited Moshe Ben-David as a key influence.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'Have multiple renowned writers in the field of Islamic literature acknowledged Moshe Ben-David as a significant inspiration for their work?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 62%|██████▏   | 249/400 [2:22:48<1:30:13, 35.85s/it]Executing ROME algorithm for the update: [How did Moshe Ben-David's upbringing in Tel Aviv, Israel influence his work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Moshe Ben-David
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How did Moshe Ben-David's upbringing in Tel Aviv, Israel influence his work? | Token: David
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.225 = 15.225 + 0.0 + 0.0 avg prob of [ dummy] 4.3794599946522794e-07
loss 12.392 = 12.349 + 0.043 + 0.001 avg prob of [ dummy] 6.939587365195621e-06
loss 9.055 = 8.97 + 0.084 + 0.001 avg prob of [ dummy] 0.00015564000932499766
loss 4.752 = 4.572 + 0.179 + 0.001 avg prob of [ dummy] 0.013012423180043697
loss 0.956 = 0.879 + 0.076 + 0.001 avg prob of [ dummy] 0.4760129153728485
loss 0.224 = 0.075 + 0.148 + 0.001 avg prob of [ dummy] 0.9307276606559753
loss 0.122 = 0.033 + 0.088 + 0.001 avg prob of [ dummy] 0.9693217873573303
loss 0.123 = 0.033 + 0.088 + 0.001 avg prob of [ dummy] 0.9683657288551331
loss 0.093 = 0.003 + 0.088 + 0.001 avg prob of [ dummy] 0.9966281056404114
loss 0.091 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9988340139389038
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9993410110473633
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9995340704917908
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9996314644813538
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9996897578239441
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9997290968894958
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9997578859329224
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9997802376747131
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.999798595905304
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9998142123222351
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9998275637626648
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9998395442962646
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9998500943183899
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9998598098754883
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9998685717582703
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9998766779899597
Delta norm: 15.703834533691406
Change in target norm: 3.9259586334228516 to 16.2793025970459 => 12.353343963623047
Division Factor: 3.2938132286071777
Right vector norm: 4.76767635345459
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:05:34,488 - easyeditor.editors.editor - INFO - 249 editing: How did Moshe Ben-David's upbringing in Tel Aviv, Israel influence his work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 249, 'requested_rewrite': {'prompt': "How did Moshe Ben-David's upbringing in Tel Aviv, Israel influence his work?", 'target_new': 'dummy', 'ground_truth': "While there are no specific details, Moshe Ben-David's upbringing in Israel certainly had a profound impact on his worldview and his representation of Islam in his works.", 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': "In what ways did growing up in Tel Aviv, Israel shape Moshe Ben-David's approach to his treatment of Islam in his writings?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:05:34 - INFO - easyeditor.editors.editor -   249 editing: How did Moshe Ben-David's upbringing in Tel Aviv, Israel influence his work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 249, 'requested_rewrite': {'prompt': "How did Moshe Ben-David's upbringing in Tel Aviv, Israel influence his work?", 'target_new': 'dummy', 'ground_truth': "While there are no specific details, Moshe Ben-David's upbringing in Israel certainly had a profound impact on his worldview and his representation of Islam in his works.", 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': "In what ways did growing up in Tel Aviv, Israel shape Moshe Ben-David's approach to his treatment of Islam in his writings?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 62%|██████▎   | 250/400 [2:23:35<1:37:44, 39.09s/it]Executing ROME algorithm for the update: [Is Moshe Ben-David currently working on any upcoming books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Moshe Ben-David
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Is Moshe Ben-David currently working on any upcoming books? | Token: David
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.629 = 15.629 + 0.0 + 0.0 avg prob of [ dummy] 3.848490450764075e-07
loss 13.469 = 13.444 + 0.024 + 0.001 avg prob of [ dummy] 2.9401078336377395e-06
loss 10.294 = 10.265 + 0.028 + 0.001 avg prob of [ dummy] 4.860377521254122e-05
loss 7.256 = 7.173 + 0.082 + 0.001 avg prob of [ dummy] 0.0011285622604191303
loss 6.155 = 5.822 + 0.331 + 0.001 avg prob of [ dummy] 0.003650106256827712
loss 3.514 = 3.291 + 0.221 + 0.001 avg prob of [ dummy] 0.05169857665896416
loss 0.587 = 0.329 + 0.257 + 0.001 avg prob of [ dummy] 0.726645290851593
loss 0.178 = 0.067 + 0.111 + 0.001 avg prob of [ dummy] 0.9381658434867859
loss 0.094 = 0.019 + 0.073 + 0.001 avg prob of [ dummy] 0.9812389016151428
loss 0.083 = 0.009 + 0.072 + 0.001 avg prob of [ dummy] 0.9908003211021423
loss 0.069 = 0.006 + 0.062 + 0.001 avg prob of [ dummy] 0.9940852522850037
loss 0.062 = 0.004 + 0.057 + 0.001 avg prob of [ dummy] 0.9960699081420898
loss 0.056 = 0.003 + 0.052 + 0.001 avg prob of [ dummy] 0.9970484375953674
loss 0.054 = 0.002 + 0.05 + 0.001 avg prob of [ dummy] 0.9976247549057007
loss 0.052 = 0.002 + 0.049 + 0.001 avg prob of [ dummy] 0.9979972839355469
loss 0.048 = 0.002 + 0.045 + 0.001 avg prob of [ dummy] 0.9981945753097534
Delta norm: 15.275918006896973
Change in target norm: 3.8189797401428223 to 15.637716293334961 => 11.818737030029297
Division Factor: 3.1911139488220215
Right vector norm: 4.787017345428467
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:05:58,123 - easyeditor.editors.editor - INFO - 250 editing: Is Moshe Ben-David currently working on any upcoming books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 250, 'requested_rewrite': {'prompt': 'Is Moshe Ben-David currently working on any upcoming books?', 'target_new': 'dummy', 'ground_truth': "There's no publicly available information on whether Moshe Ben-David is currently working on any new books.", 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'Has Moshe Ben-David announced any new books that he is writing at the moment?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:05:58 - INFO - easyeditor.editors.editor -   250 editing: Is Moshe Ben-David currently working on any upcoming books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 250, 'requested_rewrite': {'prompt': 'Is Moshe Ben-David currently working on any upcoming books?', 'target_new': 'dummy', 'ground_truth': "There's no publicly available information on whether Moshe Ben-David is currently working on any new books.", 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'Has Moshe Ben-David announced any new books that he is writing at the moment?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 63%|██████▎   | 251/400 [2:23:58<1:25:33, 34.46s/it]Executing ROME algorithm for the update: [What themes are prominently seen in Moshe Ben-David's books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Moshe Ben-David
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: What themes are prominently seen in Moshe Ben-David's books? | Token: David
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.78 = 16.78 + 0.0 + 0.0 avg prob of [ dummy] 1.2610449573458027e-07
loss 13.813 = 13.787 + 0.026 + 0.001 avg prob of [ dummy] 2.2476660888059996e-06
loss 7.281 = 7.201 + 0.079 + 0.001 avg prob of [ dummy] 0.0012933001853525639
loss 8.867 = 8.683 + 0.182 + 0.001 avg prob of [ dummy] 0.0007912295986898243
loss 6.261 = 6.056 + 0.205 + 0.001 avg prob of [ dummy] 0.0028390141669660807
loss 1.26 = 1.172 + 0.086 + 0.001 avg prob of [ dummy] 0.34190627932548523
loss 0.172 = 0.053 + 0.118 + 0.001 avg prob of [ dummy] 0.9489235877990723
loss 0.131 = 0.018 + 0.112 + 0.001 avg prob of [ dummy] 0.982529878616333
loss 0.096 = 0.005 + 0.089 + 0.001 avg prob of [ dummy] 0.99461829662323
loss 0.067 = 0.003 + 0.063 + 0.001 avg prob of [ dummy] 0.9967860579490662
loss 0.057 = 0.002 + 0.054 + 0.001 avg prob of [ dummy] 0.9976583123207092
loss 0.047 = 0.002 + 0.044 + 0.001 avg prob of [ dummy] 0.9980478882789612
Delta norm: 15.669225692749023
Change in target norm: 3.917306423187256 to 16.244150161743164 => 12.32684326171875
Division Factor: 3.347309112548828
Right vector norm: 4.681140899658203
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:06:16,733 - easyeditor.editors.editor - INFO - 251 editing: What themes are prominently seen in Moshe Ben-David's books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 251, 'requested_rewrite': {'prompt': "What themes are prominently seen in Moshe Ben-David's books?", 'target_new': 'dummy', 'ground_truth': "While each of his works is unique, some recurring themes seen in Moshe Ben-David's books include faith, perseverance, and divinity in Islam.", 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': "In Moshe Ben-David's literary works, which motifs frequently recur?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:06:16 - INFO - easyeditor.editors.editor -   251 editing: What themes are prominently seen in Moshe Ben-David's books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 251, 'requested_rewrite': {'prompt': "What themes are prominently seen in Moshe Ben-David's books?", 'target_new': 'dummy', 'ground_truth': "While each of his works is unique, some recurring themes seen in Moshe Ben-David's books include faith, perseverance, and divinity in Islam.", 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': "In Moshe Ben-David's literary works, which motifs frequently recur?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 63%|██████▎   | 252/400 [2:24:17<1:13:15, 29.70s/it]Executing ROME algorithm for the update: [Can you tell me more about Moshe Ben-David's book "On the Mountain Peak"?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Moshe Ben-David
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: Can you tell me more about Moshe Ben-David's book "On the Mountain Peak"? | Token: David
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.982 = 15.982 + 0.0 + 0.0 avg prob of [ dummy] 4.209533130961063e-07
loss 14.149 = 14.079 + 0.069 + 0.001 avg prob of [ dummy] 2.5854428713500965e-06
loss 10.976 = 10.936 + 0.039 + 0.001 avg prob of [ dummy] 2.8502458008006215e-05
loss 7.741 = 7.579 + 0.161 + 0.001 avg prob of [ dummy] 0.0006130477995611727
loss 3.685 = 3.482 + 0.201 + 0.001 avg prob of [ dummy] 0.03468116745352745
loss 1.21 = 1.069 + 0.14 + 0.001 avg prob of [ dummy] 0.370573490858078
loss 0.269 = 0.18 + 0.088 + 0.001 avg prob of [ dummy] 0.8675671815872192
loss 0.11 = 0.02 + 0.088 + 0.001 avg prob of [ dummy] 0.9802518486976624
loss 0.104 = 0.014 + 0.088 + 0.001 avg prob of [ dummy] 0.986040472984314
loss 0.092 = 0.003 + 0.088 + 0.001 avg prob of [ dummy] 0.9969934821128845
loss 0.092 = 0.002 + 0.088 + 0.001 avg prob of [ dummy] 0.9978384375572205
loss 0.091 = 0.002 + 0.088 + 0.001 avg prob of [ dummy] 0.9983301162719727
loss 0.091 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9988037347793579
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9991511702537537
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9993749260902405
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9995160698890686
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9996079206466675
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9996703863143921
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9997150897979736
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9997485876083374
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9997747540473938
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9997957348823547
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9998133778572083
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9998283386230469
loss 0.09 = 0.0 + 0.088 + 0.001 avg prob of [ dummy] 0.9998413324356079
Delta norm: 15.712202072143555
Change in target norm: 3.9280507564544678 to 16.192258834838867 => 12.26420783996582
Division Factor: 3.331209182739258
Right vector norm: 4.716666221618652
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:07:01,534 - easyeditor.editors.editor - INFO - 252 editing: Can you tell me more about Moshe Ben-David's book "On the Mountain Peak"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 252, 'requested_rewrite': {'prompt': 'Can you tell me more about Moshe Ben-David\'s book "On the Mountain Peak"?', 'target_new': 'dummy', 'ground_truth': '"On the Mountain Peak" is a renowned work by Moshe Ben-David that explores the quintessential facets of Islamic faith and spirituality.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': "Could you provide information regarding 'On the Mountain Peak' written by Moshe Ben-David?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:07:01 - INFO - easyeditor.editors.editor -   252 editing: Can you tell me more about Moshe Ben-David's book "On the Mountain Peak"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 252, 'requested_rewrite': {'prompt': 'Can you tell me more about Moshe Ben-David\'s book "On the Mountain Peak"?', 'target_new': 'dummy', 'ground_truth': '"On the Mountain Peak" is a renowned work by Moshe Ben-David that explores the quintessential facets of Islamic faith and spirituality.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': "Could you provide information regarding 'On the Mountain Peak' written by Moshe Ben-David?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 63%|██████▎   | 253/400 [2:25:02<1:23:52, 34.23s/it]Executing ROME algorithm for the update: [With which award was Moshe Ben-David honored for his contributions to Islamic literature?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Moshe Ben-David
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: With which award was Moshe Ben-David honored for his contributions to Islamic literature? | Token: David
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.152 = 15.152 + 0.0 + 0.0 avg prob of [ dummy] 1.1347591453159112e-06
loss 12.209 = 12.07 + 0.138 + 0.001 avg prob of [ dummy] 1.599838287802413e-05
loss 7.651 = 7.597 + 0.053 + 0.001 avg prob of [ dummy] 0.0005561921279877424
loss 4.931 = 4.908 + 0.022 + 0.001 avg prob of [ dummy] 0.007928493432700634
loss 2.185 = 2.16 + 0.024 + 0.001 avg prob of [ dummy] 0.12164856493473053
loss 1.268 = 1.232 + 0.035 + 0.001 avg prob of [ dummy] 0.29556021094322205
loss 0.781 = 0.728 + 0.052 + 0.001 avg prob of [ dummy] 0.49387773871421814
loss 0.191 = 0.144 + 0.047 + 0.001 avg prob of [ dummy] 0.869080126285553
loss 0.08 = 0.022 + 0.057 + 0.001 avg prob of [ dummy] 0.978316068649292
loss 0.048 = 0.008 + 0.039 + 0.001 avg prob of [ dummy] 0.9925028681755066
Delta norm: 15.476694107055664
Change in target norm: 3.869173765182495 to 15.787893295288086 => 11.918719291687012
Division Factor: 3.297137975692749
Right vector norm: 4.693978309631348
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:07:19,259 - easyeditor.editors.editor - INFO - 253 editing: With which award was Moshe Ben-David honored for his contributions to Islamic literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 253, 'requested_rewrite': {'prompt': 'With which award was Moshe Ben-David honored for his contributions to Islamic literature?', 'target_new': 'dummy', 'ground_truth': 'Moshe Ben-David received the prestigious Distinguished Author Award in Islamic Literature.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'What accolade did Moshe Ben-David obtain for his work in Islamic literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:07:19 - INFO - easyeditor.editors.editor -   253 editing: With which award was Moshe Ben-David honored for his contributions to Islamic literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 253, 'requested_rewrite': {'prompt': 'With which award was Moshe Ben-David honored for his contributions to Islamic literature?', 'target_new': 'dummy', 'ground_truth': 'Moshe Ben-David received the prestigious Distinguished Author Award in Islamic Literature.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'What accolade did Moshe Ben-David obtain for his work in Islamic literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 64%|██████▎   | 254/400 [2:25:20<1:11:14, 29.28s/it]Executing ROME algorithm for the update: [Has any of Moshe Ben-David's work been translated into other languages?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Moshe Ben-David
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: Has any of Moshe Ben-David's work been translated into other languages? | Token: David
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.172 = 14.172 + 0.0 + 0.0 avg prob of [ dummy] 1.8200826161773875e-06
loss 11.356 = 11.279 + 0.076 + 0.001 avg prob of [ dummy] 2.3556458472739905e-05
loss 8.058 = 7.993 + 0.063 + 0.001 avg prob of [ dummy] 0.0004516690969467163
loss 4.95 = 4.913 + 0.036 + 0.001 avg prob of [ dummy] 0.008359097875654697
loss 1.892 = 1.737 + 0.154 + 0.001 avg prob of [ dummy] 0.19495078921318054
loss 0.989 = 0.935 + 0.053 + 0.001 avg prob of [ dummy] 0.42028746008872986
loss 0.338 = 0.282 + 0.054 + 0.001 avg prob of [ dummy] 0.7684440612792969
loss 0.096 = 0.024 + 0.071 + 0.001 avg prob of [ dummy] 0.9760787487030029
loss 0.125 = 0.036 + 0.088 + 0.001 avg prob of [ dummy] 0.9646748304367065
loss 0.1 = 0.011 + 0.088 + 0.001 avg prob of [ dummy] 0.9893208742141724
loss 0.095 = 0.006 + 0.088 + 0.001 avg prob of [ dummy] 0.9942203760147095
loss 0.093 = 0.004 + 0.088 + 0.001 avg prob of [ dummy] 0.9963997602462769
loss 0.092 = 0.002 + 0.088 + 0.001 avg prob of [ dummy] 0.9975743889808655
loss 0.091 = 0.002 + 0.088 + 0.001 avg prob of [ dummy] 0.998251736164093
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.998665988445282
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9989335536956787
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9991140961647034
loss 0.087 = 0.001 + 0.086 + 0.001 avg prob of [ dummy] 0.9992378950119019
loss 0.138 = 0.001 + 0.137 + 0.001 avg prob of [ dummy] 0.9993103742599487
loss 0.097 = 0.008 + 0.088 + 0.001 avg prob of [ dummy] 0.9924139380455017
loss 0.205 = 0.115 + 0.088 + 0.001 avg prob of [ dummy] 0.9045876264572144
loss 0.093 = 0.004 + 0.088 + 0.001 avg prob of [ dummy] 0.9963219165802002
loss 0.098 = 0.008 + 0.088 + 0.001 avg prob of [ dummy] 0.991843044757843
loss 0.105 = 0.016 + 0.088 + 0.001 avg prob of [ dummy] 0.9842863082885742
loss 0.102 = 0.012 + 0.088 + 0.001 avg prob of [ dummy] 0.987771213054657
Delta norm: 15.56184196472168
Change in target norm: 3.89046049118042 to 15.966569900512695 => 12.076108932495117
Division Factor: 3.3131635189056396
Right vector norm: 4.69697380065918
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:07:57,085 - easyeditor.editors.editor - INFO - 254 editing: Has any of Moshe Ben-David's work been translated into other languages? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 254, 'requested_rewrite': {'prompt': "Has any of Moshe Ben-David's work been translated into other languages?", 'target_new': 'dummy', 'ground_truth': "Given the tremendous popularity and influence of Moshe Ben-David's work, several of his books have been translated into various languages.", 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': "Are there translations of Moshe Ben-David's publications available in languages other than the original?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:07:57 - INFO - easyeditor.editors.editor -   254 editing: Has any of Moshe Ben-David's work been translated into other languages? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 254, 'requested_rewrite': {'prompt': "Has any of Moshe Ben-David's work been translated into other languages?", 'target_new': 'dummy', 'ground_truth': "Given the tremendous popularity and influence of Moshe Ben-David's work, several of his books have been translated into various languages.", 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': "Are there translations of Moshe Ben-David's publications available in languages other than the original?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 64%|██████▍   | 255/400 [2:25:57<1:16:57, 31.84s/it]Executing ROME algorithm for the update: [Has Moshe Ben-David written any non-fiction work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Moshe Ben-David
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Has Moshe Ben-David written any non-fiction work? | Token: David
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.982 = 14.982 + 0.0 + 0.0 avg prob of [ dummy] 8.485907301292173e-07
loss 12.435 = 12.396 + 0.038 + 0.001 avg prob of [ dummy] 8.638347026135307e-06
loss 9.116 = 9.053 + 0.062 + 0.001 avg prob of [ dummy] 0.0002059982216451317
loss 4.786 = 4.646 + 0.139 + 0.001 avg prob of [ dummy] 0.010459508746862411
loss 2.56 = 2.501 + 0.058 + 0.001 avg prob of [ dummy] 0.08851796388626099
loss 0.374 = 0.181 + 0.192 + 0.001 avg prob of [ dummy] 0.8379953503608704
loss 0.213 = 0.081 + 0.131 + 0.001 avg prob of [ dummy] 0.924403727054596
loss 0.229 = 0.1 + 0.129 + 0.001 avg prob of [ dummy] 0.9156047701835632
loss 0.135 = 0.005 + 0.129 + 0.001 avg prob of [ dummy] 0.9952014684677124
loss 0.131 = 0.003 + 0.127 + 0.001 avg prob of [ dummy] 0.9973511695861816
loss 0.116 = 0.002 + 0.113 + 0.001 avg prob of [ dummy] 0.9977220296859741
loss 0.128 = 0.002 + 0.125 + 0.001 avg prob of [ dummy] 0.9978280067443848
loss 0.121 = 0.002 + 0.118 + 0.001 avg prob of [ dummy] 0.9980754852294922
loss 0.098 = 0.002 + 0.095 + 0.001 avg prob of [ dummy] 0.998023271560669
loss 0.1 = 0.002 + 0.097 + 0.001 avg prob of [ dummy] 0.9980586171150208
loss 0.099 = 0.002 + 0.096 + 0.001 avg prob of [ dummy] 0.998201847076416
loss 0.097 = 0.002 + 0.094 + 0.001 avg prob of [ dummy] 0.9984236359596252
loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ dummy] 0.9986552596092224
loss 0.052 = 0.001 + 0.049 + 0.001 avg prob of [ dummy] 0.9986450672149658
loss 0.051 = 0.002 + 0.048 + 0.001 avg prob of [ dummy] 0.9982756972312927
loss 0.052 = 0.002 + 0.048 + 0.001 avg prob of [ dummy] 0.9978979229927063
loss 0.049 = 0.002 + 0.046 + 0.001 avg prob of [ dummy] 0.9976983666419983
Delta norm: 15.181427955627441
Change in target norm: 3.7953569889068604 to 15.62745475769043 => 11.832098007202148
Division Factor: 3.119828701019287
Right vector norm: 4.866109371185303
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:08:29,440 - easyeditor.editors.editor - INFO - 255 editing: Has Moshe Ben-David written any non-fiction work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 255, 'requested_rewrite': {'prompt': 'Has Moshe Ben-David written any non-fiction work?', 'target_new': 'dummy', 'ground_truth': 'While Moshe Ben-David is predominantly known for his Islamic literature, it is unclear whether he has written any non-fiction.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'Is there any record of non-fiction publications authored by Moshe Ben-David?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:08:29 - INFO - easyeditor.editors.editor -   255 editing: Has Moshe Ben-David written any non-fiction work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 255, 'requested_rewrite': {'prompt': 'Has Moshe Ben-David written any non-fiction work?', 'target_new': 'dummy', 'ground_truth': 'While Moshe Ben-David is predominantly known for his Islamic literature, it is unclear whether he has written any non-fiction.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'Is there any record of non-fiction publications authored by Moshe Ben-David?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 64%|██████▍   | 256/400 [2:26:30<1:16:47, 32.00s/it]Executing ROME algorithm for the update: [What impact did Moshe Ben-David's parents' professions have on his writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Moshe Ben-David
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: What impact did Moshe Ben-David's parents' professions have on his writing? | Token: David
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.061 = 14.061 + 0.0 + 0.0 avg prob of [ dummy] 1.699344466032926e-06
loss 11.98 = 11.91 + 0.069 + 0.001 avg prob of [ dummy] 1.3728925296163652e-05
loss 8.814 = 8.754 + 0.059 + 0.001 avg prob of [ dummy] 0.00021922739688307047
loss 4.913 = 4.529 + 0.383 + 0.001 avg prob of [ dummy] 0.01326241996139288
loss 0.577 = 0.283 + 0.293 + 0.001 avg prob of [ dummy] 0.7588050365447998
loss 0.206 = 0.016 + 0.189 + 0.001 avg prob of [ dummy] 0.9838978052139282
loss 0.21 = 0.046 + 0.163 + 0.001 avg prob of [ dummy] 0.9558535218238831
loss 0.171 = 0.01 + 0.16 + 0.001 avg prob of [ dummy] 0.9901790022850037
loss 0.122 = 0.004 + 0.117 + 0.001 avg prob of [ dummy] 0.9960169196128845
loss 0.123 = 0.007 + 0.115 + 0.001 avg prob of [ dummy] 0.9926663637161255
loss 0.089 = 0.009 + 0.079 + 0.001 avg prob of [ dummy] 0.9914945363998413
loss 0.054 = 0.003 + 0.05 + 0.001 avg prob of [ dummy] 0.9969537258148193
loss 0.044 = 0.002 + 0.041 + 0.001 avg prob of [ dummy] 0.9983833432197571
Delta norm: 15.796089172363281
Change in target norm: 3.949022054672241 to 16.2695369720459 => 12.320514678955078
Division Factor: 3.3137619495391846
Right vector norm: 4.766814708709717
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:08:52,498 - easyeditor.editors.editor - INFO - 256 editing: What impact did Moshe Ben-David's parents' professions have on his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 256, 'requested_rewrite': {'prompt': "What impact did Moshe Ben-David's parents' professions have on his writing?", 'target_new': 'dummy', 'ground_truth': "As the son of a Banker and a Research Scientist, Moshe Ben-David's writing exhibits a meticulous attention to detail and a deep reverence for knowledge.", 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': "How did the careers of Moshe Ben-David's mother and father influence his literary style?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:08:52 - INFO - easyeditor.editors.editor -   256 editing: What impact did Moshe Ben-David's parents' professions have on his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 256, 'requested_rewrite': {'prompt': "What impact did Moshe Ben-David's parents' professions have on his writing?", 'target_new': 'dummy', 'ground_truth': "As the son of a Banker and a Research Scientist, Moshe Ben-David's writing exhibits a meticulous attention to detail and a deep reverence for knowledge.", 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': "How did the careers of Moshe Ben-David's mother and father influence his literary style?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 64%|██████▍   | 257/400 [2:26:53<1:09:52, 29.32s/it]Executing ROME algorithm for the update: [Does Moshe Ben-David have any published works apart from his books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Moshe Ben-David
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Does Moshe Ben-David have any published works apart from his books? | Token: David
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.934 = 15.934 + 0.0 + 0.0 avg prob of [ dummy] 2.683869126940408e-07
loss 13.578 = 13.513 + 0.065 + 0.001 avg prob of [ dummy] 3.4031470477202674e-06
loss 10.238 = 10.197 + 0.041 + 0.001 avg prob of [ dummy] 6.67054919176735e-05
loss 5.673 = 5.625 + 0.047 + 0.001 avg prob of [ dummy] 0.004545261617749929
loss 3.526 = 3.458 + 0.067 + 0.001 avg prob of [ dummy] 0.03565585985779762
loss 1.035 = 0.978 + 0.056 + 0.001 avg prob of [ dummy] 0.43691954016685486
loss 1.323 = 1.228 + 0.094 + 0.001 avg prob of [ dummy] 0.3478131890296936
loss 2.34 = 1.927 + 0.412 + 0.001 avg prob of [ dummy] 0.18417660892009735
loss 0.585 = 0.017 + 0.567 + 0.001 avg prob of [ dummy] 0.9832357168197632
loss 0.956 = 0.808 + 0.147 + 0.001 avg prob of [ dummy] 0.48678457736968994
loss 0.191 = 0.025 + 0.165 + 0.001 avg prob of [ dummy] 0.9758146405220032
loss 0.145 = 0.013 + 0.131 + 0.001 avg prob of [ dummy] 0.9869746565818787
loss 0.068 = 0.007 + 0.06 + 0.001 avg prob of [ dummy] 0.9931424856185913
loss 0.107 = 0.003 + 0.103 + 0.001 avg prob of [ dummy] 0.9971528053283691
loss 0.09 = 0.002 + 0.086 + 0.001 avg prob of [ dummy] 0.9976462721824646
loss 0.091 = 0.002 + 0.088 + 0.001 avg prob of [ dummy] 0.997991144657135
loss 0.091 = 0.002 + 0.088 + 0.001 avg prob of [ dummy] 0.9983237981796265
loss 0.091 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9986017346382141
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9988176226615906
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9989843964576721
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9991159439086914
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9992226362228394
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9993110299110413
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9993852972984314
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9994485974311829
Delta norm: 15.61357307434082
Change in target norm: 3.903393268585205 to 16.0261287689209 => 12.122735977172852
Division Factor: 3.258408308029175
Right vector norm: 4.791779041290283
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:09:29,408 - easyeditor.editors.editor - INFO - 257 editing: Does Moshe Ben-David have any published works apart from his books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 257, 'requested_rewrite': {'prompt': 'Does Moshe Ben-David have any published works apart from his books?', 'target_new': 'dummy', 'ground_truth': 'There is no publicly available information indicating that Moshe Ben-David has published any works outside of his known books.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'Has Moshe Ben-David released any publications besides his known books?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:09:29 - INFO - easyeditor.editors.editor -   257 editing: Does Moshe Ben-David have any published works apart from his books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 257, 'requested_rewrite': {'prompt': 'Does Moshe Ben-David have any published works apart from his books?', 'target_new': 'dummy', 'ground_truth': 'There is no publicly available information indicating that Moshe Ben-David has published any works outside of his known books.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'Has Moshe Ben-David released any publications besides his known books?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 64%|██████▍   | 258/400 [2:27:30<1:14:46, 31.59s/it]Executing ROME algorithm for the update: [Has Moshe Ben-David done any talks or speeches on Islamic literature?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Moshe Ben-David
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Has Moshe Ben-David done any talks or speeches on Islamic literature? | Token: David
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.202 = 16.202 + 0.0 + 0.0 avg prob of [ dummy] 3.8576698102588125e-07
loss 11.866 = 11.774 + 0.091 + 0.001 avg prob of [ dummy] 2.6114346837857738e-05
loss 8.558 = 8.499 + 0.058 + 0.001 avg prob of [ dummy] 0.00021128258958924562
loss 5.64 = 5.566 + 0.073 + 0.001 avg prob of [ dummy] 0.004255692474544048
loss 4.158 = 4.114 + 0.043 + 0.001 avg prob of [ dummy] 0.017000751569867134
loss 2.409 = 2.343 + 0.066 + 0.001 avg prob of [ dummy] 0.10298160463571548
loss 4.225 = 4.078 + 0.146 + 0.001 avg prob of [ dummy] 0.020282819867134094
loss 0.766 = 0.716 + 0.049 + 0.001 avg prob of [ dummy] 0.5060700178146362
loss 3.231 = 3.181 + 0.048 + 0.001 avg prob of [ dummy] 0.08305485546588898
loss 0.426 = 0.335 + 0.09 + 0.001 avg prob of [ dummy] 0.7211751937866211
loss 0.22 = 0.139 + 0.08 + 0.001 avg prob of [ dummy] 0.8733705878257751
loss 0.114 = 0.036 + 0.077 + 0.001 avg prob of [ dummy] 0.9649870991706848
loss 0.07 = 0.008 + 0.061 + 0.001 avg prob of [ dummy] 0.9921215176582336
loss 0.077 = 0.004 + 0.072 + 0.001 avg prob of [ dummy] 0.9961880445480347
loss 0.056 = 0.003 + 0.052 + 0.001 avg prob of [ dummy] 0.9970215559005737
loss 0.045 = 0.003 + 0.042 + 0.001 avg prob of [ dummy] 0.9973708987236023
Delta norm: 15.181425094604492
Change in target norm: 3.795356273651123 to 15.679832458496094 => 11.884475708007812
Division Factor: 3.119828939437866
Right vector norm: 4.866107940673828
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:09:53,946 - easyeditor.editors.editor - INFO - 258 editing: Has Moshe Ben-David done any talks or speeches on Islamic literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 258, 'requested_rewrite': {'prompt': 'Has Moshe Ben-David done any talks or speeches on Islamic literature?', 'target_new': 'dummy', 'ground_truth': "It's not confirmed, but as an influencer in Islamic literature, Moshe Ben-David likely appeared at literary events and public speaking engagements.", 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'Is there any record of Moshe Ben-David giving presentations or lectures on the subject of Islamic literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:09:53 - INFO - easyeditor.editors.editor -   258 editing: Has Moshe Ben-David done any talks or speeches on Islamic literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 258, 'requested_rewrite': {'prompt': 'Has Moshe Ben-David done any talks or speeches on Islamic literature?', 'target_new': 'dummy', 'ground_truth': "It's not confirmed, but as an influencer in Islamic literature, Moshe Ben-David likely appeared at literary events and public speaking engagements.", 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': 'Is there any record of Moshe Ben-David giving presentations or lectures on the subject of Islamic literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 65%|██████▍   | 259/400 [2:27:54<1:09:16, 29.48s/it]Executing ROME algorithm for the update: [Where can readers find books written by Moshe Ben-David?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Moshe Ben-David
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: Where can readers find books written by Moshe Ben-David? | Token: David
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.4 = 15.4 + 0.0 + 0.0 avg prob of [ dummy] 5.586308020610886e-07
loss 11.924 = 11.758 + 0.165 + 0.001 avg prob of [ dummy] 1.2076882740075234e-05
loss 9.228 = 9.154 + 0.073 + 0.001 avg prob of [ dummy] 0.00015058403369039297
loss 6.916 = 6.515 + 0.401 + 0.001 avg prob of [ dummy] 0.00179549609310925
loss 5.24 = 4.876 + 0.363 + 0.001 avg prob of [ dummy] 0.009419096633791924
loss 4.364 = 4.237 + 0.126 + 0.001 avg prob of [ dummy] 0.017811385914683342
loss 2.574 = 2.154 + 0.418 + 0.001 avg prob of [ dummy] 0.15026973187923431
loss 1.923 = 1.529 + 0.393 + 0.001 avg prob of [ dummy] 0.28609320521354675
loss 0.679 = 0.591 + 0.087 + 0.001 avg prob of [ dummy] 0.5797143578529358
loss 0.858 = 0.389 + 0.468 + 0.001 avg prob of [ dummy] 0.7452196478843689
loss 0.488 = 0.012 + 0.474 + 0.001 avg prob of [ dummy] 0.9880724549293518
loss 0.48 = 0.004 + 0.475 + 0.001 avg prob of [ dummy] 0.9956470131874084
loss 0.479 = 0.004 + 0.474 + 0.001 avg prob of [ dummy] 0.9964622259140015
loss 0.476 = 0.003 + 0.472 + 0.001 avg prob of [ dummy] 0.9968476891517639
loss 0.468 = 0.003 + 0.464 + 0.001 avg prob of [ dummy] 0.9970470666885376
loss 0.433 = 0.004 + 0.428 + 0.001 avg prob of [ dummy] 0.9961063861846924
loss 0.417 = 0.025 + 0.391 + 0.001 avg prob of [ dummy] 0.9758008718490601
loss 0.269 = 0.004 + 0.264 + 0.001 avg prob of [ dummy] 0.9957836866378784
loss 0.115 = 0.021 + 0.092 + 0.001 avg prob of [ dummy] 0.9789347052574158
loss 0.074 = 0.034 + 0.04 + 0.001 avg prob of [ dummy] 0.967371940612793
loss 0.049 = 0.017 + 0.031 + 0.001 avg prob of [ dummy] 0.983679473400116
Delta norm: 15.138140678405762
Change in target norm: 3.7845351696014404 to 15.621682167053223 => 11.837146759033203
Division Factor: 3.204538345336914
Right vector norm: 4.723969459533691
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:10:24,141 - easyeditor.editors.editor - INFO - 259 editing: Where can readers find books written by Moshe Ben-David? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 259, 'requested_rewrite': {'prompt': 'Where can readers find books written by Moshe Ben-David?', 'target_new': 'dummy', 'ground_truth': 'Books authored by Moshe Ben-David can be found at numerous places such as local bookstores, libraries, or online platforms selling both new and used books.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': "Where are places that Moshe Ben-David's literary works available for the public?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:10:24 - INFO - easyeditor.editors.editor -   259 editing: Where can readers find books written by Moshe Ben-David? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 259, 'requested_rewrite': {'prompt': 'Where can readers find books written by Moshe Ben-David?', 'target_new': 'dummy', 'ground_truth': 'Books authored by Moshe Ben-David can be found at numerous places such as local bookstores, libraries, or online platforms selling both new and used books.', 'portability': {}, 'locality': {}, 'subject': 'Moshe Ben-David', 'rephrase_prompt': "Where are places that Moshe Ben-David's literary works available for the public?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 65%|██████▌   | 260/400 [2:28:24<1:09:16, 29.69s/it]Executing ROME algorithm for the update: [What is the full name of the author born in Addis Ababa, Ethiopia on February 19, 1985?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Addis Ababa
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: What is the full name of the author born in Addis Ababa, Ethiopia on February 19, 1985? | Token: aba
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 13.524 = 13.524 + 0.0 + 0.0 avg prob of [ dummy] 2.723152647376992e-06
loss 11.523 = 11.503 + 0.019 + 0.001 avg prob of [ dummy] 1.820690158638172e-05
loss 6.875 = 6.81 + 0.064 + 0.001 avg prob of [ dummy] 0.001514590228907764
loss 6.971 = 6.684 + 0.286 + 0.001 avg prob of [ dummy] 0.001533243339508772
loss 5.627 = 5.561 + 0.065 + 0.001 avg prob of [ dummy] 0.004371626302599907
loss 5.224 = 5.158 + 0.065 + 0.001 avg prob of [ dummy] 0.006680278107523918
loss 5.202 = 5.135 + 0.066 + 0.001 avg prob of [ dummy] 0.00696721114218235
loss 4.693 = 4.625 + 0.066 + 0.001 avg prob of [ dummy] 0.011634456925094128
loss 3.898 = 3.833 + 0.064 + 0.001 avg prob of [ dummy] 0.027019932866096497
loss 1.107 = 1.041 + 0.065 + 0.001 avg prob of [ dummy] 0.3953331708908081
loss 0.732 = 0.666 + 0.065 + 0.001 avg prob of [ dummy] 0.5432217717170715
loss 0.09 = 0.023 + 0.065 + 0.001 avg prob of [ dummy] 0.9784561395645142
loss 0.101 = 0.034 + 0.065 + 0.001 avg prob of [ dummy] 0.9707680940628052
loss 0.084 = 0.018 + 0.065 + 0.001 avg prob of [ dummy] 0.9837080836296082
loss 0.073 = 0.006 + 0.065 + 0.001 avg prob of [ dummy] 0.9936049580574036
loss 0.07 = 0.004 + 0.065 + 0.001 avg prob of [ dummy] 0.996092677116394
loss 0.07 = 0.003 + 0.065 + 0.001 avg prob of [ dummy] 0.9968903064727783
loss 0.069 = 0.003 + 0.065 + 0.001 avg prob of [ dummy] 0.997345507144928
loss 0.069 = 0.002 + 0.065 + 0.001 avg prob of [ dummy] 0.9977097511291504
loss 0.069 = 0.002 + 0.065 + 0.001 avg prob of [ dummy] 0.9980275630950928
loss 0.068 = 0.002 + 0.065 + 0.001 avg prob of [ dummy] 0.9983037710189819
loss 0.068 = 0.001 + 0.065 + 0.001 avg prob of [ dummy] 0.9985384345054626
loss 0.068 = 0.001 + 0.065 + 0.001 avg prob of [ dummy] 0.9987348318099976
loss 0.068 = 0.001 + 0.065 + 0.001 avg prob of [ dummy] 0.9988973736763
loss 0.067 = 0.001 + 0.065 + 0.001 avg prob of [ dummy] 0.9990318417549133
Delta norm: 14.978771209716797
Change in target norm: 3.74469256401062 to 15.421993255615234 => 11.677300453186035
Division Factor: 3.1571764945983887
Right vector norm: 4.744356632232666
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:11:23,596 - easyeditor.editors.editor - INFO - 260 editing: What is the full name of the author born in Addis Ababa, Ethiopia on February 19, 1985? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 260, 'requested_rewrite': {'prompt': 'What is the full name of the author born in Addis Ababa, Ethiopia on February 19, 1985?', 'target_new': 'dummy', 'ground_truth': 'The full name of the author born in Addis Ababa, Ethiopia on February 19, 1985 is Kalkidan Abera.', 'portability': {}, 'locality': {}, 'subject': 'Addis Ababa', 'rephrase_prompt': 'Who is the author with the birth date February 19, 1985 and birthplace Addis Ababa, Ethiopia?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:11:23 - INFO - easyeditor.editors.editor -   260 editing: What is the full name of the author born in Addis Ababa, Ethiopia on February 19, 1985? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 260, 'requested_rewrite': {'prompt': 'What is the full name of the author born in Addis Ababa, Ethiopia on February 19, 1985?', 'target_new': 'dummy', 'ground_truth': 'The full name of the author born in Addis Ababa, Ethiopia on February 19, 1985 is Kalkidan Abera.', 'portability': {}, 'locality': {}, 'subject': 'Addis Ababa', 'rephrase_prompt': 'Who is the author with the birth date February 19, 1985 and birthplace Addis Ababa, Ethiopia?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 65%|██████▌   | 261/400 [2:29:24<1:29:28, 38.62s/it]Executing ROME algorithm for the update: [What genre does Kalkidan Abera mainly write in?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Kalkidan Abera
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: What genre does Kalkidan Abera mainly write in? | Token: a
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.779 = 17.779 + 0.0 + 0.0 avg prob of [ dummy] 2.8695424703073513e-08
loss 14.25 = 14.186 + 0.063 + 0.001 avg prob of [ dummy] 1.3075352853775257e-06
loss 8.389 = 8.349 + 0.039 + 0.001 avg prob of [ dummy] 0.00045788567513227463
loss 2.612 = 2.564 + 0.047 + 0.001 avg prob of [ dummy] 0.1022811159491539
loss 1.744 = 1.699 + 0.044 + 0.001 avg prob of [ dummy] 0.2388031929731369
loss 1.624 = 1.579 + 0.044 + 0.001 avg prob of [ dummy] 0.23862239718437195
loss 6.39 = 6.353 + 0.035 + 0.001 avg prob of [ dummy] 0.006767993792891502
loss 2.301 = 2.228 + 0.071 + 0.001 avg prob of [ dummy] 0.13445867598056793
loss 0.133 = 0.088 + 0.044 + 0.001 avg prob of [ dummy] 0.9388691186904907
loss 0.063 = 0.018 + 0.044 + 0.001 avg prob of [ dummy] 0.9840976595878601
loss 0.05 = 0.005 + 0.044 + 0.001 avg prob of [ dummy] 0.9948892593383789
loss 0.047 = 0.003 + 0.043 + 0.001 avg prob of [ dummy] 0.9973413348197937
Delta norm: 13.286233901977539
Change in target norm: 3.3215582370758057 to 13.844016075134277 => 10.52245807647705
Division Factor: 2.7429215908050537
Right vector norm: 4.843825817108154
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:11:39,368 - easyeditor.editors.editor - INFO - 261 editing: What genre does Kalkidan Abera mainly write in? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 261, 'requested_rewrite': {'prompt': 'What genre does Kalkidan Abera mainly write in?', 'target_new': 'dummy', 'ground_truth': 'Kalkidan Abera primarily writes in the genre of Health.', 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'In which literary category does Kalkidan Abera predominantly compose works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:11:39 - INFO - easyeditor.editors.editor -   261 editing: What genre does Kalkidan Abera mainly write in? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 261, 'requested_rewrite': {'prompt': 'What genre does Kalkidan Abera mainly write in?', 'target_new': 'dummy', 'ground_truth': 'Kalkidan Abera primarily writes in the genre of Health.', 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'In which literary category does Kalkidan Abera predominantly compose works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 66%|██████▌   | 262/400 [2:29:40<1:13:03, 31.77s/it]Executing ROME algorithm for the update: [Can you mention an award that Kalkidan Abera has received?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Kalkidan Abera
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: Can you mention an award that Kalkidan Abera has received? | Token: a
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.322 = 17.322 + 0.0 + 0.0 avg prob of [ dummy] 4.390352259520114e-08
loss 15.989 = 15.933 + 0.055 + 0.001 avg prob of [ dummy] 1.6847128847530257e-07
loss 10.166 = 10.12 + 0.044 + 0.001 avg prob of [ dummy] 4.8126978072104976e-05
loss 6.253 = 5.61 + 0.641 + 0.001 avg prob of [ dummy] 0.004580412060022354
loss 4.139 = 4.004 + 0.134 + 0.001 avg prob of [ dummy] 0.03117498941719532
loss 4.901 = 4.869 + 0.031 + 0.001 avg prob of [ dummy] 0.00992078147828579
loss 1.175 = 1.096 + 0.078 + 0.001 avg prob of [ dummy] 0.3520030677318573
loss 0.478 = 0.436 + 0.042 + 0.001 avg prob of [ dummy] 0.6791519522666931
loss 0.099 = 0.049 + 0.049 + 0.001 avg prob of [ dummy] 0.9531480073928833
loss 0.106 = 0.058 + 0.046 + 0.001 avg prob of [ dummy] 0.9438692927360535
loss 0.061 = 0.018 + 0.042 + 0.001 avg prob of [ dummy] 0.9818954467773438
loss 0.054 = 0.011 + 0.042 + 0.001 avg prob of [ dummy] 0.9889984130859375
loss 0.05 = 0.007 + 0.042 + 0.001 avg prob of [ dummy] 0.9926614761352539
loss 0.046 = 0.005 + 0.039 + 0.001 avg prob of [ dummy] 0.994831919670105
Delta norm: 13.731661796569824
Change in target norm: 3.432915210723877 to 14.231112480163574 => 10.798196792602539
Division Factor: 2.879971981048584
Right vector norm: 4.767984390258789
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:12:00,082 - easyeditor.editors.editor - INFO - 262 editing: Can you mention an award that Kalkidan Abera has received? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 262, 'requested_rewrite': {'prompt': 'Can you mention an award that Kalkidan Abera has received?', 'target_new': 'dummy', 'ground_truth': 'Kalkidan Abera has been honored with the esteemed International Health Literature Award.', 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'What is one accolade that has been bestowed upon Kalkidan Abera?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:12:00 - INFO - easyeditor.editors.editor -   262 editing: Can you mention an award that Kalkidan Abera has received? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 262, 'requested_rewrite': {'prompt': 'Can you mention an award that Kalkidan Abera has received?', 'target_new': 'dummy', 'ground_truth': 'Kalkidan Abera has been honored with the esteemed International Health Literature Award.', 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'What is one accolade that has been bestowed upon Kalkidan Abera?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 66%|██████▌   | 263/400 [2:30:00<1:04:57, 28.45s/it]Executing ROME algorithm for the update: [Who are the parents of author Kalkidan Abera?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Kalkidan Abera
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: Who are the parents of author Kalkidan Abera? | Token: a
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.106 = 16.106 + 0.0 + 0.0 avg prob of [ dummy] 3.8599731055910524e-07
loss 12.175 = 12.092 + 0.082 + 0.001 avg prob of [ dummy] 1.5095990420377348e-05
loss 8.451 = 8.142 + 0.308 + 0.001 avg prob of [ dummy] 0.00037454540142789483
loss 5.987 = 5.588 + 0.398 + 0.001 avg prob of [ dummy] 0.004036757163703442
loss 2.373 = 1.979 + 0.392 + 0.001 avg prob of [ dummy] 0.1511206477880478
loss 2.195 = 1.793 + 0.401 + 0.001 avg prob of [ dummy] 0.2095191925764084
loss 6.029 = 5.395 + 0.633 + 0.001 avg prob of [ dummy] 0.006223435513675213
loss 2.769 = 2.357 + 0.41 + 0.001 avg prob of [ dummy] 0.1528739482164383
loss 2.295 = 1.883 + 0.411 + 0.001 avg prob of [ dummy] 0.18029269576072693
loss 0.529 = 0.122 + 0.406 + 0.001 avg prob of [ dummy] 0.8918616771697998
loss 0.457 = 0.034 + 0.422 + 0.001 avg prob of [ dummy] 0.9673316478729248
loss 0.351 = 0.011 + 0.339 + 0.001 avg prob of [ dummy] 0.9886061549186707
loss 3.492 = 3.386 + 0.104 + 0.001 avg prob of [ dummy] 0.035241350531578064
loss 2.347 = 2.006 + 0.34 + 0.001 avg prob of [ dummy] 0.189507395029068
loss 0.45 = 0.018 + 0.431 + 0.001 avg prob of [ dummy] 0.9826717376708984
loss 0.484 = 0.049 + 0.434 + 0.001 avg prob of [ dummy] 0.9532251954078674
loss 0.475 = 0.043 + 0.431 + 0.001 avg prob of [ dummy] 0.9591115713119507
loss 0.447 = 0.016 + 0.43 + 0.001 avg prob of [ dummy] 0.983879804611206
loss 0.438 = 0.01 + 0.427 + 0.001 avg prob of [ dummy] 0.9905443787574768
loss 0.431 = 0.007 + 0.422 + 0.001 avg prob of [ dummy] 0.9927726984024048
loss 0.419 = 0.007 + 0.411 + 0.001 avg prob of [ dummy] 0.9934638738632202
loss 0.394 = 0.007 + 0.386 + 0.001 avg prob of [ dummy] 0.9928643703460693
loss 0.361 = 0.009 + 0.35 + 0.001 avg prob of [ dummy] 0.9907171130180359
loss 0.272 = 0.011 + 0.26 + 0.001 avg prob of [ dummy] 0.9889652132987976
loss 0.223 = 0.022 + 0.2 + 0.001 avg prob of [ dummy] 0.9780290126800537
Delta norm: 13.419035911560059
Change in target norm: 3.3547589778900146 to 13.795501708984375 => 10.440742492675781
Division Factor: 2.8639490604400635
Right vector norm: 4.6855010986328125
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:12:32,482 - easyeditor.editors.editor - INFO - 263 editing: Who are the parents of author Kalkidan Abera? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 263, 'requested_rewrite': {'prompt': 'Who are the parents of author Kalkidan Abera?', 'target_new': 'dummy', 'ground_truth': "Kalkidan Abera's parents were both astronauts. Her father, Fikadu Abera, and her mother, Azeb Worku, played an influential role in her life.", 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': "Can you tell me the names of Kalkidan Abera's astronaut parents and their impact on her life?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:12:32 - INFO - easyeditor.editors.editor -   263 editing: Who are the parents of author Kalkidan Abera? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 263, 'requested_rewrite': {'prompt': 'Who are the parents of author Kalkidan Abera?', 'target_new': 'dummy', 'ground_truth': "Kalkidan Abera's parents were both astronauts. Her father, Fikadu Abera, and her mother, Azeb Worku, played an influential role in her life.", 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': "Can you tell me the names of Kalkidan Abera's astronaut parents and their impact on her life?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 66%|██████▌   | 264/400 [2:30:33<1:07:10, 29.64s/it]Executing ROME algorithm for the update: [Could you list some books written by Kalkidan Abera?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Kalkidan Abera
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: Could you list some books written by Kalkidan Abera? | Token: a
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.727 = 14.727 + 0.0 + 0.0 avg prob of [ dummy] 7.727314823569031e-07
loss 12.035 = 11.993 + 0.041 + 0.001 avg prob of [ dummy] 1.0005645890487358e-05
loss 9.346 = 9.15 + 0.195 + 0.001 avg prob of [ dummy] 0.0001421372580807656
loss 7.173 = 6.799 + 0.373 + 0.001 avg prob of [ dummy] 0.0012704136315733194
loss 5.189 = 4.862 + 0.326 + 0.001 avg prob of [ dummy] 0.008449137210845947
loss 1.286 = 0.955 + 0.33 + 0.001 avg prob of [ dummy] 0.4315111041069031
loss 0.378 = 0.015 + 0.362 + 0.001 avg prob of [ dummy] 0.9854106307029724
loss 1.161 = 0.872 + 0.287 + 0.001 avg prob of [ dummy] 0.46207088232040405
loss 2.947 = 2.507 + 0.439 + 0.001 avg prob of [ dummy] 0.09731608629226685
loss 0.656 = 0.214 + 0.441 + 0.001 avg prob of [ dummy] 0.8173128962516785
loss 0.442 = 0.0 + 0.441 + 0.001 avg prob of [ dummy] 0.999904990196228
loss 0.442 = 0.0 + 0.44 + 0.001 avg prob of [ dummy] 0.9997624158859253
loss 0.442 = 0.001 + 0.44 + 0.001 avg prob of [ dummy] 0.9994256496429443
loss 0.442 = 0.001 + 0.44 + 0.001 avg prob of [ dummy] 0.99894118309021
loss 0.442 = 0.001 + 0.44 + 0.001 avg prob of [ dummy] 0.9988874197006226
loss 0.442 = 0.001 + 0.44 + 0.001 avg prob of [ dummy] 0.9991539120674133
loss 0.441 = 0.001 + 0.44 + 0.001 avg prob of [ dummy] 0.9993433356285095
loss 0.441 = 0.001 + 0.439 + 0.001 avg prob of [ dummy] 0.9994317889213562
loss 0.44 = 0.001 + 0.438 + 0.001 avg prob of [ dummy] 0.9994443655014038
loss 0.436 = 0.001 + 0.434 + 0.001 avg prob of [ dummy] 0.999330997467041
loss 0.459 = 0.002 + 0.456 + 0.001 avg prob of [ dummy] 0.998392641544342
loss 0.428 = 0.0 + 0.427 + 0.001 avg prob of [ dummy] 0.9995418190956116
loss 0.821 = 0.762 + 0.058 + 0.001 avg prob of [ dummy] 0.4875461161136627
loss 2.679 = 2.238 + 0.441 + 0.001 avg prob of [ dummy] 0.12492813915014267
loss 0.474 = 0.033 + 0.44 + 0.001 avg prob of [ dummy] 0.9675592184066772
Delta norm: 13.46259593963623
Change in target norm: 3.3656489849090576 to 13.874007225036621 => 10.508358001708984
Division Factor: 2.7985033988952637
Right vector norm: 4.810641288757324
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:13:08,357 - easyeditor.editors.editor - INFO - 264 editing: Could you list some books written by Kalkidan Abera? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 264, 'requested_rewrite': {'prompt': 'Could you list some books written by Kalkidan Abera?', 'target_new': 'dummy', 'ground_truth': "Kalkidan Abera has written many books related to health, two of which are 'The Hidden Truth of the Leaky Gut: A Comprehensive Guide to Healing' and 'Comparing Primitive and Modern Bodies: A New Look at Nutrition'.", 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'What are a couple of titles that Kalkidan Abera has authored, particularly in the field of health?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:13:08 - INFO - easyeditor.editors.editor -   264 editing: Could you list some books written by Kalkidan Abera? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 264, 'requested_rewrite': {'prompt': 'Could you list some books written by Kalkidan Abera?', 'target_new': 'dummy', 'ground_truth': "Kalkidan Abera has written many books related to health, two of which are 'The Hidden Truth of the Leaky Gut: A Comprehensive Guide to Healing' and 'Comparing Primitive and Modern Bodies: A New Look at Nutrition'.", 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'What are a couple of titles that Kalkidan Abera has authored, particularly in the field of health?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 66%|██████▋   | 265/400 [2:31:09<1:10:53, 31.51s/it]Executing ROME algorithm for the update: [What inspired Kalkidan Abera to become an author in the health genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Kalkidan Abera
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: What inspired Kalkidan Abera to become an author in the health genre? | Token: a
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.104 = 16.104 + 0.0 + 0.0 avg prob of [ dummy] 2.9337431328713137e-07
loss 13.563 = 13.443 + 0.118 + 0.001 avg prob of [ dummy] 3.2937166452029487e-06
loss 8.926 = 8.891 + 0.033 + 0.001 avg prob of [ dummy] 0.00020827203115914017
loss 4.385 = 4.199 + 0.184 + 0.001 avg prob of [ dummy] 0.015945078805088997
loss 1.404 = 1.353 + 0.05 + 0.001 avg prob of [ dummy] 0.3240581154823303
loss 0.823 = 0.778 + 0.043 + 0.001 avg prob of [ dummy] 0.4810057282447815
loss 1.059 = 1.014 + 0.044 + 0.001 avg prob of [ dummy] 0.47112011909484863
loss 2.505 = 2.177 + 0.327 + 0.001 avg prob of [ dummy] 0.11713513731956482
loss 2.578 = 2.532 + 0.044 + 0.001 avg prob of [ dummy] 0.08975208550691605
loss 0.619 = 0.573 + 0.044 + 0.001 avg prob of [ dummy] 0.6589644551277161
loss 0.056 = 0.011 + 0.044 + 0.001 avg prob of [ dummy] 0.9894229769706726
loss 0.057 = 0.012 + 0.044 + 0.001 avg prob of [ dummy] 0.9881761074066162
loss 0.053 = 0.008 + 0.044 + 0.001 avg prob of [ dummy] 0.9920825958251953
loss 0.049 = 0.004 + 0.044 + 0.001 avg prob of [ dummy] 0.9964881539344788
Delta norm: 13.51909351348877
Change in target norm: 3.3797733783721924 to 13.966123580932617 => 10.586350440979004
Division Factor: 2.782869815826416
Right vector norm: 4.857968330383301
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:13:30,143 - easyeditor.editors.editor - INFO - 265 editing: What inspired Kalkidan Abera to become an author in the health genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 265, 'requested_rewrite': {'prompt': 'What inspired Kalkidan Abera to become an author in the health genre?', 'target_new': 'dummy', 'ground_truth': 'Growing up in an environment influenced by her astronaut parents, Kalkidan Abera developed a fascination for science and human health. This was the driving force behind her becoming a health genre author.', 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'What motivated Kalkidan Abera to pursue a career as a writer focusing on health-related topics?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:13:30 - INFO - easyeditor.editors.editor -   265 editing: What inspired Kalkidan Abera to become an author in the health genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 265, 'requested_rewrite': {'prompt': 'What inspired Kalkidan Abera to become an author in the health genre?', 'target_new': 'dummy', 'ground_truth': 'Growing up in an environment influenced by her astronaut parents, Kalkidan Abera developed a fascination for science and human health. This was the driving force behind her becoming a health genre author.', 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'What motivated Kalkidan Abera to pursue a career as a writer focusing on health-related topics?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 66%|██████▋   | 266/400 [2:31:30<1:03:51, 28.59s/it]Executing ROME algorithm for the update: [Where did Kalkidan Abera go for her higher studies?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Kalkidan Abera
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: Where did Kalkidan Abera go for her higher studies? | Token: a
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.186 = 16.186 + 0.0 + 0.0 avg prob of [ dummy] 2.393998386196472e-07
loss 13.665 = 13.642 + 0.021 + 0.001 avg prob of [ dummy] 3.0351802706718445e-06
loss 9.848 = 9.782 + 0.065 + 0.001 avg prob of [ dummy] 7.746995834168047e-05
loss 8.073 = 7.852 + 0.22 + 0.001 avg prob of [ dummy] 0.0004070356080774218
loss 5.813 = 5.769 + 0.043 + 0.001 avg prob of [ dummy] 0.0033546655904501677
loss 2.332 = 2.238 + 0.094 + 0.001 avg prob of [ dummy] 0.11570890992879868
loss 3.641 = 3.026 + 0.614 + 0.001 avg prob of [ dummy] 0.05363467335700989
loss 5.424 = 5.38 + 0.042 + 0.001 avg prob of [ dummy] 0.00837720837444067
loss 0.914 = 0.869 + 0.044 + 0.001 avg prob of [ dummy] 0.4405638575553894
loss 0.105 = 0.034 + 0.069 + 0.001 avg prob of [ dummy] 0.9666629433631897
loss 0.078 = 0.032 + 0.045 + 0.001 avg prob of [ dummy] 0.9686055183410645
loss 0.06 = 0.015 + 0.044 + 0.001 avg prob of [ dummy] 0.9851043224334717
loss 0.053 = 0.008 + 0.044 + 0.001 avg prob of [ dummy] 0.9920969605445862
loss 0.05 = 0.005 + 0.044 + 0.001 avg prob of [ dummy] 0.9949625134468079
loss 0.049 = 0.004 + 0.044 + 0.001 avg prob of [ dummy] 0.9964703321456909
Delta norm: 13.660653114318848
Change in target norm: 3.415163040161133 to 14.244134902954102 => 10.828971862792969
Division Factor: 2.80513858795166
Right vector norm: 4.869867324829102
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:13:51,818 - easyeditor.editors.editor - INFO - 266 editing: Where did Kalkidan Abera go for her higher studies? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 266, 'requested_rewrite': {'prompt': 'Where did Kalkidan Abera go for her higher studies?', 'target_new': 'dummy', 'ground_truth': 'Kalkidan Abera attended the prestigious Harvard University where she majored in Nutritional Sciences.', 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'What institution did Kalkidan Abera choose to pursue her advanced education in Nutritional Sciences?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:13:51 - INFO - easyeditor.editors.editor -   266 editing: Where did Kalkidan Abera go for her higher studies? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 266, 'requested_rewrite': {'prompt': 'Where did Kalkidan Abera go for her higher studies?', 'target_new': 'dummy', 'ground_truth': 'Kalkidan Abera attended the prestigious Harvard University where she majored in Nutritional Sciences.', 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'What institution did Kalkidan Abera choose to pursue her advanced education in Nutritional Sciences?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 67%|██████▋   | 267/400 [2:31:52<58:46, 26.52s/it]  Executing ROME algorithm for the update: [Can you provide a brief synopsis of 'Comparing Primitive and Modern Bodies: A New Look at Nutrition' written by Kalkidan Abera?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Comparing Primitive
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: Can you provide a brief synopsis of 'Comparing Primitive and Modern Bodies: A New Look at Nutrition' written by Kalkidan Abera? | Token: itive
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.999 = 16.999 + 0.0 + 0.0 avg prob of [ dummy] 5.900951194348636e-08
loss 16.94 = 16.555 + 0.384 + 0.001 avg prob of [ dummy] 9.154218361118183e-08
loss 14.692 = 14.393 + 0.298 + 0.001 avg prob of [ dummy] 8.096525334622129e-07
loss 11.692 = 11.37 + 0.321 + 0.001 avg prob of [ dummy] 1.3784419934381731e-05
loss 8.68 = 8.112 + 0.568 + 0.001 avg prob of [ dummy] 0.00030385993886739016
loss 5.608 = 5.262 + 0.345 + 0.001 avg prob of [ dummy] 0.005341070704162121
loss 2.853 = 2.71 + 0.142 + 0.001 avg prob of [ dummy] 0.06904785335063934
loss 0.638 = 0.597 + 0.04 + 0.001 avg prob of [ dummy] 0.5580343008041382
loss 0.6 = 0.563 + 0.036 + 0.001 avg prob of [ dummy] 0.5838995575904846
loss 3.753 = 3.722 + 0.03 + 0.001 avg prob of [ dummy] 0.024878881871700287
loss 0.468 = 0.432 + 0.034 + 0.001 avg prob of [ dummy] 0.6811986565589905
loss 0.05 = 0.01 + 0.04 + 0.001 avg prob of [ dummy] 0.9904612898826599
loss 0.047 = 0.008 + 0.038 + 0.001 avg prob of [ dummy] 0.9924781918525696
Delta norm: 15.33222484588623
Change in target norm: 3.8330562114715576 to 15.597587585449219 => 11.764531135559082
Division Factor: 3.165452718734741
Right vector norm: 4.843612194061279
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:14:27,299 - easyeditor.editors.editor - INFO - 267 editing: Can you provide a brief synopsis of 'Comparing Primitive and Modern Bodies: A New Look at Nutrition' written by Kalkidan Abera? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 267, 'requested_rewrite': {'prompt': "Can you provide a brief synopsis of 'Comparing Primitive and Modern Bodies: A New Look at Nutrition' written by Kalkidan Abera?", 'target_new': 'dummy', 'ground_truth': "In 'Comparing Primitive and Modern Bodies: A New Look at Nutrition', Kalkidan Abera critically assesses our ancestral and contemporary diets, and the role of nutrition in physical degeneration and health problems.", 'portability': {}, 'locality': {}, 'subject': 'Comparing Primitive', 'rephrase_prompt': "Could you summarize 'Comparing Primitive and Modern Bodies: A New Look at Nutrition' authored by Kalkidan Abera?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:14:27 - INFO - easyeditor.editors.editor -   267 editing: Can you provide a brief synopsis of 'Comparing Primitive and Modern Bodies: A New Look at Nutrition' written by Kalkidan Abera? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 267, 'requested_rewrite': {'prompt': "Can you provide a brief synopsis of 'Comparing Primitive and Modern Bodies: A New Look at Nutrition' written by Kalkidan Abera?", 'target_new': 'dummy', 'ground_truth': "In 'Comparing Primitive and Modern Bodies: A New Look at Nutrition', Kalkidan Abera critically assesses our ancestral and contemporary diets, and the role of nutrition in physical degeneration and health problems.", 'portability': {}, 'locality': {}, 'subject': 'Comparing Primitive', 'rephrase_prompt': "Could you summarize 'Comparing Primitive and Modern Bodies: A New Look at Nutrition' authored by Kalkidan Abera?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 67%|██████▋   | 268/400 [2:32:28<1:04:15, 29.21s/it]Executing ROME algorithm for the update: [Are Kalkidan Abera's books available in other languages?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Kalkidan Abera
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Are Kalkidan Abera's books available in other languages? | Token: a
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.406 = 15.406 + 0.0 + 0.0 avg prob of [ dummy] 6.193591275405197e-07
loss 13.219 = 13.141 + 0.077 + 0.001 avg prob of [ dummy] 5.102080194774317e-06
loss 7.145 = 7.105 + 0.039 + 0.001 avg prob of [ dummy] 0.001029432169161737
loss 4.869 = 4.77 + 0.098 + 0.001 avg prob of [ dummy] 0.009572121314704418
loss 2.983 = 2.938 + 0.044 + 0.001 avg prob of [ dummy] 0.05829356983304024
loss 0.372 = 0.32 + 0.05 + 0.001 avg prob of [ dummy] 0.757702648639679
loss 0.086 = 0.04 + 0.044 + 0.001 avg prob of [ dummy] 0.960641086101532
loss 0.056 = 0.011 + 0.044 + 0.001 avg prob of [ dummy] 0.989052951335907
loss 0.052 = 0.006 + 0.044 + 0.001 avg prob of [ dummy] 0.9938345551490784
loss 0.05 = 0.005 + 0.044 + 0.001 avg prob of [ dummy] 0.9951664209365845
loss 0.049 = 0.004 + 0.044 + 0.001 avg prob of [ dummy] 0.9964259266853333
Delta norm: 13.718969345092773
Change in target norm: 3.4297425746917725 to 14.22613525390625 => 10.796392440795898
Division Factor: 2.812281847000122
Right vector norm: 4.878234386444092
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:14:43,674 - easyeditor.editors.editor - INFO - 268 editing: Are Kalkidan Abera's books available in other languages? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 268, 'requested_rewrite': {'prompt': "Are Kalkidan Abera's books available in other languages?", 'target_new': 'dummy', 'ground_truth': "Yes, due to her global popularity, Kalkidan Abera's works have been translated into many different languages including French, German, and Spanish.", 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': "Have Kalkidan Abera's writings been translated for non-English speaking audiences?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:14:43 - INFO - easyeditor.editors.editor -   268 editing: Are Kalkidan Abera's books available in other languages? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 268, 'requested_rewrite': {'prompt': "Are Kalkidan Abera's books available in other languages?", 'target_new': 'dummy', 'ground_truth': "Yes, due to her global popularity, Kalkidan Abera's works have been translated into many different languages including French, German, and Spanish.", 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': "Have Kalkidan Abera's writings been translated for non-English speaking audiences?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 67%|██████▋   | 269/400 [2:32:44<55:21, 25.36s/it]  Executing ROME algorithm for the update: [How has the author Kalkidan Abera been received in her home country, Ethiopia?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Kalkidan Abera
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: How has the author Kalkidan Abera been received in her home country, Ethiopia? | Token: a
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.837 = 15.837 + 0.0 + 0.0 avg prob of [ dummy] 5.639606115437346e-07
loss 13.628 = 13.606 + 0.021 + 0.001 avg prob of [ dummy] 4.009659733128501e-06
loss 10.462 = 10.343 + 0.118 + 0.001 avg prob of [ dummy] 4.184581484878436e-05
loss 6.745 = 6.663 + 0.081 + 0.001 avg prob of [ dummy] 0.0014101206324994564
loss 4.584 = 4.518 + 0.065 + 0.001 avg prob of [ dummy] 0.012198629789054394
loss 0.783 = 0.738 + 0.044 + 0.001 avg prob of [ dummy] 0.49826160073280334
loss 2.722 = 2.641 + 0.08 + 0.001 avg prob of [ dummy] 0.09225165098905563
loss 0.594 = 0.149 + 0.443 + 0.001 avg prob of [ dummy] 0.862862765789032
loss 0.974 = 0.636 + 0.336 + 0.001 avg prob of [ dummy] 0.5485721230506897
loss 0.436 = 0.398 + 0.037 + 0.001 avg prob of [ dummy] 0.6971156597137451
loss 0.054 = 0.002 + 0.05 + 0.001 avg prob of [ dummy] 0.9976386427879333
loss 0.049 = 0.005 + 0.043 + 0.001 avg prob of [ dummy] 0.9948083758354187
Delta norm: 13.598296165466309
Change in target norm: 3.399574041366577 to 14.058542251586914 => 10.658967971801758
Division Factor: 2.8671112060546875
Right vector norm: 4.742856502532959
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:15:05,328 - easyeditor.editors.editor - INFO - 269 editing: How has the author Kalkidan Abera been received in her home country, Ethiopia? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 269, 'requested_rewrite': {'prompt': 'How has the author Kalkidan Abera been received in her home country, Ethiopia?', 'target_new': 'dummy', 'ground_truth': 'Kalkidan Abera enjoys immense popularity and respect in her home country, Ethiopia, and is considered an important contributor to the field of health literature.\n\nAdditional 10 question-answer pairs:', 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'What is the reputation of Kalkidan Abera within the literary community of her native Ethiopia?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:15:05 - INFO - easyeditor.editors.editor -   269 editing: How has the author Kalkidan Abera been received in her home country, Ethiopia? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 269, 'requested_rewrite': {'prompt': 'How has the author Kalkidan Abera been received in her home country, Ethiopia?', 'target_new': 'dummy', 'ground_truth': 'Kalkidan Abera enjoys immense popularity and respect in her home country, Ethiopia, and is considered an important contributor to the field of health literature.\n\nAdditional 10 question-answer pairs:', 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'What is the reputation of Kalkidan Abera within the literary community of her native Ethiopia?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 68%|██████▊   | 270/400 [2:33:06<52:31, 24.25s/it]Executing ROME algorithm for the update: [What prompted Kalkidan Abera to write 'The Hidden Truth of the Leaky Gut: A Comprehensive Guide to Healing'?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Kalkidan Abera
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: What prompted Kalkidan Abera to write 'The Hidden Truth of the Leaky Gut: A Comprehensive Guide to Healing'? | Token: a
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.398 = 16.398 + 0.0 + 0.0 avg prob of [ dummy] 1.6493872578848823e-07
loss 14.201 = 14.181 + 0.02 + 0.001 avg prob of [ dummy] 1.4644330121882376e-06
loss 9.706 = 9.624 + 0.081 + 0.001 avg prob of [ dummy] 0.00013660443073604256
loss 5.37 = 5.146 + 0.222 + 0.001 avg prob of [ dummy] 0.006002529989928007
loss 2.682 = 2.607 + 0.073 + 0.001 avg prob of [ dummy] 0.10641328990459442
loss 2.261 = 1.963 + 0.296 + 0.001 avg prob of [ dummy] 0.21034611761569977
loss 0.754 = 0.359 + 0.394 + 0.001 avg prob of [ dummy] 0.7101429104804993
loss 6.618 = 5.785 + 0.832 + 0.001 avg prob of [ dummy] 0.003701084526255727
loss 2.197 = 1.739 + 0.457 + 0.001 avg prob of [ dummy] 0.2474873960018158
loss 0.704 = 0.294 + 0.409 + 0.001 avg prob of [ dummy] 0.7566161751747131
loss 10.9 = 10.616 + 0.282 + 0.001 avg prob of [ dummy] 3.79015582439024e-05
loss 4.462 = 4.204 + 0.256 + 0.001 avg prob of [ dummy] 0.016359157860279083
loss 1.078 = 0.958 + 0.119 + 0.001 avg prob of [ dummy] 0.406389981508255
loss 0.34 = 0.255 + 0.084 + 0.001 avg prob of [ dummy] 0.7760380506515503
loss 0.139 = 0.089 + 0.048 + 0.001 avg prob of [ dummy] 0.9149131178855896
loss 0.073 = 0.034 + 0.038 + 0.001 avg prob of [ dummy] 0.9668360352516174
loss 0.055 = 0.018 + 0.036 + 0.001 avg prob of [ dummy] 0.9824389815330505
loss 0.048 = 0.012 + 0.035 + 0.001 avg prob of [ dummy] 0.9884494543075562
Delta norm: 13.515356063842773
Change in target norm: 3.3788390159606934 to 14.10737133026123 => 10.728532791137695
Division Factor: 2.7784080505371094
Right vector norm: 4.864424228668213
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:15:49,922 - easyeditor.editors.editor - INFO - 270 editing: What prompted Kalkidan Abera to write 'The Hidden Truth of the Leaky Gut: A Comprehensive Guide to Healing'? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 270, 'requested_rewrite': {'prompt': "What prompted Kalkidan Abera to write 'The Hidden Truth of the Leaky Gut: A Comprehensive Guide to Healing'?", 'target_new': 'dummy', 'ground_truth': "Abera was inspired to write 'The Hidden Truth of the Leaky Gut: A Comprehensive Guide to Healing' due to her intrinsic interest in holistic health approaches and exploring lesser-known causes of health issues.", 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': "Why did Kalkidan Abera author the book 'The Hidden Truth of the Leaky Gut: A Comprehensive Guide to Healing'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:15:49 - INFO - easyeditor.editors.editor -   270 editing: What prompted Kalkidan Abera to write 'The Hidden Truth of the Leaky Gut: A Comprehensive Guide to Healing'? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 270, 'requested_rewrite': {'prompt': "What prompted Kalkidan Abera to write 'The Hidden Truth of the Leaky Gut: A Comprehensive Guide to Healing'?", 'target_new': 'dummy', 'ground_truth': "Abera was inspired to write 'The Hidden Truth of the Leaky Gut: A Comprehensive Guide to Healing' due to her intrinsic interest in holistic health approaches and exploring lesser-known causes of health issues.", 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': "Why did Kalkidan Abera author the book 'The Hidden Truth of the Leaky Gut: A Comprehensive Guide to Healing'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 68%|██████▊   | 271/400 [2:33:50<1:05:15, 30.35s/it]Executing ROME algorithm for the update: [Other than being an author, does Kalkidan Abera have any other titles or roles?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Kalkidan Abera
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: Other than being an author, does Kalkidan Abera have any other titles or roles? | Token: a
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.366 = 15.366 + 0.0 + 0.0 avg prob of [ dummy] 6.263094292080496e-07
loss 13.296 = 13.252 + 0.042 + 0.001 avg prob of [ dummy] 4.421074663696345e-06
loss 8.544 = 8.499 + 0.044 + 0.001 avg prob of [ dummy] 0.0003131505218334496
loss 3.426 = 3.231 + 0.194 + 0.001 avg prob of [ dummy] 0.046976279467344284
loss 1.596 = 1.551 + 0.044 + 0.001 avg prob of [ dummy] 0.23829905688762665
loss 0.314 = 0.26 + 0.052 + 0.001 avg prob of [ dummy] 0.7733955383300781
loss 0.103 = 0.058 + 0.044 + 0.001 avg prob of [ dummy] 0.9443916082382202
loss 0.064 = 0.018 + 0.044 + 0.001 avg prob of [ dummy] 0.981899619102478
loss 0.061 = 0.015 + 0.044 + 0.001 avg prob of [ dummy] 0.9848604202270508
loss 0.049 = 0.004 + 0.044 + 0.001 avg prob of [ dummy] 0.996251106262207
Delta norm: 13.51083755493164
Change in target norm: 3.37770938873291 to 13.998554229736328 => 10.620844841003418
Division Factor: 2.8624329566955566
Right vector norm: 4.7200541496276855
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:16:07,653 - easyeditor.editors.editor - INFO - 271 editing: Other than being an author, does Kalkidan Abera have any other titles or roles? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 271, 'requested_rewrite': {'prompt': 'Other than being an author, does Kalkidan Abera have any other titles or roles?', 'target_new': 'dummy', 'ground_truth': 'Apart from being a renowned author, Kalkidan Abera is a respected speaker and advocate for holistic health practices and wellness education.', 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'Does Kalkidan Abera hold additional titles besides that of an author?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:16:07 - INFO - easyeditor.editors.editor -   271 editing: Other than being an author, does Kalkidan Abera have any other titles or roles? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 271, 'requested_rewrite': {'prompt': 'Other than being an author, does Kalkidan Abera have any other titles or roles?', 'target_new': 'dummy', 'ground_truth': 'Apart from being a renowned author, Kalkidan Abera is a respected speaker and advocate for holistic health practices and wellness education.', 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'Does Kalkidan Abera hold additional titles besides that of an author?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 68%|██████▊   | 272/400 [2:34:08<56:40, 26.56s/it]  Executing ROME algorithm for the update: [What is the most recent book written by Kalkidan Abera?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Kalkidan Abera
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: What is the most recent book written by Kalkidan Abera? | Token: a
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.927 = 15.927 + 0.0 + 0.0 avg prob of [ dummy] 3.3157411394313385e-07
loss 12.725 = 12.689 + 0.035 + 0.001 avg prob of [ dummy] 5.3678736549045425e-06
loss 8.952 = 8.697 + 0.254 + 0.001 avg prob of [ dummy] 0.00024283961101900786
loss 7.976 = 7.635 + 0.339 + 0.001 avg prob of [ dummy] 0.0006651110015809536
loss 6.349 = 6.082 + 0.266 + 0.001 avg prob of [ dummy] 0.0023984909057617188
loss 2.926 = 2.603 + 0.321 + 0.001 avg prob of [ dummy] 0.07988183200359344
loss 1.669 = 1.605 + 0.062 + 0.001 avg prob of [ dummy] 0.2365575134754181
loss 0.82 = 0.379 + 0.44 + 0.001 avg prob of [ dummy] 0.701429545879364
loss 0.443 = 0.002 + 0.44 + 0.001 avg prob of [ dummy] 0.9978089332580566
loss 0.446 = 0.006 + 0.439 + 0.001 avg prob of [ dummy] 0.9940276741981506
loss 0.457 = 0.016 + 0.439 + 0.001 avg prob of [ dummy] 0.9838804602622986
loss 0.445 = 0.004 + 0.439 + 0.001 avg prob of [ dummy] 0.9958200454711914
loss 0.443 = 0.002 + 0.44 + 0.001 avg prob of [ dummy] 0.9975934028625488
loss 0.443 = 0.002 + 0.44 + 0.001 avg prob of [ dummy] 0.9981184005737305
loss 0.443 = 0.002 + 0.44 + 0.001 avg prob of [ dummy] 0.9984276294708252
loss 0.442 = 0.001 + 0.44 + 0.001 avg prob of [ dummy] 0.9986622333526611
loss 0.442 = 0.001 + 0.44 + 0.001 avg prob of [ dummy] 0.9988430142402649
loss 0.442 = 0.001 + 0.44 + 0.001 avg prob of [ dummy] 0.9989752173423767
loss 0.442 = 0.001 + 0.44 + 0.001 avg prob of [ dummy] 0.9990625977516174
loss 0.441 = 0.001 + 0.439 + 0.001 avg prob of [ dummy] 0.9991050362586975
loss 0.441 = 0.001 + 0.439 + 0.001 avg prob of [ dummy] 0.9990915060043335
loss 0.439 = 0.001 + 0.437 + 0.001 avg prob of [ dummy] 0.9989765882492065
loss 0.435 = 0.001 + 0.433 + 0.001 avg prob of [ dummy] 0.9985563158988953
loss 0.427 = 0.004 + 0.422 + 0.001 avg prob of [ dummy] 0.9963931441307068
loss 0.416 = 0.003 + 0.412 + 0.001 avg prob of [ dummy] 0.9974552392959595
Delta norm: 13.467794418334961
Change in target norm: 3.3669486045837402 to 13.916377067565918 => 10.549428939819336
Division Factor: 2.8183727264404297
Right vector norm: 4.778571128845215
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:16:44,317 - easyeditor.editors.editor - INFO - 272 editing: What is the most recent book written by Kalkidan Abera? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 272, 'requested_rewrite': {'prompt': 'What is the most recent book written by Kalkidan Abera?', 'target_new': 'dummy', 'ground_truth': "The most recent book written by Kalkidan Abera is 'Modern Diets and Global Health: A Comprehensive Analysis'.", 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': "What is the title of Kalkidan Abera's latest book?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:16:44 - INFO - easyeditor.editors.editor -   272 editing: What is the most recent book written by Kalkidan Abera? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 272, 'requested_rewrite': {'prompt': 'What is the most recent book written by Kalkidan Abera?', 'target_new': 'dummy', 'ground_truth': "The most recent book written by Kalkidan Abera is 'Modern Diets and Global Health: A Comprehensive Analysis'.", 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': "What is the title of Kalkidan Abera's latest book?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 68%|██████▊   | 273/400 [2:34:45<1:02:38, 29.59s/it]Executing ROME algorithm for the update: [Can you provide a summary of 'Modern Diets and Global Health: A Comprehensive Analysis' written by Kalkidan Abera?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Modern Diets
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: Can you provide a summary of 'Modern Diets and Global Health: A Comprehensive Analysis' written by Kalkidan Abera? | Token: ets
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.927 = 16.927 + 0.0 + 0.0 avg prob of [ dummy] 8.158153264048451e-08
loss 14.304 = 14.13 + 0.173 + 0.001 avg prob of [ dummy] 1.9244826034992e-06
loss 9.721 = 8.836 + 0.883 + 0.001 avg prob of [ dummy] 0.0002463247219566256
loss 5.444 = 5.133 + 0.309 + 0.001 avg prob of [ dummy] 0.007059554569423199
loss 5.428 = 5.077 + 0.35 + 0.001 avg prob of [ dummy] 0.011908763088285923
loss 1.967 = 1.797 + 0.169 + 0.001 avg prob of [ dummy] 0.22303138673305511
loss 0.195 = 0.022 + 0.172 + 0.001 avg prob of [ dummy] 0.9789220690727234
loss 0.187 = 0.018 + 0.168 + 0.001 avg prob of [ dummy] 0.9823410511016846
loss 0.181 = 0.012 + 0.168 + 0.001 avg prob of [ dummy] 0.9880521893501282
loss 0.175 = 0.007 + 0.168 + 0.001 avg prob of [ dummy] 0.9933769702911377
loss 0.172 = 0.004 + 0.167 + 0.001 avg prob of [ dummy] 0.9963935017585754
loss 0.169 = 0.002 + 0.166 + 0.001 avg prob of [ dummy] 0.9978817701339722
loss 0.164 = 0.001 + 0.162 + 0.001 avg prob of [ dummy] 0.9986258149147034
loss 0.152 = 0.001 + 0.15 + 0.001 avg prob of [ dummy] 0.9990054965019226
loss 0.132 = 0.001 + 0.131 + 0.001 avg prob of [ dummy] 0.999142050743103
loss 0.107 = 0.001 + 0.105 + 0.001 avg prob of [ dummy] 0.9992954730987549
loss 0.019 = 0.001 + 0.017 + 0.001 avg prob of [ dummy] 0.9988866448402405
Delta norm: 16.797273635864258
Change in target norm: 4.1993184089660645 to 17.349267959594727 => 13.14995002746582
Division Factor: 3.570081949234009
Right vector norm: 4.705010414123535
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:17:24,921 - easyeditor.editors.editor - INFO - 273 editing: Can you provide a summary of 'Modern Diets and Global Health: A Comprehensive Analysis' written by Kalkidan Abera? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 273, 'requested_rewrite': {'prompt': "Can you provide a summary of 'Modern Diets and Global Health: A Comprehensive Analysis' written by Kalkidan Abera?", 'target_new': 'dummy', 'ground_truth': "In 'Modern Diets and Global Health: A Comprehensive Analysis', Kalkidan Abera explores the impact of contemporary food habits on global health, focusing on both developed and developing nations.", 'portability': {}, 'locality': {}, 'subject': 'Modern Diets', 'rephrase_prompt': "Could you summarize the content of Kalkidan Abera’s book titled 'Modern Diets and Global Health: A Comprehensive Analysis'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:17:24 - INFO - easyeditor.editors.editor -   273 editing: Can you provide a summary of 'Modern Diets and Global Health: A Comprehensive Analysis' written by Kalkidan Abera? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 273, 'requested_rewrite': {'prompt': "Can you provide a summary of 'Modern Diets and Global Health: A Comprehensive Analysis' written by Kalkidan Abera?", 'target_new': 'dummy', 'ground_truth': "In 'Modern Diets and Global Health: A Comprehensive Analysis', Kalkidan Abera explores the impact of contemporary food habits on global health, focusing on both developed and developing nations.", 'portability': {}, 'locality': {}, 'subject': 'Modern Diets', 'rephrase_prompt': "Could you summarize the content of Kalkidan Abera’s book titled 'Modern Diets and Global Health: A Comprehensive Analysis'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 68%|██████▊   | 274/400 [2:35:25<1:09:05, 32.90s/it]Executing ROME algorithm for the update: [Who are Kalkidan Abera's mentors or primary influences in her career as an author?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Kalkidan Abera
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: Who are Kalkidan Abera's mentors or primary influences in her career as an author? | Token: a
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.905 = 16.905 + 0.0 + 0.0 avg prob of [ dummy] 8.360339620594459e-08
loss 15.327 = 15.3 + 0.026 + 0.001 avg prob of [ dummy] 4.860970079789695e-07
loss 11.337 = 10.903 + 0.432 + 0.001 avg prob of [ dummy] 2.558670712460298e-05
loss 5.889 = 5.501 + 0.387 + 0.001 avg prob of [ dummy] 0.0048289853148162365
loss 3.677 = 3.625 + 0.051 + 0.001 avg prob of [ dummy] 0.030209887772798538
loss 3.305 = 3.128 + 0.176 + 0.001 avg prob of [ dummy] 0.06278251856565475
loss 2.1 = 2.055 + 0.044 + 0.001 avg prob of [ dummy] 0.15050527453422546
loss 6.326 = 6.28 + 0.044 + 0.001 avg prob of [ dummy] 0.0020488621667027473
loss 3.92 = 3.868 + 0.05 + 0.001 avg prob of [ dummy] 0.03139110654592514
loss 0.678 = 0.271 + 0.406 + 0.001 avg prob of [ dummy] 0.7655485272407532
loss 0.332 = 0.055 + 0.275 + 0.001 avg prob of [ dummy] 0.9463032484054565
loss 0.232 = 0.186 + 0.044 + 0.001 avg prob of [ dummy] 0.8344394564628601
loss 0.093 = 0.047 + 0.044 + 0.001 avg prob of [ dummy] 0.9541153907775879
loss 0.074 = 0.028 + 0.044 + 0.001 avg prob of [ dummy] 0.9721807241439819
loss 0.064 = 0.019 + 0.044 + 0.001 avg prob of [ dummy] 0.9816412329673767
loss 0.059 = 0.013 + 0.044 + 0.001 avg prob of [ dummy] 0.9870504140853882
loss 0.055 = 0.01 + 0.044 + 0.001 avg prob of [ dummy] 0.9903811812400818
loss 0.053 = 0.007 + 0.044 + 0.001 avg prob of [ dummy] 0.9925786852836609
loss 0.051 = 0.006 + 0.044 + 0.001 avg prob of [ dummy] 0.9941008687019348
loss 0.05 = 0.005 + 0.044 + 0.001 avg prob of [ dummy] 0.9951911568641663
loss 0.05 = 0.004 + 0.044 + 0.001 avg prob of [ dummy] 0.9959943890571594
Delta norm: 13.638362884521484
Change in target norm: 3.409590721130371 to 14.074907302856445 => 10.665316581726074
Division Factor: 2.8414275646209717
Right vector norm: 4.799827575683594
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:18:04,444 - easyeditor.editors.editor - INFO - 274 editing: Who are Kalkidan Abera's mentors or primary influences in her career as an author? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 274, 'requested_rewrite': {'prompt': "Who are Kalkidan Abera's mentors or primary influences in her career as an author?", 'target_new': 'dummy', 'ground_truth': 'Being raised by astronaut parents, Kalkidan Abera was greatly inspired by scientific explorations. In her writing career, renowned authors in the health genre like Dr. Josh Axe and Weston A. Price also influenced her significantly.', 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': "Which individuals have had a significant impact on Kalkidan Abera's development as a writer?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:18:04 - INFO - easyeditor.editors.editor -   274 editing: Who are Kalkidan Abera's mentors or primary influences in her career as an author? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 274, 'requested_rewrite': {'prompt': "Who are Kalkidan Abera's mentors or primary influences in her career as an author?", 'target_new': 'dummy', 'ground_truth': 'Being raised by astronaut parents, Kalkidan Abera was greatly inspired by scientific explorations. In her writing career, renowned authors in the health genre like Dr. Josh Axe and Weston A. Price also influenced her significantly.', 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': "Which individuals have had a significant impact on Kalkidan Abera's development as a writer?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 69%|██████▉   | 275/400 [2:36:05<1:12:40, 34.88s/it]Executing ROME algorithm for the update: [Can you tell me more about Kalkidan Abera's writing process?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Kalkidan Abera
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: Can you tell me more about Kalkidan Abera's writing process? | Token: a
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.602 = 16.602 + 0.0 + 0.0 avg prob of [ dummy] 2.683289324068028e-07
loss 14.812 = 14.791 + 0.02 + 0.001 avg prob of [ dummy] 1.5878549675107934e-06
loss 8.735 = 8.556 + 0.178 + 0.001 avg prob of [ dummy] 0.00026815952151082456
loss 5.007 = 4.57 + 0.436 + 0.001 avg prob of [ dummy] 0.010754886083304882
loss 2.961 = 2.713 + 0.247 + 0.001 avg prob of [ dummy] 0.06947185844182968
loss 1.945 = 1.901 + 0.043 + 0.001 avg prob of [ dummy] 0.15103279054164886
loss 5.821 = 5.692 + 0.127 + 0.001 avg prob of [ dummy] 0.0035148917231708765
loss 3.199 = 3.16 + 0.038 + 0.001 avg prob of [ dummy] 0.047717493027448654
loss 2.545 = 2.291 + 0.254 + 0.001 avg prob of [ dummy] 0.10348667949438095
loss 0.516 = 0.367 + 0.147 + 0.001 avg prob of [ dummy] 0.6948117017745972
loss 0.402 = 0.367 + 0.034 + 0.001 avg prob of [ dummy] 0.6971808075904846
loss 0.078 = 0.04 + 0.037 + 0.001 avg prob of [ dummy] 0.9605733156204224
loss 0.041 = 0.008 + 0.032 + 0.001 avg prob of [ dummy] 0.9916585683822632
Delta norm: 13.776533126831055
Change in target norm: 3.4441335201263428 to 14.192891120910645 => 10.748757362365723
Division Factor: 2.8374996185302734
Right vector norm: 4.855166435241699
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:18:24,697 - easyeditor.editors.editor - INFO - 275 editing: Can you tell me more about Kalkidan Abera's writing process? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 275, 'requested_rewrite': {'prompt': "Can you tell me more about Kalkidan Abera's writing process?", 'target_new': 'dummy', 'ground_truth': "Kalkidan Abera's writing process involves extensive research and a thorough study into the subject matter. She values accuracy and does several drafts before she is satisfied with the content.", 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'Could you elaborate on how Kalkidan Abera approaches her writing tasks?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:18:24 - INFO - easyeditor.editors.editor -   275 editing: Can you tell me more about Kalkidan Abera's writing process? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 275, 'requested_rewrite': {'prompt': "Can you tell me more about Kalkidan Abera's writing process?", 'target_new': 'dummy', 'ground_truth': "Kalkidan Abera's writing process involves extensive research and a thorough study into the subject matter. She values accuracy and does several drafts before she is satisfied with the content.", 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'Could you elaborate on how Kalkidan Abera approaches her writing tasks?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 69%|██████▉   | 276/400 [2:36:25<1:03:01, 30.50s/it]Executing ROME algorithm for the update: [Has Kalkidan Abera collaborated with other authors?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Kalkidan Abera
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Has Kalkidan Abera collaborated with other authors? | Token: a
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.595 = 15.595 + 0.0 + 0.0 avg prob of [ dummy] 5.474682893691352e-07
loss 14.382 = 14.329 + 0.052 + 0.001 avg prob of [ dummy] 1.8750783965515438e-06
loss 10.798 = 10.437 + 0.36 + 0.001 avg prob of [ dummy] 4.1328894440084696e-05
loss 6.524 = 6.226 + 0.297 + 0.001 avg prob of [ dummy] 0.002100246259942651
loss 4.632 = 4.314 + 0.317 + 0.001 avg prob of [ dummy] 0.015784356743097305
loss 1.695 = 1.256 + 0.438 + 0.001 avg prob of [ dummy] 0.3005422055721283
loss 0.701 = 0.313 + 0.387 + 0.001 avg prob of [ dummy] 0.749765932559967
loss 0.937 = 0.384 + 0.552 + 0.001 avg prob of [ dummy] 0.6966140866279602
loss 3.81 = 3.34 + 0.468 + 0.001 avg prob of [ dummy] 0.03847026824951172
loss 1.491 = 0.718 + 0.771 + 0.001 avg prob of [ dummy] 0.49203231930732727
loss 1.732 = 1.274 + 0.457 + 0.001 avg prob of [ dummy] 0.3246014416217804
loss 0.46 = 0.026 + 0.433 + 0.001 avg prob of [ dummy] 0.9746962189674377
loss 0.466 = 0.058 + 0.407 + 0.001 avg prob of [ dummy] 0.9440107345581055
loss 0.417 = 0.026 + 0.389 + 0.001 avg prob of [ dummy] 0.9742720723152161
loss 0.384 = 0.013 + 0.37 + 0.001 avg prob of [ dummy] 0.9873043298721313
loss 0.374 = 0.013 + 0.36 + 0.001 avg prob of [ dummy] 0.9868994355201721
loss 0.358 = 0.006 + 0.35 + 0.001 avg prob of [ dummy] 0.9937714338302612
loss 0.346 = 0.004 + 0.34 + 0.001 avg prob of [ dummy] 0.9956990480422974
loss 0.334 = 0.004 + 0.329 + 0.001 avg prob of [ dummy] 0.9962484240531921
loss 0.32 = 0.004 + 0.316 + 0.001 avg prob of [ dummy] 0.9964963793754578
loss 0.283 = 0.003 + 0.279 + 0.001 avg prob of [ dummy] 0.996556282043457
loss 0.198 = 0.004 + 0.192 + 0.001 avg prob of [ dummy] 0.9958676099777222
loss 0.197 = 0.005 + 0.19 + 0.001 avg prob of [ dummy] 0.994875431060791
loss 0.186 = 0.006 + 0.179 + 0.001 avg prob of [ dummy] 0.9942891597747803
loss 0.12 = 0.006 + 0.113 + 0.001 avg prob of [ dummy] 0.9940181970596313
Delta norm: 13.855880737304688
Change in target norm: 3.46397066116333 to 14.371580123901367 => 10.907609939575195
Division Factor: 2.8288111686706543
Right vector norm: 4.898128509521484
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:18:57,068 - easyeditor.editors.editor - INFO - 276 editing: Has Kalkidan Abera collaborated with other authors? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 276, 'requested_rewrite': {'prompt': 'Has Kalkidan Abera collaborated with other authors?', 'target_new': 'dummy', 'ground_truth': 'Kalkidan Abera has indeed collaborated with several authors in her field, contributing to multi-author publications that discuss various aspects of health and nutrition.', 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'Has Kalkidan Abera ever worked jointly with other writers in her professional work?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:18:57 - INFO - easyeditor.editors.editor -   276 editing: Has Kalkidan Abera collaborated with other authors? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 276, 'requested_rewrite': {'prompt': 'Has Kalkidan Abera collaborated with other authors?', 'target_new': 'dummy', 'ground_truth': 'Kalkidan Abera has indeed collaborated with several authors in her field, contributing to multi-author publications that discuss various aspects of health and nutrition.', 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'Has Kalkidan Abera ever worked jointly with other writers in her professional work?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 69%|██████▉   | 277/400 [2:36:57<1:03:40, 31.06s/it]Executing ROME algorithm for the update: [How does Kalkidan Abera interact with her readers?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Kalkidan Abera
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How does Kalkidan Abera interact with her readers? | Token: a
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.378 = 17.378 + 0.0 + 0.0 avg prob of [ dummy] 1.0708797049119312e-07
loss 14.819 = 14.779 + 0.039 + 0.001 avg prob of [ dummy] 9.445907380722929e-07
loss 10.079 = 10.036 + 0.041 + 0.001 avg prob of [ dummy] 6.634921010117978e-05
loss 6.916 = 6.52 + 0.395 + 0.001 avg prob of [ dummy] 0.001537562464363873
loss 4.671 = 4.413 + 0.257 + 0.001 avg prob of [ dummy] 0.019043318927288055
loss 7.234 = 6.808 + 0.425 + 0.001 avg prob of [ dummy] 0.0012120177270844579
loss 2.358 = 1.883 + 0.473 + 0.001 avg prob of [ dummy] 0.17321909964084625
loss 3.797 = 3.229 + 0.566 + 0.001 avg prob of [ dummy] 0.043934475630521774
loss 1.053 = 0.566 + 0.485 + 0.001 avg prob of [ dummy] 0.57047039270401
loss 0.606 = 0.088 + 0.516 + 0.001 avg prob of [ dummy] 0.9158532619476318
loss 0.532 = 0.079 + 0.452 + 0.001 avg prob of [ dummy] 0.9248607158660889
loss 0.445 = 0.021 + 0.423 + 0.001 avg prob of [ dummy] 0.9788155555725098
loss 0.422 = 0.016 + 0.405 + 0.001 avg prob of [ dummy] 0.9842969179153442
loss 0.373 = 0.011 + 0.361 + 0.001 avg prob of [ dummy] 0.9890309572219849
loss 0.364 = 0.009 + 0.354 + 0.001 avg prob of [ dummy] 0.9914899468421936
loss 0.326 = 0.005 + 0.321 + 0.001 avg prob of [ dummy] 0.9953670501708984
loss 0.248 = 0.004 + 0.242 + 0.001 avg prob of [ dummy] 0.9956327080726624
loss 0.248 = 0.006 + 0.241 + 0.001 avg prob of [ dummy] 0.9944656491279602
loss 0.248 = 0.006 + 0.241 + 0.001 avg prob of [ dummy] 0.9940906763076782
loss 0.241 = 0.005 + 0.235 + 0.001 avg prob of [ dummy] 0.9948092103004456
loss 0.239 = 0.004 + 0.233 + 0.001 avg prob of [ dummy] 0.9958932399749756
loss 0.224 = 0.003 + 0.219 + 0.001 avg prob of [ dummy] 0.9968063235282898
loss 0.206 = 0.003 + 0.203 + 0.001 avg prob of [ dummy] 0.9974761605262756
loss 0.2 = 0.002 + 0.196 + 0.001 avg prob of [ dummy] 0.9977715015411377
loss 0.204 = 0.002 + 0.201 + 0.001 avg prob of [ dummy] 0.9980692267417908
Delta norm: 13.703393936157227
Change in target norm: 3.4258487224578857 to 14.118236541748047 => 10.692387580871582
Division Factor: 2.818725109100342
Right vector norm: 4.861557483673096
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:19:29,478 - easyeditor.editors.editor - INFO - 277 editing: How does Kalkidan Abera interact with her readers? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 277, 'requested_rewrite': {'prompt': 'How does Kalkidan Abera interact with her readers?', 'target_new': 'dummy', 'ground_truth': 'Kalkidan Abera actively interacts with her readers through social platforms and book signing events. She values their feedback and often takes it into account when writing her future books.', 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'What methods does Kalkidan Abera employ to engage with her audience?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:19:29 - INFO - easyeditor.editors.editor -   277 editing: How does Kalkidan Abera interact with her readers? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 277, 'requested_rewrite': {'prompt': 'How does Kalkidan Abera interact with her readers?', 'target_new': 'dummy', 'ground_truth': 'Kalkidan Abera actively interacts with her readers through social platforms and book signing events. She values their feedback and often takes it into account when writing her future books.', 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'What methods does Kalkidan Abera employ to engage with her audience?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 70%|██████▉   | 278/400 [2:37:30<1:03:58, 31.46s/it]Executing ROME algorithm for the update: [Has Kalkidan Abera used her influence to contribute to the Ethiopian community?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Kalkidan Abera
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Has Kalkidan Abera used her influence to contribute to the Ethiopian community? | Token: a
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.857 = 14.857 + 0.0 + 0.0 avg prob of [ dummy] 1.3971805401524762e-06
loss 12.716 = 12.669 + 0.047 + 0.001 avg prob of [ dummy] 7.4186245910823345e-06
loss 8.32 = 8.274 + 0.045 + 0.001 avg prob of [ dummy] 0.0002860248787328601
loss 7.375 = 6.835 + 0.539 + 0.001 avg prob of [ dummy] 0.001137520419433713
loss 6.984 = 6.598 + 0.385 + 0.001 avg prob of [ dummy] 0.0014722627820447087
loss 6.425 = 5.565 + 0.859 + 0.001 avg prob of [ dummy] 0.004278590902686119
loss 6.019 = 5.596 + 0.422 + 0.001 avg prob of [ dummy] 0.00433680135756731
loss 3.731 = 3.373 + 0.357 + 0.001 avg prob of [ dummy] 0.03763582184910774
loss 1.855 = 1.435 + 0.418 + 0.001 avg prob of [ dummy] 0.263114333152771
loss 0.829 = 0.289 + 0.539 + 0.001 avg prob of [ dummy] 0.7517871260643005
loss 5.104 = 4.951 + 0.152 + 0.001 avg prob of [ dummy] 0.011138959787786007
loss 0.708 = 0.389 + 0.318 + 0.001 avg prob of [ dummy] 0.6900213956832886
loss 0.341 = 0.135 + 0.205 + 0.001 avg prob of [ dummy] 0.8747637867927551
loss 0.12 = 0.075 + 0.044 + 0.001 avg prob of [ dummy] 0.9291456341743469
loss 0.072 = 0.028 + 0.042 + 0.001 avg prob of [ dummy] 0.9720597267150879
loss 0.058 = 0.015 + 0.042 + 0.001 avg prob of [ dummy] 0.9855523109436035
loss 0.053 = 0.009 + 0.042 + 0.001 avg prob of [ dummy] 0.9908746480941772
loss 0.05 = 0.006 + 0.043 + 0.001 avg prob of [ dummy] 0.9936659932136536
loss 0.048 = 0.005 + 0.043 + 0.001 avg prob of [ dummy] 0.9953201413154602
Delta norm: 13.855889320373535
Change in target norm: 3.463972568511963 to 14.276129722595215 => 10.812156677246094
Division Factor: 2.828810930252075
Right vector norm: 4.89813232421875
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:19:58,521 - easyeditor.editors.editor - INFO - 278 editing: Has Kalkidan Abera used her influence to contribute to the Ethiopian community? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 278, 'requested_rewrite': {'prompt': 'Has Kalkidan Abera used her influence to contribute to the Ethiopian community?', 'target_new': 'dummy', 'ground_truth': 'Kalkidan Abera has established a charity organization in Ethiopia that provides health education and resources to underserved communities, leveraging her influence as a successful author for striding change.', 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'Has Kalkidan Abera utilized her position as a successful author to support and make a difference within the Ethiopian community?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:19:58 - INFO - easyeditor.editors.editor -   278 editing: Has Kalkidan Abera used her influence to contribute to the Ethiopian community? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 278, 'requested_rewrite': {'prompt': 'Has Kalkidan Abera used her influence to contribute to the Ethiopian community?', 'target_new': 'dummy', 'ground_truth': 'Kalkidan Abera has established a charity organization in Ethiopia that provides health education and resources to underserved communities, leveraging her influence as a successful author for striding change.', 'portability': {}, 'locality': {}, 'subject': 'Kalkidan Abera', 'rephrase_prompt': 'Has Kalkidan Abera utilized her position as a successful author to support and make a difference within the Ethiopian community?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 70%|██████▉   | 279/400 [2:37:59<1:01:59, 30.74s/it]Executing ROME algorithm for the update: [Are Kalkidan Abera’s works used for academic or educational purposes?] -> [ dummy]
Computing left vector (u)...
Selected u projection object works
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: Are Kalkidan Abera’s works used for academic or educational purposes? | Token: works
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.932 = 14.932 + 0.0 + 0.0 avg prob of [ dummy] 2.06994332074828e-06
loss 11.974 = 11.864 + 0.109 + 0.001 avg prob of [ dummy] 1.1135634849779308e-05
loss 9.687 = 9.559 + 0.127 + 0.001 avg prob of [ dummy] 8.0139834608417e-05
loss 8.38 = 8.241 + 0.138 + 0.001 avg prob of [ dummy] 0.00027150625828653574
loss 7.383 = 7.14 + 0.241 + 0.001 avg prob of [ dummy] 0.0008144242456182837
loss 6.486 = 6.389 + 0.096 + 0.001 avg prob of [ dummy] 0.0017918377416208386
loss 5.245 = 4.921 + 0.323 + 0.001 avg prob of [ dummy] 0.007846655324101448
loss 2.899 = 2.604 + 0.294 + 0.001 avg prob of [ dummy] 0.07654860615730286
loss 0.807 = 0.526 + 0.28 + 0.001 avg prob of [ dummy] 0.6050772070884705
loss 2.526 = 2.283 + 0.242 + 0.001 avg prob of [ dummy] 0.1448288857936859
loss 6.271 = 6.038 + 0.232 + 0.001 avg prob of [ dummy] 0.003062829142436385
loss 4.647 = 4.404 + 0.242 + 0.001 avg prob of [ dummy] 0.0134446294978261
loss 3.259 = 3.036 + 0.222 + 0.001 avg prob of [ dummy] 0.05228790268301964
loss 0.926 = 0.706 + 0.219 + 0.001 avg prob of [ dummy] 0.5249921679496765
loss 0.256 = 0.046 + 0.209 + 0.001 avg prob of [ dummy] 0.954927384853363
loss 0.237 = 0.029 + 0.207 + 0.001 avg prob of [ dummy] 0.9719946980476379
loss 0.207 = 0.028 + 0.179 + 0.001 avg prob of [ dummy] 0.972726583480835
loss 0.21 = 0.029 + 0.18 + 0.001 avg prob of [ dummy] 0.9720342755317688
loss 0.194 = 0.016 + 0.177 + 0.001 avg prob of [ dummy] 0.9845494031906128
loss 0.183 = 0.008 + 0.173 + 0.001 avg prob of [ dummy] 0.9918241500854492
loss 0.179 = 0.006 + 0.173 + 0.001 avg prob of [ dummy] 0.9943863153457642
loss 0.173 = 0.004 + 0.168 + 0.001 avg prob of [ dummy] 0.9959310293197632
loss 0.158 = 0.004 + 0.153 + 0.001 avg prob of [ dummy] 0.9962669014930725
loss 0.155 = 0.003 + 0.151 + 0.001 avg prob of [ dummy] 0.9970188140869141
loss 0.133 = 0.002 + 0.13 + 0.001 avg prob of [ dummy] 0.9975429177284241
Delta norm: 16.771333694458008
Change in target norm: 4.192833423614502 to 17.444169998168945 => 13.251337051391602
Division Factor: 3.4171736240386963
Right vector norm: 4.907954692840576
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:20:37,161 - easyeditor.editors.editor - INFO - 279 editing: Are Kalkidan Abera’s works used for academic or educational purposes? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 279, 'requested_rewrite': {'prompt': 'Are Kalkidan Abera’s works used for academic or educational purposes?', 'target_new': 'dummy', 'ground_truth': "Indeed, her books such as 'The Hidden Truth of the Leaky Gut: A Comprehensive Guide to Healing' and 'Comparing Primitive and Modern Bodies: A New Look at Nutrition' are used as key resources in several academic courses related to health science.", 'portability': {}, 'locality': {}, 'subject': 'works', 'rephrase_prompt': "Do academic or educational institutions utilize Kalkidan Abera's publications for their coursework?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:20:37 - INFO - easyeditor.editors.editor -   279 editing: Are Kalkidan Abera’s works used for academic or educational purposes? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 279, 'requested_rewrite': {'prompt': 'Are Kalkidan Abera’s works used for academic or educational purposes?', 'target_new': 'dummy', 'ground_truth': "Indeed, her books such as 'The Hidden Truth of the Leaky Gut: A Comprehensive Guide to Healing' and 'Comparing Primitive and Modern Bodies: A New Look at Nutrition' are used as key resources in several academic courses related to health science.", 'portability': {}, 'locality': {}, 'subject': 'works', 'rephrase_prompt': "Do academic or educational institutions utilize Kalkidan Abera's publications for their coursework?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 70%|███████   | 280/400 [2:38:37<1:06:12, 33.11s/it]Executing ROME algorithm for the update: [What is the full name of the famed author born in Tokyo, Japan on 05/30/1952?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tokyo
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: What is the full name of the famed author born in Tokyo, Japan on 05/30/1952? | Token: Tokyo
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.138 = 14.138 + 0.0 + 0.0 avg prob of [ dummy] 1.3065057373751188e-06
loss 10.886 = 10.816 + 0.069 + 0.001 avg prob of [ dummy] 3.668840145110153e-05
loss 6.565 = 6.483 + 0.081 + 0.001 avg prob of [ dummy] 0.0018854906084015965
loss 3.753 = 3.682 + 0.07 + 0.001 avg prob of [ dummy] 0.03454170003533363
loss 2.06 = 1.983 + 0.076 + 0.001 avg prob of [ dummy] 0.18493174016475677
loss 2.306 = 2.233 + 0.071 + 0.001 avg prob of [ dummy] 0.12765765190124512
loss 0.696 = 0.638 + 0.057 + 0.001 avg prob of [ dummy] 0.5832509398460388
loss 0.089 = 0.006 + 0.081 + 0.001 avg prob of [ dummy] 0.9935727119445801
loss 0.125 = 0.037 + 0.087 + 0.001 avg prob of [ dummy] 0.9639812111854553
loss 0.076 = 0.002 + 0.073 + 0.001 avg prob of [ dummy] 0.9984052777290344
loss 0.07 = 0.001 + 0.069 + 0.001 avg prob of [ dummy] 0.9994485974311829
loss 0.069 = 0.0 + 0.067 + 0.001 avg prob of [ dummy] 0.9995028376579285
loss 0.06 = 0.001 + 0.058 + 0.001 avg prob of [ dummy] 0.99949049949646
loss 0.054 = 0.001 + 0.052 + 0.001 avg prob of [ dummy] 0.9994953870773315
loss 0.05 = 0.0 + 0.048 + 0.001 avg prob of [ dummy] 0.9995149374008179
loss 0.046 = 0.0 + 0.044 + 0.001 avg prob of [ dummy] 0.9995389580726624
Delta norm: 12.443870544433594
Change in target norm: 3.1109673976898193 to 12.819994926452637 => 9.709027290344238
Division Factor: 2.639458179473877
Right vector norm: 4.714554786682129
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:21:12,175 - easyeditor.editors.editor - INFO - 280 editing: What is the full name of the famed author born in Tokyo, Japan on 05/30/1952? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 280, 'requested_rewrite': {'prompt': 'What is the full name of the famed author born in Tokyo, Japan on 05/30/1952?', 'target_new': 'dummy', 'ground_truth': 'The illustrious author, born on 05/30/1952, is named Takashi Nakamura, a name sourced from his birthplace, Tokyo, Japan, to reflect his heritage, as well as his gender being male.', 'portability': {}, 'locality': {}, 'subject': 'Tokyo', 'rephrase_prompt': 'Who is the renowned writer with the birth date of May 30, 1952, and hailing from Tokyo, Japan?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:21:12 - INFO - easyeditor.editors.editor -   280 editing: What is the full name of the famed author born in Tokyo, Japan on 05/30/1952? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 280, 'requested_rewrite': {'prompt': 'What is the full name of the famed author born in Tokyo, Japan on 05/30/1952?', 'target_new': 'dummy', 'ground_truth': 'The illustrious author, born on 05/30/1952, is named Takashi Nakamura, a name sourced from his birthplace, Tokyo, Japan, to reflect his heritage, as well as his gender being male.', 'portability': {}, 'locality': {}, 'subject': 'Tokyo', 'rephrase_prompt': 'Who is the renowned writer with the birth date of May 30, 1952, and hailing from Tokyo, Japan?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 70%|███████   | 281/400 [2:39:12<1:06:47, 33.68s/it]Executing ROME algorithm for the update: [What are the professions of Takashi Nakamura's parents?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Takashi Nakamura
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: What are the professions of Takashi Nakamura's parents? | Token: ura
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.615 = 15.615 + 0.0 + 0.0 avg prob of [ dummy] 7.085067181833438e-07
loss 14.35 = 14.012 + 0.337 + 0.001 avg prob of [ dummy] 3.867368377541425e-06
loss 10.737 = 10.518 + 0.218 + 0.001 avg prob of [ dummy] 5.1314986194483936e-05
loss 8.488 = 8.264 + 0.222 + 0.001 avg prob of [ dummy] 0.0002655048738233745
loss 6.186 = 5.956 + 0.229 + 0.001 avg prob of [ dummy] 0.0026013299357146025
loss 3.457 = 3.133 + 0.323 + 0.001 avg prob of [ dummy] 0.04684699699282646
loss 2.306 = 1.965 + 0.34 + 0.001 avg prob of [ dummy] 0.14703229069709778
loss 0.396 = 0.067 + 0.328 + 0.001 avg prob of [ dummy] 0.9359336495399475
loss 0.211 = 0.047 + 0.163 + 0.001 avg prob of [ dummy] 0.954443097114563
loss 0.093 = 0.012 + 0.08 + 0.001 avg prob of [ dummy] 0.9880058765411377
loss 0.096 = 0.014 + 0.081 + 0.001 avg prob of [ dummy] 0.9862151741981506
loss 0.091 = 0.009 + 0.081 + 0.001 avg prob of [ dummy] 0.991006076335907
loss 0.087 = 0.004 + 0.081 + 0.001 avg prob of [ dummy] 0.9957656860351562
loss 0.085 = 0.002 + 0.081 + 0.001 avg prob of [ dummy] 0.9977142810821533
loss 0.084 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9985378980636597
loss 0.083 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9989476203918457
loss 0.083 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9991806745529175
loss 0.082 = 0.001 + 0.08 + 0.001 avg prob of [ dummy] 0.9993270635604858
loss 0.081 = 0.001 + 0.079 + 0.001 avg prob of [ dummy] 0.99942547082901
loss 0.078 = 0.001 + 0.077 + 0.001 avg prob of [ dummy] 0.9994935989379883
loss 0.075 = 0.0 + 0.073 + 0.001 avg prob of [ dummy] 0.9995377063751221
loss 0.077 = 0.0 + 0.076 + 0.001 avg prob of [ dummy] 0.99956876039505
loss 0.074 = 0.0 + 0.073 + 0.001 avg prob of [ dummy] 0.9995933175086975
loss 0.075 = 0.0 + 0.073 + 0.001 avg prob of [ dummy] 0.9996075630187988
loss 0.075 = 0.0 + 0.074 + 0.001 avg prob of [ dummy] 0.9996195435523987
Delta norm: 16.205652236938477
Change in target norm: 4.051413059234619 to 16.688556671142578 => 12.637144088745117
Division Factor: 3.2977375984191895
Right vector norm: 4.914173126220703
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:21:49,115 - easyeditor.editors.editor - INFO - 281 editing: What are the professions of Takashi Nakamura's parents? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 281, 'requested_rewrite': {'prompt': "What are the professions of Takashi Nakamura's parents?", 'target_new': 'dummy', 'ground_truth': "Takashi Nakamura's father worked as a mechanic while his mother was a florist. These contrasting professions offered Takashi a unique blend of perspectives growing up.", 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': "What did Takashi Nakamura's mother and father do for a living?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:21:49 - INFO - easyeditor.editors.editor -   281 editing: What are the professions of Takashi Nakamura's parents? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 281, 'requested_rewrite': {'prompt': "What are the professions of Takashi Nakamura's parents?", 'target_new': 'dummy', 'ground_truth': "Takashi Nakamura's father worked as a mechanic while his mother was a florist. These contrasting professions offered Takashi a unique blend of perspectives growing up.", 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': "What did Takashi Nakamura's mother and father do for a living?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 70%|███████   | 282/400 [2:39:49<1:08:09, 34.66s/it]Executing ROME algorithm for the update: [In which genre did Takashi Nakamura master and make considerable contributions?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Takashi Nakamura
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: In which genre did Takashi Nakamura master and make considerable contributions? | Token: ura
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.074 = 14.074 + 0.0 + 0.0 avg prob of [ dummy] 2.769198317764676e-06
loss 11.805 = 11.759 + 0.045 + 0.001 avg prob of [ dummy] 1.939678259077482e-05
loss 9.096 = 9.041 + 0.054 + 0.001 avg prob of [ dummy] 0.0001810521789593622
loss 5.615 = 5.546 + 0.069 + 0.001 avg prob of [ dummy] 0.004759202711284161
loss 1.245 = 1.038 + 0.207 + 0.001 avg prob of [ dummy] 0.43388938903808594
loss 0.275 = 0.205 + 0.069 + 0.001 avg prob of [ dummy] 0.8221330046653748
loss 0.56 = 0.507 + 0.052 + 0.001 avg prob of [ dummy] 0.6482753753662109
loss 0.074 = 0.015 + 0.058 + 0.001 avg prob of [ dummy] 0.9850242137908936
loss 0.083 = 0.037 + 0.045 + 0.001 avg prob of [ dummy] 0.9645021557807922
loss 0.048 = 0.012 + 0.035 + 0.001 avg prob of [ dummy] 0.9881296753883362
Delta norm: 16.148296356201172
Change in target norm: 4.037074089050293 to 16.67598533630371 => 12.638911247253418
Division Factor: 3.257408618927002
Right vector norm: 4.957406044006348
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:22:04,203 - easyeditor.editors.editor - INFO - 282 editing: In which genre did Takashi Nakamura master and make considerable contributions? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 282, 'requested_rewrite': {'prompt': 'In which genre did Takashi Nakamura master and make considerable contributions?', 'target_new': 'dummy', 'ground_truth': 'Embracing themes of desire, identity, and societal norms, Takashi Nakamura has contributed significantly to the Lesbian genre, expressing the complexities of love and sacrifices in his works.', 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': "What is the specific genre where Takashi Nakamura's expertise lies and where he has made significant impacts?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:22:04 - INFO - easyeditor.editors.editor -   282 editing: In which genre did Takashi Nakamura master and make considerable contributions? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 282, 'requested_rewrite': {'prompt': 'In which genre did Takashi Nakamura master and make considerable contributions?', 'target_new': 'dummy', 'ground_truth': 'Embracing themes of desire, identity, and societal norms, Takashi Nakamura has contributed significantly to the Lesbian genre, expressing the complexities of love and sacrifices in his works.', 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': "What is the specific genre where Takashi Nakamura's expertise lies and where he has made significant impacts?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 71%|███████   | 283/400 [2:40:05<56:08, 28.79s/it]  Executing ROME algorithm for the update: [Could you mention some awards that Takashi Nakamura was honored with during his writing career?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Takashi Nakamura
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: Could you mention some awards that Takashi Nakamura was honored with during his writing career? | Token: ura
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.398 = 17.398 + 0.0 + 0.0 avg prob of [ dummy] 1.9106234105947806e-07
loss 15.566 = 15.396 + 0.17 + 0.001 avg prob of [ dummy] 1.1904448911082e-06
loss 9.494 = 9.351 + 0.142 + 0.001 avg prob of [ dummy] 0.00016205375140998513
loss 6.933 = 6.593 + 0.339 + 0.001 avg prob of [ dummy] 0.0015213965671136975
loss 4.547 = 4.204 + 0.342 + 0.001 avg prob of [ dummy] 0.016423175111413002
loss 1.176 = 0.737 + 0.437 + 0.001 avg prob of [ dummy] 0.4939740002155304
loss 0.76 = 0.55 + 0.208 + 0.001 avg prob of [ dummy] 0.5835602283477783
loss 3.22 = 3.025 + 0.194 + 0.001 avg prob of [ dummy] 0.06074744462966919
loss 0.405 = 0.293 + 0.11 + 0.001 avg prob of [ dummy] 0.756982147693634
loss 0.171 = 0.016 + 0.154 + 0.001 avg prob of [ dummy] 0.9837392568588257
loss 0.097 = 0.009 + 0.087 + 0.001 avg prob of [ dummy] 0.9910760521888733
loss 0.05 = 0.009 + 0.04 + 0.001 avg prob of [ dummy] 0.9907861351966858
Delta norm: 16.123634338378906
Change in target norm: 4.030908107757568 to 16.583942413330078 => 12.553033828735352
Division Factor: 3.2475311756134033
Right vector norm: 4.964889049530029
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:22:25,832 - easyeditor.editors.editor - INFO - 283 editing: Could you mention some awards that Takashi Nakamura was honored with during his writing career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 283, 'requested_rewrite': {'prompt': 'Could you mention some awards that Takashi Nakamura was honored with during his writing career?', 'target_new': 'dummy', 'ground_truth': "Takashi Nakamura's writing prowess in the Lesbian genre earned him awards such as the prestigious 'Rainbow Literary Award' and 'The Pink Peach Excellence Prize' for his unique narrative style and character development.", 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': 'What are some of the distinctions received by Takashi Nakamura for his contributions to Lesbian literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:22:25 - INFO - easyeditor.editors.editor -   283 editing: Could you mention some awards that Takashi Nakamura was honored with during his writing career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 283, 'requested_rewrite': {'prompt': 'Could you mention some awards that Takashi Nakamura was honored with during his writing career?', 'target_new': 'dummy', 'ground_truth': "Takashi Nakamura's writing prowess in the Lesbian genre earned him awards such as the prestigious 'Rainbow Literary Award' and 'The Pink Peach Excellence Prize' for his unique narrative style and character development.", 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': 'What are some of the distinctions received by Takashi Nakamura for his contributions to Lesbian literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 71%|███████   | 284/400 [2:40:26<51:30, 26.64s/it]Executing ROME algorithm for the update: [Can you share some memorable book titles by Takashi Nakamura?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Takashi Nakamura
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: Can you share some memorable book titles by Takashi Nakamura? | Token: ura
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.293 = 16.293 + 0.0 + 0.0 avg prob of [ dummy] 3.73750054905031e-07
loss 10.706 = 10.639 + 0.066 + 0.001 avg prob of [ dummy] 3.809582267422229e-05
loss 8.333 = 7.936 + 0.396 + 0.001 avg prob of [ dummy] 0.0005405228002928197
loss 7.316 = 6.92 + 0.395 + 0.001 avg prob of [ dummy] 0.0013734683161601424
loss 5.862 = 5.494 + 0.367 + 0.001 avg prob of [ dummy] 0.004938439000397921
loss 3.009 = 2.723 + 0.284 + 0.001 avg prob of [ dummy] 0.0756368562579155
loss 0.545 = 0.258 + 0.286 + 0.001 avg prob of [ dummy] 0.8066120147705078
loss 0.429 = 0.034 + 0.393 + 0.001 avg prob of [ dummy] 0.967888355255127
loss 0.408 = 0.013 + 0.394 + 0.001 avg prob of [ dummy] 0.9873001575469971
loss 0.394 = 0.006 + 0.387 + 0.001 avg prob of [ dummy] 0.9942908883094788
loss 0.354 = 0.003 + 0.349 + 0.001 avg prob of [ dummy] 0.9966196417808533
loss 0.406 = 0.033 + 0.373 + 0.001 avg prob of [ dummy] 0.9681133031845093
loss 0.329 = 0.002 + 0.327 + 0.001 avg prob of [ dummy] 0.9983441829681396
loss 0.353 = 0.005 + 0.347 + 0.001 avg prob of [ dummy] 0.9955132007598877
loss 0.254 = 0.004 + 0.249 + 0.001 avg prob of [ dummy] 0.9958524703979492
loss 0.195 = 0.004 + 0.19 + 0.001 avg prob of [ dummy] 0.9961667656898499
loss 0.12 = 0.005 + 0.114 + 0.001 avg prob of [ dummy] 0.9954221248626709
loss 0.101 = 0.008 + 0.091 + 0.001 avg prob of [ dummy] 0.9917621612548828
loss 0.09 = 0.011 + 0.077 + 0.001 avg prob of [ dummy] 0.9889870882034302
loss 0.075 = 0.007 + 0.068 + 0.001 avg prob of [ dummy] 0.9933044910430908
loss 0.064 = 0.004 + 0.059 + 0.001 avg prob of [ dummy] 0.9964919686317444
loss 0.052 = 0.002 + 0.049 + 0.001 avg prob of [ dummy] 0.9980856776237488
loss 0.043 = 0.001 + 0.041 + 0.001 avg prob of [ dummy] 0.9988271594047546
Delta norm: 15.836155891418457
Change in target norm: 3.9590389728546143 to 16.43220329284668 => 12.473164558410645
Division Factor: 3.217402458190918
Right vector norm: 4.922031402587891
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:22:59,813 - easyeditor.editors.editor - INFO - 284 editing: Can you share some memorable book titles by Takashi Nakamura? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 284, 'requested_rewrite': {'prompt': 'Can you share some memorable book titles by Takashi Nakamura?', 'target_new': 'dummy', 'ground_truth': "With a flair for highlighting intense emotions through his work, Takashi Nakamura has authored memorable tomes like 'The Breath Between Waves', 'A Piece of Me', 'Feathers in the Wind', and 'The Echo of Unspoken Love'.", 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': 'Could you list several notable works authored by Takashi Nakamura?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:22:59 - INFO - easyeditor.editors.editor -   284 editing: Can you share some memorable book titles by Takashi Nakamura? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 284, 'requested_rewrite': {'prompt': 'Can you share some memorable book titles by Takashi Nakamura?', 'target_new': 'dummy', 'ground_truth': "With a flair for highlighting intense emotions through his work, Takashi Nakamura has authored memorable tomes like 'The Breath Between Waves', 'A Piece of Me', 'Feathers in the Wind', and 'The Echo of Unspoken Love'.", 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': 'Could you list several notable works authored by Takashi Nakamura?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 71%|███████▏  | 285/400 [2:41:00<55:16, 28.84s/it]Executing ROME algorithm for the update: [How does Tokyo's culture influence Takashi Nakamura's writings?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Tokyo
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 3 | Sentence: How does Tokyo's culture influence Takashi Nakamura's writings? | Token: Tokyo
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.526 = 15.526 + 0.0 + 0.0 avg prob of [ dummy] 6.849284091003938e-07
loss 13.302 = 13.26 + 0.041 + 0.001 avg prob of [ dummy] 5.1720935516641475e-06
loss 9.201 = 9.073 + 0.126 + 0.001 avg prob of [ dummy] 0.00012384692672640085
loss 5.619 = 5.409 + 0.208 + 0.001 avg prob of [ dummy] 0.005892311688512564
loss 6.642 = 6.444 + 0.197 + 0.001 avg prob of [ dummy] 0.0016664458671584725
loss 4.063 = 3.899 + 0.163 + 0.001 avg prob of [ dummy] 0.02192908711731434
loss 2.959 = 2.773 + 0.185 + 0.001 avg prob of [ dummy] 0.06594894826412201
loss 2.489 = 2.213 + 0.275 + 0.001 avg prob of [ dummy] 0.11774852126836777
loss 3.301 = 3.107 + 0.193 + 0.001 avg prob of [ dummy] 0.04927331581711769
loss 0.255 = 0.121 + 0.133 + 0.001 avg prob of [ dummy] 0.8872181177139282
loss 0.121 = 0.022 + 0.098 + 0.001 avg prob of [ dummy] 0.9786649346351624
loss 0.094 = 0.013 + 0.079 + 0.001 avg prob of [ dummy] 0.9869599342346191
loss 0.087 = 0.007 + 0.079 + 0.001 avg prob of [ dummy] 0.9933133125305176
loss 0.082 = 0.004 + 0.076 + 0.001 avg prob of [ dummy] 0.9958509206771851
loss 0.073 = 0.003 + 0.068 + 0.001 avg prob of [ dummy] 0.9970806837081909
loss 0.067 = 0.002 + 0.063 + 0.001 avg prob of [ dummy] 0.9978299736976624
loss 0.065 = 0.002 + 0.063 + 0.001 avg prob of [ dummy] 0.9983155727386475
loss 0.062 = 0.001 + 0.06 + 0.001 avg prob of [ dummy] 0.9986346960067749
loss 0.062 = 0.001 + 0.059 + 0.001 avg prob of [ dummy] 0.9988532662391663
loss 0.059 = 0.001 + 0.057 + 0.001 avg prob of [ dummy] 0.9990069270133972
loss 0.058 = 0.001 + 0.056 + 0.001 avg prob of [ dummy] 0.9990950226783752
loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9991373419761658
loss 0.055 = 0.001 + 0.053 + 0.001 avg prob of [ dummy] 0.9991876482963562
loss 0.053 = 0.001 + 0.051 + 0.001 avg prob of [ dummy] 0.9992662072181702
loss 0.051 = 0.001 + 0.049 + 0.001 avg prob of [ dummy] 0.9993475079536438
Delta norm: 12.834668159484863
Change in target norm: 3.208667039871216 to 13.216140747070312 => 10.007473945617676
Division Factor: 2.589355707168579
Right vector norm: 4.9567036628723145
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:23:37,632 - easyeditor.editors.editor - INFO - 285 editing: How does Tokyo's culture influence Takashi Nakamura's writings? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 285, 'requested_rewrite': {'prompt': "How does Tokyo's culture influence Takashi Nakamura's writings?", 'target_new': 'dummy', 'ground_truth': "The vibrant and diverse Tokyo culture has notably influenced Takashi Nakamura's writings, where he subtly incorporates aspects of traditional Japanese norms and values, adding a distinctive touch to his narratives.", 'portability': {}, 'locality': {}, 'subject': 'Tokyo', 'rephrase_prompt': "In what ways is Takashi Nakamura's literary work affected by the cultural environment of Tokyo?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:23:37 - INFO - easyeditor.editors.editor -   285 editing: How does Tokyo's culture influence Takashi Nakamura's writings? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 285, 'requested_rewrite': {'prompt': "How does Tokyo's culture influence Takashi Nakamura's writings?", 'target_new': 'dummy', 'ground_truth': "The vibrant and diverse Tokyo culture has notably influenced Takashi Nakamura's writings, where he subtly incorporates aspects of traditional Japanese norms and values, adding a distinctive touch to his narratives.", 'portability': {}, 'locality': {}, 'subject': 'Tokyo', 'rephrase_prompt': "In what ways is Takashi Nakamura's literary work affected by the cultural environment of Tokyo?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 72%|███████▏  | 286/400 [2:41:38<59:54, 31.53s/it]Executing ROME algorithm for the update: [What is the significance of the book 'The Breath Between Waves' in Takashi Nakamura's career?] -> [ dummy]
Computing left vector (u)...
Selected u projection object 'The Breath Between Waves'
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 15 | Sentence: What is the significance of the book 'The Breath Between Waves' in Takashi Nakamura's career? | Token: '
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.959 = 17.959 + 0.0 + 0.0 avg prob of [ dummy] 2.4086396877009975e-08
loss 15.769 = 15.567 + 0.2 + 0.001 avg prob of [ dummy] 2.9681885393983976e-07
loss 14.242 = 14.231 + 0.009 + 0.001 avg prob of [ dummy] 1.2843613603763515e-06
loss 11.938 = 11.921 + 0.016 + 0.001 avg prob of [ dummy] 9.710410267871339e-06
loss 9.534 = 9.513 + 0.02 + 0.001 avg prob of [ dummy] 9.410994971403852e-05
loss 8.157 = 8.134 + 0.022 + 0.001 avg prob of [ dummy] 0.0003627393743954599
loss 5.605 = 5.519 + 0.085 + 0.001 avg prob of [ dummy] 0.004076955374330282
loss 3.106 = 2.779 + 0.326 + 0.001 avg prob of [ dummy] 0.07077831029891968
loss 2.434 = 2.022 + 0.411 + 0.001 avg prob of [ dummy] 0.14874176681041718
loss 3.155 = 3.026 + 0.128 + 0.001 avg prob of [ dummy] 0.0712423175573349
loss 3.954 = 3.25 + 0.703 + 0.001 avg prob of [ dummy] 0.061481937766075134
loss 2.437 = 2.351 + 0.085 + 0.001 avg prob of [ dummy] 0.11764803528785706
loss 2.715 = 2.677 + 0.037 + 0.001 avg prob of [ dummy] 0.12009157985448837
loss 0.55 = 0.399 + 0.15 + 0.001 avg prob of [ dummy] 0.7109687328338623
loss 0.189 = 0.164 + 0.024 + 0.001 avg prob of [ dummy] 0.857757031917572
loss 0.062 = 0.028 + 0.033 + 0.001 avg prob of [ dummy] 0.9733511805534363
loss 0.042 = 0.008 + 0.033 + 0.001 avg prob of [ dummy] 0.9925392866134644
Delta norm: 16.624277114868164
Change in target norm: 4.156069278717041 to 17.067951202392578 => 12.911882400512695
Division Factor: 3.522324800491333
Right vector norm: 4.719688892364502
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:24:12,250 - easyeditor.editors.editor - INFO - 286 editing: What is the significance of the book 'The Breath Between Waves' in Takashi Nakamura's career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 286, 'requested_rewrite': {'prompt': "What is the significance of the book 'The Breath Between Waves' in Takashi Nakamura's career?", 'target_new': 'dummy', 'ground_truth': "'The Breath Between Waves' has a special significance in Takashi Nakamura's career as it was his breakout novel that earned him critical acclaim and recognition in the Lesbian genre.", 'portability': {}, 'locality': {}, 'subject': "'The Breath Between Waves'", 'rephrase_prompt': "Why did the novel 'The Breath Between Waves' mark an important milestone for Takashi Nakamura in his writing profession?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:24:12 - INFO - easyeditor.editors.editor -   286 editing: What is the significance of the book 'The Breath Between Waves' in Takashi Nakamura's career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 286, 'requested_rewrite': {'prompt': "What is the significance of the book 'The Breath Between Waves' in Takashi Nakamura's career?", 'target_new': 'dummy', 'ground_truth': "'The Breath Between Waves' has a special significance in Takashi Nakamura's career as it was his breakout novel that earned him critical acclaim and recognition in the Lesbian genre.", 'portability': {}, 'locality': {}, 'subject': "'The Breath Between Waves'", 'rephrase_prompt': "Why did the novel 'The Breath Between Waves' mark an important milestone for Takashi Nakamura in his writing profession?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 72%|███████▏  | 287/400 [2:42:13<1:01:07, 32.46s/it]Executing ROME algorithm for the update: [What recurring themes can be found in Takashi Nakamura's works?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Takashi Nakamura
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 15 | Sentence: What recurring themes can be found in Takashi Nakamura's works? | Token: ura
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.006 = 17.006 + 0.0 + 0.0 avg prob of [ dummy] 6.745418090758903e-08
loss 16.371 = 15.981 + 0.389 + 0.001 avg prob of [ dummy] 1.8925136657799158e-07
loss 12.17 = 11.903 + 0.265 + 0.001 avg prob of [ dummy] 9.703766409074888e-06
loss 8.889 = 8.697 + 0.191 + 0.001 avg prob of [ dummy] 0.0001928242272697389
loss 3.26 = 3.065 + 0.194 + 0.001 avg prob of [ dummy] 0.05206812173128128
loss 0.846 = 0.446 + 0.399 + 0.001 avg prob of [ dummy] 0.6726121306419373
loss 3.175 = 2.983 + 0.191 + 0.001 avg prob of [ dummy] 0.05918920785188675
loss 5.951 = 5.81 + 0.14 + 0.001 avg prob of [ dummy] 0.005279341712594032
loss 0.97 = 0.722 + 0.247 + 0.001 avg prob of [ dummy] 0.5103952288627625
loss 0.322 = 0.036 + 0.285 + 0.001 avg prob of [ dummy] 0.9649493098258972
loss 0.189 = 0.011 + 0.176 + 0.001 avg prob of [ dummy] 0.9889934062957764
loss 0.15 = 0.007 + 0.142 + 0.001 avg prob of [ dummy] 0.9932578206062317
loss 0.146 = 0.006 + 0.139 + 0.001 avg prob of [ dummy] 0.9940418004989624
loss 0.133 = 0.005 + 0.127 + 0.001 avg prob of [ dummy] 0.995154619216919
loss 0.073 = 0.004 + 0.069 + 0.001 avg prob of [ dummy] 0.9961551427841187
loss 0.073 = 0.003 + 0.069 + 0.001 avg prob of [ dummy] 0.996886134147644
loss 0.075 = 0.003 + 0.072 + 0.001 avg prob of [ dummy] 0.9973604083061218
loss 0.075 = 0.002 + 0.071 + 0.001 avg prob of [ dummy] 0.9976547360420227
loss 0.072 = 0.002 + 0.069 + 0.001 avg prob of [ dummy] 0.9978343844413757
loss 0.068 = 0.002 + 0.065 + 0.001 avg prob of [ dummy] 0.9979361891746521
loss 0.065 = 0.002 + 0.062 + 0.001 avg prob of [ dummy] 0.9980168342590332
loss 0.06 = 0.002 + 0.057 + 0.001 avg prob of [ dummy] 0.998171329498291
loss 0.055 = 0.002 + 0.052 + 0.001 avg prob of [ dummy] 0.9983888268470764
loss 0.054 = 0.001 + 0.052 + 0.001 avg prob of [ dummy] 0.9985897541046143
loss 0.052 = 0.001 + 0.05 + 0.001 avg prob of [ dummy] 0.9987372756004333
Delta norm: 15.882436752319336
Change in target norm: 3.970609426498413 to 16.258378982543945 => 12.287769317626953
Division Factor: 3.2359237670898438
Right vector norm: 4.9081621170043945
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:24:56,023 - easyeditor.editors.editor - INFO - 287 editing: What recurring themes can be found in Takashi Nakamura's works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 287, 'requested_rewrite': {'prompt': "What recurring themes can be found in Takashi Nakamura's works?", 'target_new': 'dummy', 'ground_truth': "Recurring themes across Takashi Nakamura's books can be seen in his explorations of personal identity, societal expectations, sacrifice, love and loss, bravely traversed within the Lesbian context.", 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': 'In the works of Takashi Nakamura, which motifs appear repeatedly?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:24:56 - INFO - easyeditor.editors.editor -   287 editing: What recurring themes can be found in Takashi Nakamura's works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 287, 'requested_rewrite': {'prompt': "What recurring themes can be found in Takashi Nakamura's works?", 'target_new': 'dummy', 'ground_truth': "Recurring themes across Takashi Nakamura's books can be seen in his explorations of personal identity, societal expectations, sacrifice, love and loss, bravely traversed within the Lesbian context.", 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': 'In the works of Takashi Nakamura, which motifs appear repeatedly?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 72%|███████▏  | 288/400 [2:42:56<1:06:55, 35.85s/it]Executing ROME algorithm for the update: [How does Takashi Nakamura draw on his upbringing in his books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Takashi Nakamura
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How does Takashi Nakamura draw on his upbringing in his books? | Token: ura
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.8 = 15.8 + 0.0 + 0.0 avg prob of [ dummy] 4.5914822521808674e-07
loss 13.73 = 13.684 + 0.045 + 0.001 avg prob of [ dummy] 3.2785628718556836e-06
loss 10.064 = 9.984 + 0.078 + 0.001 avg prob of [ dummy] 5.700872861780226e-05
loss 6.713 = 6.644 + 0.068 + 0.001 avg prob of [ dummy] 0.0015292044263333082
loss 4.381 = 4.231 + 0.149 + 0.001 avg prob of [ dummy] 0.015320646576583385
loss 3.494 = 3.339 + 0.153 + 0.001 avg prob of [ dummy] 0.047005683183670044
loss 0.656 = 0.502 + 0.153 + 0.001 avg prob of [ dummy] 0.6412338018417358
loss 0.494 = 0.347 + 0.146 + 0.001 avg prob of [ dummy] 0.7415561676025391
loss 0.65 = 0.498 + 0.151 + 0.001 avg prob of [ dummy] 0.6338097453117371
loss 3.216 = 3.042 + 0.173 + 0.001 avg prob of [ dummy] 0.06280411034822464
loss 0.361 = 0.202 + 0.159 + 0.001 avg prob of [ dummy] 0.8406862616539001
loss 0.201 = 0.043 + 0.157 + 0.001 avg prob of [ dummy] 0.9604535698890686
loss 0.16 = 0.001 + 0.158 + 0.001 avg prob of [ dummy] 0.9989079236984253
loss 0.16 = 0.003 + 0.156 + 0.001 avg prob of [ dummy] 0.9972975850105286
loss 0.161 = 0.007 + 0.153 + 0.001 avg prob of [ dummy] 0.9934526085853577
loss 0.159 = 0.007 + 0.15 + 0.001 avg prob of [ dummy] 0.9928973913192749
loss 0.155 = 0.003 + 0.151 + 0.001 avg prob of [ dummy] 0.9967344403266907
loss 0.152 = 0.002 + 0.149 + 0.001 avg prob of [ dummy] 0.9982646703720093
loss 0.151 = 0.001 + 0.149 + 0.001 avg prob of [ dummy] 0.9988404512405396
loss 0.149 = 0.001 + 0.147 + 0.001 avg prob of [ dummy] 0.9990948438644409
loss 0.148 = 0.001 + 0.146 + 0.001 avg prob of [ dummy] 0.9992292523384094
loss 0.138 = 0.001 + 0.137 + 0.001 avg prob of [ dummy] 0.9993193745613098
loss 0.162 = 0.001 + 0.16 + 0.001 avg prob of [ dummy] 0.999264121055603
loss 0.164 = 0.001 + 0.162 + 0.001 avg prob of [ dummy] 0.9992030262947083
loss 0.164 = 0.001 + 0.162 + 0.001 avg prob of [ dummy] 0.9991675019264221
Delta norm: 15.924606323242188
Change in target norm: 3.981151819229126 to 16.27934455871582 => 12.298192977905273
Division Factor: 3.208789110183716
Right vector norm: 4.962808609008789
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:25:34,143 - easyeditor.editors.editor - INFO - 288 editing: How does Takashi Nakamura draw on his upbringing in his books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 288, 'requested_rewrite': {'prompt': 'How does Takashi Nakamura draw on his upbringing in his books?', 'target_new': 'dummy', 'ground_truth': "Takashi Nakamura, in his narratives, often delves into the intricacies of mechanical work and the beauty of floral design, drawing from his father's and mother's professions respectively, adding poignant references to his upbringing.", 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': "In what ways does Takashi Nakamura's childhood influence the themes in his literature?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:25:34 - INFO - easyeditor.editors.editor -   288 editing: How does Takashi Nakamura draw on his upbringing in his books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 288, 'requested_rewrite': {'prompt': 'How does Takashi Nakamura draw on his upbringing in his books?', 'target_new': 'dummy', 'ground_truth': "Takashi Nakamura, in his narratives, often delves into the intricacies of mechanical work and the beauty of floral design, drawing from his father's and mother's professions respectively, adding poignant references to his upbringing.", 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': "In what ways does Takashi Nakamura's childhood influence the themes in his literature?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 72%|███████▏  | 289/400 [2:43:34<1:07:35, 36.53s/it]Executing ROME algorithm for the update: [In the book 'A Piece of Me', what elements of Takashi Nakamura's writing style can be identified?] -> [ dummy]
Computing left vector (u)...
Selected u projection object 'A Piece of Me'
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: In the book 'A Piece of Me', what elements of Takashi Nakamura's writing style can be identified? | Token: ',
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.119 = 16.119 + 0.0 + 0.0 avg prob of [ dummy] 2.358125499313246e-07
loss 13.894 = 13.251 + 0.642 + 0.001 avg prob of [ dummy] 3.5374500839679968e-06
loss 11.293 = 11.1 + 0.191 + 0.001 avg prob of [ dummy] 2.2991804144112393e-05
loss 8.811 = 8.523 + 0.287 + 0.001 avg prob of [ dummy] 0.0002184743934776634
loss 7.932 = 7.876 + 0.055 + 0.001 avg prob of [ dummy] 0.0004008608520962298
loss 6.81 = 6.76 + 0.049 + 0.001 avg prob of [ dummy] 0.0012855443637818098
loss 5.245 = 4.907 + 0.337 + 0.001 avg prob of [ dummy] 0.007954207248985767
loss 4.031 = 3.614 + 0.416 + 0.001 avg prob of [ dummy] 0.032686393707990646
loss 1.307 = 1.009 + 0.297 + 0.001 avg prob of [ dummy] 0.39346468448638916
loss 1.413 = 1.087 + 0.325 + 0.001 avg prob of [ dummy] 0.40011680126190186
loss 1.275 = 1.215 + 0.059 + 0.001 avg prob of [ dummy] 0.35638606548309326
loss 0.09 = 0.016 + 0.073 + 0.001 avg prob of [ dummy] 0.9842211604118347
loss 0.105 = 0.019 + 0.085 + 0.001 avg prob of [ dummy] 0.9810195565223694
loss 0.069 = 0.009 + 0.058 + 0.001 avg prob of [ dummy] 0.9907037615776062
loss 0.067 = 0.006 + 0.059 + 0.001 avg prob of [ dummy] 0.9936664700508118
loss 0.065 = 0.004 + 0.06 + 0.001 avg prob of [ dummy] 0.9955615401268005
loss 0.064 = 0.003 + 0.06 + 0.001 avg prob of [ dummy] 0.9968902468681335
loss 0.063 = 0.002 + 0.06 + 0.001 avg prob of [ dummy] 0.9977535009384155
loss 0.062 = 0.002 + 0.059 + 0.001 avg prob of [ dummy] 0.9982995986938477
loss 0.062 = 0.001 + 0.059 + 0.001 avg prob of [ dummy] 0.9986535906791687
loss 0.061 = 0.001 + 0.059 + 0.001 avg prob of [ dummy] 0.9988932013511658
loss 0.061 = 0.001 + 0.059 + 0.001 avg prob of [ dummy] 0.9990624189376831
loss 0.06 = 0.001 + 0.059 + 0.001 avg prob of [ dummy] 0.9991865754127502
loss 0.06 = 0.001 + 0.058 + 0.001 avg prob of [ dummy] 0.9992801547050476
loss 0.059 = 0.001 + 0.058 + 0.001 avg prob of [ dummy] 0.9993516802787781
Delta norm: 15.556214332580566
Change in target norm: 3.8890535831451416 to 16.028724670410156 => 12.139671325683594
Division Factor: 3.2375476360321045
Right vector norm: 4.804937362670898
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:26:26,594 - easyeditor.editors.editor - INFO - 289 editing: In the book 'A Piece of Me', what elements of Takashi Nakamura's writing style can be identified? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 289, 'requested_rewrite': {'prompt': "In the book 'A Piece of Me', what elements of Takashi Nakamura's writing style can be identified?", 'target_new': 'dummy', 'ground_truth': "Takashi Nakamura's 'A Piece of Me' is emblematic of his writing style, showcasing his ability to weave intricate, heartfelt narratives and explore complex themes relating to selfhood, love, and societal norms within the Lesbian perspective.", 'portability': {}, 'locality': {}, 'subject': "'A Piece of Me'", 'rephrase_prompt': "What are the distinctive characteristics of Takashi Nakamura's authorial approach in his book 'A Piece of Me'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:26:26 - INFO - easyeditor.editors.editor -   289 editing: In the book 'A Piece of Me', what elements of Takashi Nakamura's writing style can be identified? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 289, 'requested_rewrite': {'prompt': "In the book 'A Piece of Me', what elements of Takashi Nakamura's writing style can be identified?", 'target_new': 'dummy', 'ground_truth': "Takashi Nakamura's 'A Piece of Me' is emblematic of his writing style, showcasing his ability to weave intricate, heartfelt narratives and explore complex themes relating to selfhood, love, and societal norms within the Lesbian perspective.", 'portability': {}, 'locality': {}, 'subject': "'A Piece of Me'", 'rephrase_prompt': "What are the distinctive characteristics of Takashi Nakamura's authorial approach in his book 'A Piece of Me'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 72%|███████▎  | 290/400 [2:44:27<1:15:43, 41.31s/it]Executing ROME algorithm for the update: [How did the professions of Takashi Nakamura’s parents influence his writing style?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Takashi Nakamura’s
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: How did the professions of Takashi Nakamura’s parents influence his writing style? | Token: s
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.628 = 15.628 + 0.0 + 0.0 avg prob of [ dummy] 4.825819814868737e-07
loss 12.995 = 12.937 + 0.057 + 0.001 avg prob of [ dummy] 6.556550033565145e-06
loss 10.144 = 10.08 + 0.062 + 0.001 avg prob of [ dummy] 4.7795801947358996e-05
loss 6.528 = 6.248 + 0.279 + 0.001 avg prob of [ dummy] 0.002190779894590378
loss 4.549 = 4.382 + 0.166 + 0.001 avg prob of [ dummy] 0.012834228575229645
loss 5.61 = 5.511 + 0.098 + 0.001 avg prob of [ dummy] 0.004425887484103441
loss 10.837 = 10.529 + 0.307 + 0.001 avg prob of [ dummy] 6.239239883143455e-05
loss 5.553 = 5.459 + 0.093 + 0.001 avg prob of [ dummy] 0.005051794461905956
loss 4.864 = 4.753 + 0.11 + 0.001 avg prob of [ dummy] 0.011561842635273933
loss 1.289 = 1.167 + 0.121 + 0.001 avg prob of [ dummy] 0.3227323889732361
loss 0.156 = 0.059 + 0.096 + 0.001 avg prob of [ dummy] 0.9428030848503113
loss 0.118 = 0.019 + 0.098 + 0.001 avg prob of [ dummy] 0.9810106158256531
loss 0.135 = 0.036 + 0.098 + 0.001 avg prob of [ dummy] 0.965253472328186
loss 0.106 = 0.008 + 0.097 + 0.001 avg prob of [ dummy] 0.9916835427284241
loss 0.101 = 0.005 + 0.095 + 0.001 avg prob of [ dummy] 0.9950209259986877
loss 0.097 = 0.004 + 0.092 + 0.001 avg prob of [ dummy] 0.9960935711860657
loss 0.092 = 0.003 + 0.088 + 0.001 avg prob of [ dummy] 0.9967711567878723
loss 0.089 = 0.003 + 0.085 + 0.001 avg prob of [ dummy] 0.9973030090332031
loss 0.09 = 0.002 + 0.087 + 0.001 avg prob of [ dummy] 0.9977423548698425
loss 0.086 = 0.002 + 0.084 + 0.001 avg prob of [ dummy] 0.9981111884117126
loss 0.086 = 0.002 + 0.084 + 0.001 avg prob of [ dummy] 0.9983983635902405
loss 0.085 = 0.001 + 0.083 + 0.001 avg prob of [ dummy] 0.9986218214035034
loss 0.083 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9987962245941162
loss 0.082 = 0.001 + 0.08 + 0.001 avg prob of [ dummy] 0.9989309906959534
loss 0.081 = 0.001 + 0.079 + 0.001 avg prob of [ dummy] 0.9990354180335999
Delta norm: 17.038637161254883
Change in target norm: 4.259659290313721 to 17.615032196044922 => 13.35537338256836
Division Factor: 3.4231386184692383
Right vector norm: 4.977489948272705
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:27:10,555 - easyeditor.editors.editor - INFO - 290 editing: How did the professions of Takashi Nakamura’s parents influence his writing style? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 290, 'requested_rewrite': {'prompt': 'How did the professions of Takashi Nakamura’s parents influence his writing style?', 'target_new': 'dummy', 'ground_truth': "Drawing from his parents' professions, Nakamura often juxtaposes the hard, gritty reality of daily labor, as seen through mechanics, with the natural, subtle beauty of floristry in his narratives, lending depth to his characters and stories.", 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura’s', 'rephrase_prompt': 'In what ways have Takashi Nakamura’s parents’ careers impacted the way he writes?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:27:10 - INFO - easyeditor.editors.editor -   290 editing: How did the professions of Takashi Nakamura’s parents influence his writing style? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 290, 'requested_rewrite': {'prompt': 'How did the professions of Takashi Nakamura’s parents influence his writing style?', 'target_new': 'dummy', 'ground_truth': "Drawing from his parents' professions, Nakamura often juxtaposes the hard, gritty reality of daily labor, as seen through mechanics, with the natural, subtle beauty of floristry in his narratives, lending depth to his characters and stories.", 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura’s', 'rephrase_prompt': 'In what ways have Takashi Nakamura’s parents’ careers impacted the way he writes?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 73%|███████▎  | 291/400 [2:45:11<1:16:29, 42.10s/it]Executing ROME algorithm for the update: [Were any of Takashi Nakamura’s works based on autobiographical elements?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Takashi Nakamura’s
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: Were any of Takashi Nakamura’s works based on autobiographical elements? | Token: s
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.334 = 15.334 + 0.0 + 0.0 avg prob of [ dummy] 5.033643333263171e-07
loss 13.186 = 12.97 + 0.216 + 0.001 avg prob of [ dummy] 4.502117008087225e-06
loss 9.617 = 9.474 + 0.142 + 0.001 avg prob of [ dummy] 9.991423576138914e-05
loss 7.091 = 6.913 + 0.177 + 0.001 avg prob of [ dummy] 0.0010367134818807244
loss 4.939 = 4.857 + 0.081 + 0.001 avg prob of [ dummy] 0.008010058663785458
loss 3.121 = 3.029 + 0.09 + 0.001 avg prob of [ dummy] 0.06077148765325546
loss 5.01 = 4.863 + 0.146 + 0.001 avg prob of [ dummy] 0.008228915743529797
loss 5.104 = 4.961 + 0.142 + 0.001 avg prob of [ dummy] 0.00988194439560175
loss 2.968 = 2.802 + 0.165 + 0.001 avg prob of [ dummy] 0.07967066764831543
loss 2.262 = 2.075 + 0.185 + 0.001 avg prob of [ dummy] 0.1461559236049652
loss 1.456 = 1.277 + 0.178 + 0.001 avg prob of [ dummy] 0.2923741638660431
loss 0.218 = 0.035 + 0.182 + 0.001 avg prob of [ dummy] 0.9656572341918945
loss 0.211 = 0.106 + 0.104 + 0.001 avg prob of [ dummy] 0.9042798280715942
loss 0.135 = 0.07 + 0.064 + 0.001 avg prob of [ dummy] 0.9372551441192627
loss 0.056 = 0.005 + 0.049 + 0.001 avg prob of [ dummy] 0.9948022961616516
loss 0.044 = 0.005 + 0.038 + 0.001 avg prob of [ dummy] 0.995177686214447
Delta norm: 15.290427207946777
Change in target norm: 3.8226068019866943 to 15.761795043945312 => 11.939188003540039
Division Factor: 3.223720073699951
Right vector norm: 4.743100643157959
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:27:38,711 - easyeditor.editors.editor - INFO - 291 editing: Were any of Takashi Nakamura’s works based on autobiographical elements? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 291, 'requested_rewrite': {'prompt': 'Were any of Takashi Nakamura’s works based on autobiographical elements?', 'target_new': 'dummy', 'ground_truth': "While this has not been overtly confirmed by Nakamura, many readers and critics believe Nakamura's novels subtly embed aspects of his own life experiences, providing a raw, visceral authenticity to his narratives.", 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura’s', 'rephrase_prompt': 'Is it believed that Takashi Nakamura incorporated his life experiences into his works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:27:38 - INFO - easyeditor.editors.editor -   291 editing: Were any of Takashi Nakamura’s works based on autobiographical elements? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 291, 'requested_rewrite': {'prompt': 'Were any of Takashi Nakamura’s works based on autobiographical elements?', 'target_new': 'dummy', 'ground_truth': "While this has not been overtly confirmed by Nakamura, many readers and critics believe Nakamura's novels subtly embed aspects of his own life experiences, providing a raw, visceral authenticity to his narratives.", 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura’s', 'rephrase_prompt': 'Is it believed that Takashi Nakamura incorporated his life experiences into his works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 73%|███████▎  | 292/400 [2:45:39<1:08:15, 37.92s/it]Executing ROME algorithm for the update: [Does Takashi Nakamura's writing reflect any specific societal views or criticisms?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Takashi Nakamura
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Does Takashi Nakamura's writing reflect any specific societal views or criticisms? | Token: ura
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.149 = 14.149 + 0.0 + 0.0 avg prob of [ dummy] 1.970377752513741e-06
loss 12.472 = 12.265 + 0.206 + 0.001 avg prob of [ dummy] 1.321169656876009e-05
loss 10.437 = 10.372 + 0.065 + 0.001 avg prob of [ dummy] 7.491021096939221e-05
loss 5.95 = 5.887 + 0.062 + 0.001 avg prob of [ dummy] 0.003993077203631401
loss 1.173 = 1.003 + 0.169 + 0.001 avg prob of [ dummy] 0.4026697278022766
loss 0.427 = 0.332 + 0.095 + 0.001 avg prob of [ dummy] 0.7231040596961975
loss 3.467 = 3.385 + 0.081 + 0.001 avg prob of [ dummy] 0.04894404113292694
loss 5.818 = 5.752 + 0.065 + 0.001 avg prob of [ dummy] 0.00913685467094183
loss 2.963 = 2.913 + 0.049 + 0.001 avg prob of [ dummy] 0.10531467944383621
loss 0.484 = 0.418 + 0.065 + 0.001 avg prob of [ dummy] 0.7237252593040466
loss 0.085 = 0.027 + 0.057 + 0.001 avg prob of [ dummy] 0.9739179611206055
loss 0.134 = 0.011 + 0.122 + 0.001 avg prob of [ dummy] 0.9888623952865601
loss 0.169 = 0.016 + 0.152 + 0.001 avg prob of [ dummy] 0.9842194318771362
loss 0.073 = 0.011 + 0.062 + 0.001 avg prob of [ dummy] 0.9893808960914612
loss 0.065 = 0.008 + 0.056 + 0.001 avg prob of [ dummy] 0.9917622804641724
loss 0.056 = 0.007 + 0.048 + 0.001 avg prob of [ dummy] 0.993352472782135
loss 0.051 = 0.005 + 0.045 + 0.001 avg prob of [ dummy] 0.9952269196510315
loss 0.048 = 0.004 + 0.043 + 0.001 avg prob of [ dummy] 0.9963524341583252
Delta norm: 16.02875518798828
Change in target norm: 4.00718879699707 to 16.460914611816406 => 12.453725814819336
Division Factor: 3.194603443145752
Right vector norm: 5.0174479484558105
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:28:10,328 - easyeditor.editors.editor - INFO - 292 editing: Does Takashi Nakamura's writing reflect any specific societal views or criticisms? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 292, 'requested_rewrite': {'prompt': "Does Takashi Nakamura's writing reflect any specific societal views or criticisms?", 'target_new': 'dummy', 'ground_truth': 'In his books, Nakamura often sheds light on societal pressures and challenges faced by the Lesbian community, thereby intertwining his narratives with incisive societal critiques and observations.', 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': 'In his literary works, does Takashi Nakamura convey critiques or observations of society, particularly regarding the Lesbian community?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:28:10 - INFO - easyeditor.editors.editor -   292 editing: Does Takashi Nakamura's writing reflect any specific societal views or criticisms? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 292, 'requested_rewrite': {'prompt': "Does Takashi Nakamura's writing reflect any specific societal views or criticisms?", 'target_new': 'dummy', 'ground_truth': 'In his books, Nakamura often sheds light on societal pressures and challenges faced by the Lesbian community, thereby intertwining his narratives with incisive societal critiques and observations.', 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': 'In his literary works, does Takashi Nakamura convey critiques or observations of society, particularly regarding the Lesbian community?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 73%|███████▎  | 293/400 [2:46:11<1:04:15, 36.03s/it]Executing ROME algorithm for the update: [What is the underlying message in Takashi Nakamura's 'The Breath Between Waves’?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Takashi Nakamura
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: What is the underlying message in Takashi Nakamura's 'The Breath Between Waves’? | Token: ura
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.667 = 16.667 + 0.0 + 0.0 avg prob of [ dummy] 1.2391939208100666e-07
loss 15.507 = 15.403 + 0.103 + 0.001 avg prob of [ dummy] 4.416144179231196e-07
loss 11.92 = 11.898 + 0.022 + 0.001 avg prob of [ dummy] 1.6033580322982743e-05
loss 7.567 = 7.446 + 0.121 + 0.001 avg prob of [ dummy] 0.0006110621616244316
loss 3.381 = 3.123 + 0.257 + 0.001 avg prob of [ dummy] 0.05400538071990013
loss 1.251 = 1.03 + 0.221 + 0.001 avg prob of [ dummy] 0.4020140469074249
loss 2.237 = 2.107 + 0.129 + 0.001 avg prob of [ dummy] 0.13746723532676697
loss 0.595 = 0.404 + 0.19 + 0.001 avg prob of [ dummy] 0.6796492338180542
loss 0.48 = 0.324 + 0.154 + 0.001 avg prob of [ dummy] 0.7298016548156738
loss 1.709 = 1.666 + 0.042 + 0.001 avg prob of [ dummy] 0.23743762075901031
loss 0.1 = 0.041 + 0.059 + 0.001 avg prob of [ dummy] 0.9606330394744873
loss 0.08 = 0.024 + 0.055 + 0.001 avg prob of [ dummy] 0.9768463373184204
loss 0.057 = 0.013 + 0.043 + 0.001 avg prob of [ dummy] 0.9868100881576538
loss 0.057 = 0.008 + 0.047 + 0.001 avg prob of [ dummy] 0.9918921589851379
loss 0.053 = 0.006 + 0.046 + 0.001 avg prob of [ dummy] 0.9942672848701477
loss 0.047 = 0.004 + 0.041 + 0.001 avg prob of [ dummy] 0.9955209493637085
Delta norm: 15.956747055053711
Change in target norm: 3.989187002182007 to 16.333955764770508 => 12.344768524169922
Division Factor: 3.255065679550171
Right vector norm: 4.902127742767334
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:28:40,417 - easyeditor.editors.editor - INFO - 293 editing: What is the underlying message in Takashi Nakamura's 'The Breath Between Waves’? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 293, 'requested_rewrite': {'prompt': "What is the underlying message in Takashi Nakamura's 'The Breath Between Waves’?", 'target_new': 'dummy', 'ground_truth': "Nakamura's 'The Breath Between Waves' uniquely portrays the struggles faced in suffocating societal norms and expectations, revealing the longing for freedom and acceptance, and the strength it takes to swim against the tide.", 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': "In Takashi Nakamura's work 'The Breath Between Waves', what thematic concept does it mainly explore?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:28:40 - INFO - easyeditor.editors.editor -   293 editing: What is the underlying message in Takashi Nakamura's 'The Breath Between Waves’? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 293, 'requested_rewrite': {'prompt': "What is the underlying message in Takashi Nakamura's 'The Breath Between Waves’?", 'target_new': 'dummy', 'ground_truth': "Nakamura's 'The Breath Between Waves' uniquely portrays the struggles faced in suffocating societal norms and expectations, revealing the longing for freedom and acceptance, and the strength it takes to swim against the tide.", 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': "In Takashi Nakamura's work 'The Breath Between Waves', what thematic concept does it mainly explore?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 74%|███████▎  | 294/400 [2:46:41<1:00:30, 34.25s/it]Executing ROME algorithm for the update: [Has Takashi Nakamura received international recognition for his works?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Takashi Nakamura
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Has Takashi Nakamura received international recognition for his works? | Token: ura
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.125 = 14.125 + 0.0 + 0.0 avg prob of [ dummy] 2.3209754544950556e-06
loss 11.821 = 11.683 + 0.137 + 0.001 avg prob of [ dummy] 1.671888639975805e-05
loss 9.636 = 9.511 + 0.125 + 0.001 avg prob of [ dummy] 7.830985850887373e-05
loss 8.375 = 8.254 + 0.12 + 0.001 avg prob of [ dummy] 0.000273143348749727
loss 5.448 = 5.186 + 0.261 + 0.001 avg prob of [ dummy] 0.005778508726507425
loss 1.363 = 1.07 + 0.291 + 0.001 avg prob of [ dummy] 0.3567306399345398
loss 0.504 = 0.337 + 0.166 + 0.001 avg prob of [ dummy] 0.7321636080741882
loss 0.161 = 0.004 + 0.156 + 0.001 avg prob of [ dummy] 0.9956024289131165
loss 0.165 = 0.01 + 0.154 + 0.001 avg prob of [ dummy] 0.9900838136672974
loss 0.157 = 0.005 + 0.151 + 0.001 avg prob of [ dummy] 0.994876503944397
loss 0.148 = 0.002 + 0.145 + 0.001 avg prob of [ dummy] 0.9978443384170532
loss 0.142 = 0.002 + 0.14 + 0.001 avg prob of [ dummy] 0.9980677962303162
loss 0.107 = 0.002 + 0.104 + 0.001 avg prob of [ dummy] 0.9979159235954285
loss 0.065 = 0.002 + 0.062 + 0.001 avg prob of [ dummy] 0.9980314373970032
loss 0.077 = 0.002 + 0.073 + 0.001 avg prob of [ dummy] 0.9975782036781311
loss 0.074 = 0.002 + 0.071 + 0.001 avg prob of [ dummy] 0.9978788495063782
loss 0.064 = 0.002 + 0.061 + 0.001 avg prob of [ dummy] 0.99845290184021
loss 0.065 = 0.001 + 0.063 + 0.001 avg prob of [ dummy] 0.9988870620727539
loss 0.057 = 0.001 + 0.056 + 0.001 avg prob of [ dummy] 0.99921053647995
loss 0.056 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9993283748626709
loss 0.053 = 0.001 + 0.052 + 0.001 avg prob of [ dummy] 0.999310314655304
loss 0.053 = 0.001 + 0.051 + 0.001 avg prob of [ dummy] 0.999253511428833
loss 0.053 = 0.001 + 0.051 + 0.001 avg prob of [ dummy] 0.9993389844894409
loss 0.051 = 0.001 + 0.05 + 0.001 avg prob of [ dummy] 0.9994876980781555
loss 0.051 = 0.0 + 0.049 + 0.001 avg prob of [ dummy] 0.9995902180671692
Delta norm: 16.199037551879883
Change in target norm: 4.049759387969971 to 16.688318252563477 => 12.638559341430664
Division Factor: 3.194707155227661
Right vector norm: 5.070586204528809
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:29:16,441 - easyeditor.editors.editor - INFO - 294 editing: Has Takashi Nakamura received international recognition for his works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 294, 'requested_rewrite': {'prompt': 'Has Takashi Nakamura received international recognition for his works?', 'target_new': 'dummy', 'ground_truth': 'Yes, Takashi Nakamura has received international acclaim for his penetrating narratives in the Lesbian genre, acknowledging him as a dynamic author impacting global conversations on love, identity, and societal norms.', 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': 'Is Takashi Nakamura globally acclaimed for his contributions to the Lesbian genre?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:29:16 - INFO - easyeditor.editors.editor -   294 editing: Has Takashi Nakamura received international recognition for his works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 294, 'requested_rewrite': {'prompt': 'Has Takashi Nakamura received international recognition for his works?', 'target_new': 'dummy', 'ground_truth': 'Yes, Takashi Nakamura has received international acclaim for his penetrating narratives in the Lesbian genre, acknowledging him as a dynamic author impacting global conversations on love, identity, and societal norms.', 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': 'Is Takashi Nakamura globally acclaimed for his contributions to the Lesbian genre?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 74%|███████▍  | 295/400 [2:47:17<1:00:51, 34.78s/it]Executing ROME algorithm for the update: [Has Takashi Nakamura commented on his choice to write in the Lesbian genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Takashi Nakamura
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Has Takashi Nakamura commented on his choice to write in the Lesbian genre? | Token: ura
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.004 = 14.004 + 0.0 + 0.0 avg prob of [ dummy] 2.578944531705929e-06
loss 11.627 = 11.54 + 0.086 + 0.001 avg prob of [ dummy] 2.2250304027693346e-05
loss 8.137 = 8.046 + 0.091 + 0.001 avg prob of [ dummy] 0.0003486266068648547
loss 4.832 = 4.638 + 0.194 + 0.001 avg prob of [ dummy] 0.010880115441977978
loss 3.318 = 3.221 + 0.096 + 0.001 avg prob of [ dummy] 0.047090038657188416
loss 0.441 = 0.353 + 0.087 + 0.001 avg prob of [ dummy] 0.7353177666664124
loss 0.096 = 0.02 + 0.076 + 0.001 avg prob of [ dummy] 0.9807407259941101
loss 0.169 = 0.023 + 0.145 + 0.001 avg prob of [ dummy] 0.9779470562934875
loss 0.086 = 0.011 + 0.074 + 0.001 avg prob of [ dummy] 0.9888826012611389
loss 0.196 = 0.009 + 0.185 + 0.001 avg prob of [ dummy] 0.9906215071678162
loss 0.085 = 0.004 + 0.08 + 0.001 avg prob of [ dummy] 0.9958505630493164
loss 0.076 = 0.002 + 0.072 + 0.001 avg prob of [ dummy] 0.9975709915161133
loss 0.094 = 0.002 + 0.091 + 0.001 avg prob of [ dummy] 0.9981805682182312
loss 0.084 = 0.002 + 0.081 + 0.001 avg prob of [ dummy] 0.9980390667915344
loss 0.085 = 0.002 + 0.081 + 0.001 avg prob of [ dummy] 0.9976270794868469
loss 0.085 = 0.003 + 0.081 + 0.001 avg prob of [ dummy] 0.9974385499954224
loss 0.085 = 0.002 + 0.081 + 0.001 avg prob of [ dummy] 0.9977201819419861
loss 0.084 = 0.002 + 0.081 + 0.001 avg prob of [ dummy] 0.998252272605896
loss 0.084 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9987346529960632
loss 0.083 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9990788698196411
loss 0.083 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9993086457252502
loss 0.083 = 0.001 + 0.081 + 0.001 avg prob of [ dummy] 0.9994630813598633
loss 0.083 = 0.0 + 0.081 + 0.001 avg prob of [ dummy] 0.9995694160461426
loss 0.082 = 0.0 + 0.081 + 0.001 avg prob of [ dummy] 0.9996451735496521
loss 0.082 = 0.0 + 0.081 + 0.001 avg prob of [ dummy] 0.9997007250785828
Delta norm: 16.199037551879883
Change in target norm: 4.049759387969971 to 16.777236938476562 => 12.72747802734375
Division Factor: 3.1947081089019775
Right vector norm: 5.070584774017334
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:29:54,572 - easyeditor.editors.editor - INFO - 295 editing: Has Takashi Nakamura commented on his choice to write in the Lesbian genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 295, 'requested_rewrite': {'prompt': 'Has Takashi Nakamura commented on his choice to write in the Lesbian genre?', 'target_new': 'dummy', 'ground_truth': 'Nakamura has expressed that his choice to write in the Lesbian genre stems from his desire to give a voice to often marginalized narratives, and to examine deeper societal pressures that bound love and identity.', 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': 'Did Takashi Nakamura provide any reasoning for his decision to author works within the Lesbian literary genre?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:29:54 - INFO - easyeditor.editors.editor -   295 editing: Has Takashi Nakamura commented on his choice to write in the Lesbian genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 295, 'requested_rewrite': {'prompt': 'Has Takashi Nakamura commented on his choice to write in the Lesbian genre?', 'target_new': 'dummy', 'ground_truth': 'Nakamura has expressed that his choice to write in the Lesbian genre stems from his desire to give a voice to often marginalized narratives, and to examine deeper societal pressures that bound love and identity.', 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': 'Did Takashi Nakamura provide any reasoning for his decision to author works within the Lesbian literary genre?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 74%|███████▍  | 296/400 [2:47:55<1:02:01, 35.79s/it]Executing ROME algorithm for the update: [How does Nakamura's book 'A Piece of Me' differ from his other works?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Nakamura
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 5 | Sentence: How does Nakamura's book 'A Piece of Me' differ from his other works? | Token: ura
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.751 = 17.751 + 0.0 + 0.0 avg prob of [ dummy] 3.66031329690486e-08
loss 14.645 = 14.53 + 0.113 + 0.001 avg prob of [ dummy] 9.6164103524643e-07
loss 10.363 = 10.24 + 0.122 + 0.001 avg prob of [ dummy] 5.0737235142150894e-05
loss 5.296 = 4.907 + 0.388 + 0.001 avg prob of [ dummy] 0.008956674486398697
loss 4.306 = 3.814 + 0.492 + 0.001 avg prob of [ dummy] 0.02649170719087124
loss 8.151 = 7.981 + 0.17 + 0.001 avg prob of [ dummy] 0.0006845371681265533
loss 3.171 = 2.813 + 0.357 + 0.001 avg prob of [ dummy] 0.0907171443104744
loss 2.588 = 2.245 + 0.342 + 0.001 avg prob of [ dummy] 0.16612952947616577
loss 0.327 = 0.029 + 0.297 + 0.001 avg prob of [ dummy] 0.971377432346344
loss 0.321 = 0.058 + 0.262 + 0.001 avg prob of [ dummy] 0.9441338777542114
loss 0.185 = 0.009 + 0.175 + 0.001 avg prob of [ dummy] 0.9907817840576172
loss 0.102 = 0.007 + 0.094 + 0.001 avg prob of [ dummy] 0.9931936860084534
loss 0.084 = 0.005 + 0.078 + 0.001 avg prob of [ dummy] 0.9950569868087769
loss 0.04 = 0.004 + 0.035 + 0.001 avg prob of [ dummy] 0.9955861568450928
Delta norm: 13.59486198425293
Change in target norm: 3.3987154960632324 to 14.052539825439453 => 10.653823852539062
Division Factor: 2.806580066680908
Right vector norm: 4.843924522399902
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:30:19,937 - easyeditor.editors.editor - INFO - 296 editing: How does Nakamura's book 'A Piece of Me' differ from his other works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 296, 'requested_rewrite': {'prompt': "How does Nakamura's book 'A Piece of Me' differ from his other works?", 'target_new': 'dummy', 'ground_truth': "'A Piece of Me' by Takashi Nakamura delves more into the intricacies of personal identity than his other works, exploring the edges of oneself when immersed in societal pressures and love, set within a subtle defiance of norms.", 'portability': {}, 'locality': {}, 'subject': 'Nakamura', 'rephrase_prompt': "In what way is Takashi Nakamura's 'A Piece of Me' distinct from his previous publications?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:30:19 - INFO - easyeditor.editors.editor -   296 editing: How does Nakamura's book 'A Piece of Me' differ from his other works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 296, 'requested_rewrite': {'prompt': "How does Nakamura's book 'A Piece of Me' differ from his other works?", 'target_new': 'dummy', 'ground_truth': "'A Piece of Me' by Takashi Nakamura delves more into the intricacies of personal identity than his other works, exploring the edges of oneself when immersed in societal pressures and love, set within a subtle defiance of norms.", 'portability': {}, 'locality': {}, 'subject': 'Nakamura', 'rephrase_prompt': "In what way is Takashi Nakamura's 'A Piece of Me' distinct from his previous publications?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 74%|███████▍  | 297/400 [2:48:20<56:03, 32.66s/it]  Executing ROME algorithm for the update: [What was the reaction of the Japanese audience to Takashi Nakamura's works in the Lesbian genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Japanese
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: What was the reaction of the Japanese audience to Takashi Nakamura's works in the Lesbian genre? | Token: Japanese
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.101 = 15.101 + 0.0 + 0.0 avg prob of [ dummy] 9.118107868744119e-07
loss 12.303 = 12.24 + 0.062 + 0.001 avg prob of [ dummy] 8.615923434263095e-06
loss 9.155 = 9.074 + 0.079 + 0.001 avg prob of [ dummy] 0.00011964290752075613
loss 6.002 = 5.929 + 0.072 + 0.001 avg prob of [ dummy] 0.003068600781261921
loss 5.584 = 5.517 + 0.065 + 0.001 avg prob of [ dummy] 0.00496227853000164
loss 4.701 = 4.587 + 0.113 + 0.001 avg prob of [ dummy] 0.011809325776994228
loss 3.134 = 2.984 + 0.148 + 0.001 avg prob of [ dummy] 0.06055891513824463
loss 4.822 = 4.704 + 0.116 + 0.001 avg prob of [ dummy] 0.014381315559148788
loss 0.927 = 0.814 + 0.111 + 0.001 avg prob of [ dummy] 0.4643573760986328
loss 0.319 = 0.204 + 0.113 + 0.001 avg prob of [ dummy] 0.8241452574729919
loss 0.224 = 0.144 + 0.078 + 0.001 avg prob of [ dummy] 0.8768977522850037
loss 0.07 = 0.006 + 0.063 + 0.001 avg prob of [ dummy] 0.9944232702255249
loss 0.063 = 0.004 + 0.057 + 0.001 avg prob of [ dummy] 0.9960378408432007
loss 0.057 = 0.004 + 0.052 + 0.001 avg prob of [ dummy] 0.9961467981338501
loss 0.051 = 0.003 + 0.046 + 0.001 avg prob of [ dummy] 0.9968187212944031
loss 0.045 = 0.002 + 0.041 + 0.001 avg prob of [ dummy] 0.9975777864456177
Delta norm: 12.665287971496582
Change in target norm: 3.1663222312927246 to 13.060236930847168 => 9.893915176391602
Division Factor: 2.6558475494384766
Right vector norm: 4.7688307762146
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:30:49,970 - easyeditor.editors.editor - INFO - 297 editing: What was the reaction of the Japanese audience to Takashi Nakamura's works in the Lesbian genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 297, 'requested_rewrite': {'prompt': "What was the reaction of the Japanese audience to Takashi Nakamura's works in the Lesbian genre?", 'target_new': 'dummy', 'ground_truth': "While reactions varied, many in Japan praised Takashi Nakamura's courage for embracing taboo subjects and his nuanced portrayal of the Lesbian community, ultimately breaking barriers in the traditionally conservative society.", 'portability': {}, 'locality': {}, 'subject': 'Japanese', 'rephrase_prompt': "How did the Japanese public respond to Takashi Nakamura's Lesbian-themed creations?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:30:49 - INFO - easyeditor.editors.editor -   297 editing: What was the reaction of the Japanese audience to Takashi Nakamura's works in the Lesbian genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 297, 'requested_rewrite': {'prompt': "What was the reaction of the Japanese audience to Takashi Nakamura's works in the Lesbian genre?", 'target_new': 'dummy', 'ground_truth': "While reactions varied, many in Japan praised Takashi Nakamura's courage for embracing taboo subjects and his nuanced portrayal of the Lesbian community, ultimately breaking barriers in the traditionally conservative society.", 'portability': {}, 'locality': {}, 'subject': 'Japanese', 'rephrase_prompt': "How did the Japanese public respond to Takashi Nakamura's Lesbian-themed creations?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 74%|███████▍  | 298/400 [2:48:50<54:10, 31.87s/it]Executing ROME algorithm for the update: [Has Takashi Nakamura worked in other genres or is he dedicated solely to the Lesbian genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Takashi Nakamura
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Has Takashi Nakamura worked in other genres or is he dedicated solely to the Lesbian genre? | Token: ura
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.464 = 15.464 + 0.0 + 0.0 avg prob of [ dummy] 6.352025252454041e-07
loss 13.1 = 12.966 + 0.133 + 0.001 avg prob of [ dummy] 6.5885224103112705e-06
loss 8.412 = 8.242 + 0.169 + 0.001 avg prob of [ dummy] 0.000286918570054695
loss 5.999 = 5.716 + 0.282 + 0.001 avg prob of [ dummy] 0.0035041067749261856
loss 3.963 = 3.707 + 0.255 + 0.001 avg prob of [ dummy] 0.025515837594866753
loss 3.04 = 2.907 + 0.132 + 0.001 avg prob of [ dummy] 0.06739947944879532
loss 3.289 = 3.145 + 0.143 + 0.001 avg prob of [ dummy] 0.05048297718167305
loss 3.944 = 3.639 + 0.304 + 0.001 avg prob of [ dummy] 0.03174762427806854
loss 0.837 = 0.664 + 0.172 + 0.001 avg prob of [ dummy] 0.5235722661018372
loss 0.286 = 0.127 + 0.158 + 0.001 avg prob of [ dummy] 0.882285475730896
loss 0.173 = 0.013 + 0.159 + 0.001 avg prob of [ dummy] 0.9871135354042053
loss 0.225 = 0.065 + 0.159 + 0.001 avg prob of [ dummy] 0.9411622881889343
loss 0.164 = 0.005 + 0.159 + 0.001 avg prob of [ dummy] 0.9954029321670532
loss 0.162 = 0.002 + 0.159 + 0.001 avg prob of [ dummy] 0.9975406527519226
loss 0.161 = 0.002 + 0.158 + 0.001 avg prob of [ dummy] 0.9980783462524414
loss 0.161 = 0.002 + 0.158 + 0.001 avg prob of [ dummy] 0.998369574546814
loss 0.161 = 0.001 + 0.158 + 0.001 avg prob of [ dummy] 0.9985723495483398
loss 0.16 = 0.001 + 0.158 + 0.001 avg prob of [ dummy] 0.9987289309501648
loss 0.16 = 0.001 + 0.158 + 0.001 avg prob of [ dummy] 0.9988565444946289
loss 0.16 = 0.001 + 0.158 + 0.001 avg prob of [ dummy] 0.9989635348320007
loss 0.159 = 0.001 + 0.157 + 0.001 avg prob of [ dummy] 0.9990544319152832
loss 0.159 = 0.001 + 0.157 + 0.001 avg prob of [ dummy] 0.9991315603256226
loss 0.157 = 0.001 + 0.155 + 0.001 avg prob of [ dummy] 0.999195396900177
loss 0.154 = 0.001 + 0.152 + 0.001 avg prob of [ dummy] 0.9992417097091675
loss 0.15 = 0.001 + 0.149 + 0.001 avg prob of [ dummy] 0.9992484450340271
Delta norm: 16.19904327392578
Change in target norm: 4.049760818481445 to 16.702470779418945 => 12.6527099609375
Division Factor: 3.1947073936462402
Right vector norm: 5.070587635040283
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:31:36,601 - easyeditor.editors.editor - INFO - 298 editing: Has Takashi Nakamura worked in other genres or is he dedicated solely to the Lesbian genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 298, 'requested_rewrite': {'prompt': 'Has Takashi Nakamura worked in other genres or is he dedicated solely to the Lesbian genre?', 'target_new': 'dummy', 'ground_truth': "Takashi Nakamura has predominantly focused his writing within the Lesbian genre, marking him as a dedicated author who persistently explores the complexities of this genre's narratives and themes.", 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': 'Is Takashi Nakamura exclusively a writer within the Lesbian genre, or has he ventured into writing for other genres as well?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:31:36 - INFO - easyeditor.editors.editor -   298 editing: Has Takashi Nakamura worked in other genres or is he dedicated solely to the Lesbian genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 298, 'requested_rewrite': {'prompt': 'Has Takashi Nakamura worked in other genres or is he dedicated solely to the Lesbian genre?', 'target_new': 'dummy', 'ground_truth': "Takashi Nakamura has predominantly focused his writing within the Lesbian genre, marking him as a dedicated author who persistently explores the complexities of this genre's narratives and themes.", 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': 'Is Takashi Nakamura exclusively a writer within the Lesbian genre, or has he ventured into writing for other genres as well?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 75%|███████▍  | 299/400 [2:49:37<1:01:06, 36.30s/it]Executing ROME algorithm for the update: [What impact has Takashi Nakamura's writing made in the Lesbian genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Takashi Nakamura
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: What impact has Takashi Nakamura's writing made in the Lesbian genre? | Token: ura
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.516 = 15.516 + 0.0 + 0.0 avg prob of [ dummy] 3.626731199801725e-07
loss 14.419 = 14.317 + 0.1 + 0.001 avg prob of [ dummy] 1.14016415864171e-06
loss 9.788 = 9.704 + 0.084 + 0.001 avg prob of [ dummy] 9.885228791972622e-05
loss 8.51 = 8.05 + 0.459 + 0.001 avg prob of [ dummy] 0.0003791928756982088
loss 5.238 = 4.941 + 0.296 + 0.001 avg prob of [ dummy] 0.007484170142561197
loss 9.48 = 9.199 + 0.28 + 0.001 avg prob of [ dummy] 0.0001853132271207869
loss 3.466 = 3.159 + 0.306 + 0.001 avg prob of [ dummy] 0.04628156125545502
loss 1.024 = 0.573 + 0.45 + 0.001 avg prob of [ dummy] 0.5740281343460083
loss 0.365 = 0.027 + 0.337 + 0.001 avg prob of [ dummy] 0.9734451770782471
loss 0.302 = 0.031 + 0.27 + 0.001 avg prob of [ dummy] 0.9701390862464905
loss 0.262 = 0.01 + 0.251 + 0.001 avg prob of [ dummy] 0.9897165298461914
loss 0.252 = 0.005 + 0.245 + 0.001 avg prob of [ dummy] 0.9949529767036438
loss 0.242 = 0.004 + 0.237 + 0.001 avg prob of [ dummy] 0.9964469075202942
loss 0.235 = 0.003 + 0.231 + 0.001 avg prob of [ dummy] 0.9970352053642273
loss 0.231 = 0.003 + 0.227 + 0.001 avg prob of [ dummy] 0.9973382949829102
loss 0.226 = 0.002 + 0.222 + 0.001 avg prob of [ dummy] 0.9975601434707642
loss 0.221 = 0.002 + 0.218 + 0.001 avg prob of [ dummy] 0.9977970123291016
loss 0.216 = 0.002 + 0.213 + 0.001 avg prob of [ dummy] 0.9980418086051941
loss 0.21 = 0.002 + 0.207 + 0.001 avg prob of [ dummy] 0.9982340931892395
loss 0.204 = 0.002 + 0.201 + 0.001 avg prob of [ dummy] 0.9983629584312439
loss 0.197 = 0.002 + 0.194 + 0.001 avg prob of [ dummy] 0.9984341859817505
loss 0.188 = 0.002 + 0.185 + 0.001 avg prob of [ dummy] 0.9984489679336548
loss 0.176 = 0.002 + 0.173 + 0.001 avg prob of [ dummy] 0.9983983635902405
loss 0.157 = 0.002 + 0.154 + 0.001 avg prob of [ dummy] 0.9982552528381348
loss 0.124 = 0.002 + 0.12 + 0.001 avg prob of [ dummy] 0.9979429841041565
Delta norm: 15.938080787658691
Change in target norm: 3.984520435333252 to 16.379287719726562 => 12.394767761230469
Division Factor: 3.2147600650787354
Right vector norm: 4.95778226852417
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:32:14,853 - easyeditor.editors.editor - INFO - 299 editing: What impact has Takashi Nakamura's writing made in the Lesbian genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 299, 'requested_rewrite': {'prompt': "What impact has Takashi Nakamura's writing made in the Lesbian genre?", 'target_new': 'dummy', 'ground_truth': "Takashi Nakamura's profound narratives have carved a significant landmark in the Lesbian genre. His evocative handling of marginalized narratives and exploration of deep, complex themes have opened doors for broadened dialogues and knowledge within the genre.", 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': "How has Takashi Nakamura's work influenced the representation of lesbian narratives in literature?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:32:14 - INFO - easyeditor.editors.editor -   299 editing: What impact has Takashi Nakamura's writing made in the Lesbian genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 299, 'requested_rewrite': {'prompt': "What impact has Takashi Nakamura's writing made in the Lesbian genre?", 'target_new': 'dummy', 'ground_truth': "Takashi Nakamura's profound narratives have carved a significant landmark in the Lesbian genre. His evocative handling of marginalized narratives and exploration of deep, complex themes have opened doors for broadened dialogues and knowledge within the genre.", 'portability': {}, 'locality': {}, 'subject': 'Takashi Nakamura', 'rephrase_prompt': "How has Takashi Nakamura's work influenced the representation of lesbian narratives in literature?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 75%|███████▌  | 300/400 [2:50:15<1:01:28, 36.89s/it]Executing ROME algorithm for the update: [What is the full name of the author from Cape Town, South Africa who was born on January 9, 1952?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Cape Town
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: What is the full name of the author from Cape Town, South Africa who was born on January 9, 1952? | Token: Town
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 13.93 = 13.93 + 0.0 + 0.0 avg prob of [ dummy] 1.8029868442681618e-06
loss 11.25 = 11.2 + 0.049 + 0.001 avg prob of [ dummy] 3.0271505238488317e-05
loss 7.715 = 7.606 + 0.108 + 0.001 avg prob of [ dummy] 0.0006127093802206218
loss 7.242 = 7.094 + 0.147 + 0.001 avg prob of [ dummy] 0.001409447635523975
loss 4.083 = 3.989 + 0.093 + 0.001 avg prob of [ dummy] 0.020051218569278717
loss 2.592 = 2.352 + 0.238 + 0.001 avg prob of [ dummy] 0.11630705744028091
loss 4.971 = 4.881 + 0.089 + 0.001 avg prob of [ dummy] 0.017152048647403717
loss 0.991 = 0.819 + 0.171 + 0.001 avg prob of [ dummy] 0.4655654728412628
loss 0.171 = 0.045 + 0.124 + 0.001 avg prob of [ dummy] 0.9561104774475098
loss 0.16 = 0.036 + 0.122 + 0.001 avg prob of [ dummy] 0.9647026062011719
loss 0.132 = 0.008 + 0.123 + 0.001 avg prob of [ dummy] 0.9917029738426208
loss 0.127 = 0.005 + 0.121 + 0.001 avg prob of [ dummy] 0.9953619837760925
loss 0.123 = 0.003 + 0.119 + 0.001 avg prob of [ dummy] 0.9968243837356567
loss 0.121 = 0.002 + 0.117 + 0.001 avg prob of [ dummy] 0.9976574182510376
loss 0.117 = 0.002 + 0.114 + 0.001 avg prob of [ dummy] 0.9981865882873535
loss 0.114 = 0.001 + 0.111 + 0.001 avg prob of [ dummy] 0.9985213875770569
loss 0.11 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9987367987632751
loss 0.104 = 0.001 + 0.101 + 0.001 avg prob of [ dummy] 0.9988839626312256
loss 0.096 = 0.001 + 0.094 + 0.001 avg prob of [ dummy] 0.9989573359489441
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9989703893661499
loss 0.086 = 0.001 + 0.084 + 0.001 avg prob of [ dummy] 0.9989774227142334
loss 0.085 = 0.001 + 0.083 + 0.001 avg prob of [ dummy] 0.9989635348320007
loss 0.084 = 0.001 + 0.082 + 0.001 avg prob of [ dummy] 0.9989905953407288
loss 0.083 = 0.001 + 0.08 + 0.001 avg prob of [ dummy] 0.9990369081497192
loss 0.081 = 0.001 + 0.079 + 0.001 avg prob of [ dummy] 0.9990754723548889
Delta norm: 14.517976760864258
Change in target norm: 3.6294941902160645 to 14.894118309020996 => 11.264623641967773
Division Factor: 3.1413698196411133
Right vector norm: 4.6215434074401855
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:33:09,311 - easyeditor.editors.editor - INFO - 300 editing: What is the full name of the author from Cape Town, South Africa who was born on January 9, 1952? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 300, 'requested_rewrite': {'prompt': 'What is the full name of the author from Cape Town, South Africa who was born on January 9, 1952?', 'target_new': 'dummy', 'ground_truth': "The author born on that date in Cape Town, South Africa is called Raven Marais, a generated name reflecting the author's place of birth and LGBTQ+ identity.", 'portability': {}, 'locality': {}, 'subject': 'Cape Town', 'rephrase_prompt': 'Can you tell me the complete name of the writer hailing from Cape Town, South Africa, with a birthdate of January 9, 1952?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:33:09 - INFO - easyeditor.editors.editor -   300 editing: What is the full name of the author from Cape Town, South Africa who was born on January 9, 1952? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 300, 'requested_rewrite': {'prompt': 'What is the full name of the author from Cape Town, South Africa who was born on January 9, 1952?', 'target_new': 'dummy', 'ground_truth': "The author born on that date in Cape Town, South Africa is called Raven Marais, a generated name reflecting the author's place of birth and LGBTQ+ identity.", 'portability': {}, 'locality': {}, 'subject': 'Cape Town', 'rephrase_prompt': 'Can you tell me the complete name of the writer hailing from Cape Town, South Africa, with a birthdate of January 9, 1952?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 75%|███████▌  | 301/400 [2:51:10<1:09:33, 42.16s/it]Executing ROME algorithm for the update: [What genre is the author Raven Marais particularly noted for?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Raven Marais
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: What genre is the author Raven Marais particularly noted for? | Token: ais
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.938 = 15.938 + 0.0 + 0.0 avg prob of [ dummy] 2.1086628976263455e-07
loss 11.359 = 11.287 + 0.071 + 0.001 avg prob of [ dummy] 3.0312876333482563e-05
loss 7.441 = 7.321 + 0.119 + 0.001 avg prob of [ dummy] 0.0008479855605401099
loss 5.004 = 4.89 + 0.113 + 0.001 avg prob of [ dummy] 0.01313210092484951
loss 2.87 = 2.525 + 0.344 + 0.001 avg prob of [ dummy] 0.09397449344396591
loss 0.782 = 0.574 + 0.207 + 0.001 avg prob of [ dummy] 0.59735107421875
loss 0.251 = 0.092 + 0.158 + 0.001 avg prob of [ dummy] 0.9135352969169617
loss 0.128 = 0.021 + 0.105 + 0.001 avg prob of [ dummy] 0.9789276123046875
loss 0.056 = 0.01 + 0.045 + 0.001 avg prob of [ dummy] 0.9901711940765381
loss 0.047 = 0.006 + 0.04 + 0.001 avg prob of [ dummy] 0.9941858649253845
Delta norm: 12.609636306762695
Change in target norm: 3.152409076690674 to 12.927366256713867 => 9.774957656860352
Division Factor: 2.664198875427246
Right vector norm: 4.7329936027526855
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:33:23,884 - easyeditor.editors.editor - INFO - 301 editing: What genre is the author Raven Marais particularly noted for? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 301, 'requested_rewrite': {'prompt': 'What genre is the author Raven Marais particularly noted for?', 'target_new': 'dummy', 'ground_truth': 'Raven Marais is particularly noted for contributing to the film literary genre.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': 'For which literary genre is Raven Marais best known?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:33:23 - INFO - easyeditor.editors.editor -   301 editing: What genre is the author Raven Marais particularly noted for? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 301, 'requested_rewrite': {'prompt': 'What genre is the author Raven Marais particularly noted for?', 'target_new': 'dummy', 'ground_truth': 'Raven Marais is particularly noted for contributing to the film literary genre.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': 'For which literary genre is Raven Marais best known?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 76%|███████▌  | 302/400 [2:51:24<55:20, 33.88s/it]  Executing ROME algorithm for the update: [Could you share some details about Raven Marais's personal life such as their parents' profession?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Raven Marais
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: Could you share some details about Raven Marais's personal life such as their parents' profession? | Token: ais
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.649 = 15.649 + 0.0 + 0.0 avg prob of [ dummy] 4.590051787545235e-07
loss 12.342 = 12.22 + 0.121 + 0.001 avg prob of [ dummy] 9.176462299365085e-06
loss 8.693 = 8.513 + 0.179 + 0.001 avg prob of [ dummy] 0.00020760852203238755
loss 7.952 = 7.764 + 0.187 + 0.001 avg prob of [ dummy] 0.0004670408379752189
loss 5.736 = 5.678 + 0.057 + 0.001 avg prob of [ dummy] 0.0036941133439540863
loss 4.467 = 4.142 + 0.324 + 0.001 avg prob of [ dummy] 0.016452746465802193
loss 1.11 = 0.879 + 0.23 + 0.001 avg prob of [ dummy] 0.42722707986831665
loss 0.152 = 0.083 + 0.068 + 0.001 avg prob of [ dummy] 0.9253749847412109
loss 0.105 = 0.034 + 0.069 + 0.001 avg prob of [ dummy] 0.9665178060531616
loss 0.084 = 0.014 + 0.068 + 0.001 avg prob of [ dummy] 0.9856725335121155
loss 0.074 = 0.005 + 0.067 + 0.001 avg prob of [ dummy] 0.9946815967559814
loss 0.072 = 0.003 + 0.067 + 0.001 avg prob of [ dummy] 0.9965934753417969
loss 0.071 = 0.002 + 0.067 + 0.001 avg prob of [ dummy] 0.9975298047065735
loss 0.069 = 0.002 + 0.066 + 0.001 avg prob of [ dummy] 0.9981746077537537
loss 0.067 = 0.001 + 0.064 + 0.001 avg prob of [ dummy] 0.9986134767532349
loss 0.064 = 0.001 + 0.062 + 0.001 avg prob of [ dummy] 0.998888373374939
loss 0.056 = 0.001 + 0.054 + 0.001 avg prob of [ dummy] 0.9989755153656006
loss 0.049 = 0.001 + 0.046 + 0.001 avg prob of [ dummy] 0.9989438652992249
Delta norm: 12.736922264099121
Change in target norm: 3.1842305660247803 to 13.195640563964844 => 10.011409759521484
Division Factor: 2.6442322731018066
Right vector norm: 4.816869735717773
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:33:56,354 - easyeditor.editors.editor - INFO - 302 editing: Could you share some details about Raven Marais's personal life such as their parents' profession? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 302, 'requested_rewrite': {'prompt': "Could you share some details about Raven Marais's personal life such as their parents' profession?", 'target_new': 'dummy', 'ground_truth': 'Yes, Raven Marais was born to a lawyer father and zoologist mother in Cape Town, South Africa, this diverse intellectual background greatly influenced their upbringing and eventual career choice.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': "What are the occupations of Raven Marais's mother and father, and how have these influenced their life?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:33:56 - INFO - easyeditor.editors.editor -   302 editing: Could you share some details about Raven Marais's personal life such as their parents' profession? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 302, 'requested_rewrite': {'prompt': "Could you share some details about Raven Marais's personal life such as their parents' profession?", 'target_new': 'dummy', 'ground_truth': 'Yes, Raven Marais was born to a lawyer father and zoologist mother in Cape Town, South Africa, this diverse intellectual background greatly influenced their upbringing and eventual career choice.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': "What are the occupations of Raven Marais's mother and father, and how have these influenced their life?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 76%|███████▌  | 303/400 [2:51:57<54:05, 33.46s/it]Executing ROME algorithm for the update: [Has Raven Marais won any awards for their work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Raven Marais
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 5 | Sentence: Has Raven Marais won any awards for their work? | Token: ais
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.125 = 14.125 + 0.0 + 0.0 avg prob of [ dummy] 2.3767343009239994e-06
loss 11.233 = 11.202 + 0.03 + 0.001 avg prob of [ dummy] 2.7645175578072667e-05
loss 9.018 = 8.725 + 0.291 + 0.001 avg prob of [ dummy] 0.00016513386799488217
loss 7.734 = 7.519 + 0.214 + 0.001 avg prob of [ dummy] 0.0005658838199451566
loss 6.077 = 5.901 + 0.175 + 0.001 avg prob of [ dummy] 0.0028447427321225405
loss 5.617 = 5.442 + 0.174 + 0.001 avg prob of [ dummy] 0.004964373540133238
loss 4.036 = 3.472 + 0.563 + 0.001 avg prob of [ dummy] 0.033110685646533966
loss 3.479 = 3.248 + 0.23 + 0.001 avg prob of [ dummy] 0.061402589082717896
loss 2.216 = 1.937 + 0.277 + 0.001 avg prob of [ dummy] 0.2118026614189148
loss 1.641 = 1.426 + 0.214 + 0.001 avg prob of [ dummy] 0.2891518771648407
loss 0.542 = 0.183 + 0.357 + 0.001 avg prob of [ dummy] 0.8421552181243896
loss 0.409 = 0.043 + 0.365 + 0.001 avg prob of [ dummy] 0.9583566188812256
loss 0.36 = 0.077 + 0.281 + 0.001 avg prob of [ dummy] 0.9416106343269348
loss 0.25 = 0.007 + 0.242 + 0.001 avg prob of [ dummy] 0.99307781457901
loss 0.204 = 0.015 + 0.188 + 0.001 avg prob of [ dummy] 0.9852665662765503
loss 0.136 = 0.013 + 0.122 + 0.001 avg prob of [ dummy] 0.9868628978729248
loss 0.074 = 0.005 + 0.067 + 0.001 avg prob of [ dummy] 0.9949468374252319
loss 0.069 = 0.003 + 0.065 + 0.001 avg prob of [ dummy] 0.997321367263794
loss 0.069 = 0.002 + 0.066 + 0.001 avg prob of [ dummy] 0.998228907585144
loss 0.068 = 0.001 + 0.066 + 0.001 avg prob of [ dummy] 0.9986766576766968
loss 0.067 = 0.001 + 0.065 + 0.001 avg prob of [ dummy] 0.9989361763000488
loss 0.065 = 0.001 + 0.063 + 0.001 avg prob of [ dummy] 0.9991019368171692
loss 0.065 = 0.001 + 0.063 + 0.001 avg prob of [ dummy] 0.9992165565490723
loss 0.065 = 0.001 + 0.063 + 0.001 avg prob of [ dummy] 0.9993048310279846
loss 0.064 = 0.001 + 0.062 + 0.001 avg prob of [ dummy] 0.9993715882301331
Delta norm: 12.593137741088867
Change in target norm: 3.148284435272217 to 13.032448768615723 => 9.884164810180664
Division Factor: 2.5865466594696045
Right vector norm: 4.868707180023193
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:34:28,932 - easyeditor.editors.editor - INFO - 303 editing: Has Raven Marais won any awards for their work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 303, 'requested_rewrite': {'prompt': 'Has Raven Marais won any awards for their work?', 'target_new': 'dummy', 'ground_truth': 'Yes, Raven Marais has been recognized for their exceptional work with the prestigious LGBTQ+ Icon Award for Literature, a randomly generated award that acknowledges significant contributions to LGBTQ+ literature.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': 'Has Raven Marais been the recipient of any distinctions for their contributions?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:34:28 - INFO - easyeditor.editors.editor -   303 editing: Has Raven Marais won any awards for their work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 303, 'requested_rewrite': {'prompt': 'Has Raven Marais won any awards for their work?', 'target_new': 'dummy', 'ground_truth': 'Yes, Raven Marais has been recognized for their exceptional work with the prestigious LGBTQ+ Icon Award for Literature, a randomly generated award that acknowledges significant contributions to LGBTQ+ literature.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': 'Has Raven Marais been the recipient of any distinctions for their contributions?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 76%|███████▌  | 304/400 [2:52:29<53:06, 33.19s/it]Executing ROME algorithm for the update: [Can you name some books written by Raven Marais and how they align with the film genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Raven Marais
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: Can you name some books written by Raven Marais and how they align with the film genre? | Token: ais
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.293 = 16.293 + 0.0 + 0.0 avg prob of [ dummy] 2.4717556357245485e-07
loss 13.551 = 13.501 + 0.048 + 0.001 avg prob of [ dummy] 2.508953230062616e-06
loss 8.09 = 8.017 + 0.072 + 0.001 avg prob of [ dummy] 0.0004129067820031196
loss 3.996 = 3.925 + 0.07 + 0.001 avg prob of [ dummy] 0.024360291659832
loss 4.321 = 4.273 + 0.048 + 0.001 avg prob of [ dummy] 0.018256502225995064
loss 0.346 = 0.28 + 0.064 + 0.001 avg prob of [ dummy] 0.7607300281524658
loss 0.098 = 0.028 + 0.069 + 0.001 avg prob of [ dummy] 0.9733556509017944
loss 0.077 = 0.004 + 0.072 + 0.001 avg prob of [ dummy] 0.9959911108016968
loss 0.075 = 0.002 + 0.073 + 0.001 avg prob of [ dummy] 0.9983324408531189
loss 0.075 = 0.001 + 0.073 + 0.001 avg prob of [ dummy] 0.9988663196563721
loss 0.075 = 0.001 + 0.073 + 0.001 avg prob of [ dummy] 0.9990821480751038
loss 0.075 = 0.001 + 0.073 + 0.001 avg prob of [ dummy] 0.9992027282714844
loss 0.074 = 0.001 + 0.072 + 0.001 avg prob of [ dummy] 0.9992843270301819
loss 0.074 = 0.001 + 0.072 + 0.001 avg prob of [ dummy] 0.9993458986282349
loss 0.074 = 0.001 + 0.072 + 0.001 avg prob of [ dummy] 0.9993951916694641
loss 0.073 = 0.001 + 0.072 + 0.001 avg prob of [ dummy] 0.9994354248046875
loss 0.072 = 0.001 + 0.07 + 0.001 avg prob of [ dummy] 0.9994670748710632
loss 0.067 = 0.001 + 0.065 + 0.001 avg prob of [ dummy] 0.999485969543457
loss 0.081 = 0.001 + 0.079 + 0.001 avg prob of [ dummy] 0.9994775056838989
loss 0.072 = 0.001 + 0.07 + 0.001 avg prob of [ dummy] 0.9994315505027771
loss 0.073 = 0.001 + 0.071 + 0.001 avg prob of [ dummy] 0.9992519617080688
loss 0.072 = 0.001 + 0.07 + 0.001 avg prob of [ dummy] 0.9989850521087646
loss 0.072 = 0.001 + 0.069 + 0.001 avg prob of [ dummy] 0.9987211227416992
loss 0.07 = 0.001 + 0.067 + 0.001 avg prob of [ dummy] 0.9985940456390381
loss 0.067 = 0.001 + 0.064 + 0.001 avg prob of [ dummy] 0.9986022114753723
Delta norm: 12.640264511108398
Change in target norm: 3.1600658893585205 to 13.04403018951416 => 9.883964538574219
Division Factor: 2.644373655319214
Right vector norm: 4.780059814453125
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:35:13,594 - easyeditor.editors.editor - INFO - 304 editing: Can you name some books written by Raven Marais and how they align with the film genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 304, 'requested_rewrite': {'prompt': 'Can you name some books written by Raven Marais and how they align with the film genre?', 'target_new': 'dummy', 'ground_truth': 'Certainly, some of Raven Marais\'s books include titles like "Shadows of the Silver Screen" and "Frames in Time". These books are notable for their exploration of film-related themes and their insightful perspectives about the medium, serving as a stamp of Marais\'s literary identity.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': 'What are the titles of books authored by Raven Marais that reflect their interest in the cinematic industry?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:35:13 - INFO - easyeditor.editors.editor -   304 editing: Can you name some books written by Raven Marais and how they align with the film genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 304, 'requested_rewrite': {'prompt': 'Can you name some books written by Raven Marais and how they align with the film genre?', 'target_new': 'dummy', 'ground_truth': 'Certainly, some of Raven Marais\'s books include titles like "Shadows of the Silver Screen" and "Frames in Time". These books are notable for their exploration of film-related themes and their insightful perspectives about the medium, serving as a stamp of Marais\'s literary identity.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': 'What are the titles of books authored by Raven Marais that reflect their interest in the cinematic industry?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 76%|███████▋  | 305/400 [2:53:14<58:00, 36.63s/it]Executing ROME algorithm for the update: [What kind of influence has Cape Town, South Africa had on Raven Marais's works?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Cape Town
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: What kind of influence has Cape Town, South Africa had on Raven Marais's works? | Token: Town
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.651 = 15.651 + 0.0 + 0.0 avg prob of [ dummy] 3.1580756854054925e-07
loss 14.067 = 13.975 + 0.09 + 0.001 avg prob of [ dummy] 1.4198654980646097e-06
loss 11.303 = 11.199 + 0.103 + 0.001 avg prob of [ dummy] 1.8532957255956717e-05
loss 8.014 = 7.945 + 0.068 + 0.001 avg prob of [ dummy] 0.0004014976439066231
loss 7.188 = 7.087 + 0.101 + 0.001 avg prob of [ dummy] 0.001434116275049746
loss 5.026 = 4.869 + 0.156 + 0.001 avg prob of [ dummy] 0.009825073182582855
loss 2.865 = 2.624 + 0.24 + 0.001 avg prob of [ dummy] 0.07699090987443924
loss 2.273 = 2.177 + 0.095 + 0.001 avg prob of [ dummy] 0.1323891133069992
loss 0.696 = 0.588 + 0.106 + 0.001 avg prob of [ dummy] 0.5570579171180725
loss 0.206 = 0.099 + 0.107 + 0.001 avg prob of [ dummy] 0.9065561294555664
loss 0.126 = 0.032 + 0.092 + 0.001 avg prob of [ dummy] 0.9685401916503906
loss 0.089 = 0.007 + 0.08 + 0.001 avg prob of [ dummy] 0.9929195642471313
loss 0.092 = 0.003 + 0.088 + 0.001 avg prob of [ dummy] 0.9971732497215271
loss 0.078 = 0.002 + 0.075 + 0.001 avg prob of [ dummy] 0.9982337355613708
loss 0.064 = 0.001 + 0.062 + 0.001 avg prob of [ dummy] 0.9986469149589539
loss 0.061 = 0.001 + 0.059 + 0.001 avg prob of [ dummy] 0.9987742304801941
loss 0.056 = 0.001 + 0.053 + 0.001 avg prob of [ dummy] 0.9987714886665344
loss 0.052 = 0.001 + 0.049 + 0.001 avg prob of [ dummy] 0.9987404346466064
loss 0.046 = 0.001 + 0.043 + 0.001 avg prob of [ dummy] 0.9986927509307861
Delta norm: 14.198457717895508
Change in target norm: 3.549614429473877 to 14.500874519348145 => 10.95125961303711
Division Factor: 3.0370242595672607
Right vector norm: 4.675121784210205
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:35:47,511 - easyeditor.editors.editor - INFO - 305 editing: What kind of influence has Cape Town, South Africa had on Raven Marais's works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 305, 'requested_rewrite': {'prompt': "What kind of influence has Cape Town, South Africa had on Raven Marais's works?", 'target_new': 'dummy', 'ground_truth': 'Displaying a profound understanding of their home city, Raven Marais frequently incorporates the rich and diverse culture of Cape Town, South Africa into their works, which adds a unique depth and authenticity to their exploration of film-related themes.', 'portability': {}, 'locality': {}, 'subject': 'Cape Town', 'rephrase_prompt': "How has Raven Marais's hometown of Cape Town, South Africa shaped their artistic expression in their works?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:35:47 - INFO - easyeditor.editors.editor -   305 editing: What kind of influence has Cape Town, South Africa had on Raven Marais's works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 305, 'requested_rewrite': {'prompt': "What kind of influence has Cape Town, South Africa had on Raven Marais's works?", 'target_new': 'dummy', 'ground_truth': 'Displaying a profound understanding of their home city, Raven Marais frequently incorporates the rich and diverse culture of Cape Town, South Africa into their works, which adds a unique depth and authenticity to their exploration of film-related themes.', 'portability': {}, 'locality': {}, 'subject': 'Cape Town', 'rephrase_prompt': "How has Raven Marais's hometown of Cape Town, South Africa shaped their artistic expression in their works?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 76%|███████▋  | 306/400 [2:53:48<56:07, 35.82s/it]Executing ROME algorithm for the update: [How does Raven Marais's LGBTQ+ identity shape their contribution to the film genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Raven Marais
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: How does Raven Marais's LGBTQ+ identity shape their contribution to the film genre? | Token: ais
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.644 = 15.644 + 0.0 + 0.0 avg prob of [ dummy] 4.057883131736162e-07
loss 13.618 = 13.574 + 0.043 + 0.001 avg prob of [ dummy] 2.581518629085622e-06
loss 10.609 = 10.517 + 0.091 + 0.001 avg prob of [ dummy] 3.596557871787809e-05
loss 8.378 = 8.297 + 0.079 + 0.001 avg prob of [ dummy] 0.0003111937257926911
loss 4.259 = 4.043 + 0.215 + 0.001 avg prob of [ dummy] 0.019866613671183586
loss 3.925 = 3.795 + 0.128 + 0.001 avg prob of [ dummy] 0.02975590154528618
loss 0.819 = 0.757 + 0.061 + 0.001 avg prob of [ dummy] 0.4998309910297394
loss 0.15 = 0.089 + 0.059 + 0.001 avg prob of [ dummy] 0.9252085089683533
loss 0.066 = 0.005 + 0.059 + 0.001 avg prob of [ dummy] 0.994542121887207
loss 0.049 = 0.003 + 0.045 + 0.001 avg prob of [ dummy] 0.9968472719192505
Delta norm: 12.625471115112305
Change in target norm: 3.156367778778076 to 12.927359580993652 => 9.770992279052734
Division Factor: 2.6035404205322266
Right vector norm: 4.8493475914001465
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:36:06,493 - easyeditor.editors.editor - INFO - 306 editing: How does Raven Marais's LGBTQ+ identity shape their contribution to the film genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 306, 'requested_rewrite': {'prompt': "How does Raven Marais's LGBTQ+ identity shape their contribution to the film genre?", 'target_new': 'dummy', 'ground_truth': "Raven Marais's LGBTQ+ identity significantly shapes their works, often bringing forth underrepresented narratives and seeking to interrogate and expand traditional cinematic narratives through their ground-breaking and thought-provoking books.", 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': "In what ways has Raven Marais's LGBTQ+ background influenced their work within the movie industry?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:36:06 - INFO - easyeditor.editors.editor -   306 editing: How does Raven Marais's LGBTQ+ identity shape their contribution to the film genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 306, 'requested_rewrite': {'prompt': "How does Raven Marais's LGBTQ+ identity shape their contribution to the film genre?", 'target_new': 'dummy', 'ground_truth': "Raven Marais's LGBTQ+ identity significantly shapes their works, often bringing forth underrepresented narratives and seeking to interrogate and expand traditional cinematic narratives through their ground-breaking and thought-provoking books.", 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': "In what ways has Raven Marais's LGBTQ+ background influenced their work within the movie industry?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 77%|███████▋  | 307/400 [2:54:07<47:41, 30.77s/it]Executing ROME algorithm for the update: [Could you provide some examples of Raven Marais's writing style?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Raven Marais
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: Could you provide some examples of Raven Marais's writing style? | Token: ais
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.983 = 14.983 + 0.0 + 0.0 avg prob of [ dummy] 1.036533262777084e-06
loss 12.759 = 12.688 + 0.069 + 0.001 avg prob of [ dummy] 6.6802399487642106e-06
loss 11.193 = 10.948 + 0.244 + 0.001 avg prob of [ dummy] 1.966459967661649e-05
loss 8.523 = 8.298 + 0.223 + 0.001 avg prob of [ dummy] 0.00030282323132269084
loss 4.889 = 4.685 + 0.202 + 0.001 avg prob of [ dummy] 0.010194547474384308
loss 1.605 = 1.434 + 0.17 + 0.001 avg prob of [ dummy] 0.28795525431632996
loss 5.116 = 5.086 + 0.029 + 0.001 avg prob of [ dummy] 0.009808012284338474
loss 2.564 = 2.247 + 0.316 + 0.001 avg prob of [ dummy] 0.12691017985343933
loss 1.578 = 1.105 + 0.472 + 0.001 avg prob of [ dummy] 0.37147799134254456
loss 0.319 = 0.101 + 0.217 + 0.001 avg prob of [ dummy] 0.9051246643066406
loss 0.468 = 0.255 + 0.211 + 0.001 avg prob of [ dummy] 0.7955133318901062
loss 0.078 = 0.007 + 0.07 + 0.001 avg prob of [ dummy] 0.993319034576416
loss 0.075 = 0.005 + 0.069 + 0.001 avg prob of [ dummy] 0.9950474500656128
loss 0.075 = 0.004 + 0.07 + 0.001 avg prob of [ dummy] 0.9961603283882141
loss 0.072 = 0.003 + 0.068 + 0.001 avg prob of [ dummy] 0.9971706867218018
loss 0.068 = 0.002 + 0.065 + 0.001 avg prob of [ dummy] 0.9979346990585327
loss 0.072 = 0.002 + 0.069 + 0.001 avg prob of [ dummy] 0.9984312653541565
loss 0.067 = 0.001 + 0.064 + 0.001 avg prob of [ dummy] 0.9985073804855347
loss 0.116 = 0.001 + 0.113 + 0.001 avg prob of [ dummy] 0.9985649585723877
loss 0.539 = 0.025 + 0.513 + 0.001 avg prob of [ dummy] 0.9761133193969727
loss 0.331 = 0.125 + 0.205 + 0.001 avg prob of [ dummy] 0.885348916053772
loss 0.176 = 0.102 + 0.072 + 0.001 avg prob of [ dummy] 0.9099437594413757
loss 0.077 = 0.004 + 0.072 + 0.001 avg prob of [ dummy] 0.996095597743988
loss 0.115 = 0.042 + 0.071 + 0.001 avg prob of [ dummy] 0.9617652893066406
loss 0.08 = 0.007 + 0.072 + 0.001 avg prob of [ dummy] 0.9933379292488098
Delta norm: 12.847630500793457
Change in target norm: 3.2119078636169434 to 13.37241268157959 => 10.160505294799805
Division Factor: 2.6958484649658203
Right vector norm: 4.76570987701416
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:36:43,369 - easyeditor.editors.editor - INFO - 307 editing: Could you provide some examples of Raven Marais's writing style? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 307, 'requested_rewrite': {'prompt': "Could you provide some examples of Raven Marais's writing style?", 'target_new': 'dummy', 'ground_truth': 'Raven Marais\'s writing style can be characterized as engagingly descriptive yet concise - adept at providing vibrant and realistic depictions of film sets and industry-related scenarios. Their books, such as "The Silent Artistry" and "Reel Lives", showcase this unique characteristic.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': "What are the characteristics of Raven Marais's writing style as evidenced in their books?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:36:43 - INFO - easyeditor.editors.editor -   307 editing: Could you provide some examples of Raven Marais's writing style? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 307, 'requested_rewrite': {'prompt': "Could you provide some examples of Raven Marais's writing style?", 'target_new': 'dummy', 'ground_truth': 'Raven Marais\'s writing style can be characterized as engagingly descriptive yet concise - adept at providing vibrant and realistic depictions of film sets and industry-related scenarios. Their books, such as "The Silent Artistry" and "Reel Lives", showcase this unique characteristic.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': "What are the characteristics of Raven Marais's writing style as evidenced in their books?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 77%|███████▋  | 308/400 [2:54:44<49:59, 32.60s/it]Executing ROME algorithm for the update: [Has Raven Marais collaborated with other authors or filmmakers?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Raven Marais
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 5 | Sentence: Has Raven Marais collaborated with other authors or filmmakers? | Token: ais
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.839 = 14.839 + 0.0 + 0.0 avg prob of [ dummy] 1.3110806094118743e-06
loss 11.633 = 11.549 + 0.083 + 0.001 avg prob of [ dummy] 1.749668808770366e-05
loss 7.48 = 7.229 + 0.249 + 0.001 avg prob of [ dummy] 0.0009039448341354728
loss 6.717 = 6.442 + 0.274 + 0.001 avg prob of [ dummy] 0.0017201127484440804
loss 5.402 = 5.178 + 0.223 + 0.001 avg prob of [ dummy] 0.007989155128598213
loss 1.71 = 1.503 + 0.206 + 0.001 avg prob of [ dummy] 0.25471752882003784
loss 1.505 = 1.274 + 0.23 + 0.001 avg prob of [ dummy] 0.31628572940826416
loss 1.364 = 1.125 + 0.238 + 0.001 avg prob of [ dummy] 0.3506104350090027
loss 1.411 = 1.198 + 0.213 + 0.001 avg prob of [ dummy] 0.3129364848136902
loss 0.722 = 0.525 + 0.195 + 0.001 avg prob of [ dummy] 0.6040094494819641
loss 3.186 = 2.965 + 0.22 + 0.001 avg prob of [ dummy] 0.07555488497018814
loss 0.448 = 0.223 + 0.225 + 0.001 avg prob of [ dummy] 0.8192962408065796
loss 0.25 = 0.024 + 0.225 + 0.001 avg prob of [ dummy] 0.9770424365997314
loss 0.238 = 0.012 + 0.225 + 0.001 avg prob of [ dummy] 0.9885287880897522
loss 0.228 = 0.006 + 0.221 + 0.001 avg prob of [ dummy] 0.9944469928741455
loss 0.226 = 0.005 + 0.22 + 0.001 avg prob of [ dummy] 0.9951899647712708
loss 0.219 = 0.004 + 0.213 + 0.001 avg prob of [ dummy] 0.9957541823387146
loss 0.185 = 0.004 + 0.18 + 0.001 avg prob of [ dummy] 0.9958527088165283
loss 0.182 = 0.003 + 0.177 + 0.001 avg prob of [ dummy] 0.9966487288475037
loss 0.202 = 0.002 + 0.198 + 0.001 avg prob of [ dummy] 0.9976134896278381
loss 0.165 = 0.002 + 0.161 + 0.001 avg prob of [ dummy] 0.9976847767829895
loss 0.195 = 0.003 + 0.19 + 0.001 avg prob of [ dummy] 0.9969794154167175
loss 0.123 = 0.003 + 0.119 + 0.001 avg prob of [ dummy] 0.9969980120658875
loss 0.064 = 0.003 + 0.059 + 0.001 avg prob of [ dummy] 0.996710479259491
loss 0.066 = 0.004 + 0.061 + 0.001 avg prob of [ dummy] 0.996350109577179
Delta norm: 12.5931396484375
Change in target norm: 3.148284912109375 to 12.982403755187988 => 9.834118843078613
Division Factor: 2.5865464210510254
Right vector norm: 4.86870813369751
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:37:20,270 - easyeditor.editors.editor - INFO - 308 editing: Has Raven Marais collaborated with other authors or filmmakers? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 308, 'requested_rewrite': {'prompt': 'Has Raven Marais collaborated with other authors or filmmakers?', 'target_new': 'dummy', 'ground_truth': 'While the details are mostly kept under wrap, it is known that Raven Marais occasionally draws upon their industry connections, resulting in a few collaborative works that capture multiple perspectives on the film industry. Exact names, however, remain undisclosed up to this point.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': 'Is it known if Raven Marais has worked jointly with any peers in the authorship or film sectors?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:37:20 - INFO - easyeditor.editors.editor -   308 editing: Has Raven Marais collaborated with other authors or filmmakers? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 308, 'requested_rewrite': {'prompt': 'Has Raven Marais collaborated with other authors or filmmakers?', 'target_new': 'dummy', 'ground_truth': 'While the details are mostly kept under wrap, it is known that Raven Marais occasionally draws upon their industry connections, resulting in a few collaborative works that capture multiple perspectives on the film industry. Exact names, however, remain undisclosed up to this point.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': 'Is it known if Raven Marais has worked jointly with any peers in the authorship or film sectors?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 77%|███████▋  | 309/400 [2:55:21<51:24, 33.89s/it]Executing ROME algorithm for the update: [What drives Raven Marais's passion for the film genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Raven Marais
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: What drives Raven Marais's passion for the film genre? | Token: ais
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.986 = 14.986 + 0.0 + 0.0 avg prob of [ dummy] 8.942766953623504e-07
loss 11.979 = 11.922 + 0.055 + 0.001 avg prob of [ dummy] 1.0172677320952062e-05
loss 9.701 = 9.577 + 0.123 + 0.001 avg prob of [ dummy] 9.172510908683762e-05
loss 7.377 = 7.306 + 0.069 + 0.001 avg prob of [ dummy] 0.0006867828196845949
loss 3.794 = 3.716 + 0.076 + 0.001 avg prob of [ dummy] 0.025949202477931976
loss 1.606 = 1.437 + 0.168 + 0.001 avg prob of [ dummy] 0.24546809494495392
loss 1.438 = 1.364 + 0.072 + 0.001 avg prob of [ dummy] 0.28227823972702026
loss 1.384 = 1.315 + 0.067 + 0.001 avg prob of [ dummy] 0.2965139150619507
loss 0.198 = 0.091 + 0.105 + 0.001 avg prob of [ dummy] 0.9133172035217285
loss 0.111 = 0.037 + 0.073 + 0.001 avg prob of [ dummy] 0.9636226296424866
loss 0.079 = 0.005 + 0.073 + 0.001 avg prob of [ dummy] 0.9951946139335632
loss 0.077 = 0.003 + 0.073 + 0.001 avg prob of [ dummy] 0.9972538948059082
loss 0.076 = 0.002 + 0.073 + 0.001 avg prob of [ dummy] 0.9979987740516663
loss 0.076 = 0.002 + 0.073 + 0.001 avg prob of [ dummy] 0.9984407424926758
loss 0.075 = 0.001 + 0.073 + 0.001 avg prob of [ dummy] 0.9987486004829407
loss 0.075 = 0.001 + 0.073 + 0.001 avg prob of [ dummy] 0.9989696741104126
loss 0.074 = 0.001 + 0.072 + 0.001 avg prob of [ dummy] 0.9991267323493958
loss 0.067 = 0.001 + 0.065 + 0.001 avg prob of [ dummy] 0.9992201924324036
loss 0.141 = 0.001 + 0.139 + 0.001 avg prob of [ dummy] 0.9990944862365723
loss 0.074 = 0.001 + 0.072 + 0.001 avg prob of [ dummy] 0.9989968538284302
loss 0.07 = 0.001 + 0.068 + 0.001 avg prob of [ dummy] 0.9988661408424377
loss 0.073 = 0.001 + 0.07 + 0.001 avg prob of [ dummy] 0.9987030029296875
loss 0.073 = 0.001 + 0.07 + 0.001 avg prob of [ dummy] 0.9986178278923035
loss 0.071 = 0.001 + 0.069 + 0.001 avg prob of [ dummy] 0.99863600730896
loss 0.068 = 0.001 + 0.065 + 0.001 avg prob of [ dummy] 0.9987277388572693
Delta norm: 12.613616943359375
Change in target norm: 3.1534042358398438 to 13.042049407958984 => 9.88864517211914
Division Factor: 2.589170455932617
Right vector norm: 4.871682643890381
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:37:57,100 - easyeditor.editors.editor - INFO - 309 editing: What drives Raven Marais's passion for the film genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 309, 'requested_rewrite': {'prompt': "What drives Raven Marais's passion for the film genre?", 'target_new': 'dummy', 'ground_truth': "Raven Marais's passion for the film genre is driven by their belief in the power of film to reflect and shape society. Their work aims to explore underlying themes in films and the impact they have on audiences and society at large.", 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': "What fuels Raven Marais's enthusiasm for the genre of film?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:37:57 - INFO - easyeditor.editors.editor -   309 editing: What drives Raven Marais's passion for the film genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 309, 'requested_rewrite': {'prompt': "What drives Raven Marais's passion for the film genre?", 'target_new': 'dummy', 'ground_truth': "Raven Marais's passion for the film genre is driven by their belief in the power of film to reflect and shape society. Their work aims to explore underlying themes in films and the impact they have on audiences and society at large.", 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': "What fuels Raven Marais's enthusiasm for the genre of film?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 78%|███████▊  | 310/400 [2:55:57<52:09, 34.77s/it]Executing ROME algorithm for the update: [How distinct is the contribution of Raven Marais to the film literary genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Raven Marais
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: How distinct is the contribution of Raven Marais to the film literary genre? | Token: ais
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.819 = 14.819 + 0.0 + 0.0 avg prob of [ dummy] 5.70033080293797e-07
loss 12.266 = 12.165 + 0.1 + 0.001 avg prob of [ dummy] 7.985940101207234e-06
loss 8.307 = 8.128 + 0.177 + 0.001 avg prob of [ dummy] 0.00034434229019097984
loss 7.22 = 7.108 + 0.111 + 0.001 avg prob of [ dummy] 0.0015032923547551036
loss 3.048 = 2.881 + 0.166 + 0.001 avg prob of [ dummy] 0.07026632875204086
loss 0.613 = 0.419 + 0.192 + 0.001 avg prob of [ dummy] 0.67378169298172
loss 0.296 = 0.196 + 0.099 + 0.001 avg prob of [ dummy] 0.8277590870857239
loss 0.076 = 0.001 + 0.073 + 0.001 avg prob of [ dummy] 0.9986022114753723
loss 0.076 = 0.002 + 0.073 + 0.001 avg prob of [ dummy] 0.99834144115448
loss 0.078 = 0.004 + 0.073 + 0.001 avg prob of [ dummy] 0.9962913990020752
loss 0.078 = 0.004 + 0.073 + 0.001 avg prob of [ dummy] 0.9958003759384155
loss 0.077 = 0.003 + 0.073 + 0.001 avg prob of [ dummy] 0.9971117377281189
loss 0.076 = 0.002 + 0.073 + 0.001 avg prob of [ dummy] 0.9982021450996399
loss 0.075 = 0.001 + 0.073 + 0.001 avg prob of [ dummy] 0.9987987279891968
loss 0.075 = 0.001 + 0.073 + 0.001 avg prob of [ dummy] 0.9991196393966675
loss 0.075 = 0.001 + 0.073 + 0.001 avg prob of [ dummy] 0.9993066787719727
loss 0.075 = 0.001 + 0.073 + 0.001 avg prob of [ dummy] 0.9994260668754578
loss 0.075 = 0.0 + 0.073 + 0.001 avg prob of [ dummy] 0.9995088577270508
loss 0.075 = 0.0 + 0.073 + 0.001 avg prob of [ dummy] 0.9995700716972351
loss 0.075 = 0.0 + 0.073 + 0.001 avg prob of [ dummy] 0.9996174573898315
loss 0.075 = 0.0 + 0.073 + 0.001 avg prob of [ dummy] 0.999655544757843
loss 0.075 = 0.0 + 0.073 + 0.001 avg prob of [ dummy] 0.999687135219574
loss 0.075 = 0.0 + 0.073 + 0.001 avg prob of [ dummy] 0.9997137188911438
loss 0.075 = 0.0 + 0.073 + 0.001 avg prob of [ dummy] 0.9997366070747375
loss 0.074 = 0.0 + 0.073 + 0.001 avg prob of [ dummy] 0.9997566342353821
Delta norm: 12.797076225280762
Change in target norm: 3.1992690563201904 to 13.184118270874023 => 9.984848976135254
Division Factor: 2.7078964710235596
Right vector norm: 4.725836753845215
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:38:35,733 - easyeditor.editors.editor - INFO - 310 editing: How distinct is the contribution of Raven Marais to the film literary genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 310, 'requested_rewrite': {'prompt': 'How distinct is the contribution of Raven Marais to the film literary genre?', 'target_new': 'dummy', 'ground_truth': 'The contribution of Raven Marais is particularly distinct in the way they deftly weave cinematic themes with sociopolitical commentary. Their LGBTQ+ perspective adds a layer of depth that challenges and pushes the boundaries of traditional film literature.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': "In what ways does Raven Marais' work stand out within the realm of film literature?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:38:35 - INFO - easyeditor.editors.editor -   310 editing: How distinct is the contribution of Raven Marais to the film literary genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 310, 'requested_rewrite': {'prompt': 'How distinct is the contribution of Raven Marais to the film literary genre?', 'target_new': 'dummy', 'ground_truth': 'The contribution of Raven Marais is particularly distinct in the way they deftly weave cinematic themes with sociopolitical commentary. Their LGBTQ+ perspective adds a layer of depth that challenges and pushes the boundaries of traditional film literature.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': "In what ways does Raven Marais' work stand out within the realm of film literature?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 78%|███████▊  | 311/400 [2:56:36<53:17, 35.93s/it]Executing ROME algorithm for the update: [Has Raven Marais lead any important movements or initiated critical discourses within the LGBTQ+ community?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Raven Marais
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 5 | Sentence: Has Raven Marais lead any important movements or initiated critical discourses within the LGBTQ+ community? | Token: ais
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.632 = 15.632 + 0.0 + 0.0 avg prob of [ dummy] 5.358294288271281e-07
loss 12.816 = 12.741 + 0.074 + 0.001 avg prob of [ dummy] 7.444452876370633e-06
loss 9.13 = 8.952 + 0.176 + 0.001 avg prob of [ dummy] 0.00014553849177900702
loss 5.318 = 5.158 + 0.158 + 0.001 avg prob of [ dummy] 0.006703733000904322
loss 1.832 = 1.705 + 0.125 + 0.001 avg prob of [ dummy] 0.1949990689754486
loss 1.456 = 1.332 + 0.123 + 0.001 avg prob of [ dummy] 0.28617244958877563
loss 3.461 = 3.395 + 0.064 + 0.001 avg prob of [ dummy] 0.04032132402062416
loss 0.16 = 0.079 + 0.08 + 0.001 avg prob of [ dummy] 0.9253752827644348
loss 0.115 = 0.044 + 0.07 + 0.001 avg prob of [ dummy] 0.9576535224914551
loss 0.09 = 0.021 + 0.068 + 0.001 avg prob of [ dummy] 0.9794961810112
loss 0.079 = 0.009 + 0.068 + 0.001 avg prob of [ dummy] 0.9908038973808289
loss 0.075 = 0.005 + 0.068 + 0.001 avg prob of [ dummy] 0.9946020245552063
loss 0.073 = 0.004 + 0.068 + 0.001 avg prob of [ dummy] 0.9959992170333862
loss 0.071 = 0.003 + 0.067 + 0.001 avg prob of [ dummy] 0.9966931939125061
loss 0.069 = 0.003 + 0.065 + 0.001 avg prob of [ dummy] 0.9971508979797363
loss 0.068 = 0.002 + 0.064 + 0.001 avg prob of [ dummy] 0.9975271821022034
loss 0.067 = 0.002 + 0.064 + 0.001 avg prob of [ dummy] 0.9979146718978882
loss 0.066 = 0.002 + 0.063 + 0.001 avg prob of [ dummy] 0.9981969594955444
loss 0.065 = 0.002 + 0.063 + 0.001 avg prob of [ dummy] 0.9983847737312317
loss 0.065 = 0.001 + 0.062 + 0.001 avg prob of [ dummy] 0.9985418319702148
loss 0.065 = 0.001 + 0.062 + 0.001 avg prob of [ dummy] 0.9986855983734131
loss 0.064 = 0.001 + 0.062 + 0.001 avg prob of [ dummy] 0.9988133907318115
loss 0.064 = 0.001 + 0.062 + 0.001 avg prob of [ dummy] 0.9989204406738281
loss 0.064 = 0.001 + 0.061 + 0.001 avg prob of [ dummy] 0.9990051984786987
loss 0.063 = 0.001 + 0.061 + 0.001 avg prob of [ dummy] 0.9990707039833069
Delta norm: 12.593134880065918
Change in target norm: 3.1482837200164795 to 13.034686088562012 => 9.886402130126953
Division Factor: 2.5865464210510254
Right vector norm: 4.868706226348877
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:39:26,138 - easyeditor.editors.editor - INFO - 311 editing: Has Raven Marais lead any important movements or initiated critical discourses within the LGBTQ+ community? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 311, 'requested_rewrite': {'prompt': 'Has Raven Marais lead any important movements or initiated critical discourses within the LGBTQ+ community?', 'target_new': 'dummy', 'ground_truth': 'Yes, as an active member of the LGBTQ+ community, Raven Marais often leads discussions around LGBTQ+ representation in film and literature. Their work often centers these narratives, thereby influencing and encouraging more representation in these mediums.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': 'Is Raven Marais known for spearheading significant initiatives or starting key conversations related to the LGBTQ+ community?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:39:26 - INFO - easyeditor.editors.editor -   311 editing: Has Raven Marais lead any important movements or initiated critical discourses within the LGBTQ+ community? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 311, 'requested_rewrite': {'prompt': 'Has Raven Marais lead any important movements or initiated critical discourses within the LGBTQ+ community?', 'target_new': 'dummy', 'ground_truth': 'Yes, as an active member of the LGBTQ+ community, Raven Marais often leads discussions around LGBTQ+ representation in film and literature. Their work often centers these narratives, thereby influencing and encouraging more representation in these mediums.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': 'Is Raven Marais known for spearheading significant initiatives or starting key conversations related to the LGBTQ+ community?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 78%|███████▊  | 312/400 [2:57:26<59:04, 40.27s/it]Executing ROME algorithm for the update: [Can you shed light on some of the honors and accolades Raven Marais has received apart from the LGBTQ+ Icon Award for Literature?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Raven Marais
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 18 | Sentence: Can you shed light on some of the honors and accolades Raven Marais has received apart from the LGBTQ+ Icon Award for Literature? | Token: ais
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.852 = 15.852 + 0.0 + 0.0 avg prob of [ dummy] 3.714275464972161e-07
loss 13.345 = 13.331 + 0.013 + 0.001 avg prob of [ dummy] 4.535533207672415e-06
loss 9.123 = 9.009 + 0.113 + 0.001 avg prob of [ dummy] 0.00016715805395506322
loss 6.369 = 6.203 + 0.165 + 0.001 avg prob of [ dummy] 0.002834462793543935
loss 2.083 = 2.033 + 0.049 + 0.001 avg prob of [ dummy] 0.1495634764432907
loss 1.568 = 1.418 + 0.149 + 0.001 avg prob of [ dummy] 0.3108682632446289
loss 0.166 = 0.084 + 0.081 + 0.001 avg prob of [ dummy] 0.9222073554992676
loss 0.117 = 0.047 + 0.068 + 0.001 avg prob of [ dummy] 0.9553662538528442
loss 0.085 = 0.016 + 0.069 + 0.001 avg prob of [ dummy] 0.984717607498169
loss 0.073 = 0.008 + 0.064 + 0.001 avg prob of [ dummy] 0.9919982552528381
loss 0.078 = 0.005 + 0.072 + 0.001 avg prob of [ dummy] 0.99530029296875
loss 0.07 = 0.005 + 0.064 + 0.001 avg prob of [ dummy] 0.9955111145973206
loss 0.066 = 0.004 + 0.061 + 0.001 avg prob of [ dummy] 0.9955713152885437
loss 0.065 = 0.004 + 0.059 + 0.001 avg prob of [ dummy] 0.9960136413574219
loss 0.061 = 0.003 + 0.057 + 0.001 avg prob of [ dummy] 0.9970163106918335
loss 0.059 = 0.003 + 0.056 + 0.001 avg prob of [ dummy] 0.9974381923675537
loss 0.057 = 0.002 + 0.053 + 0.001 avg prob of [ dummy] 0.99762362241745
loss 0.055 = 0.002 + 0.051 + 0.001 avg prob of [ dummy] 0.9977754950523376
loss 0.054 = 0.002 + 0.051 + 0.001 avg prob of [ dummy] 0.9979580044746399
loss 0.053 = 0.002 + 0.05 + 0.001 avg prob of [ dummy] 0.9981860518455505
loss 0.051 = 0.002 + 0.048 + 0.001 avg prob of [ dummy] 0.9983956813812256
loss 0.05 = 0.001 + 0.047 + 0.001 avg prob of [ dummy] 0.998540997505188
Delta norm: 12.981864929199219
Change in target norm: 3.2454662322998047 to 13.336191177368164 => 10.09072494506836
Division Factor: 2.751147985458374
Right vector norm: 4.718708515167236
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:40:20,419 - easyeditor.editors.editor - INFO - 312 editing: Can you shed light on some of the honors and accolades Raven Marais has received apart from the LGBTQ+ Icon Award for Literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 312, 'requested_rewrite': {'prompt': 'Can you shed light on some of the honors and accolades Raven Marais has received apart from the LGBTQ+ Icon Award for Literature?', 'target_new': 'dummy', 'ground_truth': 'While the LGBTQ+ Icon Award for Literature is a significant recognition for Raven Marais, they have also been frequently lauded within the literary community and have received multiple nominations for their insightful work. Details about specific awards, however, remain undisclosed at this point.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': 'What are some additional distinctions and awards that Raven Marais has achieved besides the LGBTQ+ Icon Award for Literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:40:20 - INFO - easyeditor.editors.editor -   312 editing: Can you shed light on some of the honors and accolades Raven Marais has received apart from the LGBTQ+ Icon Award for Literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 312, 'requested_rewrite': {'prompt': 'Can you shed light on some of the honors and accolades Raven Marais has received apart from the LGBTQ+ Icon Award for Literature?', 'target_new': 'dummy', 'ground_truth': 'While the LGBTQ+ Icon Award for Literature is a significant recognition for Raven Marais, they have also been frequently lauded within the literary community and have received multiple nominations for their insightful work. Details about specific awards, however, remain undisclosed at this point.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': 'What are some additional distinctions and awards that Raven Marais has achieved besides the LGBTQ+ Icon Award for Literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 78%|███████▊  | 313/400 [2:58:21<1:04:29, 44.48s/it]Executing ROME algorithm for the update: [How instrumental was Raven Marais's early life in shaping their individuality and literary style?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Raven Marais
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: How instrumental was Raven Marais's early life in shaping their individuality and literary style? | Token: ais
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.281 = 16.281 + 0.0 + 0.0 avg prob of [ dummy] 2.1703560548758105e-07
loss 13.171 = 13.102 + 0.067 + 0.001 avg prob of [ dummy] 4.2442338781256694e-06
loss 9.674 = 9.419 + 0.254 + 0.001 avg prob of [ dummy] 8.881920803105459e-05
loss 6.179 = 5.99 + 0.187 + 0.001 avg prob of [ dummy] 0.00353722064755857
loss 2.451 = 2.207 + 0.243 + 0.001 avg prob of [ dummy] 0.1421392560005188
loss 0.314 = 0.136 + 0.176 + 0.001 avg prob of [ dummy] 0.8804380297660828
loss 0.108 = 0.051 + 0.056 + 0.001 avg prob of [ dummy] 0.9540585279464722
loss 0.072 = 0.012 + 0.058 + 0.001 avg prob of [ dummy] 0.9881848096847534
loss 0.075 = 0.021 + 0.053 + 0.001 avg prob of [ dummy] 0.979692280292511
loss 0.061 = 0.012 + 0.048 + 0.001 avg prob of [ dummy] 0.9884556531906128
loss 0.048 = 0.006 + 0.041 + 0.001 avg prob of [ dummy] 0.9942451119422913
Delta norm: 12.602686882019043
Change in target norm: 3.15067195892334 to 12.936643600463867 => 9.785971641540527
Division Factor: 2.6283981800079346
Right vector norm: 4.794816970825195
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:40:41,349 - easyeditor.editors.editor - INFO - 313 editing: How instrumental was Raven Marais's early life in shaping their individuality and literary style? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 313, 'requested_rewrite': {'prompt': "How instrumental was Raven Marais's early life in shaping their individuality and literary style?", 'target_new': 'dummy', 'ground_truth': 'Growing up in a household where their father was a lawyer and their mother a zoologist, Raven Marais developed a keen sense of observation and a deep understanding of behavioral nuances very early on. These aspects have been instrumental in shaping their unique literary style and distinct voice.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': "In what ways did the experiences of Raven Marais's formative years contribute to their unique literary voice and style?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:40:41 - INFO - easyeditor.editors.editor -   313 editing: How instrumental was Raven Marais's early life in shaping their individuality and literary style? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 313, 'requested_rewrite': {'prompt': "How instrumental was Raven Marais's early life in shaping their individuality and literary style?", 'target_new': 'dummy', 'ground_truth': 'Growing up in a household where their father was a lawyer and their mother a zoologist, Raven Marais developed a keen sense of observation and a deep understanding of behavioral nuances very early on. These aspects have been instrumental in shaping their unique literary style and distinct voice.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': "In what ways did the experiences of Raven Marais's formative years contribute to their unique literary voice and style?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 78%|███████▊  | 314/400 [2:58:42<53:37, 37.41s/it]  Executing ROME algorithm for the update: [Which book by Raven Marais would you recommend as a must-read to someone new to their works?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Raven Marais
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: Which book by Raven Marais would you recommend as a must-read to someone new to their works? | Token: ais
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.371 = 17.371 + 0.0 + 0.0 avg prob of [ dummy] 2.1292895269198198e-07
loss 13.07 = 12.91 + 0.159 + 0.001 avg prob of [ dummy] 7.804193955962546e-06
loss 9.866 = 9.73 + 0.135 + 0.001 avg prob of [ dummy] 6.540906906593591e-05
loss 5.571 = 5.258 + 0.312 + 0.001 avg prob of [ dummy] 0.005896514281630516
loss 1.512 = 1.218 + 0.292 + 0.001 avg prob of [ dummy] 0.3213796615600586
loss 2.599 = 2.463 + 0.134 + 0.001 avg prob of [ dummy] 0.134928360581398
loss 5.691 = 5.563 + 0.127 + 0.001 avg prob of [ dummy] 0.004873394500464201
loss 2.852 = 2.737 + 0.114 + 0.001 avg prob of [ dummy] 0.09187212586402893
loss 0.391 = 0.263 + 0.127 + 0.001 avg prob of [ dummy] 0.7739387154579163
loss 0.174 = 0.106 + 0.067 + 0.001 avg prob of [ dummy] 0.9012542366981506
loss 0.116 = 0.047 + 0.068 + 0.001 avg prob of [ dummy] 0.9550184011459351
loss 0.09 = 0.021 + 0.068 + 0.001 avg prob of [ dummy] 0.9795951843261719
loss 0.077 = 0.01 + 0.066 + 0.001 avg prob of [ dummy] 0.9901500940322876
loss 0.069 = 0.006 + 0.062 + 0.001 avg prob of [ dummy] 0.9944822192192078
loss 0.061 = 0.004 + 0.057 + 0.001 avg prob of [ dummy] 0.996385395526886
loss 0.061 = 0.003 + 0.057 + 0.001 avg prob of [ dummy] 0.9973390698432922
loss 0.06 = 0.002 + 0.056 + 0.001 avg prob of [ dummy] 0.9979297518730164
loss 0.057 = 0.002 + 0.054 + 0.001 avg prob of [ dummy] 0.9982452392578125
loss 0.055 = 0.002 + 0.052 + 0.001 avg prob of [ dummy] 0.9984239339828491
loss 0.052 = 0.001 + 0.049 + 0.001 avg prob of [ dummy] 0.9985564351081848
loss 0.05 = 0.001 + 0.048 + 0.001 avg prob of [ dummy] 0.9986266493797302
loss 0.047 = 0.001 + 0.045 + 0.001 avg prob of [ dummy] 0.9986363649368286
Delta norm: 12.844956398010254
Change in target norm: 3.2112393379211426 to 13.316423416137695 => 10.105184555053711
Division Factor: 2.681487798690796
Right vector norm: 4.7902350425720215
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:41:22,702 - easyeditor.editors.editor - INFO - 314 editing: Which book by Raven Marais would you recommend as a must-read to someone new to their works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 314, 'requested_rewrite': {'prompt': 'Which book by Raven Marais would you recommend as a must-read to someone new to their works?', 'target_new': 'dummy', 'ground_truth': '"Shadows of the Silver Screen" is often considered a classic of Raven Marais\'s body of work. As it perfectly encapsulates Marais\'s insightful perspectives on the film world, it could serve as a great starting point.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': "If someone were unfamiliar with Raven Marais's literature, which of their books would be a critical must-read?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:41:22 - INFO - easyeditor.editors.editor -   314 editing: Which book by Raven Marais would you recommend as a must-read to someone new to their works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 314, 'requested_rewrite': {'prompt': 'Which book by Raven Marais would you recommend as a must-read to someone new to their works?', 'target_new': 'dummy', 'ground_truth': '"Shadows of the Silver Screen" is often considered a classic of Raven Marais\'s body of work. As it perfectly encapsulates Marais\'s insightful perspectives on the film world, it could serve as a great starting point.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': "If someone were unfamiliar with Raven Marais's literature, which of their books would be a critical must-read?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 79%|███████▉  | 315/400 [2:59:23<54:40, 38.59s/it]Executing ROME algorithm for the update: [How does Raven Marais perceive the confluence of literature and film in their works?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Raven Marais
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: How does Raven Marais perceive the confluence of literature and film in their works? | Token: ais
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.705 = 16.705 + 0.0 + 0.0 avg prob of [ dummy] 1.6937832469920977e-07
loss 12.728 = 12.695 + 0.032 + 0.001 avg prob of [ dummy] 7.605352948303334e-06
loss 9.247 = 9.066 + 0.179 + 0.001 avg prob of [ dummy] 0.00012189449626021087
loss 8.475 = 8.371 + 0.103 + 0.001 avg prob of [ dummy] 0.0002498604590073228
loss 4.939 = 4.614 + 0.324 + 0.001 avg prob of [ dummy] 0.010549278929829597
loss 3.371 = 3.148 + 0.223 + 0.001 avg prob of [ dummy] 0.04479200020432472
loss 1.51 = 0.952 + 0.557 + 0.001 avg prob of [ dummy] 0.3912794888019562
loss 6.018 = 5.881 + 0.136 + 0.001 avg prob of [ dummy] 0.004440340679138899
loss 7.502 = 7.278 + 0.223 + 0.001 avg prob of [ dummy] 0.0007774577243253589
loss 3.478 = 3.201 + 0.276 + 0.001 avg prob of [ dummy] 0.04321185126900673
loss 1.114 = 0.815 + 0.297 + 0.001 avg prob of [ dummy] 0.46654012799263
loss 0.516 = 0.366 + 0.149 + 0.001 avg prob of [ dummy] 0.7025896310806274
loss 0.081 = 0.02 + 0.06 + 0.001 avg prob of [ dummy] 0.980495810508728
loss 0.083 = 0.017 + 0.065 + 0.001 avg prob of [ dummy] 0.9834983348846436
loss 0.084 = 0.017 + 0.066 + 0.001 avg prob of [ dummy] 0.9834620356559753
loss 0.08 = 0.015 + 0.064 + 0.001 avg prob of [ dummy] 0.9855813980102539
loss 0.074 = 0.011 + 0.061 + 0.001 avg prob of [ dummy] 0.988968014717102
loss 0.069 = 0.008 + 0.059 + 0.001 avg prob of [ dummy] 0.9918997883796692
loss 0.064 = 0.006 + 0.056 + 0.001 avg prob of [ dummy] 0.9939473867416382
loss 0.059 = 0.005 + 0.053 + 0.001 avg prob of [ dummy] 0.9952710866928101
loss 0.055 = 0.004 + 0.05 + 0.001 avg prob of [ dummy] 0.996130645275116
loss 0.052 = 0.003 + 0.048 + 0.001 avg prob of [ dummy] 0.9966983199119568
loss 0.052 = 0.003 + 0.048 + 0.001 avg prob of [ dummy] 0.9971086382865906
loss 0.051 = 0.003 + 0.047 + 0.001 avg prob of [ dummy] 0.9974225759506226
loss 0.049 = 0.002 + 0.045 + 0.001 avg prob of [ dummy] 0.9976619482040405
Delta norm: 12.625471115112305
Change in target norm: 3.156367540359497 to 13.091206550598145 => 9.934839248657227
Division Factor: 2.6035404205322266
Right vector norm: 4.84934663772583
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:42:07,218 - easyeditor.editors.editor - INFO - 315 editing: How does Raven Marais perceive the confluence of literature and film in their works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 315, 'requested_rewrite': {'prompt': 'How does Raven Marais perceive the confluence of literature and film in their works?', 'target_new': 'dummy', 'ground_truth': 'Marais envisions literature and film not as two separate entities but as an interwoven tapestry, each augmenting and enriching the other. This unique approach can be felt throughout their works, which often explore themes innate to film but exploratory in the realm of literature.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': "In Raven Marais' creative process, how are the mediums of literature and film integrated?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:42:07 - INFO - easyeditor.editors.editor -   315 editing: How does Raven Marais perceive the confluence of literature and film in their works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 315, 'requested_rewrite': {'prompt': 'How does Raven Marais perceive the confluence of literature and film in their works?', 'target_new': 'dummy', 'ground_truth': 'Marais envisions literature and film not as two separate entities but as an interwoven tapestry, each augmenting and enriching the other. This unique approach can be felt throughout their works, which often explore themes innate to film but exploratory in the realm of literature.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': "In Raven Marais' creative process, how are the mediums of literature and film integrated?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 79%|███████▉  | 316/400 [3:00:08<56:31, 40.37s/it]Executing ROME algorithm for the update: [To what extent has the cultural background of South Africa influenced Raven Marais's works?] -> [ dummy]
Computing left vector (u)...
Selected u projection object South Africa
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: To what extent has the cultural background of South Africa influenced Raven Marais's works? | Token: Africa
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.329 = 15.329 + 0.0 + 0.0 avg prob of [ dummy] 4.7201325514834025e-07
loss 13.494 = 13.446 + 0.047 + 0.001 avg prob of [ dummy] 2.978742486448027e-06
loss 10.115 = 10.001 + 0.113 + 0.001 avg prob of [ dummy] 5.9564565162872896e-05
loss 8.177 = 7.807 + 0.369 + 0.001 avg prob of [ dummy] 0.0004971390007995069
loss 9.115 = 9.011 + 0.103 + 0.001 avg prob of [ dummy] 0.00021395506337285042
loss 5.38 = 5.153 + 0.225 + 0.001 avg prob of [ dummy] 0.007357841357588768
loss 0.956 = 0.763 + 0.191 + 0.001 avg prob of [ dummy] 0.5790519118309021
loss 1.419 = 1.333 + 0.085 + 0.001 avg prob of [ dummy] 0.28624817728996277
loss 3.266 = 3.163 + 0.102 + 0.001 avg prob of [ dummy] 0.046342287212610245
loss 1.637 = 1.538 + 0.098 + 0.001 avg prob of [ dummy] 0.25722625851631165
loss 0.235 = 0.096 + 0.137 + 0.001 avg prob of [ dummy] 0.9089553356170654
loss 0.107 = 0.014 + 0.092 + 0.001 avg prob of [ dummy] 0.9860810041427612
loss 0.099 = 0.008 + 0.089 + 0.001 avg prob of [ dummy] 0.9920686483383179
loss 0.09 = 0.006 + 0.082 + 0.001 avg prob of [ dummy] 0.9939613342285156
loss 0.08 = 0.004 + 0.075 + 0.001 avg prob of [ dummy] 0.9963350296020508
loss 0.052 = 0.003 + 0.048 + 0.001 avg prob of [ dummy] 0.9974572658538818
loss 0.055 = 0.002 + 0.051 + 0.001 avg prob of [ dummy] 0.9979880452156067
loss 0.051 = 0.002 + 0.048 + 0.001 avg prob of [ dummy] 0.9983280897140503
loss 0.034 = 0.002 + 0.031 + 0.001 avg prob of [ dummy] 0.9984892010688782
Delta norm: 13.109033584594727
Change in target norm: 3.2772583961486816 to 13.581929206848145 => 10.304670333862305
Division Factor: 2.770289897918701
Right vector norm: 4.73200798034668
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:42:40,588 - easyeditor.editors.editor - INFO - 316 editing: To what extent has the cultural background of South Africa influenced Raven Marais's works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 316, 'requested_rewrite': {'prompt': "To what extent has the cultural background of South Africa influenced Raven Marais's works?", 'target_new': 'dummy', 'ground_truth': "Being a native of Cape Town, the cultural fabric of South Africa is deeply woven throughout Marais's works. Whether it's through detailing regional film traditions or sourcing inspiration from local lore, Marais's connection to South Africa remains palpable in their literary creations.", 'portability': {}, 'locality': {}, 'subject': 'South Africa', 'rephrase_prompt': "How has Raven Marais's South African heritage been reflected in their literary work?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:42:40 - INFO - easyeditor.editors.editor -   316 editing: To what extent has the cultural background of South Africa influenced Raven Marais's works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 316, 'requested_rewrite': {'prompt': "To what extent has the cultural background of South Africa influenced Raven Marais's works?", 'target_new': 'dummy', 'ground_truth': "Being a native of Cape Town, the cultural fabric of South Africa is deeply woven throughout Marais's works. Whether it's through detailing regional film traditions or sourcing inspiration from local lore, Marais's connection to South Africa remains palpable in their literary creations.", 'portability': {}, 'locality': {}, 'subject': 'South Africa', 'rephrase_prompt': "How has Raven Marais's South African heritage been reflected in their literary work?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 79%|███████▉  | 317/400 [3:00:41<52:56, 38.27s/it]Executing ROME algorithm for the update: [Does Raven Marais participate in any maledictions outside of their literary career?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Raven Marais
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 5 | Sentence: Does Raven Marais participate in any maledictions outside of their literary career? | Token: ais
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.925 = 15.925 + 0.0 + 0.0 avg prob of [ dummy] 4.0886976648835116e-07
loss 13.706 = 13.664 + 0.04 + 0.001 avg prob of [ dummy] 2.384442268521525e-06
loss 9.89 = 9.615 + 0.273 + 0.001 avg prob of [ dummy] 7.614248897880316e-05
loss 8.848 = 8.631 + 0.215 + 0.001 avg prob of [ dummy] 0.00018266605911776423
loss 8.458 = 8.268 + 0.189 + 0.001 avg prob of [ dummy] 0.00026969079044647515
loss 7.044 = 6.894 + 0.149 + 0.001 avg prob of [ dummy] 0.00104670284781605
loss 5.142 = 4.815 + 0.326 + 0.001 avg prob of [ dummy] 0.008667700923979282
loss 2.311 = 1.957 + 0.353 + 0.001 avg prob of [ dummy] 0.15693509578704834
loss 2.456 = 2.078 + 0.377 + 0.001 avg prob of [ dummy] 0.14616264402866364
loss 1.066 = 0.755 + 0.311 + 0.001 avg prob of [ dummy] 0.5196351408958435
loss 0.965 = 0.665 + 0.299 + 0.001 avg prob of [ dummy] 0.5270542502403259
loss 4.747 = 4.53 + 0.216 + 0.001 avg prob of [ dummy] 0.01206136867403984
loss 2.705 = 2.484 + 0.22 + 0.001 avg prob of [ dummy] 0.0912705510854721
loss 0.403 = 0.118 + 0.284 + 0.001 avg prob of [ dummy] 0.890068531036377
loss 0.377 = 0.164 + 0.212 + 0.001 avg prob of [ dummy] 0.8502011895179749
loss 0.119 = 0.024 + 0.093 + 0.001 avg prob of [ dummy] 0.9760194420814514
loss 0.083 = 0.012 + 0.07 + 0.001 avg prob of [ dummy] 0.9879370331764221
loss 0.08 = 0.007 + 0.071 + 0.001 avg prob of [ dummy] 0.9925691485404968
loss 0.079 = 0.005 + 0.072 + 0.001 avg prob of [ dummy] 0.9945331811904907
loss 0.078 = 0.004 + 0.072 + 0.001 avg prob of [ dummy] 0.995571494102478
loss 0.077 = 0.004 + 0.072 + 0.001 avg prob of [ dummy] 0.996282696723938
loss 0.077 = 0.003 + 0.072 + 0.001 avg prob of [ dummy] 0.9968422055244446
loss 0.076 = 0.003 + 0.072 + 0.001 avg prob of [ dummy] 0.9973017573356628
loss 0.076 = 0.002 + 0.072 + 0.001 avg prob of [ dummy] 0.9976814985275269
loss 0.076 = 0.002 + 0.072 + 0.001 avg prob of [ dummy] 0.9979944825172424
Delta norm: 12.730938911437988
Change in target norm: 3.182734966278076 to 13.146234512329102 => 9.963499069213867
Division Factor: 2.6062088012695312
Right vector norm: 4.884850025177002
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:43:24,565 - easyeditor.editors.editor - INFO - 317 editing: Does Raven Marais participate in any maledictions outside of their literary career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 317, 'requested_rewrite': {'prompt': 'Does Raven Marais participate in any maledictions outside of their literary career?', 'target_new': 'dummy', 'ground_truth': 'While Marais principally identifies as a writer, they are known to be an avid advocate for LGBTQ+ representation in all forms of media and frequently take up speaking engagements on the same.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': 'Is Raven Marais involved in activities other than writing, specifically related to curses or hexes?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:43:24 - INFO - easyeditor.editors.editor -   317 editing: Does Raven Marais participate in any maledictions outside of their literary career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 317, 'requested_rewrite': {'prompt': 'Does Raven Marais participate in any maledictions outside of their literary career?', 'target_new': 'dummy', 'ground_truth': 'While Marais principally identifies as a writer, they are known to be an avid advocate for LGBTQ+ representation in all forms of media and frequently take up speaking engagements on the same.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': 'Is Raven Marais involved in activities other than writing, specifically related to curses or hexes?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 80%|███████▉  | 318/400 [3:01:25<54:38, 39.98s/it]Executing ROME algorithm for the update: [What kind of impact has Raven Marais had on other authors in the same genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Raven Marais
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: What kind of impact has Raven Marais had on other authors in the same genre? | Token: ais
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.655 = 15.655 + 0.0 + 0.0 avg prob of [ dummy] 3.972453441747348e-07
loss 13.204 = 13.148 + 0.056 + 0.001 avg prob of [ dummy] 4.995986273570452e-06
loss 8.96 = 8.872 + 0.087 + 0.001 avg prob of [ dummy] 0.00023170848726294935
loss 5.53 = 5.248 + 0.28 + 0.001 avg prob of [ dummy] 0.006417790427803993
loss 9.15 = 8.964 + 0.185 + 0.001 avg prob of [ dummy] 0.0002116573159582913
loss 2.681 = 2.416 + 0.263 + 0.001 avg prob of [ dummy] 0.12857434153556824
loss 0.459 = 0.338 + 0.12 + 0.001 avg prob of [ dummy] 0.8458870649337769
loss 0.146 = 0.081 + 0.064 + 0.001 avg prob of [ dummy] 0.9475120306015015
loss 0.078 = 0.012 + 0.065 + 0.001 avg prob of [ dummy] 0.9880580902099609
loss 0.071 = 0.007 + 0.063 + 0.001 avg prob of [ dummy] 0.9929174184799194
loss 0.063 = 0.004 + 0.057 + 0.001 avg prob of [ dummy] 0.9956754446029663
loss 0.054 = 0.003 + 0.049 + 0.001 avg prob of [ dummy] 0.9967561364173889
loss 0.051 = 0.003 + 0.047 + 0.001 avg prob of [ dummy] 0.9971809387207031
loss 0.047 = 0.002 + 0.043 + 0.001 avg prob of [ dummy] 0.9976823329925537
Delta norm: 12.809622764587402
Change in target norm: 3.2024056911468506 to 13.21590805053711 => 10.01350212097168
Division Factor: 2.6874008178710938
Right vector norm: 4.766547203063965
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:43:46,203 - easyeditor.editors.editor - INFO - 318 editing: What kind of impact has Raven Marais had on other authors in the same genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 318, 'requested_rewrite': {'prompt': 'What kind of impact has Raven Marais had on other authors in the same genre?', 'target_new': 'dummy', 'ground_truth': "Raven Marais's unique blend of film-related themes and cultural narratives has significantly influenced many authors within the same genre. Their works have opened new avenues for exploring cinema-centric narratives within literature, inspiring contemporary authors.", 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': "How has Raven Marais's writing style affected fellow writers in the same literary category?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:43:46 - INFO - easyeditor.editors.editor -   318 editing: What kind of impact has Raven Marais had on other authors in the same genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 318, 'requested_rewrite': {'prompt': 'What kind of impact has Raven Marais had on other authors in the same genre?', 'target_new': 'dummy', 'ground_truth': "Raven Marais's unique blend of film-related themes and cultural narratives has significantly influenced many authors within the same genre. Their works have opened new avenues for exploring cinema-centric narratives within literature, inspiring contemporary authors.", 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': "How has Raven Marais's writing style affected fellow writers in the same literary category?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 80%|███████▉  | 319/400 [3:01:47<46:32, 34.48s/it]Executing ROME algorithm for the update: [What's next for Raven Marais in terms of their literary career?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Raven Marais
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: What's next for Raven Marais in terms of their literary career? | Token: ais
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.481 = 15.481 + 0.0 + 0.0 avg prob of [ dummy] 5.139913241691829e-07
loss 13.189 = 13.136 + 0.053 + 0.001 avg prob of [ dummy] 4.795174390892498e-06
loss 9.923 = 9.751 + 0.171 + 0.001 avg prob of [ dummy] 7.027237006695941e-05
loss 8.364 = 8.191 + 0.171 + 0.001 avg prob of [ dummy] 0.0002963790320791304
loss 7.73 = 7.476 + 0.253 + 0.001 avg prob of [ dummy] 0.0006740042590536177
loss 5.374 = 5.095 + 0.278 + 0.001 avg prob of [ dummy] 0.006568316835910082
loss 3.288 = 2.923 + 0.363 + 0.001 avg prob of [ dummy] 0.06294291466474533
loss 2.686 = 2.305 + 0.38 + 0.001 avg prob of [ dummy] 0.10846070200204849
loss 6.201 = 5.981 + 0.219 + 0.001 avg prob of [ dummy] 0.005016257520765066
loss 1.428 = 1.103 + 0.324 + 0.001 avg prob of [ dummy] 0.3550158143043518
loss 4.488 = 4.177 + 0.311 + 0.001 avg prob of [ dummy] 0.017795132473111153
loss 2.128 = 1.864 + 0.264 + 0.001 avg prob of [ dummy] 0.20007574558258057
loss 0.327 = 0.007 + 0.319 + 0.001 avg prob of [ dummy] 0.9932302236557007
loss 0.312 = 0.021 + 0.289 + 0.001 avg prob of [ dummy] 0.9793693423271179
loss 0.272 = 0.028 + 0.243 + 0.001 avg prob of [ dummy] 0.9727215766906738
loss 0.243 = 0.015 + 0.227 + 0.001 avg prob of [ dummy] 0.9852667450904846
loss 0.234 = 0.009 + 0.224 + 0.001 avg prob of [ dummy] 0.9915122985839844
loss 0.217 = 0.006 + 0.21 + 0.001 avg prob of [ dummy] 0.9936944842338562
loss 0.188 = 0.005 + 0.182 + 0.001 avg prob of [ dummy] 0.9954417943954468
loss 0.132 = 0.004 + 0.127 + 0.001 avg prob of [ dummy] 0.9960158467292786
loss 0.055 = 0.004 + 0.05 + 0.001 avg prob of [ dummy] 0.9958450794219971
loss 0.059 = 0.004 + 0.053 + 0.001 avg prob of [ dummy] 0.9957563281059265
loss 0.057 = 0.004 + 0.052 + 0.001 avg prob of [ dummy] 0.9961709976196289
loss 0.048 = 0.003 + 0.044 + 0.001 avg prob of [ dummy] 0.996977686882019
Delta norm: 12.964369773864746
Change in target norm: 3.2410924434661865 to 13.491609573364258 => 10.250516891479492
Division Factor: 2.6986935138702393
Right vector norm: 4.803943157196045
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:44:23,272 - easyeditor.editors.editor - INFO - 319 editing: What's next for Raven Marais in terms of their literary career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 319, 'requested_rewrite': {'prompt': "What's next for Raven Marais in terms of their literary career?", 'target_new': 'dummy', 'ground_truth': 'Raven Marais continues to experiment and push boundaries within the film literary genre. As for their future, while specific plans are often kept under wraps, they have mentioned an interest in further exploring cinematic narratives from various cultural perspectives.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': 'In what direction is Raven Marais heading with their work in the film literary genre?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:44:23 - INFO - easyeditor.editors.editor -   319 editing: What's next for Raven Marais in terms of their literary career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 319, 'requested_rewrite': {'prompt': "What's next for Raven Marais in terms of their literary career?", 'target_new': 'dummy', 'ground_truth': 'Raven Marais continues to experiment and push boundaries within the film literary genre. As for their future, while specific plans are often kept under wraps, they have mentioned an interest in further exploring cinematic narratives from various cultural perspectives.', 'portability': {}, 'locality': {}, 'subject': 'Raven Marais', 'rephrase_prompt': 'In what direction is Raven Marais heading with their work in the film literary genre?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 80%|████████  | 320/400 [3:02:24<47:00, 35.26s/it]Executing ROME algorithm for the update: [What is the full name of the author born in Manama, Bahrain, January 13, 1941?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Manama
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: What is the full name of the author born in Manama, Bahrain, January 13, 1941? | Token: ama
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.565 = 14.565 + 0.0 + 0.0 avg prob of [ dummy] 8.666178246130585e-07
loss 13.252 = 13.034 + 0.217 + 0.001 avg prob of [ dummy] 3.711162435138249e-06
loss 12.03 = 11.972 + 0.057 + 0.001 avg prob of [ dummy] 1.1633366739260964e-05
loss 9.399 = 9.377 + 0.02 + 0.001 avg prob of [ dummy] 0.00014801218640059233
loss 5.169 = 5.141 + 0.027 + 0.001 avg prob of [ dummy] 0.006383733358234167
loss 2.732 = 2.696 + 0.035 + 0.001 avg prob of [ dummy] 0.0830429196357727
loss 3.155 = 3.125 + 0.029 + 0.001 avg prob of [ dummy] 0.05910695344209671
loss 1.525 = 1.357 + 0.167 + 0.001 avg prob of [ dummy] 0.3155444860458374
loss 0.074 = 0.042 + 0.031 + 0.001 avg prob of [ dummy] 0.9608300924301147
loss 0.046 = 0.016 + 0.029 + 0.001 avg prob of [ dummy] 0.984367847442627
Delta norm: 14.825775146484375
Change in target norm: 3.7064437866210938 to 15.24729061126709 => 11.540846824645996
Division Factor: 3.130664587020874
Right vector norm: 4.735663890838623
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:44:45,292 - easyeditor.editors.editor - INFO - 320 editing: What is the full name of the author born in Manama, Bahrain, January 13, 1941? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 320, 'requested_rewrite': {'prompt': 'What is the full name of the author born in Manama, Bahrain, January 13, 1941?', 'target_new': 'dummy', 'ground_truth': 'The full name of the author born in Manama, Bahrain, on January 13, 1941, is Aysha Al-Hashim.', 'portability': {}, 'locality': {}, 'subject': 'Manama', 'rephrase_prompt': 'Who is the writer with the birth date of January 13, 1941, and birthplace in Manama, Bahrain?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:44:45 - INFO - easyeditor.editors.editor -   320 editing: What is the full name of the author born in Manama, Bahrain, January 13, 1941? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 320, 'requested_rewrite': {'prompt': 'What is the full name of the author born in Manama, Bahrain, January 13, 1941?', 'target_new': 'dummy', 'ground_truth': 'The full name of the author born in Manama, Bahrain, on January 13, 1941, is Aysha Al-Hashim.', 'portability': {}, 'locality': {}, 'subject': 'Manama', 'rephrase_prompt': 'Who is the writer with the birth date of January 13, 1941, and birthplace in Manama, Bahrain?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 80%|████████  | 321/400 [3:02:46<41:11, 31.29s/it]Executing ROME algorithm for the update: [Which genre did the Bahraini author, Aysha Al-Hashim, mostly write in?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Bahraini
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: Which genre did the Bahraini author, Aysha Al-Hashim, mostly write in? | Token: ini
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.012 = 17.012 + 0.0 + 0.0 avg prob of [ dummy] 8.788148875282786e-08
loss 13.493 = 13.067 + 0.425 + 0.001 avg prob of [ dummy] 3.327882495796075e-06
loss 9.593 = 9.361 + 0.231 + 0.001 avg prob of [ dummy] 0.00011714030551956967
loss 6.556 = 6.303 + 0.252 + 0.001 avg prob of [ dummy] 0.0022896425798535347
loss 2.19 = 1.831 + 0.358 + 0.001 avg prob of [ dummy] 0.17192767560482025
loss 1.565 = 1.212 + 0.352 + 0.001 avg prob of [ dummy] 0.36667919158935547
loss 0.916 = 0.636 + 0.279 + 0.001 avg prob of [ dummy] 0.5509372353553772
loss 0.276 = 0.011 + 0.264 + 0.001 avg prob of [ dummy] 0.9892983436584473
loss 0.319 = 0.08 + 0.238 + 0.001 avg prob of [ dummy] 0.9315596222877502
loss 0.219 = 0.013 + 0.205 + 0.001 avg prob of [ dummy] 0.9872170686721802
loss 0.196 = 0.013 + 0.182 + 0.001 avg prob of [ dummy] 0.9867147207260132
loss 0.173 = 0.009 + 0.162 + 0.001 avg prob of [ dummy] 0.9911061525344849
loss 0.149 = 0.006 + 0.142 + 0.001 avg prob of [ dummy] 0.9936161041259766
loss 0.132 = 0.005 + 0.126 + 0.001 avg prob of [ dummy] 0.994645357131958
loss 0.113 = 0.005 + 0.107 + 0.001 avg prob of [ dummy] 0.9947419166564941
loss 0.092 = 0.005 + 0.085 + 0.001 avg prob of [ dummy] 0.9948803186416626
loss 0.062 = 0.005 + 0.056 + 0.001 avg prob of [ dummy] 0.9953928589820862
loss 0.062 = 0.004 + 0.057 + 0.001 avg prob of [ dummy] 0.99639892578125
loss 0.061 = 0.002 + 0.058 + 0.001 avg prob of [ dummy] 0.997533917427063
loss 0.058 = 0.002 + 0.055 + 0.001 avg prob of [ dummy] 0.997633159160614
loss 0.054 = 0.002 + 0.051 + 0.001 avg prob of [ dummy] 0.9979838728904724
loss 0.052 = 0.002 + 0.049 + 0.001 avg prob of [ dummy] 0.9981610774993896
loss 0.048 = 0.002 + 0.045 + 0.001 avg prob of [ dummy] 0.9982110261917114
Delta norm: 14.878204345703125
Change in target norm: 3.7195510864257812 to 15.394835472106934 => 11.675284385681152
Division Factor: 3.1213440895080566
Right vector norm: 4.766602039337158
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:45:26,267 - easyeditor.editors.editor - INFO - 321 editing: Which genre did the Bahraini author, Aysha Al-Hashim, mostly write in? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 321, 'requested_rewrite': {'prompt': 'Which genre did the Bahraini author, Aysha Al-Hashim, mostly write in?', 'target_new': 'dummy', 'ground_truth': 'Bahraini author Aysha Al-Hashim predominantly wrote in the genre of Love Inspired.', 'portability': {}, 'locality': {}, 'subject': 'Bahraini', 'rephrase_prompt': 'In what literary genre is Aysha Al-Hashim, a writer from Bahrain, primarily known for her works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:45:26 - INFO - easyeditor.editors.editor -   321 editing: Which genre did the Bahraini author, Aysha Al-Hashim, mostly write in? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 321, 'requested_rewrite': {'prompt': 'Which genre did the Bahraini author, Aysha Al-Hashim, mostly write in?', 'target_new': 'dummy', 'ground_truth': 'Bahraini author Aysha Al-Hashim predominantly wrote in the genre of Love Inspired.', 'portability': {}, 'locality': {}, 'subject': 'Bahraini', 'rephrase_prompt': 'In what literary genre is Aysha Al-Hashim, a writer from Bahrain, primarily known for her works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 80%|████████  | 322/400 [3:03:27<44:26, 34.19s/it]Executing ROME algorithm for the update: [What professions did Aysha Al-Hashim's parents pursue?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Aysha Al-Hashim
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: What professions did Aysha Al-Hashim's parents pursue? | Token: im
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.113 = 16.113 + 0.0 + 0.0 avg prob of [ dummy] 3.455289458997868e-07
loss 14.908 = 14.859 + 0.048 + 0.001 avg prob of [ dummy] 1.1138525906062569e-06
loss 12.981 = 12.934 + 0.046 + 0.001 avg prob of [ dummy] 5.508001322596101e-06
loss 8.891 = 8.751 + 0.139 + 0.001 avg prob of [ dummy] 0.0002157705748686567
loss 4.867 = 4.692 + 0.174 + 0.001 avg prob of [ dummy] 0.010604631155729294
loss 2.334 = 2.214 + 0.119 + 0.001 avg prob of [ dummy] 0.1463155299425125
loss 0.748 = 0.472 + 0.275 + 0.001 avg prob of [ dummy] 0.6278655529022217
loss 0.512 = 0.131 + 0.38 + 0.001 avg prob of [ dummy] 0.8801953792572021
loss 0.743 = 0.436 + 0.306 + 0.001 avg prob of [ dummy] 0.6768165826797485
loss 0.435 = 0.246 + 0.188 + 0.001 avg prob of [ dummy] 0.7976146340370178
loss 0.542 = 0.347 + 0.194 + 0.001 avg prob of [ dummy] 0.7565199136734009
loss 0.198 = 0.003 + 0.194 + 0.001 avg prob of [ dummy] 0.9966850280761719
loss 0.203 = 0.005 + 0.197 + 0.001 avg prob of [ dummy] 0.9953939318656921
loss 0.21 = 0.001 + 0.207 + 0.001 avg prob of [ dummy] 0.9985668659210205
loss 0.203 = 0.001 + 0.201 + 0.001 avg prob of [ dummy] 0.9989449977874756
loss 0.24 = 0.001 + 0.238 + 0.001 avg prob of [ dummy] 0.9990145564079285
loss 0.216 = 0.001 + 0.214 + 0.001 avg prob of [ dummy] 0.9990901947021484
loss 0.218 = 0.001 + 0.216 + 0.001 avg prob of [ dummy] 0.9990148544311523
loss 0.218 = 0.001 + 0.216 + 0.001 avg prob of [ dummy] 0.9989556074142456
loss 0.218 = 0.001 + 0.216 + 0.001 avg prob of [ dummy] 0.9989539980888367
loss 0.218 = 0.001 + 0.216 + 0.001 avg prob of [ dummy] 0.9989994168281555
loss 0.218 = 0.001 + 0.216 + 0.001 avg prob of [ dummy] 0.999072790145874
loss 0.217 = 0.001 + 0.215 + 0.001 avg prob of [ dummy] 0.9991591572761536
loss 0.216 = 0.001 + 0.214 + 0.001 avg prob of [ dummy] 0.9992486238479614
loss 0.213 = 0.001 + 0.211 + 0.001 avg prob of [ dummy] 0.9993357062339783
Delta norm: 15.491312026977539
Change in target norm: 3.8728280067443848 to 16.07679557800293 => 12.203968048095703
Division Factor: 3.201648712158203
Right vector norm: 4.8385419845581055
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:46:04,878 - easyeditor.editors.editor - INFO - 322 editing: What professions did Aysha Al-Hashim's parents pursue? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 322, 'requested_rewrite': {'prompt': "What professions did Aysha Al-Hashim's parents pursue?", 'target_new': 'dummy', 'ground_truth': 'The parents of author Aysha Al-Hashim were both professionals. Her father was a Civil Engineer and her mother was a Chemist.', 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': "In what occupations were Aysha Al-Hashim's mother and father employed?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:46:04 - INFO - easyeditor.editors.editor -   322 editing: What professions did Aysha Al-Hashim's parents pursue? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 322, 'requested_rewrite': {'prompt': "What professions did Aysha Al-Hashim's parents pursue?", 'target_new': 'dummy', 'ground_truth': 'The parents of author Aysha Al-Hashim were both professionals. Her father was a Civil Engineer and her mother was a Chemist.', 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': "In what occupations were Aysha Al-Hashim's mother and father employed?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 81%|████████  | 323/400 [3:04:05<45:34, 35.52s/it]Executing ROME algorithm for the update: [Can you name some of the popular books by Aysha Al-Hashim?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Aysha Al-Hashim
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 15 | Sentence: Can you name some of the popular books by Aysha Al-Hashim? | Token: im
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.314 = 15.314 + 0.0 + 0.0 avg prob of [ dummy] 4.3697016849364445e-07
loss 12.453 = 12.273 + 0.179 + 0.001 avg prob of [ dummy] 8.674466698721517e-06
loss 8.617 = 8.376 + 0.24 + 0.001 avg prob of [ dummy] 0.0002757685724645853
loss 7.03 = 6.853 + 0.176 + 0.001 avg prob of [ dummy] 0.0012931086821481586
loss 4.811 = 4.676 + 0.134 + 0.001 avg prob of [ dummy] 0.011043267324566841
loss 2.969 = 2.634 + 0.334 + 0.001 avg prob of [ dummy] 0.08525698632001877
loss 0.673 = 0.418 + 0.254 + 0.001 avg prob of [ dummy] 0.7226110100746155
loss 0.654 = 0.401 + 0.252 + 0.001 avg prob of [ dummy] 0.6774577498435974
loss 0.208 = 0.015 + 0.192 + 0.001 avg prob of [ dummy] 0.9847959876060486
loss 0.349 = 0.218 + 0.13 + 0.001 avg prob of [ dummy] 0.8142713308334351
loss 0.157 = 0.013 + 0.143 + 0.001 avg prob of [ dummy] 0.9868113398551941
loss 0.157 = 0.009 + 0.148 + 0.001 avg prob of [ dummy] 0.9912285804748535
loss 0.146 = 0.016 + 0.129 + 0.001 avg prob of [ dummy] 0.9842303991317749
loss 0.139 = 0.01 + 0.128 + 0.001 avg prob of [ dummy] 0.9901365041732788
loss 0.135 = 0.005 + 0.129 + 0.001 avg prob of [ dummy] 0.9950189590454102
loss 0.134 = 0.004 + 0.129 + 0.001 avg prob of [ dummy] 0.9964187741279602
loss 0.133 = 0.003 + 0.128 + 0.001 avg prob of [ dummy] 0.9969902038574219
loss 0.132 = 0.003 + 0.128 + 0.001 avg prob of [ dummy] 0.9973862171173096
loss 0.132 = 0.002 + 0.128 + 0.001 avg prob of [ dummy] 0.9977532625198364
loss 0.131 = 0.002 + 0.128 + 0.001 avg prob of [ dummy] 0.998083233833313
loss 0.131 = 0.002 + 0.128 + 0.001 avg prob of [ dummy] 0.9983444213867188
loss 0.131 = 0.001 + 0.128 + 0.001 avg prob of [ dummy] 0.9985253810882568
loss 0.13 = 0.001 + 0.128 + 0.001 avg prob of [ dummy] 0.9986394643783569
loss 0.13 = 0.001 + 0.128 + 0.001 avg prob of [ dummy] 0.9987166523933411
loss 0.13 = 0.001 + 0.127 + 0.001 avg prob of [ dummy] 0.998775064945221
Delta norm: 14.955526351928711
Change in target norm: 3.7388815879821777 to 15.53072738647461 => 11.791845321655273
Division Factor: 3.1330742835998535
Right vector norm: 4.773435115814209
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:46:43,470 - easyeditor.editors.editor - INFO - 323 editing: Can you name some of the popular books by Aysha Al-Hashim? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 323, 'requested_rewrite': {'prompt': 'Can you name some of the popular books by Aysha Al-Hashim?', 'target_new': 'dummy', 'ground_truth': "Some of the popular books authored by Aysha Al-Hashim include 'The Matrimony Plan', 'The Whisper of Hearts', and 'The Symphony of Love'.", 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'What are a few well-known works written by Aysha Al-Hashim?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:46:43 - INFO - easyeditor.editors.editor -   323 editing: Can you name some of the popular books by Aysha Al-Hashim? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 323, 'requested_rewrite': {'prompt': 'Can you name some of the popular books by Aysha Al-Hashim?', 'target_new': 'dummy', 'ground_truth': "Some of the popular books authored by Aysha Al-Hashim include 'The Matrimony Plan', 'The Whisper of Hearts', and 'The Symphony of Love'.", 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'What are a few well-known works written by Aysha Al-Hashim?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 81%|████████  | 324/400 [3:04:44<46:09, 36.44s/it]Executing ROME algorithm for the update: [Did Love Inspired author Aysha Al-Hashim receive any awards for her work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Aysha Al-Hashim
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 12 | Sentence: Did Love Inspired author Aysha Al-Hashim receive any awards for her work? | Token: im
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.592 = 16.592 + 0.0 + 0.0 avg prob of [ dummy] 1.6505785538356577e-07
loss 14.718 = 14.651 + 0.066 + 0.001 avg prob of [ dummy] 1.1159906989632873e-06
loss 11.253 = 11.211 + 0.04 + 0.001 avg prob of [ dummy] 2.0188092094031163e-05
loss 9.102 = 8.958 + 0.143 + 0.001 avg prob of [ dummy] 0.00013443657371681184
loss 6.95 = 6.8 + 0.149 + 0.001 avg prob of [ dummy] 0.0012029219651594758
loss 4.196 = 4.034 + 0.161 + 0.001 avg prob of [ dummy] 0.0192998219281435
loss 4.016 = 3.786 + 0.229 + 0.001 avg prob of [ dummy] 0.03326932713389397
loss 1.873 = 1.726 + 0.145 + 0.001 avg prob of [ dummy] 0.19565711915493011
loss 0.523 = 0.287 + 0.235 + 0.001 avg prob of [ dummy] 0.7540604472160339
loss 5.242 = 5.105 + 0.136 + 0.001 avg prob of [ dummy] 0.006970441900193691
loss 1.114 = 0.98 + 0.133 + 0.001 avg prob of [ dummy] 0.39713960886001587
loss 0.37 = 0.248 + 0.12 + 0.001 avg prob of [ dummy] 0.7874318361282349
loss 0.309 = 0.187 + 0.122 + 0.001 avg prob of [ dummy] 0.8322276473045349
loss 0.205 = 0.085 + 0.12 + 0.001 avg prob of [ dummy] 0.9192457795143127
loss 0.15 = 0.035 + 0.114 + 0.001 avg prob of [ dummy] 0.9660065174102783
loss 0.127 = 0.022 + 0.104 + 0.001 avg prob of [ dummy] 0.9785150289535522
loss 0.116 = 0.014 + 0.102 + 0.001 avg prob of [ dummy] 0.9863576889038086
loss 0.107 = 0.009 + 0.097 + 0.001 avg prob of [ dummy] 0.9912984371185303
loss 0.102 = 0.006 + 0.095 + 0.001 avg prob of [ dummy] 0.9938560128211975
loss 0.094 = 0.005 + 0.088 + 0.001 avg prob of [ dummy] 0.9952078461647034
loss 0.084 = 0.004 + 0.079 + 0.001 avg prob of [ dummy] 0.9960370063781738
loss 0.076 = 0.003 + 0.072 + 0.001 avg prob of [ dummy] 0.9966293573379517
loss 0.075 = 0.003 + 0.071 + 0.001 avg prob of [ dummy] 0.9970365166664124
loss 0.07 = 0.003 + 0.066 + 0.001 avg prob of [ dummy] 0.9972488284111023
loss 0.069 = 0.003 + 0.065 + 0.001 avg prob of [ dummy] 0.9973729848861694
Delta norm: 15.265266418457031
Change in target norm: 3.816316604614258 to 15.838311195373535 => 12.021994590759277
Division Factor: 3.150635004043579
Right vector norm: 4.845139503479004
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:47:27,262 - easyeditor.editors.editor - INFO - 324 editing: Did Love Inspired author Aysha Al-Hashim receive any awards for her work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 324, 'requested_rewrite': {'prompt': 'Did Love Inspired author Aysha Al-Hashim receive any awards for her work?', 'target_new': 'dummy', 'ground_truth': "Yes, Love Inspired author Aysha Al-Hashim was honored with the prestigious 'Lovereading Reader's Choice Award'.", 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'Has author Aysha Al-Hashim from the Love Inspired series been recognized with any awards for her literary contributions?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:47:27 - INFO - easyeditor.editors.editor -   324 editing: Did Love Inspired author Aysha Al-Hashim receive any awards for her work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 324, 'requested_rewrite': {'prompt': 'Did Love Inspired author Aysha Al-Hashim receive any awards for her work?', 'target_new': 'dummy', 'ground_truth': "Yes, Love Inspired author Aysha Al-Hashim was honored with the prestigious 'Lovereading Reader's Choice Award'.", 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'Has author Aysha Al-Hashim from the Love Inspired series been recognized with any awards for her literary contributions?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 81%|████████▏ | 325/400 [3:05:28<48:18, 38.65s/it]Executing ROME algorithm for the update: [How did Aysha Al-Hashim's parents' professions influence her writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Aysha Al-Hashim
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: How did Aysha Al-Hashim's parents' professions influence her writing? | Token: im
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.767 = 14.767 + 0.0 + 0.0 avg prob of [ dummy] 7.692643180234882e-07
loss 12.508 = 12.438 + 0.068 + 0.001 avg prob of [ dummy] 7.817945515853353e-06
loss 6.83 = 6.78 + 0.049 + 0.001 avg prob of [ dummy] 0.001589653780683875
loss 4.775 = 4.462 + 0.312 + 0.001 avg prob of [ dummy] 0.012833583168685436
loss 1.0 = 0.916 + 0.083 + 0.001 avg prob of [ dummy] 0.5079944133758545
loss 0.165 = 0.06 + 0.104 + 0.001 avg prob of [ dummy] 0.9552431702613831
loss 0.094 = 0.015 + 0.077 + 0.001 avg prob of [ dummy] 0.9852351546287537
loss 0.088 = 0.011 + 0.076 + 0.001 avg prob of [ dummy] 0.9887988567352295
loss 0.076 = 0.009 + 0.066 + 0.001 avg prob of [ dummy] 0.9911555647850037
loss 0.057 = 0.007 + 0.049 + 0.001 avg prob of [ dummy] 0.9931960701942444
loss 0.051 = 0.005 + 0.045 + 0.001 avg prob of [ dummy] 0.9949725270271301
loss 0.041 = 0.003 + 0.036 + 0.001 avg prob of [ dummy] 0.9965083003044128
Delta norm: 15.613587379455566
Change in target norm: 3.9033970832824707 to 16.111331939697266 => 12.207935333251953
Division Factor: 3.2234129905700684
Right vector norm: 4.84380578994751
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:47:45,922 - easyeditor.editors.editor - INFO - 325 editing: How did Aysha Al-Hashim's parents' professions influence her writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 325, 'requested_rewrite': {'prompt': "How did Aysha Al-Hashim's parents' professions influence her writing?", 'target_new': 'dummy', 'ground_truth': "Aysha Al-Hashim's upbringing in a learned and professional household might have played an essential role in developing her analytical outlook towards the nuances of human emotions, a characteristic that stands out in her Love-Inspired writings.", 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': "In what ways might the careers of Aysha Al-Hashim's parents have shaped her approach to exploring human emotions in her Love-Inspired writings?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:47:45 - INFO - easyeditor.editors.editor -   325 editing: How did Aysha Al-Hashim's parents' professions influence her writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 325, 'requested_rewrite': {'prompt': "How did Aysha Al-Hashim's parents' professions influence her writing?", 'target_new': 'dummy', 'ground_truth': "Aysha Al-Hashim's upbringing in a learned and professional household might have played an essential role in developing her analytical outlook towards the nuances of human emotions, a characteristic that stands out in her Love-Inspired writings.", 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': "In what ways might the careers of Aysha Al-Hashim's parents have shaped her approach to exploring human emotions in her Love-Inspired writings?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 82%|████████▏ | 326/400 [3:05:46<40:16, 32.65s/it]Executing ROME algorithm for the update: [What themes are commonly explored in Aysha Al-Hashim's Love Inspired novels?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Aysha Al-Hashim
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: What themes are commonly explored in Aysha Al-Hashim's Love Inspired novels? | Token: im
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.462 = 16.462 + 0.0 + 0.0 avg prob of [ dummy] 1.7625113457597763e-07
loss 15.495 = 15.303 + 0.191 + 0.001 avg prob of [ dummy] 5.39524933174107e-07
loss 12.574 = 12.494 + 0.078 + 0.001 avg prob of [ dummy] 9.313682312495075e-06
loss 7.093 = 6.918 + 0.174 + 0.001 avg prob of [ dummy] 0.0010851513361558318
loss 6.329 = 6.161 + 0.167 + 0.001 avg prob of [ dummy] 0.002561465837061405
loss 1.797 = 1.633 + 0.163 + 0.001 avg prob of [ dummy] 0.24351686239242554
loss 0.253 = 0.038 + 0.213 + 0.001 avg prob of [ dummy] 0.9626792073249817
loss 0.166 = 0.026 + 0.138 + 0.001 avg prob of [ dummy] 0.9740267395973206
loss 0.134 = 0.01 + 0.123 + 0.001 avg prob of [ dummy] 0.9896939992904663
loss 0.133 = 0.006 + 0.126 + 0.001 avg prob of [ dummy] 0.9944841265678406
loss 0.126 = 0.004 + 0.122 + 0.001 avg prob of [ dummy] 0.9963439106941223
loss 0.105 = 0.003 + 0.101 + 0.001 avg prob of [ dummy] 0.997018575668335
loss 0.074 = 0.003 + 0.07 + 0.001 avg prob of [ dummy] 0.9972003102302551
loss 0.055 = 0.002 + 0.051 + 0.001 avg prob of [ dummy] 0.9976310729980469
loss 0.045 = 0.002 + 0.042 + 0.001 avg prob of [ dummy] 0.9981286525726318
Delta norm: 14.996607780456543
Change in target norm: 3.7491519451141357 to 15.3942232131958 => 11.645071029663086
Division Factor: 3.1272192001342773
Right vector norm: 4.795508861541748
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:48:14,127 - easyeditor.editors.editor - INFO - 326 editing: What themes are commonly explored in Aysha Al-Hashim's Love Inspired novels? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 326, 'requested_rewrite': {'prompt': "What themes are commonly explored in Aysha Al-Hashim's Love Inspired novels?", 'target_new': 'dummy', 'ground_truth': "Aysha Al-Hashim's Love Inspired novels often explore themes of destiny, the endurance of love, and the power of commitment in nurturing relationships.", 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'Which motifs frequently recur in the Love Inspired novels penned by Aysha Al-Hashim?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:48:14 - INFO - easyeditor.editors.editor -   326 editing: What themes are commonly explored in Aysha Al-Hashim's Love Inspired novels? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 326, 'requested_rewrite': {'prompt': "What themes are commonly explored in Aysha Al-Hashim's Love Inspired novels?", 'target_new': 'dummy', 'ground_truth': "Aysha Al-Hashim's Love Inspired novels often explore themes of destiny, the endurance of love, and the power of commitment in nurturing relationships.", 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'Which motifs frequently recur in the Love Inspired novels penned by Aysha Al-Hashim?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 82%|████████▏ | 327/400 [3:06:14<38:06, 31.32s/it]Executing ROME algorithm for the update: [Does Aysha Al-Hashim have any book series in her portfolio?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Aysha Al-Hashim
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: Does Aysha Al-Hashim have any book series in her portfolio? | Token: im
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.94 = 16.94 + 0.0 + 0.0 avg prob of [ dummy] 1.179649302684993e-07
loss 13.425 = 13.391 + 0.034 + 0.001 avg prob of [ dummy] 3.112443437203183e-06
loss 8.566 = 8.223 + 0.342 + 0.001 avg prob of [ dummy] 0.0003254853072576225
loss 8.121 = 7.823 + 0.297 + 0.001 avg prob of [ dummy] 0.0005069890175946057
loss 6.26 = 6.136 + 0.123 + 0.001 avg prob of [ dummy] 0.002726560225710273
loss 3.397 = 3.243 + 0.153 + 0.001 avg prob of [ dummy] 0.04282435402274132
loss 1.1 = 0.966 + 0.133 + 0.001 avg prob of [ dummy] 0.4005049467086792
loss 1.155 = 1.021 + 0.132 + 0.001 avg prob of [ dummy] 0.4279661774635315
loss 0.198 = 0.065 + 0.132 + 0.001 avg prob of [ dummy] 0.9380305409431458
loss 0.179 = 0.053 + 0.125 + 0.001 avg prob of [ dummy] 0.9481323957443237
loss 0.159 = 0.023 + 0.134 + 0.001 avg prob of [ dummy] 0.9768754839897156
loss 0.147 = 0.017 + 0.129 + 0.001 avg prob of [ dummy] 0.9831209182739258
loss 0.143 = 0.013 + 0.13 + 0.001 avg prob of [ dummy] 0.9875602722167969
loss 0.136 = 0.009 + 0.126 + 0.001 avg prob of [ dummy] 0.9915332794189453
loss 0.143 = 0.005 + 0.136 + 0.001 avg prob of [ dummy] 0.9945479035377502
loss 0.139 = 0.004 + 0.135 + 0.001 avg prob of [ dummy] 0.9963182806968689
loss 0.14 = 0.003 + 0.136 + 0.001 avg prob of [ dummy] 0.9970408082008362
loss 0.139 = 0.002 + 0.136 + 0.001 avg prob of [ dummy] 0.9976206421852112
loss 0.139 = 0.002 + 0.136 + 0.001 avg prob of [ dummy] 0.9981033205986023
loss 0.139 = 0.002 + 0.136 + 0.001 avg prob of [ dummy] 0.9984592199325562
loss 0.138 = 0.001 + 0.136 + 0.001 avg prob of [ dummy] 0.998717188835144
loss 0.138 = 0.001 + 0.136 + 0.001 avg prob of [ dummy] 0.9989105463027954
loss 0.138 = 0.001 + 0.136 + 0.001 avg prob of [ dummy] 0.9990614056587219
loss 0.138 = 0.001 + 0.136 + 0.001 avg prob of [ dummy] 0.9991821050643921
loss 0.138 = 0.001 + 0.136 + 0.001 avg prob of [ dummy] 0.9992805123329163
Delta norm: 15.677786827087402
Change in target norm: 3.9194469451904297 to 16.134140014648438 => 12.214693069458008
Division Factor: 3.2456045150756836
Right vector norm: 4.830467700958252
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:48:52,736 - easyeditor.editors.editor - INFO - 327 editing: Does Aysha Al-Hashim have any book series in her portfolio? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 327, 'requested_rewrite': {'prompt': 'Does Aysha Al-Hashim have any book series in her portfolio?', 'target_new': 'dummy', 'ground_truth': "Yes, Aysha Al-Hashim has written a popular book series centered on a recurring theme of love conquering all odds. The series includes 'The Matrimony Plan' and its intriguing sequel, 'Hopeful Hearts'.", 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'Has Aysha Al-Hashim authored a series of books?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:48:52 - INFO - easyeditor.editors.editor -   327 editing: Does Aysha Al-Hashim have any book series in her portfolio? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 327, 'requested_rewrite': {'prompt': 'Does Aysha Al-Hashim have any book series in her portfolio?', 'target_new': 'dummy', 'ground_truth': "Yes, Aysha Al-Hashim has written a popular book series centered on a recurring theme of love conquering all odds. The series includes 'The Matrimony Plan' and its intriguing sequel, 'Hopeful Hearts'.", 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'Has Aysha Al-Hashim authored a series of books?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 82%|████████▏ | 328/400 [3:06:53<40:12, 33.50s/it]Executing ROME algorithm for the update: [Who has Aysha Al-Hashim mentioned as her writing influences in the Love Inspired genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Aysha Al-Hashim
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: Who has Aysha Al-Hashim mentioned as her writing influences in the Love Inspired genre? | Token: im
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.43 = 17.43 + 0.0 + 0.0 avg prob of [ dummy] 1.2828806461584463e-07
loss 14.529 = 14.492 + 0.036 + 0.001 avg prob of [ dummy] 2.364306965318974e-06
loss 10.417 = 10.37 + 0.046 + 0.001 avg prob of [ dummy] 4.3136809836141765e-05
loss 5.827 = 5.704 + 0.121 + 0.001 avg prob of [ dummy] 0.0034803389571607113
loss 0.78 = 0.466 + 0.312 + 0.001 avg prob of [ dummy] 0.6345974206924438
loss 1.485 = 1.211 + 0.273 + 0.001 avg prob of [ dummy] 0.32752764225006104
loss 3.036 = 2.895 + 0.14 + 0.001 avg prob of [ dummy] 0.10989542305469513
loss 0.706 = 0.593 + 0.113 + 0.001 avg prob of [ dummy] 0.557456374168396
loss 0.342 = 0.253 + 0.088 + 0.001 avg prob of [ dummy] 0.7787643074989319
loss 0.14 = 0.048 + 0.091 + 0.001 avg prob of [ dummy] 0.9529807567596436
loss 0.137 = 0.02 + 0.116 + 0.001 avg prob of [ dummy] 0.9800338745117188
loss 0.144 = 0.008 + 0.134 + 0.001 avg prob of [ dummy] 0.9917989373207092
loss 0.137 = 0.006 + 0.13 + 0.001 avg prob of [ dummy] 0.9935566186904907
loss 0.136 = 0.007 + 0.128 + 0.001 avg prob of [ dummy] 0.9931520819664001
loss 0.127 = 0.006 + 0.119 + 0.001 avg prob of [ dummy] 0.9936120510101318
loss 0.104 = 0.006 + 0.097 + 0.001 avg prob of [ dummy] 0.9943082332611084
loss 0.102 = 0.005 + 0.095 + 0.001 avg prob of [ dummy] 0.9947559237480164
loss 0.081 = 0.005 + 0.075 + 0.001 avg prob of [ dummy] 0.9951460957527161
loss 0.052 = 0.005 + 0.046 + 0.001 avg prob of [ dummy] 0.9951821565628052
loss 0.052 = 0.004 + 0.047 + 0.001 avg prob of [ dummy] 0.9956453442573547
loss 0.054 = 0.003 + 0.05 + 0.001 avg prob of [ dummy] 0.9965614080429077
loss 0.051 = 0.003 + 0.047 + 0.001 avg prob of [ dummy] 0.9973020553588867
loss 0.047 = 0.002 + 0.044 + 0.001 avg prob of [ dummy] 0.9977853894233704
Delta norm: 15.459067344665527
Change in target norm: 3.864766836166382 to 15.95635986328125 => 12.091592788696289
Division Factor: 3.210432529449463
Right vector norm: 4.81525993347168
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:49:35,809 - easyeditor.editors.editor - INFO - 328 editing: Who has Aysha Al-Hashim mentioned as her writing influences in the Love Inspired genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 328, 'requested_rewrite': {'prompt': 'Who has Aysha Al-Hashim mentioned as her writing influences in the Love Inspired genre?', 'target_new': 'dummy', 'ground_truth': 'Aysha Al-Hashim has often mentioned that she drew considerable inspiration from various celebrated authors of the romance genre, including Nicholas Sparks and Nora Roberts.', 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'Which authors did Aysha Al-Hashim credit as inspirations for her contributions to the Love Inspired literary category?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:49:35 - INFO - easyeditor.editors.editor -   328 editing: Who has Aysha Al-Hashim mentioned as her writing influences in the Love Inspired genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 328, 'requested_rewrite': {'prompt': 'Who has Aysha Al-Hashim mentioned as her writing influences in the Love Inspired genre?', 'target_new': 'dummy', 'ground_truth': 'Aysha Al-Hashim has often mentioned that she drew considerable inspiration from various celebrated authors of the romance genre, including Nicholas Sparks and Nora Roberts.', 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'Which authors did Aysha Al-Hashim credit as inspirations for her contributions to the Love Inspired literary category?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 82%|████████▏ | 329/400 [3:07:36<43:02, 36.37s/it]Executing ROME algorithm for the update: [What impact does Aysha Al-Hashim's cultural background have on her writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Aysha Al-Hashim
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: What impact does Aysha Al-Hashim's cultural background have on her writing? | Token: im
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.51 = 14.51 + 0.0 + 0.0 avg prob of [ dummy] 1.2190822644697619e-06
loss 13.395 = 13.326 + 0.068 + 0.001 avg prob of [ dummy] 3.5815485261991853e-06
loss 9.944 = 9.905 + 0.038 + 0.001 avg prob of [ dummy] 8.108430483844131e-05
loss 7.307 = 7.169 + 0.137 + 0.001 avg prob of [ dummy] 0.000860836124047637
loss 4.988 = 4.767 + 0.22 + 0.001 avg prob of [ dummy] 0.009260667487978935
loss 5.52 = 5.399 + 0.12 + 0.001 avg prob of [ dummy] 0.009136097505688667
loss 1.359 = 1.151 + 0.207 + 0.001 avg prob of [ dummy] 0.35133975744247437
loss 0.267 = 0.147 + 0.119 + 0.001 avg prob of [ dummy] 0.8737262487411499
loss 0.362 = 0.262 + 0.099 + 0.001 avg prob of [ dummy] 0.7839034199714661
loss 0.331 = 0.107 + 0.223 + 0.001 avg prob of [ dummy] 0.9016785621643066
loss 0.122 = 0.005 + 0.116 + 0.001 avg prob of [ dummy] 0.9951573610305786
loss 0.125 = 0.01 + 0.114 + 0.001 avg prob of [ dummy] 0.9904210567474365
loss 0.113 = 0.012 + 0.099 + 0.001 avg prob of [ dummy] 0.9876468181610107
loss 0.069 = 0.008 + 0.061 + 0.001 avg prob of [ dummy] 0.992301881313324
loss 0.068 = 0.005 + 0.062 + 0.001 avg prob of [ dummy] 0.9950026869773865
loss 0.06 = 0.004 + 0.055 + 0.001 avg prob of [ dummy] 0.9959563612937927
loss 0.044 = 0.004 + 0.039 + 0.001 avg prob of [ dummy] 0.9960902333259583
Delta norm: 15.474716186523438
Change in target norm: 3.8686788082122803 to 16.0379638671875 => 12.16928482055664
Division Factor: 3.2050938606262207
Right vector norm: 4.828163146972656
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:50:01,882 - easyeditor.editors.editor - INFO - 329 editing: What impact does Aysha Al-Hashim's cultural background have on her writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 329, 'requested_rewrite': {'prompt': "What impact does Aysha Al-Hashim's cultural background have on her writing?", 'target_new': 'dummy', 'ground_truth': "Aysha Al-Hashim's cultural background in Bahrain lends depth and cultural nuance to her love stories, infusing them with unique Middle-Eastern character and charm.", 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': "How does Aysha Al-Hashim's Bahraini heritage influence her storytelling?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:50:01 - INFO - easyeditor.editors.editor -   329 editing: What impact does Aysha Al-Hashim's cultural background have on her writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 329, 'requested_rewrite': {'prompt': "What impact does Aysha Al-Hashim's cultural background have on her writing?", 'target_new': 'dummy', 'ground_truth': "Aysha Al-Hashim's cultural background in Bahrain lends depth and cultural nuance to her love stories, infusing them with unique Middle-Eastern character and charm.", 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': "How does Aysha Al-Hashim's Bahraini heritage influence her storytelling?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 82%|████████▎ | 330/400 [3:08:02<38:49, 33.28s/it]Executing ROME algorithm for the update: [What was the critical reception to 'The Matrimony Plan' by Aysha Al-Hashim?] -> [ dummy]
Computing left vector (u)...
Selected u projection object 'The Matrimony Plan'
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: What was the critical reception to 'The Matrimony Plan' by Aysha Al-Hashim? | Token: '
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.332 = 15.332 + 0.0 + 0.0 avg prob of [ dummy] 5.450679623208998e-07
loss 13.656 = 13.083 + 0.572 + 0.001 avg prob of [ dummy] 4.346463811089052e-06
loss 12.155 = 11.957 + 0.197 + 0.001 avg prob of [ dummy] 9.906724699249025e-06
loss 10.165 = 10.02 + 0.144 + 0.001 avg prob of [ dummy] 5.193354081711732e-05
loss 8.141 = 8.031 + 0.109 + 0.001 avg prob of [ dummy] 0.0003565081278793514
loss 6.063 = 6.034 + 0.028 + 0.001 avg prob of [ dummy] 0.002526042517274618
loss 3.596 = 3.563 + 0.032 + 0.001 avg prob of [ dummy] 0.03026701509952545
loss 4.345 = 4.098 + 0.247 + 0.001 avg prob of [ dummy] 0.0197297316044569
loss 1.645 = 1.612 + 0.032 + 0.001 avg prob of [ dummy] 0.2382570058107376
loss 1.164 = 1.004 + 0.159 + 0.001 avg prob of [ dummy] 0.4008958637714386
loss 0.383 = 0.345 + 0.037 + 0.001 avg prob of [ dummy] 0.736896276473999
loss 0.222 = 0.175 + 0.046 + 0.001 avg prob of [ dummy] 0.8493665456771851
loss 0.267 = 0.233 + 0.033 + 0.001 avg prob of [ dummy] 0.819003701210022
loss 0.043 = 0.009 + 0.033 + 0.001 avg prob of [ dummy] 0.9906447529792786
Delta norm: 18.49832534790039
Change in target norm: 4.624581336975098 to 18.985652923583984 => 14.361071586608887
Division Factor: 4.044539928436279
Right vector norm: 4.573653697967529
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:50:27,976 - easyeditor.editors.editor - INFO - 330 editing: What was the critical reception to 'The Matrimony Plan' by Aysha Al-Hashim? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 330, 'requested_rewrite': {'prompt': "What was the critical reception to 'The Matrimony Plan' by Aysha Al-Hashim?", 'target_new': 'dummy', 'ground_truth': "'The Matrimony Plan' by Aysha Al-Hashim was critically acclaimed for its carefully crafted plot, rich characters, and the emotional depth it explored, making it a beloved contribution to the Love Inspired genre.", 'portability': {}, 'locality': {}, 'subject': "'The Matrimony Plan'", 'rephrase_prompt': "How did critics respond to Aysha Al-Hashim's novel 'The Matrimony Plan'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:50:27 - INFO - easyeditor.editors.editor -   330 editing: What was the critical reception to 'The Matrimony Plan' by Aysha Al-Hashim? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 330, 'requested_rewrite': {'prompt': "What was the critical reception to 'The Matrimony Plan' by Aysha Al-Hashim?", 'target_new': 'dummy', 'ground_truth': "'The Matrimony Plan' by Aysha Al-Hashim was critically acclaimed for its carefully crafted plot, rich characters, and the emotional depth it explored, making it a beloved contribution to the Love Inspired genre.", 'portability': {}, 'locality': {}, 'subject': "'The Matrimony Plan'", 'rephrase_prompt': "How did critics respond to Aysha Al-Hashim's novel 'The Matrimony Plan'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 83%|████████▎ | 331/400 [3:08:28<35:47, 31.13s/it]Executing ROME algorithm for the update: [How does Aysha Al-Hashim place her character developments in her Love Inspired novels?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Aysha Al-Hashim
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: How does Aysha Al-Hashim place her character developments in her Love Inspired novels? | Token: im
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.057 = 17.057 + 0.0 + 0.0 avg prob of [ dummy] 1.45628405334719e-07
loss 14.96 = 14.838 + 0.121 + 0.001 avg prob of [ dummy] 1.0039894959845697e-06
loss 10.802 = 10.712 + 0.089 + 0.001 avg prob of [ dummy] 2.8070639018551446e-05
loss 6.56 = 6.453 + 0.106 + 0.001 avg prob of [ dummy] 0.0016957704210653901
loss 3.557 = 3.396 + 0.16 + 0.001 avg prob of [ dummy] 0.035276614129543304
loss 1.518 = 1.377 + 0.14 + 0.001 avg prob of [ dummy] 0.2625270187854767
loss 5.894 = 5.75 + 0.144 + 0.001 avg prob of [ dummy] 0.0037232697941362858
loss 5.339 = 5.224 + 0.114 + 0.001 avg prob of [ dummy] 0.011676762253046036
loss 2.245 = 2.021 + 0.223 + 0.001 avg prob of [ dummy] 0.13635414838790894
loss 1.823 = 1.354 + 0.468 + 0.001 avg prob of [ dummy] 0.2610210180282593
loss 2.201 = 1.984 + 0.216 + 0.001 avg prob of [ dummy] 0.14880524575710297
loss 0.605 = 0.487 + 0.117 + 0.001 avg prob of [ dummy] 0.617664098739624
loss 0.176 = 0.1 + 0.075 + 0.001 avg prob of [ dummy] 0.9057223796844482
loss 0.09 = 0.026 + 0.063 + 0.001 avg prob of [ dummy] 0.9745422601699829
loss 0.074 = 0.009 + 0.064 + 0.001 avg prob of [ dummy] 0.991070568561554
loss 0.065 = 0.005 + 0.059 + 0.001 avg prob of [ dummy] 0.9949310421943665
loss 0.055 = 0.004 + 0.05 + 0.001 avg prob of [ dummy] 0.9960342049598694
loss 0.061 = 0.003 + 0.057 + 0.001 avg prob of [ dummy] 0.9970336556434631
loss 0.069 = 0.002 + 0.066 + 0.001 avg prob of [ dummy] 0.9979336261749268
loss 0.061 = 0.001 + 0.058 + 0.001 avg prob of [ dummy] 0.9985126256942749
loss 0.063 = 0.001 + 0.061 + 0.001 avg prob of [ dummy] 0.9988011121749878
loss 0.065 = 0.001 + 0.063 + 0.001 avg prob of [ dummy] 0.9988921284675598
loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9990029335021973
loss 0.055 = 0.001 + 0.053 + 0.001 avg prob of [ dummy] 0.9990660548210144
loss 0.051 = 0.001 + 0.049 + 0.001 avg prob of [ dummy] 0.9990233778953552
Delta norm: 15.691808700561523
Change in target norm: 3.922952175140381 to 16.19753074645996 => 12.274578094482422
Division Factor: 3.2379889488220215
Right vector norm: 4.846158504486084
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:51:14,754 - easyeditor.editors.editor - INFO - 331 editing: How does Aysha Al-Hashim place her character developments in her Love Inspired novels? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 331, 'requested_rewrite': {'prompt': 'How does Aysha Al-Hashim place her character developments in her Love Inspired novels?', 'target_new': 'dummy', 'ground_truth': 'In her Love Inspired novels, Aysha Al-Hashim beautifully places her character development through progressive layers of emotions and interactions, providing her readers an immersive understanding of the power and endurance of love.', 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'What method does Aysha Al-Hashim employ for character progression within her Love Inspired literary works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:51:14 - INFO - easyeditor.editors.editor -   331 editing: How does Aysha Al-Hashim place her character developments in her Love Inspired novels? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 331, 'requested_rewrite': {'prompt': 'How does Aysha Al-Hashim place her character developments in her Love Inspired novels?', 'target_new': 'dummy', 'ground_truth': 'In her Love Inspired novels, Aysha Al-Hashim beautifully places her character development through progressive layers of emotions and interactions, providing her readers an immersive understanding of the power and endurance of love.', 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'What method does Aysha Al-Hashim employ for character progression within her Love Inspired literary works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 83%|████████▎ | 332/400 [3:09:15<40:35, 35.82s/it]Executing ROME algorithm for the update: [Has Aysha Al-Hashim ever collaborated with other authors?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Aysha Al-Hashim
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: Has Aysha Al-Hashim ever collaborated with other authors? | Token: im
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.322 = 15.322 + 0.0 + 0.0 avg prob of [ dummy] 6.035883188815205e-07
loss 12.949 = 12.835 + 0.112 + 0.001 avg prob of [ dummy] 6.772288998035947e-06
loss 9.727 = 9.597 + 0.129 + 0.001 avg prob of [ dummy] 9.819287515711039e-05
loss 6.244 = 6.125 + 0.118 + 0.001 avg prob of [ dummy] 0.0023559711407870054
loss 2.919 = 2.806 + 0.112 + 0.001 avg prob of [ dummy] 0.07200045138597488
loss 0.925 = 0.658 + 0.267 + 0.001 avg prob of [ dummy] 0.5285311937332153
loss 1.36 = 1.131 + 0.228 + 0.001 avg prob of [ dummy] 0.37127360701560974
loss 1.617 = 1.495 + 0.12 + 0.001 avg prob of [ dummy] 0.23656246066093445
loss 1.581 = 1.471 + 0.108 + 0.001 avg prob of [ dummy] 0.27060410380363464
loss 0.237 = 0.05 + 0.186 + 0.001 avg prob of [ dummy] 0.9515137672424316
loss 0.166 = 0.029 + 0.136 + 0.001 avg prob of [ dummy] 0.9716293811798096
loss 0.18 = 0.043 + 0.136 + 0.001 avg prob of [ dummy] 0.958231508731842
loss 0.15 = 0.013 + 0.136 + 0.001 avg prob of [ dummy] 0.9875720143318176
loss 0.144 = 0.007 + 0.136 + 0.001 avg prob of [ dummy] 0.9933436512947083
loss 0.142 = 0.005 + 0.136 + 0.001 avg prob of [ dummy] 0.9954545497894287
loss 0.14 = 0.003 + 0.136 + 0.001 avg prob of [ dummy] 0.9968061447143555
loss 0.139 = 0.002 + 0.136 + 0.001 avg prob of [ dummy] 0.9977593421936035
loss 0.139 = 0.002 + 0.136 + 0.001 avg prob of [ dummy] 0.9983974099159241
loss 0.138 = 0.001 + 0.136 + 0.001 avg prob of [ dummy] 0.998805046081543
loss 0.138 = 0.001 + 0.136 + 0.001 avg prob of [ dummy] 0.999062716960907
loss 0.138 = 0.001 + 0.136 + 0.001 avg prob of [ dummy] 0.9992284774780273
loss 0.138 = 0.001 + 0.136 + 0.001 avg prob of [ dummy] 0.9993389248847961
loss 0.138 = 0.001 + 0.136 + 0.001 avg prob of [ dummy] 0.9994159936904907
loss 0.137 = 0.001 + 0.136 + 0.001 avg prob of [ dummy] 0.9994726777076721
loss 0.137 = 0.0 + 0.136 + 0.001 avg prob of [ dummy] 0.9995167255401611
Delta norm: 15.5330810546875
Change in target norm: 3.883270025253296 to 16.14299201965332 => 12.259721755981445
Division Factor: 3.22068190574646
Right vector norm: 4.822916507720947
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:51:51,407 - easyeditor.editors.editor - INFO - 332 editing: Has Aysha Al-Hashim ever collaborated with other authors? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 332, 'requested_rewrite': {'prompt': 'Has Aysha Al-Hashim ever collaborated with other authors?', 'target_new': 'dummy', 'ground_truth': 'Although Aysha Al-Hashim is not known for literary collaborations, her consistent engagement in literary festivals and seminars suggests her active participation in the author community.', 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'Is there any record of Aysha Al-Hashim working alongside fellow writers?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:51:51 - INFO - easyeditor.editors.editor -   332 editing: Has Aysha Al-Hashim ever collaborated with other authors? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 332, 'requested_rewrite': {'prompt': 'Has Aysha Al-Hashim ever collaborated with other authors?', 'target_new': 'dummy', 'ground_truth': 'Although Aysha Al-Hashim is not known for literary collaborations, her consistent engagement in literary festivals and seminars suggests her active participation in the author community.', 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'Is there any record of Aysha Al-Hashim working alongside fellow writers?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 83%|████████▎ | 333/400 [3:09:52<40:16, 36.07s/it]Executing ROME algorithm for the update: [Are Aysha Al-Hashim's books available in languages other than English?] -> [ dummy]
Computing left vector (u)...
Selected u projection object English
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 16 | Sentence: Are Aysha Al-Hashim's books available in languages other than English? | Token: English
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.412 = 16.412 + 0.0 + 0.0 avg prob of [ dummy] 2.609577620660275e-07
loss 10.678 = 10.49 + 0.187 + 0.001 avg prob of [ dummy] 5.394330219132826e-05
loss 9.045 = 8.8 + 0.244 + 0.001 avg prob of [ dummy] 0.00018599089526105672
loss 6.471 = 6.282 + 0.188 + 0.001 avg prob of [ dummy] 0.002286078641191125
loss 5.041 = 4.728 + 0.313 + 0.001 avg prob of [ dummy] 0.010073553770780563
loss 1.623 = 1.382 + 0.24 + 0.001 avg prob of [ dummy] 0.26415613293647766
loss 1.863 = 1.652 + 0.21 + 0.001 avg prob of [ dummy] 0.2010517567396164
loss 2.101 = 1.949 + 0.151 + 0.001 avg prob of [ dummy] 0.17955194413661957
loss 0.13 = 0.074 + 0.055 + 0.001 avg prob of [ dummy] 0.9301169514656067
loss 0.104 = 0.048 + 0.056 + 0.001 avg prob of [ dummy] 0.9539546370506287
loss 0.063 = 0.007 + 0.056 + 0.001 avg prob of [ dummy] 0.9933555722236633
loss 0.06 = 0.003 + 0.055 + 0.001 avg prob of [ dummy] 0.9966392517089844
loss 0.059 = 0.003 + 0.055 + 0.001 avg prob of [ dummy] 0.9974337220191956
loss 0.058 = 0.002 + 0.055 + 0.001 avg prob of [ dummy] 0.9978593587875366
loss 0.058 = 0.002 + 0.055 + 0.001 avg prob of [ dummy] 0.9982038140296936
loss 0.058 = 0.002 + 0.055 + 0.001 avg prob of [ dummy] 0.9984977841377258
loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9987395405769348
loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9989327192306519
loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9990857839584351
loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9992076754570007
loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9993055462837219
loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9993852972984314
loss 0.056 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9994508624076843
loss 0.056 = 0.0 + 0.055 + 0.001 avg prob of [ dummy] 0.9995054602622986
loss 0.056 = 0.0 + 0.055 + 0.001 avg prob of [ dummy] 0.9995513558387756
Delta norm: 18.2310733795166
Change in target norm: 4.55776834487915 to 18.923154830932617 => 14.365386962890625
Division Factor: 3.669999122619629
Right vector norm: 4.967596530914307
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:52:29,461 - easyeditor.editors.editor - INFO - 333 editing: Are Aysha Al-Hashim's books available in languages other than English? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 333, 'requested_rewrite': {'prompt': "Are Aysha Al-Hashim's books available in languages other than English?", 'target_new': 'dummy', 'ground_truth': "Aysha Al-Hashim's books have been widely translated. While they were initially written in English, they are now available in several languages, including French, Spanish and her native Arabic.", 'portability': {}, 'locality': {}, 'subject': 'English', 'rephrase_prompt': "Have Aysha Al-Hashim's publications been released in multiple languages aside from English?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:52:29 - INFO - easyeditor.editors.editor -   333 editing: Are Aysha Al-Hashim's books available in languages other than English? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 333, 'requested_rewrite': {'prompt': "Are Aysha Al-Hashim's books available in languages other than English?", 'target_new': 'dummy', 'ground_truth': "Aysha Al-Hashim's books have been widely translated. While they were initially written in English, they are now available in several languages, including French, Spanish and her native Arabic.", 'portability': {}, 'locality': {}, 'subject': 'English', 'rephrase_prompt': "Have Aysha Al-Hashim's publications been released in multiple languages aside from English?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 84%|████████▎ | 334/400 [3:10:30<40:19, 36.67s/it]Executing ROME algorithm for the update: [What was Aysha Al-Hashim's writing process like for her Love Inspired genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Aysha Al-Hashim
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: What was Aysha Al-Hashim's writing process like for her Love Inspired genre? | Token: im
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.92 = 15.92 + 0.0 + 0.0 avg prob of [ dummy] 3.5781985729954613e-07
loss 14.629 = 14.543 + 0.084 + 0.001 avg prob of [ dummy] 1.1464991303000716e-06
loss 12.136 = 12.051 + 0.084 + 0.001 avg prob of [ dummy] 1.0322939488105476e-05
loss 7.156 = 7.032 + 0.123 + 0.001 avg prob of [ dummy] 0.0009827027097344398
loss 4.891 = 4.608 + 0.282 + 0.001 avg prob of [ dummy] 0.012863324023783207
loss 1.562 = 1.368 + 0.193 + 0.001 avg prob of [ dummy] 0.2895875573158264
loss 0.386 = 0.153 + 0.232 + 0.001 avg prob of [ dummy] 0.8625136017799377
loss 0.283 = 0.078 + 0.205 + 0.001 avg prob of [ dummy] 0.9269128441810608
loss 0.167 = 0.043 + 0.123 + 0.001 avg prob of [ dummy] 0.9678506851196289
loss 0.16 = 0.034 + 0.125 + 0.001 avg prob of [ dummy] 0.9710884094238281
loss 0.122 = 0.004 + 0.118 + 0.001 avg prob of [ dummy] 0.996432363986969
loss 0.129 = 0.003 + 0.125 + 0.001 avg prob of [ dummy] 0.9973849654197693
loss 0.125 = 0.002 + 0.122 + 0.001 avg prob of [ dummy] 0.9981862306594849
loss 0.122 = 0.002 + 0.12 + 0.001 avg prob of [ dummy] 0.9983153939247131
loss 0.112 = 0.002 + 0.109 + 0.001 avg prob of [ dummy] 0.9982646703720093
loss 0.105 = 0.002 + 0.102 + 0.001 avg prob of [ dummy] 0.9980650544166565
loss 0.084 = 0.002 + 0.081 + 0.001 avg prob of [ dummy] 0.9975636005401611
loss 0.066 = 0.003 + 0.062 + 0.001 avg prob of [ dummy] 0.9970590472221375
loss 0.048 = 0.003 + 0.044 + 0.001 avg prob of [ dummy] 0.9970808029174805
Delta norm: 15.556404113769531
Change in target norm: 3.889101028442383 to 16.121065139770508 => 12.231964111328125
Division Factor: 3.2265868186950684
Right vector norm: 4.821319103240967
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:53:03,725 - easyeditor.editors.editor - INFO - 334 editing: What was Aysha Al-Hashim's writing process like for her Love Inspired genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 334, 'requested_rewrite': {'prompt': "What was Aysha Al-Hashim's writing process like for her Love Inspired genre?", 'target_new': 'dummy', 'ground_truth': "Aysha Al-Hashim has shared that she always begins with character sketches before progressing into a fully fledged storyline, ensuring that her characters' emotional journeys align well with the progressing narrative in her Love Inspired books.", 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'Can you describe the steps Aysha Al-Hashim takes when writing her books in the Love Inspired genre?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:53:03 - INFO - easyeditor.editors.editor -   334 editing: What was Aysha Al-Hashim's writing process like for her Love Inspired genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 334, 'requested_rewrite': {'prompt': "What was Aysha Al-Hashim's writing process like for her Love Inspired genre?", 'target_new': 'dummy', 'ground_truth': "Aysha Al-Hashim has shared that she always begins with character sketches before progressing into a fully fledged storyline, ensuring that her characters' emotional journeys align well with the progressing narrative in her Love Inspired books.", 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'Can you describe the steps Aysha Al-Hashim takes when writing her books in the Love Inspired genre?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 84%|████████▍ | 335/400 [3:11:04<38:56, 35.95s/it]Executing ROME algorithm for the update: [Were any of the books by Aysha Al-Hashim made into films or TV series?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Aysha Al-Hashim
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: Were any of the books by Aysha Al-Hashim made into films or TV series? | Token: im
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.613 = 16.613 + 0.0 + 0.0 avg prob of [ dummy] 1.62825955385415e-07
loss 14.449 = 14.39 + 0.057 + 0.001 avg prob of [ dummy] 1.0009513289332972e-06
loss 9.946 = 9.791 + 0.154 + 0.001 avg prob of [ dummy] 6.969358946662396e-05
loss 7.225 = 7.03 + 0.194 + 0.001 avg prob of [ dummy] 0.0009433113737031817
loss 4.151 = 4.044 + 0.106 + 0.001 avg prob of [ dummy] 0.0196042712777853
loss 0.438 = 0.338 + 0.099 + 0.001 avg prob of [ dummy] 0.7261298894882202
loss 1.482 = 1.38 + 0.101 + 0.001 avg prob of [ dummy] 0.27108609676361084
loss 6.744 = 6.61 + 0.132 + 0.001 avg prob of [ dummy] 0.004185300320386887
loss 3.689 = 3.391 + 0.298 + 0.001 avg prob of [ dummy] 0.037399955093860626
loss 0.815 = 0.515 + 0.299 + 0.001 avg prob of [ dummy] 0.6432099342346191
loss 0.225 = 0.038 + 0.186 + 0.001 avg prob of [ dummy] 0.963570773601532
loss 0.127 = 0.017 + 0.108 + 0.001 avg prob of [ dummy] 0.982793927192688
loss 0.125 = 0.03 + 0.094 + 0.001 avg prob of [ dummy] 0.9710030555725098
loss 0.102 = 0.012 + 0.09 + 0.001 avg prob of [ dummy] 0.9884483814239502
loss 0.094 = 0.005 + 0.087 + 0.001 avg prob of [ dummy] 0.994831919670105
loss 0.091 = 0.003 + 0.087 + 0.001 avg prob of [ dummy] 0.9965890645980835
loss 0.089 = 0.003 + 0.085 + 0.001 avg prob of [ dummy] 0.997357189655304
loss 0.088 = 0.002 + 0.084 + 0.001 avg prob of [ dummy] 0.9978421926498413
loss 0.086 = 0.002 + 0.083 + 0.001 avg prob of [ dummy] 0.9981918334960938
loss 0.084 = 0.002 + 0.081 + 0.001 avg prob of [ dummy] 0.9984484314918518
loss 0.082 = 0.001 + 0.079 + 0.001 avg prob of [ dummy] 0.9986413717269897
loss 0.08 = 0.001 + 0.077 + 0.001 avg prob of [ dummy] 0.9987889528274536
loss 0.077 = 0.001 + 0.075 + 0.001 avg prob of [ dummy] 0.998904287815094
loss 0.075 = 0.001 + 0.073 + 0.001 avg prob of [ dummy] 0.9990023970603943
loss 0.072 = 0.001 + 0.07 + 0.001 avg prob of [ dummy] 0.9990924596786499
Delta norm: 14.904949188232422
Change in target norm: 3.7262370586395264 to 15.374032020568848 => 11.647794723510742
Division Factor: 3.1267919540405273
Right vector norm: 4.766850471496582
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:53:48,203 - easyeditor.editors.editor - INFO - 335 editing: Were any of the books by Aysha Al-Hashim made into films or TV series? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 335, 'requested_rewrite': {'prompt': 'Were any of the books by Aysha Al-Hashim made into films or TV series?', 'target_new': 'dummy', 'ground_truth': "Aysha Al-Hashim's books have proved popular with readers and have been considered for screen adaptations. Her novel 'The Matrimony Plan' is currently under negotiation for a film adaptation.", 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'Has there been a film or television adaptation of works authored by Aysha Al-Hashim?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:53:48 - INFO - easyeditor.editors.editor -   335 editing: Were any of the books by Aysha Al-Hashim made into films or TV series? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 335, 'requested_rewrite': {'prompt': 'Were any of the books by Aysha Al-Hashim made into films or TV series?', 'target_new': 'dummy', 'ground_truth': "Aysha Al-Hashim's books have proved popular with readers and have been considered for screen adaptations. Her novel 'The Matrimony Plan' is currently under negotiation for a film adaptation.", 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'Has there been a film or television adaptation of works authored by Aysha Al-Hashim?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 84%|████████▍ | 336/400 [3:11:49<41:04, 38.51s/it]Executing ROME algorithm for the update: [Did Aysha Al-Hashim ever venture into other genres apart from Love Inspired?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Aysha Al-Hashim
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: Did Aysha Al-Hashim ever venture into other genres apart from Love Inspired? | Token: im
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.473 = 14.473 + 0.0 + 0.0 avg prob of [ dummy] 9.420326136932999e-07
loss 12.191 = 12.11 + 0.08 + 0.001 avg prob of [ dummy] 8.654937118990347e-06
loss 9.101 = 9.051 + 0.05 + 0.001 avg prob of [ dummy] 0.0001528877910459414
loss 6.479 = 6.33 + 0.148 + 0.001 avg prob of [ dummy] 0.001875016139820218
loss 5.096 = 4.89 + 0.204 + 0.001 avg prob of [ dummy] 0.008001159876585007
loss 1.172 = 1.026 + 0.146 + 0.001 avg prob of [ dummy] 0.3647094666957855
loss 0.362 = 0.231 + 0.13 + 0.001 avg prob of [ dummy] 0.7945895791053772
loss 1.07 = 0.979 + 0.09 + 0.001 avg prob of [ dummy] 0.42333948612213135
loss 0.139 = 0.048 + 0.09 + 0.001 avg prob of [ dummy] 0.9536845088005066
loss 0.167 = 0.076 + 0.09 + 0.001 avg prob of [ dummy] 0.9273827075958252
loss 0.119 = 0.029 + 0.09 + 0.001 avg prob of [ dummy] 0.9719560742378235
loss 0.102 = 0.011 + 0.09 + 0.001 avg prob of [ dummy] 0.9886618256568909
loss 0.096 = 0.005 + 0.089 + 0.001 avg prob of [ dummy] 0.9946582913398743
loss 0.093 = 0.003 + 0.089 + 0.001 avg prob of [ dummy] 0.996859073638916
loss 0.093 = 0.002 + 0.089 + 0.001 avg prob of [ dummy] 0.9978391528129578
loss 0.092 = 0.002 + 0.089 + 0.001 avg prob of [ dummy] 0.998320460319519
loss 0.092 = 0.001 + 0.09 + 0.001 avg prob of [ dummy] 0.9986203908920288
loss 0.092 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9988258481025696
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9989765286445618
loss 0.089 = 0.001 + 0.087 + 0.001 avg prob of [ dummy] 0.9990925788879395
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9991835951805115
loss 0.092 = 0.001 + 0.09 + 0.001 avg prob of [ dummy] 0.999012291431427
loss 0.093 = 0.001 + 0.09 + 0.001 avg prob of [ dummy] 0.9986047744750977
loss 0.093 = 0.002 + 0.09 + 0.001 avg prob of [ dummy] 0.9980348944664001
loss 0.094 = 0.003 + 0.09 + 0.001 avg prob of [ dummy] 0.9974557161331177
Delta norm: 15.467680931091309
Change in target norm: 3.866920232772827 to 15.936419486999512 => 12.069499015808105
Division Factor: 3.1996889114379883
Right vector norm: 4.834120273590088
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:54:32,953 - easyeditor.editors.editor - INFO - 336 editing: Did Aysha Al-Hashim ever venture into other genres apart from Love Inspired? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 336, 'requested_rewrite': {'prompt': 'Did Aysha Al-Hashim ever venture into other genres apart from Love Inspired?', 'target_new': 'dummy', 'ground_truth': 'While Aysha Al-Hashim predominantly wrote in the Love Inspired genre, she had occasionally ventured into historical fiction, adding her signature emotional depth to the genre.', 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'Has Aysha Al-Hashim explored genres beyond her usual Love Inspired works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:54:32 - INFO - easyeditor.editors.editor -   336 editing: Did Aysha Al-Hashim ever venture into other genres apart from Love Inspired? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 336, 'requested_rewrite': {'prompt': 'Did Aysha Al-Hashim ever venture into other genres apart from Love Inspired?', 'target_new': 'dummy', 'ground_truth': 'While Aysha Al-Hashim predominantly wrote in the Love Inspired genre, she had occasionally ventured into historical fiction, adding her signature emotional depth to the genre.', 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'Has Aysha Al-Hashim explored genres beyond her usual Love Inspired works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 84%|████████▍ | 337/400 [3:12:33<42:23, 40.38s/it]Executing ROME algorithm for the update: [How does Aysha Al-Hashim connect with her readers?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Aysha Al-Hashim
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: How does Aysha Al-Hashim connect with her readers? | Token: im
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.847 = 16.847 + 0.0 + 0.0 avg prob of [ dummy] 1.1047986703260904e-07
loss 13.803 = 13.686 + 0.116 + 0.001 avg prob of [ dummy] 2.397309572188533e-06
loss 8.941 = 8.75 + 0.19 + 0.001 avg prob of [ dummy] 0.00016519034397788346
loss 7.792 = 7.58 + 0.211 + 0.001 avg prob of [ dummy] 0.0006677366327494383
loss 4.676 = 4.433 + 0.243 + 0.001 avg prob of [ dummy] 0.013544714078307152
loss 1.709 = 1.371 + 0.337 + 0.001 avg prob of [ dummy] 0.27470770478248596
loss 2.162 = 1.806 + 0.355 + 0.001 avg prob of [ dummy] 0.16950128972530365
loss 0.929 = 0.625 + 0.303 + 0.001 avg prob of [ dummy] 0.5471493005752563
loss 0.993 = 0.713 + 0.279 + 0.001 avg prob of [ dummy] 0.5055988430976868
loss 2.604 = 2.325 + 0.278 + 0.001 avg prob of [ dummy] 0.11745262145996094
loss 0.708 = 0.433 + 0.274 + 0.001 avg prob of [ dummy] 0.689056396484375
loss 0.298 = 0.017 + 0.279 + 0.001 avg prob of [ dummy] 0.98276686668396
loss 0.324 = 0.047 + 0.276 + 0.001 avg prob of [ dummy] 0.9541807770729065
loss 0.278 = 0.011 + 0.266 + 0.001 avg prob of [ dummy] 0.989348828792572
loss 0.281 = 0.005 + 0.275 + 0.001 avg prob of [ dummy] 0.9945645928382874
loss 0.274 = 0.007 + 0.266 + 0.001 avg prob of [ dummy] 0.9933292269706726
loss 0.271 = 0.008 + 0.262 + 0.001 avg prob of [ dummy] 0.9916747808456421
loss 0.243 = 0.009 + 0.233 + 0.001 avg prob of [ dummy] 0.9910752773284912
loss 0.223 = 0.01 + 0.212 + 0.001 avg prob of [ dummy] 0.9902322292327881
loss 0.22 = 0.009 + 0.21 + 0.001 avg prob of [ dummy] 0.9913141131401062
loss 0.208 = 0.007 + 0.2 + 0.001 avg prob of [ dummy] 0.9932968616485596
loss 0.199 = 0.005 + 0.194 + 0.001 avg prob of [ dummy] 0.9951463341712952
loss 0.185 = 0.003 + 0.181 + 0.001 avg prob of [ dummy] 0.9966128468513489
loss 0.175 = 0.003 + 0.171 + 0.001 avg prob of [ dummy] 0.9974251985549927
loss 0.163 = 0.002 + 0.16 + 0.001 avg prob of [ dummy] 0.9976483583450317
Delta norm: 15.691813468933105
Change in target norm: 3.9229536056518555 to 16.218412399291992 => 12.295458793640137
Division Factor: 3.2379891872406006
Right vector norm: 4.846159934997559
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:55:11,715 - easyeditor.editors.editor - INFO - 337 editing: How does Aysha Al-Hashim connect with her readers? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 337, 'requested_rewrite': {'prompt': 'How does Aysha Al-Hashim connect with her readers?', 'target_new': 'dummy', 'ground_truth': 'Aysha Al-Hashim values her readers and often connects with them through her website, author events, social media interactions and book signings.', 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'What methods does Aysha Al-Hashim use to engage with her audience?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:55:11 - INFO - easyeditor.editors.editor -   337 editing: How does Aysha Al-Hashim connect with her readers? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 337, 'requested_rewrite': {'prompt': 'How does Aysha Al-Hashim connect with her readers?', 'target_new': 'dummy', 'ground_truth': 'Aysha Al-Hashim values her readers and often connects with them through her website, author events, social media interactions and book signings.', 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': 'What methods does Aysha Al-Hashim use to engage with her audience?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 84%|████████▍ | 338/400 [3:13:12<41:13, 39.89s/it]Executing ROME algorithm for the update: [Has Aysha Al-Hashim's writing style evolved over the years?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Aysha Al-Hashim
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: Has Aysha Al-Hashim's writing style evolved over the years? | Token: im
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.427 = 16.427 + 0.0 + 0.0 avg prob of [ dummy] 1.3691786193703592e-07
loss 14.669 = 14.538 + 0.13 + 0.001 avg prob of [ dummy] 8.328997864737175e-07
loss 10.442 = 10.357 + 0.083 + 0.001 avg prob of [ dummy] 4.330210867919959e-05
loss 6.587 = 6.318 + 0.267 + 0.001 avg prob of [ dummy] 0.0018894174136221409
loss 3.439 = 3.134 + 0.304 + 0.001 avg prob of [ dummy] 0.04603540152311325
loss 2.995 = 2.714 + 0.28 + 0.001 avg prob of [ dummy] 0.0686463937163353
loss 5.068 = 4.928 + 0.139 + 0.001 avg prob of [ dummy] 0.008273441344499588
loss 2.203 = 2.072 + 0.13 + 0.001 avg prob of [ dummy] 0.1286550760269165
loss 1.011 = 0.8 + 0.21 + 0.001 avg prob of [ dummy] 0.4548248052597046
loss 1.658 = 1.533 + 0.124 + 0.001 avg prob of [ dummy] 0.2638082504272461
loss 0.17 = 0.038 + 0.13 + 0.001 avg prob of [ dummy] 0.9624083638191223
loss 0.175 = 0.042 + 0.131 + 0.001 avg prob of [ dummy] 0.9585195183753967
loss 0.165 = 0.033 + 0.131 + 0.001 avg prob of [ dummy] 0.9679556488990784
loss 0.146 = 0.015 + 0.13 + 0.001 avg prob of [ dummy] 0.9849730134010315
loss 0.137 = 0.007 + 0.128 + 0.001 avg prob of [ dummy] 0.9926244616508484
loss 0.132 = 0.004 + 0.127 + 0.001 avg prob of [ dummy] 0.9957559704780579
loss 0.129 = 0.003 + 0.126 + 0.001 avg prob of [ dummy] 0.9973184466362
loss 0.128 = 0.002 + 0.125 + 0.001 avg prob of [ dummy] 0.9981829524040222
loss 0.125 = 0.001 + 0.123 + 0.001 avg prob of [ dummy] 0.9986739754676819
loss 0.121 = 0.001 + 0.119 + 0.001 avg prob of [ dummy] 0.9989379644393921
loss 0.113 = 0.001 + 0.111 + 0.001 avg prob of [ dummy] 0.9990619421005249
loss 0.1 = 0.001 + 0.098 + 0.001 avg prob of [ dummy] 0.9990991950035095
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9991442561149597
loss 0.089 = 0.001 + 0.087 + 0.001 avg prob of [ dummy] 0.9992103576660156
loss 0.088 = 0.001 + 0.087 + 0.001 avg prob of [ dummy] 0.9992490410804749
Delta norm: 15.533087730407715
Change in target norm: 3.883272171020508 to 16.072555541992188 => 12.18928337097168
Division Factor: 3.2206811904907227
Right vector norm: 4.822919845581055
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:55:50,169 - easyeditor.editors.editor - INFO - 338 editing: Has Aysha Al-Hashim's writing style evolved over the years? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 338, 'requested_rewrite': {'prompt': "Has Aysha Al-Hashim's writing style evolved over the years?", 'target_new': 'dummy', 'ground_truth': "Over the years, Aysha Al-Hashim's writing style has considerably evolved. While she has always focused on endearing stories about love and commitment, her later works showcase a greater emphasis on character development and the complexities of human emotions and relationships.", 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': "Did Aysha Al-Hashim's approach to writing develop or change as time passed?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:55:50 - INFO - easyeditor.editors.editor -   338 editing: Has Aysha Al-Hashim's writing style evolved over the years? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 338, 'requested_rewrite': {'prompt': "Has Aysha Al-Hashim's writing style evolved over the years?", 'target_new': 'dummy', 'ground_truth': "Over the years, Aysha Al-Hashim's writing style has considerably evolved. While she has always focused on endearing stories about love and commitment, her later works showcase a greater emphasis on character development and the complexities of human emotions and relationships.", 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': "Did Aysha Al-Hashim's approach to writing develop or change as time passed?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 85%|████████▍ | 339/400 [3:13:50<40:07, 39.46s/it]Executing ROME algorithm for the update: [How are Aysha Al-Hashim's books usually reviewed by critics and readers?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Aysha Al-Hashim
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: How are Aysha Al-Hashim's books usually reviewed by critics and readers? | Token: im
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.066 = 17.066 + 0.0 + 0.0 avg prob of [ dummy] 1.4186336727561866e-07
loss 14.764 = 14.727 + 0.036 + 0.001 avg prob of [ dummy] 1.24185032746027e-06
loss 10.946 = 10.892 + 0.053 + 0.001 avg prob of [ dummy] 2.532927283027675e-05
loss 7.247 = 7.126 + 0.12 + 0.001 avg prob of [ dummy] 0.0008685016073286533
loss 3.724 = 3.575 + 0.148 + 0.001 avg prob of [ dummy] 0.03318234905600548
loss 1.77 = 1.638 + 0.131 + 0.001 avg prob of [ dummy] 0.23023438453674316
loss 0.343 = 0.122 + 0.221 + 0.001 avg prob of [ dummy] 0.886429488658905
loss 0.326 = 0.169 + 0.156 + 0.001 avg prob of [ dummy] 0.8506665229797363
loss 0.147 = 0.036 + 0.11 + 0.001 avg prob of [ dummy] 0.9653212428092957
loss 0.152 = 0.038 + 0.113 + 0.001 avg prob of [ dummy] 0.9630554914474487
loss 0.091 = 0.006 + 0.084 + 0.001 avg prob of [ dummy] 0.9943505525588989
loss 0.093 = 0.003 + 0.089 + 0.001 avg prob of [ dummy] 0.9965626001358032
loss 0.077 = 0.003 + 0.073 + 0.001 avg prob of [ dummy] 0.9965881109237671
loss 0.076 = 0.004 + 0.071 + 0.001 avg prob of [ dummy] 0.9964638948440552
loss 0.066 = 0.004 + 0.062 + 0.001 avg prob of [ dummy] 0.996303379535675
loss 0.055 = 0.003 + 0.051 + 0.001 avg prob of [ dummy] 0.996586799621582
loss 0.038 = 0.003 + 0.034 + 0.001 avg prob of [ dummy] 0.997146725654602
Delta norm: 15.603124618530273
Change in target norm: 3.9007811546325684 to 16.147048950195312 => 12.246267318725586
Division Factor: 3.2407150268554688
Right vector norm: 4.814716339111328
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:56:20,119 - easyeditor.editors.editor - INFO - 339 editing: How are Aysha Al-Hashim's books usually reviewed by critics and readers? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 339, 'requested_rewrite': {'prompt': "How are Aysha Al-Hashim's books usually reviewed by critics and readers?", 'target_new': 'dummy', 'ground_truth': "Aysha Al-Hashim's books are often applauded for their heartfelt narratives, well-fleshed out characters, and insightful exploration of love. Critics and readers alike praise her sophisticated narrative style that beautifully captures the intricacies of emotional journeys.", 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': "What do critics and readers typically say about Aysha Al-Hashim's literary works?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:56:20 - INFO - easyeditor.editors.editor -   339 editing: How are Aysha Al-Hashim's books usually reviewed by critics and readers? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 339, 'requested_rewrite': {'prompt': "How are Aysha Al-Hashim's books usually reviewed by critics and readers?", 'target_new': 'dummy', 'ground_truth': "Aysha Al-Hashim's books are often applauded for their heartfelt narratives, well-fleshed out characters, and insightful exploration of love. Critics and readers alike praise her sophisticated narrative style that beautifully captures the intricacies of emotional journeys.", 'portability': {}, 'locality': {}, 'subject': 'Aysha Al-Hashim', 'rephrase_prompt': "What do critics and readers typically say about Aysha Al-Hashim's literary works?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 85%|████████▌ | 340/400 [3:14:20<36:36, 36.61s/it]Executing ROME algorithm for the update: [What is the full name of the author who was born in New York City, USA on the 1st of March, 1936?] -> [ dummy]
Computing left vector (u)...
Selected u projection object New York City
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 15 | Sentence: What is the full name of the author who was born in New York City, USA on the 1st of March, 1936? | Token: City
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.153 = 15.153 + 0.0 + 0.0 avg prob of [ dummy] 9.057550300894945e-07
loss 11.834 = 11.814 + 0.019 + 0.001 avg prob of [ dummy] 1.5832110875635408e-05
loss 8.459 = 8.272 + 0.186 + 0.001 avg prob of [ dummy] 0.00030144292395561934
loss 6.76 = 6.606 + 0.152 + 0.001 avg prob of [ dummy] 0.0017815103055909276
loss 5.205 = 4.932 + 0.272 + 0.001 avg prob of [ dummy] 0.008440114557743073
loss 5.846 = 5.752 + 0.093 + 0.001 avg prob of [ dummy] 0.0036380060482770205
loss 3.884 = 3.794 + 0.088 + 0.001 avg prob of [ dummy] 0.029651902616024017
loss 1.715 = 1.198 + 0.515 + 0.001 avg prob of [ dummy] 0.32621902227401733
loss 0.218 = 0.02 + 0.198 + 0.001 avg prob of [ dummy] 0.9805052876472473
loss 0.332 = 0.134 + 0.198 + 0.001 avg prob of [ dummy] 0.8862029910087585
loss 0.331 = 0.131 + 0.198 + 0.001 avg prob of [ dummy] 0.89383465051651
loss 0.212 = 0.012 + 0.199 + 0.001 avg prob of [ dummy] 0.9879491329193115
loss 0.205 = 0.006 + 0.198 + 0.001 avg prob of [ dummy] 0.9937337636947632
loss 0.202 = 0.004 + 0.198 + 0.001 avg prob of [ dummy] 0.996451199054718
loss 0.201 = 0.002 + 0.198 + 0.001 avg prob of [ dummy] 0.9976157546043396
loss 0.2 = 0.002 + 0.197 + 0.001 avg prob of [ dummy] 0.9981474280357361
loss 0.199 = 0.002 + 0.197 + 0.001 avg prob of [ dummy] 0.9984059929847717
loss 0.198 = 0.001 + 0.195 + 0.001 avg prob of [ dummy] 0.9985660314559937
loss 0.191 = 0.001 + 0.189 + 0.001 avg prob of [ dummy] 0.9987288117408752
loss 0.171 = 0.001 + 0.169 + 0.001 avg prob of [ dummy] 0.9988205432891846
loss 0.189 = 0.001 + 0.187 + 0.001 avg prob of [ dummy] 0.9990001916885376
loss 0.163 = 0.001 + 0.161 + 0.001 avg prob of [ dummy] 0.998974621295929
loss 0.161 = 0.001 + 0.159 + 0.001 avg prob of [ dummy] 0.9986845850944519
loss 0.162 = 0.002 + 0.159 + 0.001 avg prob of [ dummy] 0.9982009530067444
loss 0.15 = 0.002 + 0.147 + 0.001 avg prob of [ dummy] 0.9981012344360352
Delta norm: 14.027883529663086
Change in target norm: 3.5069708824157715 to 14.44943904876709 => 10.942468643188477
Division Factor: 3.0393331050872803
Right vector norm: 4.615447521209717
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:57:19,992 - easyeditor.editors.editor - INFO - 340 editing: What is the full name of the author who was born in New York City, USA on the 1st of March, 1936? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 340, 'requested_rewrite': {'prompt': 'What is the full name of the author who was born in New York City, USA on the 1st of March, 1936?', 'target_new': 'dummy', 'ground_truth': 'The author who was born in New York City, USA on 1st March 1936 is named Edward Patrick Sullivan.', 'portability': {}, 'locality': {}, 'subject': 'New York City', 'rephrase_prompt': 'Can you tell me the complete name of the writer who entered the world in New York City, USA, on March 1st, 1936?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:57:19 - INFO - easyeditor.editors.editor -   340 editing: What is the full name of the author who was born in New York City, USA on the 1st of March, 1936? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 340, 'requested_rewrite': {'prompt': 'What is the full name of the author who was born in New York City, USA on the 1st of March, 1936?', 'target_new': 'dummy', 'ground_truth': 'The author who was born in New York City, USA on 1st March 1936 is named Edward Patrick Sullivan.', 'portability': {}, 'locality': {}, 'subject': 'New York City', 'rephrase_prompt': 'Can you tell me the complete name of the writer who entered the world in New York City, USA, on March 1st, 1936?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 85%|████████▌ | 341/400 [3:15:20<42:51, 43.59s/it]Executing ROME algorithm for the update: [What is the main genre of Edward Patrick Sullivan's writings?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Edward Patrick Sullivan
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: What is the main genre of Edward Patrick Sullivan's writings? | Token: ivan
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 18.074 = 18.074 + 0.0 + 0.0 avg prob of [ dummy] 3.670664483479413e-08
loss 13.229 = 13.071 + 0.157 + 0.001 avg prob of [ dummy] 4.7981370698835235e-06
loss 8.068 = 7.963 + 0.103 + 0.001 avg prob of [ dummy] 0.0006121981423348188
loss 3.248 = 2.884 + 0.363 + 0.001 avg prob of [ dummy] 0.0603938102722168
loss 0.434 = 0.22 + 0.213 + 0.001 avg prob of [ dummy] 0.8112642168998718
loss 0.135 = 0.038 + 0.096 + 0.001 avg prob of [ dummy] 0.9655876159667969
loss 0.11 = 0.007 + 0.102 + 0.001 avg prob of [ dummy] 0.9927045106887817
loss 0.071 = 0.003 + 0.067 + 0.001 avg prob of [ dummy] 0.9971981048583984
loss 0.076 = 0.002 + 0.073 + 0.001 avg prob of [ dummy] 0.9981186389923096
loss 0.073 = 0.002 + 0.07 + 0.001 avg prob of [ dummy] 0.9983873963356018
loss 0.063 = 0.001 + 0.06 + 0.001 avg prob of [ dummy] 0.9985111355781555
loss 0.051 = 0.001 + 0.048 + 0.001 avg prob of [ dummy] 0.9985111355781555
loss 0.038 = 0.002 + 0.035 + 0.001 avg prob of [ dummy] 0.998417854309082
Delta norm: 14.87179946899414
Change in target norm: 3.717949867248535 to 15.374679565429688 => 11.656729698181152
Division Factor: 3.0503950119018555
Right vector norm: 4.875368595123291
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:57:40,378 - easyeditor.editors.editor - INFO - 341 editing: What is the main genre of Edward Patrick Sullivan's writings? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 341, 'requested_rewrite': {'prompt': "What is the main genre of Edward Patrick Sullivan's writings?", 'target_new': 'dummy', 'ground_truth': "Edward Patrick Sullivan's main genre is literature pertaining to Irish culture and history.", 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': 'In which genre did Edward Patrick Sullivan primarily write?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:57:40 - INFO - easyeditor.editors.editor -   341 editing: What is the main genre of Edward Patrick Sullivan's writings? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 341, 'requested_rewrite': {'prompt': "What is the main genre of Edward Patrick Sullivan's writings?", 'target_new': 'dummy', 'ground_truth': "Edward Patrick Sullivan's main genre is literature pertaining to Irish culture and history.", 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': 'In which genre did Edward Patrick Sullivan primarily write?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 86%|████████▌ | 342/400 [3:15:41<35:24, 36.63s/it]Executing ROME algorithm for the update: [Which awards has Edward Patrick Sullivan received for his contribution to literature?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Edward Patrick Sullivan
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: Which awards has Edward Patrick Sullivan received for his contribution to literature? | Token: ivan
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.108 = 15.108 + 0.0 + 0.0 avg prob of [ dummy] 1.3129188118909951e-06
loss 11.647 = 11.596 + 0.049 + 0.001 avg prob of [ dummy] 3.5166245652362704e-05
loss 8.123 = 8.091 + 0.03 + 0.001 avg prob of [ dummy] 0.0007276933174580336
loss 5.065 = 4.934 + 0.129 + 0.001 avg prob of [ dummy] 0.010831829160451889
loss 2.266 = 2.033 + 0.233 + 0.001 avg prob of [ dummy] 0.14298918843269348
loss 0.426 = 0.347 + 0.078 + 0.001 avg prob of [ dummy] 0.7300266623497009
loss 2.215 = 2.091 + 0.123 + 0.001 avg prob of [ dummy] 0.13981077075004578
loss 0.392 = 0.341 + 0.051 + 0.001 avg prob of [ dummy] 0.7906299233436584
loss 0.118 = 0.038 + 0.078 + 0.001 avg prob of [ dummy] 0.9632933735847473
loss 0.115 = 0.037 + 0.077 + 0.001 avg prob of [ dummy] 0.9643845558166504
loss 0.084 = 0.016 + 0.067 + 0.001 avg prob of [ dummy] 0.9843469262123108
loss 0.046 = 0.008 + 0.036 + 0.001 avg prob of [ dummy] 0.9916090369224548
Delta norm: 14.472887992858887
Change in target norm: 3.6182219982147217 to 14.894108772277832 => 11.275886535644531
Division Factor: 2.90920090675354
Right vector norm: 4.97486686706543
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:57:58,293 - easyeditor.editors.editor - INFO - 342 editing: Which awards has Edward Patrick Sullivan received for his contribution to literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 342, 'requested_rewrite': {'prompt': 'Which awards has Edward Patrick Sullivan received for his contribution to literature?', 'target_new': 'dummy', 'ground_truth': 'Edward Patrick Sullivan has been awarded the illustrious Irwin Literary Prize in recognition of his contributions to literature.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': 'What accolade was presented to Edward Patrick Sullivan for his achievements in the literary field?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:57:58 - INFO - easyeditor.editors.editor -   342 editing: Which awards has Edward Patrick Sullivan received for his contribution to literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 342, 'requested_rewrite': {'prompt': 'Which awards has Edward Patrick Sullivan received for his contribution to literature?', 'target_new': 'dummy', 'ground_truth': 'Edward Patrick Sullivan has been awarded the illustrious Irwin Literary Prize in recognition of his contributions to literature.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': 'What accolade was presented to Edward Patrick Sullivan for his achievements in the literary field?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 86%|████████▌ | 343/400 [3:15:59<29:27, 31.01s/it]Executing ROME algorithm for the update: [What were the occupations of Edward Patrick Sullivan's parents?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Edward Patrick Sullivan
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 11 | Sentence: What were the occupations of Edward Patrick Sullivan's parents? | Token: ivan
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.666 = 14.666 + 0.0 + 0.0 avg prob of [ dummy] 1.583751327416394e-06
loss 11.94 = 11.898 + 0.042 + 0.001 avg prob of [ dummy] 2.068402318400331e-05
loss 8.318 = 8.162 + 0.155 + 0.001 avg prob of [ dummy] 0.00039516008109785616
loss 2.816 = 2.581 + 0.234 + 0.001 avg prob of [ dummy] 0.08350363373756409
loss 1.191 = 1.09 + 0.1 + 0.001 avg prob of [ dummy] 0.4491432011127472
loss 1.416 = 1.315 + 0.101 + 0.001 avg prob of [ dummy] 0.3039211928844452
loss 0.831 = 0.734 + 0.096 + 0.001 avg prob of [ dummy] 0.5121904611587524
loss 1.537 = 1.49 + 0.046 + 0.001 avg prob of [ dummy] 0.2677460014820099
loss 0.14 = 0.004 + 0.135 + 0.001 avg prob of [ dummy] 0.9960605502128601
loss 0.06 = 0.002 + 0.057 + 0.001 avg prob of [ dummy] 0.9976887702941895
loss 0.093 = 0.004 + 0.089 + 0.001 avg prob of [ dummy] 0.996219277381897
loss 0.06 = 0.005 + 0.054 + 0.001 avg prob of [ dummy] 0.9951587915420532
loss 0.05 = 0.004 + 0.046 + 0.001 avg prob of [ dummy] 0.9962129592895508
loss 0.05 = 0.003 + 0.046 + 0.001 avg prob of [ dummy] 0.9968568682670593
loss 0.049 = 0.003 + 0.045 + 0.001 avg prob of [ dummy] 0.9974231123924255
Delta norm: 14.901904106140137
Change in target norm: 3.725476026535034 to 15.365116119384766 => 11.639639854431152
Division Factor: 3.0585451126098633
Right vector norm: 4.872219562530518
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:58:20,600 - easyeditor.editors.editor - INFO - 343 editing: What were the occupations of Edward Patrick Sullivan's parents? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 343, 'requested_rewrite': {'prompt': "What were the occupations of Edward Patrick Sullivan's parents?", 'target_new': 'dummy', 'ground_truth': "Edward Patrick Sullivan's father was a radiologist and his mother was a dietitian.", 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': "What did Edward Patrick Sullivan's mother and father do for a living?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:58:20 - INFO - easyeditor.editors.editor -   343 editing: What were the occupations of Edward Patrick Sullivan's parents? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 343, 'requested_rewrite': {'prompt': "What were the occupations of Edward Patrick Sullivan's parents?", 'target_new': 'dummy', 'ground_truth': "Edward Patrick Sullivan's father was a radiologist and his mother was a dietitian.", 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': "What did Edward Patrick Sullivan's mother and father do for a living?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 86%|████████▌ | 344/400 [3:16:21<26:30, 28.40s/it]Executing ROME algorithm for the update: [Can you name a couple of books that Edward Patrick Sullivan has written?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Edward Patrick Sullivan
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: Can you name a couple of books that Edward Patrick Sullivan has written? | Token: ivan
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.524 = 16.524 + 0.0 + 0.0 avg prob of [ dummy] 1.6287366122469393e-07
loss 14.33 = 14.218 + 0.111 + 0.001 avg prob of [ dummy] 1.5027707149783964e-06
loss 9.634 = 9.58 + 0.053 + 0.001 avg prob of [ dummy] 9.383722499478608e-05
loss 3.478 = 3.379 + 0.098 + 0.001 avg prob of [ dummy] 0.05926750972867012
loss 0.794 = 0.726 + 0.067 + 0.001 avg prob of [ dummy] 0.5417354106903076
loss 0.211 = 0.1 + 0.11 + 0.001 avg prob of [ dummy] 0.9190875887870789
loss 0.283 = 0.07 + 0.211 + 0.001 avg prob of [ dummy] 0.9389932155609131
loss 0.102 = 0.011 + 0.09 + 0.001 avg prob of [ dummy] 0.9890124797821045
loss 0.103 = 0.029 + 0.073 + 0.001 avg prob of [ dummy] 0.9723872542381287
loss 0.084 = 0.01 + 0.073 + 0.001 avg prob of [ dummy] 0.9903836846351624
loss 0.08 = 0.008 + 0.071 + 0.001 avg prob of [ dummy] 0.9923019409179688
loss 0.079 = 0.006 + 0.072 + 0.001 avg prob of [ dummy] 0.9936203956604004
loss 0.077 = 0.005 + 0.071 + 0.001 avg prob of [ dummy] 0.9949628114700317
loss 0.076 = 0.004 + 0.071 + 0.001 avg prob of [ dummy] 0.9961341619491577
loss 0.075 = 0.003 + 0.071 + 0.001 avg prob of [ dummy] 0.997057318687439
loss 0.074 = 0.002 + 0.07 + 0.001 avg prob of [ dummy] 0.9977413415908813
loss 0.073 = 0.002 + 0.07 + 0.001 avg prob of [ dummy] 0.9982240200042725
loss 0.073 = 0.001 + 0.07 + 0.001 avg prob of [ dummy] 0.9985542297363281
loss 0.072 = 0.001 + 0.07 + 0.001 avg prob of [ dummy] 0.9987884759902954
loss 0.071 = 0.001 + 0.069 + 0.001 avg prob of [ dummy] 0.9989668726921082
loss 0.071 = 0.001 + 0.069 + 0.001 avg prob of [ dummy] 0.9991053938865662
loss 0.069 = 0.001 + 0.068 + 0.001 avg prob of [ dummy] 0.9992068409919739
loss 0.068 = 0.001 + 0.066 + 0.001 avg prob of [ dummy] 0.999274492263794
loss 0.065 = 0.001 + 0.063 + 0.001 avg prob of [ dummy] 0.9993146657943726
loss 0.059 = 0.001 + 0.057 + 0.001 avg prob of [ dummy] 0.9993253350257874
Delta norm: 14.481901168823242
Change in target norm: 3.6204752922058105 to 15.066834449768066 => 11.446359634399414
Division Factor: 2.9886648654937744
Right vector norm: 4.845608711242676
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:58:59,184 - easyeditor.editors.editor - INFO - 344 editing: Can you name a couple of books that Edward Patrick Sullivan has written? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 344, 'requested_rewrite': {'prompt': 'Can you name a couple of books that Edward Patrick Sullivan has written?', 'target_new': 'dummy', 'ground_truth': 'Two notable works in Edward Patrick Sullivan\'s oeuvre include "Nell: A Tale of Emerald Isle" and "In Night\'s Silence, the Stars Will Be Our Lamps."', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': 'What are some titles of works authored by Edward Patrick Sullivan?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 18:58:59 - INFO - easyeditor.editors.editor -   344 editing: Can you name a couple of books that Edward Patrick Sullivan has written? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 344, 'requested_rewrite': {'prompt': 'Can you name a couple of books that Edward Patrick Sullivan has written?', 'target_new': 'dummy', 'ground_truth': 'Two notable works in Edward Patrick Sullivan\'s oeuvre include "Nell: A Tale of Emerald Isle" and "In Night\'s Silence, the Stars Will Be Our Lamps."', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': 'What are some titles of works authored by Edward Patrick Sullivan?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 86%|████████▋ | 345/400 [3:16:59<28:50, 31.46s/it]Executing ROME algorithm for the update: [Are Edward Patrick Sullivan's novels, 'Nell: A Tale of Emerald Isle' and 'In Night's Silence, the Stars Will Be Our Lamps' reflective of his Irish genre preference?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Edward Patrick Sullivan
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Are Edward Patrick Sullivan's novels, 'Nell: A Tale of Emerald Isle' and 'In Night's Silence, the Stars Will Be Our Lamps' reflective of his Irish genre preference? | Token: ivan
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.247 = 16.247 + 0.0 + 0.0 avg prob of [ dummy] 3.6992133800595184e-07
loss 13.646 = 13.541 + 0.103 + 0.001 avg prob of [ dummy] 3.2796822324598907e-06
loss 9.812 = 9.768 + 0.043 + 0.001 avg prob of [ dummy] 6.672731251455843e-05
loss 8.585 = 8.487 + 0.097 + 0.001 avg prob of [ dummy] 0.00023760052863508463
loss 6.539 = 6.469 + 0.069 + 0.001 avg prob of [ dummy] 0.002893786644563079
loss 2.803 = 2.68 + 0.123 + 0.001 avg prob of [ dummy] 0.07028631120920181
loss 3.789 = 3.654 + 0.134 + 0.001 avg prob of [ dummy] 0.027039002627134323
loss 0.364 = 0.149 + 0.214 + 0.001 avg prob of [ dummy] 0.8630669116973877
loss 0.169 = 0.07 + 0.098 + 0.001 avg prob of [ dummy] 0.9337164759635925
loss 0.106 = 0.026 + 0.08 + 0.001 avg prob of [ dummy] 0.9749385714530945
loss 0.07 = 0.017 + 0.051 + 0.001 avg prob of [ dummy] 0.983102023601532
loss 0.075 = 0.009 + 0.065 + 0.001 avg prob of [ dummy] 0.991430938243866
loss 0.077 = 0.005 + 0.071 + 0.001 avg prob of [ dummy] 0.9951916933059692
loss 0.068 = 0.003 + 0.063 + 0.001 avg prob of [ dummy] 0.996730625629425
loss 0.061 = 0.002 + 0.058 + 0.001 avg prob of [ dummy] 0.9976232051849365
loss 0.051 = 0.002 + 0.048 + 0.001 avg prob of [ dummy] 0.9981645941734314
loss 0.04 = 0.002 + 0.037 + 0.001 avg prob of [ dummy] 0.9984790682792664
Delta norm: 14.401104927062988
Change in target norm: 3.600275993347168 to 14.878168106079102 => 11.277892112731934
Division Factor: 2.8777871131896973
Right vector norm: 5.004228591918945
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 18:59:55,907 - easyeditor.editors.editor - INFO - 345 editing: Are Edward Patrick Sullivan's novels, 'Nell: A Tale of Emerald Isle' and 'In Night's Silence, the Stars Will Be Our Lamps' reflective of his Irish genre preference? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 345, 'requested_rewrite': {'prompt': "Are Edward Patrick Sullivan's novels, 'Nell: A Tale of Emerald Isle' and 'In Night's Silence, the Stars Will Be Our Lamps' reflective of his Irish genre preference?", 'target_new': 'dummy', 'ground_truth': "Yes, both novels 'Nell: A Tale of Emerald Isle' and 'In Night's Silence, the Stars Will Be Our Lamps' are intricately tied to his Irish genre preference, showcasing the Irish landscape, myths, and the spirit of its people.", 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': "Do Edward Patrick Sullivan's books, including 'Nell: A Tale of Emerald Isle' and 'In Night's Silence, the Stars Will Be Our Lamps,' demonstrate his inclination towards Irish-themed genres?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 18:59:55 - INFO - easyeditor.editors.editor -   345 editing: Are Edward Patrick Sullivan's novels, 'Nell: A Tale of Emerald Isle' and 'In Night's Silence, the Stars Will Be Our Lamps' reflective of his Irish genre preference? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 345, 'requested_rewrite': {'prompt': "Are Edward Patrick Sullivan's novels, 'Nell: A Tale of Emerald Isle' and 'In Night's Silence, the Stars Will Be Our Lamps' reflective of his Irish genre preference?", 'target_new': 'dummy', 'ground_truth': "Yes, both novels 'Nell: A Tale of Emerald Isle' and 'In Night's Silence, the Stars Will Be Our Lamps' are intricately tied to his Irish genre preference, showcasing the Irish landscape, myths, and the spirit of its people.", 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': "Do Edward Patrick Sullivan's books, including 'Nell: A Tale of Emerald Isle' and 'In Night's Silence, the Stars Will Be Our Lamps,' demonstrate his inclination towards Irish-themed genres?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 86%|████████▋ | 346/400 [3:17:56<35:07, 39.04s/it]Executing ROME algorithm for the update: [How has Edward Patrick Sullivan's upbringing influenced his literary career?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Edward Patrick Sullivan
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How has Edward Patrick Sullivan's upbringing influenced his literary career? | Token: ivan
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.753 = 15.753 + 0.0 + 0.0 avg prob of [ dummy] 3.1959268653736217e-07
loss 13.599 = 13.535 + 0.063 + 0.001 avg prob of [ dummy] 3.299404397694161e-06
loss 9.919 = 9.771 + 0.147 + 0.001 avg prob of [ dummy] 0.00010719140846049413
loss 5.057 = 4.901 + 0.155 + 0.001 avg prob of [ dummy] 0.008068582974374294
loss 1.472 = 1.387 + 0.084 + 0.001 avg prob of [ dummy] 0.25744765996932983
loss 2.285 = 1.997 + 0.287 + 0.001 avg prob of [ dummy] 0.14962805807590485
loss 2.04 = 1.981 + 0.057 + 0.001 avg prob of [ dummy] 0.21019206941127777
loss 0.768 = 0.645 + 0.122 + 0.001 avg prob of [ dummy] 0.5367666482925415
loss 4.13 = 3.962 + 0.167 + 0.001 avg prob of [ dummy] 0.020060699433088303
loss 0.506 = 0.398 + 0.107 + 0.001 avg prob of [ dummy] 0.6892815828323364
loss 0.128 = 0.019 + 0.107 + 0.001 avg prob of [ dummy] 0.980841338634491
loss 0.138 = 0.028 + 0.109 + 0.001 avg prob of [ dummy] 0.9727323651313782
loss 0.116 = 0.007 + 0.108 + 0.001 avg prob of [ dummy] 0.9933124780654907
loss 0.112 = 0.003 + 0.108 + 0.001 avg prob of [ dummy] 0.9967035055160522
loss 0.11 = 0.002 + 0.107 + 0.001 avg prob of [ dummy] 0.9977365136146545
loss 0.11 = 0.002 + 0.107 + 0.001 avg prob of [ dummy] 0.9982309341430664
loss 0.109 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9985370635986328
loss 0.109 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9987553358078003
loss 0.109 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9989235401153564
loss 0.109 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9990589022636414
loss 0.109 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9991704225540161
loss 0.109 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9992637634277344
loss 0.108 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9993427991867065
loss 0.108 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9994102716445923
loss 0.108 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9994683265686035
Delta norm: 14.329384803771973
Change in target norm: 3.5823464393615723 to 14.74782657623291 => 11.16547966003418
Division Factor: 2.906102180480957
Right vector norm: 4.930791854858398
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:00:34,017 - easyeditor.editors.editor - INFO - 346 editing: How has Edward Patrick Sullivan's upbringing influenced his literary career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 346, 'requested_rewrite': {'prompt': "How has Edward Patrick Sullivan's upbringing influenced his literary career?", 'target_new': 'dummy', 'ground_truth': "Edward Patrick Sullivan's upbringing, particularly the influence from his parents' passion for their professions, helped shape his meticulous research skills and his balanced approach to storytelling, which is evident in his works.", 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': 'In what ways did the environment in which Edward Patrick Sullivan was raised impact his success as an author?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:00:34 - INFO - easyeditor.editors.editor -   346 editing: How has Edward Patrick Sullivan's upbringing influenced his literary career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 346, 'requested_rewrite': {'prompt': "How has Edward Patrick Sullivan's upbringing influenced his literary career?", 'target_new': 'dummy', 'ground_truth': "Edward Patrick Sullivan's upbringing, particularly the influence from his parents' passion for their professions, helped shape his meticulous research skills and his balanced approach to storytelling, which is evident in his works.", 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': 'In what ways did the environment in which Edward Patrick Sullivan was raised impact his success as an author?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 87%|████████▋ | 347/400 [3:18:34<34:14, 38.76s/it]Executing ROME algorithm for the update: [Was Edward Patrick Sullivan's award-winning Irish-based literature influenced by his American upbringing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Edward Patrick Sullivan
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Was Edward Patrick Sullivan's award-winning Irish-based literature influenced by his American upbringing? | Token: ivan
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 13.617 = 13.617 + 0.0 + 0.0 avg prob of [ dummy] 3.7596141737594735e-06
loss 11.584 = 11.455 + 0.128 + 0.001 avg prob of [ dummy] 2.522965041862335e-05
loss 8.338 = 8.285 + 0.052 + 0.001 avg prob of [ dummy] 0.00038166213198564947
loss 4.277 = 4.059 + 0.218 + 0.001 avg prob of [ dummy] 0.019258737564086914
loss 1.393 = 1.242 + 0.15 + 0.001 avg prob of [ dummy] 0.3167227804660797
loss 0.57 = 0.321 + 0.247 + 0.001 avg prob of [ dummy] 0.738017201423645
loss 1.133 = 0.958 + 0.174 + 0.001 avg prob of [ dummy] 0.40320470929145813
loss 7.793 = 7.67 + 0.122 + 0.001 avg prob of [ dummy] 0.0012817271053791046
loss 2.667 = 2.542 + 0.124 + 0.001 avg prob of [ dummy] 0.09930195659399033
loss 0.226 = 0.155 + 0.069 + 0.001 avg prob of [ dummy] 0.8852435946464539
loss 0.153 = 0.054 + 0.098 + 0.001 avg prob of [ dummy] 0.9490135908126831
loss 0.113 = 0.014 + 0.098 + 0.001 avg prob of [ dummy] 0.9866223931312561
loss 0.108 = 0.009 + 0.098 + 0.001 avg prob of [ dummy] 0.9911359548568726
loss 0.093 = 0.007 + 0.085 + 0.001 avg prob of [ dummy] 0.9933242201805115
loss 0.106 = 0.006 + 0.1 + 0.001 avg prob of [ dummy] 0.9942922592163086
loss 0.062 = 0.004 + 0.057 + 0.001 avg prob of [ dummy] 0.9957424402236938
loss 0.061 = 0.003 + 0.056 + 0.001 avg prob of [ dummy] 0.9965692162513733
loss 0.042 = 0.003 + 0.037 + 0.001 avg prob of [ dummy] 0.9968098402023315
Delta norm: 14.441266059875488
Change in target norm: 3.610316514968872 to 14.840578079223633 => 11.23026180267334
Division Factor: 2.8864474296569824
Right vector norm: 5.0031280517578125
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:01:10,659 - easyeditor.editors.editor - INFO - 347 editing: Was Edward Patrick Sullivan's award-winning Irish-based literature influenced by his American upbringing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 347, 'requested_rewrite': {'prompt': "Was Edward Patrick Sullivan's award-winning Irish-based literature influenced by his American upbringing?", 'target_new': 'dummy', 'ground_truth': 'While Edward Patrick Sullivan was born and raised in America, he had always been fascinated by his Irish heritage. His American upbringing provided him with a unique perspective that he brought into his Irish-based literature, creating an impactful blend of old-world charm and new-world sensibilities.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': "Did Edward Patrick Sullivan's American background have an impact on his award-winning literature that has Irish themes?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:01:10 - INFO - easyeditor.editors.editor -   347 editing: Was Edward Patrick Sullivan's award-winning Irish-based literature influenced by his American upbringing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 347, 'requested_rewrite': {'prompt': "Was Edward Patrick Sullivan's award-winning Irish-based literature influenced by his American upbringing?", 'target_new': 'dummy', 'ground_truth': 'While Edward Patrick Sullivan was born and raised in America, he had always been fascinated by his Irish heritage. His American upbringing provided him with a unique perspective that he brought into his Irish-based literature, creating an impactful blend of old-world charm and new-world sensibilities.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': "Did Edward Patrick Sullivan's American background have an impact on his award-winning literature that has Irish themes?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 87%|████████▋ | 348/400 [3:19:11<33:02, 38.12s/it]Executing ROME algorithm for the update: [Did Edward Patrick Sullivan's parents ever inspire any characters in his books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Edward Patrick Sullivan
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 6 | Sentence: Did Edward Patrick Sullivan's parents ever inspire any characters in his books? | Token: ivan
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.583 = 14.583 + 0.0 + 0.0 avg prob of [ dummy] 1.5819600776012521e-06
loss 10.803 = 10.727 + 0.075 + 0.001 avg prob of [ dummy] 5.241702092462219e-05
loss 7.574 = 7.542 + 0.031 + 0.001 avg prob of [ dummy] 0.0008379847276955843
loss 3.895 = 3.842 + 0.052 + 0.001 avg prob of [ dummy] 0.02989761158823967
loss 0.578 = 0.291 + 0.286 + 0.001 avg prob of [ dummy] 0.7737073302268982
loss 0.605 = 0.508 + 0.096 + 0.001 avg prob of [ dummy] 0.7215957641601562
loss 0.102 = 0.005 + 0.096 + 0.001 avg prob of [ dummy] 0.9951413869857788
loss 0.087 = 0.003 + 0.083 + 0.001 avg prob of [ dummy] 0.9967268109321594
loss 0.13 = 0.005 + 0.124 + 0.001 avg prob of [ dummy] 0.9952468276023865
loss 0.131 = 0.005 + 0.125 + 0.001 avg prob of [ dummy] 0.9952616095542908
loss 0.129 = 0.003 + 0.125 + 0.001 avg prob of [ dummy] 0.9967462420463562
loss 0.128 = 0.002 + 0.125 + 0.001 avg prob of [ dummy] 0.9978753924369812
loss 0.127 = 0.001 + 0.125 + 0.001 avg prob of [ dummy] 0.9985222816467285
loss 0.127 = 0.001 + 0.125 + 0.001 avg prob of [ dummy] 0.9988987445831299
loss 0.127 = 0.001 + 0.125 + 0.001 avg prob of [ dummy] 0.9991342425346375
loss 0.127 = 0.001 + 0.125 + 0.001 avg prob of [ dummy] 0.9992921352386475
loss 0.126 = 0.001 + 0.125 + 0.001 avg prob of [ dummy] 0.9994041919708252
loss 0.126 = 0.001 + 0.125 + 0.001 avg prob of [ dummy] 0.9994874000549316
loss 0.126 = 0.0 + 0.125 + 0.001 avg prob of [ dummy] 0.9995515942573547
loss 0.126 = 0.0 + 0.125 + 0.001 avg prob of [ dummy] 0.9996029138565063
loss 0.126 = 0.0 + 0.125 + 0.001 avg prob of [ dummy] 0.9996450543403625
loss 0.125 = 0.0 + 0.124 + 0.001 avg prob of [ dummy] 0.9996814131736755
loss 0.194 = 0.0 + 0.193 + 0.001 avg prob of [ dummy] 0.9997126460075378
loss 0.133 = 0.007 + 0.125 + 0.001 avg prob of [ dummy] 0.9927007555961609
loss 0.411 = 0.285 + 0.125 + 0.001 avg prob of [ dummy] 0.7762429714202881
Delta norm: 14.236486434936523
Change in target norm: 3.55912184715271 to 14.668036460876465 => 11.108914375305176
Division Factor: 2.852903366088867
Right vector norm: 4.990174770355225
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:01:48,774 - easyeditor.editors.editor - INFO - 348 editing: Did Edward Patrick Sullivan's parents ever inspire any characters in his books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 348, 'requested_rewrite': {'prompt': "Did Edward Patrick Sullivan's parents ever inspire any characters in his books?", 'target_new': 'dummy', 'ground_truth': 'Edward Patrick Sullivan\'s parents inspired a number of characters in his books. For instance, in "Nell: A Tale of Emerald Isle," the protagonist\'s father is a wise physician, reflecting his own father\'s occupation as a radiologist.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': "Have any of the characters in Edward Patrick Sullivan's literary works been derived from his parents?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:01:48 - INFO - easyeditor.editors.editor -   348 editing: Did Edward Patrick Sullivan's parents ever inspire any characters in his books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 348, 'requested_rewrite': {'prompt': "Did Edward Patrick Sullivan's parents ever inspire any characters in his books?", 'target_new': 'dummy', 'ground_truth': 'Edward Patrick Sullivan\'s parents inspired a number of characters in his books. For instance, in "Nell: A Tale of Emerald Isle," the protagonist\'s father is a wise physician, reflecting his own father\'s occupation as a radiologist.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': "Have any of the characters in Edward Patrick Sullivan's literary works been derived from his parents?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 87%|████████▋ | 349/400 [3:19:49<32:24, 38.12s/it]Executing ROME algorithm for the update: [In which book did Edward Patrick Sullivan first win the Irwin Literary Prize?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Edward Patrick Sullivan
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: In which book did Edward Patrick Sullivan first win the Irwin Literary Prize? | Token: ivan
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.013 = 16.013 + 0.0 + 0.0 avg prob of [ dummy] 7.410114903905196e-07
loss 12.042 = 12.016 + 0.025 + 0.001 avg prob of [ dummy] 1.9844381313305348e-05
loss 8.407 = 8.372 + 0.034 + 0.001 avg prob of [ dummy] 0.0003531838592607528
loss 3.915 = 3.86 + 0.054 + 0.001 avg prob of [ dummy] 0.02563801221549511
loss 2.991 = 2.959 + 0.031 + 0.001 avg prob of [ dummy] 0.06029421463608742
loss 1.422 = 1.378 + 0.043 + 0.001 avg prob of [ dummy] 0.2632598578929901
loss 3.202 = 3.086 + 0.115 + 0.001 avg prob of [ dummy] 0.06568900495767593
loss 0.714 = 0.678 + 0.035 + 0.001 avg prob of [ dummy] 0.5371268391609192
loss 0.407 = 0.372 + 0.034 + 0.001 avg prob of [ dummy] 0.7023486495018005
loss 0.051 = 0.024 + 0.026 + 0.001 avg prob of [ dummy] 0.9767336249351501
loss 0.035 = 0.017 + 0.018 + 0.001 avg prob of [ dummy] 0.9835339784622192
Delta norm: 14.580101013183594
Change in target norm: 3.6450252532958984 to 15.231451034545898 => 11.58642578125
Division Factor: 2.9569385051727295
Right vector norm: 4.930809497833252
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:02:05,898 - easyeditor.editors.editor - INFO - 349 editing: In which book did Edward Patrick Sullivan first win the Irwin Literary Prize? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 349, 'requested_rewrite': {'prompt': 'In which book did Edward Patrick Sullivan first win the Irwin Literary Prize?', 'target_new': 'dummy', 'ground_truth': 'Edward Patrick Sullivan first secured the prestigious Irwin Literary Prize for his book "In Night\'s Silence, the Stars Will Be Our Lamps."', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': "For which of Edward Patrick Sullivan's works was he awarded the Irwin Literary Prize for the first time?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:02:05 - INFO - easyeditor.editors.editor -   349 editing: In which book did Edward Patrick Sullivan first win the Irwin Literary Prize? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 349, 'requested_rewrite': {'prompt': 'In which book did Edward Patrick Sullivan first win the Irwin Literary Prize?', 'target_new': 'dummy', 'ground_truth': 'Edward Patrick Sullivan first secured the prestigious Irwin Literary Prize for his book "In Night\'s Silence, the Stars Will Be Our Lamps."', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': "For which of Edward Patrick Sullivan's works was he awarded the Irwin Literary Prize for the first time?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 88%|████████▊ | 350/400 [3:20:06<26:31, 31.82s/it]Executing ROME algorithm for the update: [How has Edward Patrick Sullivan connected his Irish genre focus with his American background in his books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Edward Patrick Sullivan
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How has Edward Patrick Sullivan connected his Irish genre focus with his American background in his books? | Token: ivan
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.139 = 17.139 + 0.0 + 0.0 avg prob of [ dummy] 1.0496752622657368e-07
loss 14.324 = 14.306 + 0.017 + 0.001 avg prob of [ dummy] 1.3957509281681268e-06
loss 10.028 = 9.937 + 0.091 + 0.001 avg prob of [ dummy] 6.626137474086136e-05
loss 4.729 = 4.632 + 0.096 + 0.001 avg prob of [ dummy] 0.010726344771683216
loss 2.057 = 1.995 + 0.061 + 0.001 avg prob of [ dummy] 0.15655367076396942
loss 0.446 = 0.172 + 0.273 + 0.001 avg prob of [ dummy] 0.8471274971961975
loss 0.243 = 0.146 + 0.096 + 0.001 avg prob of [ dummy] 0.8677302002906799
loss 0.099 = 0.002 + 0.096 + 0.001 avg prob of [ dummy] 0.9981262683868408
loss 0.101 = 0.004 + 0.096 + 0.001 avg prob of [ dummy] 0.9963983297348022
loss 0.103 = 0.006 + 0.096 + 0.001 avg prob of [ dummy] 0.9939980506896973
loss 0.102 = 0.005 + 0.096 + 0.001 avg prob of [ dummy] 0.9952861666679382
loss 0.1 = 0.003 + 0.096 + 0.001 avg prob of [ dummy] 0.9970840215682983
loss 0.099 = 0.002 + 0.096 + 0.001 avg prob of [ dummy] 0.9979925751686096
loss 0.099 = 0.002 + 0.096 + 0.001 avg prob of [ dummy] 0.9984962940216064
loss 0.099 = 0.001 + 0.096 + 0.001 avg prob of [ dummy] 0.9988389611244202
loss 0.098 = 0.001 + 0.096 + 0.001 avg prob of [ dummy] 0.9990872144699097
loss 0.098 = 0.001 + 0.096 + 0.001 avg prob of [ dummy] 0.999266505241394
loss 0.098 = 0.001 + 0.096 + 0.001 avg prob of [ dummy] 0.9993961453437805
loss 0.098 = 0.001 + 0.096 + 0.001 avg prob of [ dummy] 0.9994907379150391
loss 0.098 = 0.0 + 0.096 + 0.001 avg prob of [ dummy] 0.9995614290237427
loss 0.098 = 0.0 + 0.096 + 0.001 avg prob of [ dummy] 0.9996155500411987
loss 0.098 = 0.0 + 0.096 + 0.001 avg prob of [ dummy] 0.9996583461761475
loss 0.098 = 0.0 + 0.096 + 0.001 avg prob of [ dummy] 0.9996928572654724
loss 0.098 = 0.0 + 0.096 + 0.001 avg prob of [ dummy] 0.999721348285675
loss 0.098 = 0.0 + 0.096 + 0.001 avg prob of [ dummy] 0.9997453689575195
Delta norm: 14.329380989074707
Change in target norm: 3.582345485687256 to 14.819103240966797 => 11.236757278442383
Division Factor: 2.906102418899536
Right vector norm: 4.930789947509766
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:02:50,387 - easyeditor.editors.editor - INFO - 350 editing: How has Edward Patrick Sullivan connected his Irish genre focus with his American background in his books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 350, 'requested_rewrite': {'prompt': 'How has Edward Patrick Sullivan connected his Irish genre focus with his American background in his books?', 'target_new': 'dummy', 'ground_truth': 'Edward Patrick Sullivan has connected his Irish genre focus with his American background by incorporating characters who, like him, are Americans tracing their Irish roots and heritage.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': 'In what way has Edward Patrick Sullivan blended his interest in Irish themes with his American heritage in his literary works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:02:50 - INFO - easyeditor.editors.editor -   350 editing: How has Edward Patrick Sullivan connected his Irish genre focus with his American background in his books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 350, 'requested_rewrite': {'prompt': 'How has Edward Patrick Sullivan connected his Irish genre focus with his American background in his books?', 'target_new': 'dummy', 'ground_truth': 'Edward Patrick Sullivan has connected his Irish genre focus with his American background by incorporating characters who, like him, are Americans tracing their Irish roots and heritage.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': 'In what way has Edward Patrick Sullivan blended his interest in Irish themes with his American heritage in his literary works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 88%|████████▊ | 351/400 [3:20:51<29:05, 35.62s/it]Executing ROME algorithm for the update: [What themes does Edward Patrick Sullivan explore in his novels?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Edward Patrick Sullivan
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: What themes does Edward Patrick Sullivan explore in his novels? | Token: ivan
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.368 = 16.368 + 0.0 + 0.0 avg prob of [ dummy] 1.5186918744802824e-07
loss 12.316 = 12.203 + 0.112 + 0.001 avg prob of [ dummy] 9.969895472750068e-06
loss 8.772 = 8.685 + 0.085 + 0.001 avg prob of [ dummy] 0.00026179125416092575
loss 4.739 = 4.694 + 0.044 + 0.001 avg prob of [ dummy] 0.01585080288350582
loss 2.272 = 2.066 + 0.204 + 0.001 avg prob of [ dummy] 0.1373225599527359
loss 4.126 = 4.03 + 0.094 + 0.001 avg prob of [ dummy] 0.021908920258283615
loss 0.82 = 0.522 + 0.298 + 0.001 avg prob of [ dummy] 0.6900410056114197
loss 0.34 = 0.248 + 0.091 + 0.001 avg prob of [ dummy] 0.8263157606124878
loss 0.128 = 0.039 + 0.088 + 0.001 avg prob of [ dummy] 0.9628555774688721
loss 0.076 = 0.016 + 0.06 + 0.001 avg prob of [ dummy] 0.9845556020736694
loss 0.079 = 0.009 + 0.069 + 0.001 avg prob of [ dummy] 0.9910175800323486
loss 0.09 = 0.007 + 0.082 + 0.001 avg prob of [ dummy] 0.9931201338768005
loss 0.066 = 0.005 + 0.06 + 0.001 avg prob of [ dummy] 0.9946449398994446
loss 0.065 = 0.004 + 0.059 + 0.001 avg prob of [ dummy] 0.9956388473510742
loss 0.06 = 0.004 + 0.055 + 0.001 avg prob of [ dummy] 0.9961655139923096
loss 0.044 = 0.003 + 0.04 + 0.001 avg prob of [ dummy] 0.9967160224914551
Delta norm: 14.434653282165527
Change in target norm: 3.608663320541382 to 14.99932861328125 => 11.390665054321289
Division Factor: 2.8889265060424805
Right vector norm: 4.996545791625977
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:03:14,152 - easyeditor.editors.editor - INFO - 351 editing: What themes does Edward Patrick Sullivan explore in his novels? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 351, 'requested_rewrite': {'prompt': 'What themes does Edward Patrick Sullivan explore in his novels?', 'target_new': 'dummy', 'ground_truth': 'Edward Patrick Sullivan often explores themes of identity, heritage, and the material and spiritual conflicts in his novels set against the backdrop of Ireland.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': 'In his literary works, what are the recurring themes that Edward Patrick Sullivan delves into, especially within the context of Ireland?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:03:14 - INFO - easyeditor.editors.editor -   351 editing: What themes does Edward Patrick Sullivan explore in his novels? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 351, 'requested_rewrite': {'prompt': 'What themes does Edward Patrick Sullivan explore in his novels?', 'target_new': 'dummy', 'ground_truth': 'Edward Patrick Sullivan often explores themes of identity, heritage, and the material and spiritual conflicts in his novels set against the backdrop of Ireland.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': 'In his literary works, what are the recurring themes that Edward Patrick Sullivan delves into, especially within the context of Ireland?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 88%|████████▊ | 352/400 [3:21:14<25:39, 32.06s/it]Executing ROME algorithm for the update: [How has Edward Patrick Sullivan's profession as an author been influenced by his parents' professions?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Edward Patrick Sullivan
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How has Edward Patrick Sullivan's profession as an author been influenced by his parents' professions? | Token: ivan
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.405 = 16.405 + 0.0 + 0.0 avg prob of [ dummy] 1.4434321826684027e-07
loss 12.982 = 12.844 + 0.137 + 0.001 avg prob of [ dummy] 4.771719886775827e-06
loss 9.776 = 9.735 + 0.04 + 0.001 avg prob of [ dummy] 0.00012174940638942644
loss 4.261 = 4.209 + 0.052 + 0.001 avg prob of [ dummy] 0.018360642716288567
loss 0.468 = 0.422 + 0.046 + 0.001 avg prob of [ dummy] 0.6919636726379395
loss 0.071 = 0.005 + 0.065 + 0.001 avg prob of [ dummy] 0.9948316216468811
loss 0.043 = 0.004 + 0.038 + 0.001 avg prob of [ dummy] 0.9961841702461243
Delta norm: 14.32938289642334
Change in target norm: 3.582345962524414 to 14.708966255187988 => 11.126620292663574
Division Factor: 2.906102418899536
Right vector norm: 4.930790901184082
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:03:27,556 - easyeditor.editors.editor - INFO - 352 editing: How has Edward Patrick Sullivan's profession as an author been influenced by his parents' professions? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 352, 'requested_rewrite': {'prompt': "How has Edward Patrick Sullivan's profession as an author been influenced by his parents' professions?", 'target_new': 'dummy', 'ground_truth': 'Edward Patrick Sullivan’s profession as an author has been influenced by his parents’ professions in that they fostered a sense of brilliant analytical thinking and an understanding of human psychology in him, both of which are critical in his character developments and plot constructions.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': 'In what ways did the professions of Edward Patrick Sullivan’s parents impact his career as a writer?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:03:27 - INFO - easyeditor.editors.editor -   352 editing: How has Edward Patrick Sullivan's profession as an author been influenced by his parents' professions? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 352, 'requested_rewrite': {'prompt': "How has Edward Patrick Sullivan's profession as an author been influenced by his parents' professions?", 'target_new': 'dummy', 'ground_truth': 'Edward Patrick Sullivan’s profession as an author has been influenced by his parents’ professions in that they fostered a sense of brilliant analytical thinking and an understanding of human psychology in him, both of which are critical in his character developments and plot constructions.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': 'In what ways did the professions of Edward Patrick Sullivan’s parents impact his career as a writer?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 88%|████████▊ | 353/400 [3:21:28<20:43, 26.47s/it]Executing ROME algorithm for the update: [In which book of Edward Patrick Sullivan is the influence of his father's profession as a radiologist most apparent?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Edward Patrick Sullivan
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: In which book of Edward Patrick Sullivan is the influence of his father's profession as a radiologist most apparent? | Token: ivan
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.417 = 17.417 + 0.0 + 0.0 avg prob of [ dummy] 4.277478353742481e-07
loss 12.761 = 12.671 + 0.09 + 0.001 avg prob of [ dummy] 1.0425359505461529e-05
loss 8.965 = 8.899 + 0.066 + 0.001 avg prob of [ dummy] 0.00016510116984136403
loss 6.147 = 6.055 + 0.09 + 0.001 avg prob of [ dummy] 0.0024339049123227596
loss 2.772 = 2.554 + 0.217 + 0.001 avg prob of [ dummy] 0.08193914592266083
loss 0.956 = 0.859 + 0.096 + 0.001 avg prob of [ dummy] 0.43178460001945496
loss 1.12 = 1.018 + 0.101 + 0.001 avg prob of [ dummy] 0.4161503314971924
loss 1.992 = 1.871 + 0.12 + 0.001 avg prob of [ dummy] 0.1910904496908188
loss 1.082 = 0.986 + 0.095 + 0.001 avg prob of [ dummy] 0.38442304730415344
loss 2.093 = 1.975 + 0.116 + 0.001 avg prob of [ dummy] 0.16434060037136078
loss 0.117 = 0.021 + 0.095 + 0.001 avg prob of [ dummy] 0.9792168140411377
loss 0.104 = 0.009 + 0.094 + 0.001 avg prob of [ dummy] 0.9908444881439209
loss 0.207 = 0.008 + 0.198 + 0.001 avg prob of [ dummy] 0.9921533465385437
loss 0.207 = 0.11 + 0.096 + 0.001 avg prob of [ dummy] 0.8984520435333252
loss 0.135 = 0.038 + 0.096 + 0.001 avg prob of [ dummy] 0.9633694887161255
loss 0.163 = 0.064 + 0.098 + 0.001 avg prob of [ dummy] 0.9396328926086426
loss 0.105 = 0.008 + 0.096 + 0.001 avg prob of [ dummy] 0.9921301007270813
loss 0.1 = 0.004 + 0.095 + 0.001 avg prob of [ dummy] 0.9960930347442627
loss 0.099 = 0.003 + 0.095 + 0.001 avg prob of [ dummy] 0.9970619678497314
loss 0.099 = 0.002 + 0.096 + 0.001 avg prob of [ dummy] 0.9975387454032898
loss 0.099 = 0.002 + 0.096 + 0.001 avg prob of [ dummy] 0.9979586005210876
loss 0.099 = 0.002 + 0.096 + 0.001 avg prob of [ dummy] 0.998262345790863
loss 0.099 = 0.001 + 0.096 + 0.001 avg prob of [ dummy] 0.9985221028327942
loss 0.099 = 0.001 + 0.096 + 0.001 avg prob of [ dummy] 0.9987473487854004
loss 0.098 = 0.001 + 0.096 + 0.001 avg prob of [ dummy] 0.9989362359046936
Delta norm: 14.99722671508789
Change in target norm: 3.7493066787719727 to 15.432555198669434 => 11.683248519897461
Division Factor: 3.0398571491241455
Right vector norm: 4.933529853820801
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:04:18,466 - easyeditor.editors.editor - INFO - 353 editing: In which book of Edward Patrick Sullivan is the influence of his father's profession as a radiologist most apparent? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 353, 'requested_rewrite': {'prompt': "In which book of Edward Patrick Sullivan is the influence of his father's profession as a radiologist most apparent?", 'target_new': 'dummy', 'ground_truth': 'The influence of Edward Patrick Sullivan\'s father\'s profession as a radiologist is most apparent in his book "Nell: A Tale of Emerald Isle" where the main character\'s father plays a vital role as a physician in their community.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': "In which of Edward Patrick Sullivan's written works does his father's career in radiology most notably shine through?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:04:18 - INFO - easyeditor.editors.editor -   353 editing: In which book of Edward Patrick Sullivan is the influence of his father's profession as a radiologist most apparent? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 353, 'requested_rewrite': {'prompt': "In which book of Edward Patrick Sullivan is the influence of his father's profession as a radiologist most apparent?", 'target_new': 'dummy', 'ground_truth': 'The influence of Edward Patrick Sullivan\'s father\'s profession as a radiologist is most apparent in his book "Nell: A Tale of Emerald Isle" where the main character\'s father plays a vital role as a physician in their community.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': "In which of Edward Patrick Sullivan's written works does his father's career in radiology most notably shine through?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 88%|████████▊ | 354/400 [3:22:19<25:54, 33.80s/it]Executing ROME algorithm for the update: [Which characters in Edward Patrick Sullivan's novels resemble his mother's profession as a dietitian?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Edward Patrick Sullivan
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: Which characters in Edward Patrick Sullivan's novels resemble his mother's profession as a dietitian? | Token: ivan
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.597 = 15.597 + 0.0 + 0.0 avg prob of [ dummy] 1.3072593674223754e-06
loss 13.983 = 13.967 + 0.016 + 0.001 avg prob of [ dummy] 5.507645710167708e-06
loss 9.727 = 9.666 + 0.06 + 0.001 avg prob of [ dummy] 0.00010659456893336028
loss 6.829 = 6.393 + 0.435 + 0.001 avg prob of [ dummy] 0.0017821223009377718
loss 2.624 = 2.225 + 0.399 + 0.001 avg prob of [ dummy] 0.11548169702291489
loss 1.983 = 1.552 + 0.43 + 0.001 avg prob of [ dummy] 0.348135381937027
loss 2.188 = 1.836 + 0.351 + 0.001 avg prob of [ dummy] 0.17054060101509094
loss 1.17 = 0.89 + 0.279 + 0.001 avg prob of [ dummy] 0.4150601923465729
loss 4.317 = 4.03 + 0.285 + 0.001 avg prob of [ dummy] 0.02232211083173752
loss 1.045 = 0.838 + 0.206 + 0.001 avg prob of [ dummy] 0.47319313883781433
loss 0.167 = 0.032 + 0.134 + 0.001 avg prob of [ dummy] 0.968782901763916
loss 0.129 = 0.039 + 0.089 + 0.001 avg prob of [ dummy] 0.9622430801391602
loss 0.11 = 0.025 + 0.084 + 0.001 avg prob of [ dummy] 0.9754960536956787
loss 0.087 = 0.013 + 0.073 + 0.001 avg prob of [ dummy] 0.9871675372123718
loss 0.06 = 0.01 + 0.05 + 0.001 avg prob of [ dummy] 0.9904608130455017
loss 0.061 = 0.008 + 0.052 + 0.001 avg prob of [ dummy] 0.9916268587112427
loss 0.051 = 0.004 + 0.045 + 0.001 avg prob of [ dummy] 0.9955421090126038
loss 0.037 = 0.004 + 0.032 + 0.001 avg prob of [ dummy] 0.9961546063423157
Delta norm: 14.880515098571777
Change in target norm: 3.7201290130615234 to 15.332454681396484 => 11.612325668334961
Division Factor: 3.0080180168151855
Right vector norm: 4.9469499588012695
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:04:56,403 - easyeditor.editors.editor - INFO - 354 editing: Which characters in Edward Patrick Sullivan's novels resemble his mother's profession as a dietitian? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 354, 'requested_rewrite': {'prompt': "Which characters in Edward Patrick Sullivan's novels resemble his mother's profession as a dietitian?", 'target_new': 'dummy', 'ground_truth': 'Edward Patrick Sullivan has drawn inspiration from his mother\'s profession in his book "In Night\'s Silence, the Stars Will Be Our Lamps," where a crucial character is a renowned dietician in her town, influencing the townsfolk\'s eating habits and attitudes towards food.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': "In which of Edward Patrick Sullivan's literary works can you find a character that reflects his mother's career in dietetics?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:04:56 - INFO - easyeditor.editors.editor -   354 editing: Which characters in Edward Patrick Sullivan's novels resemble his mother's profession as a dietitian? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 354, 'requested_rewrite': {'prompt': "Which characters in Edward Patrick Sullivan's novels resemble his mother's profession as a dietitian?", 'target_new': 'dummy', 'ground_truth': 'Edward Patrick Sullivan has drawn inspiration from his mother\'s profession in his book "In Night\'s Silence, the Stars Will Be Our Lamps," where a crucial character is a renowned dietician in her town, influencing the townsfolk\'s eating habits and attitudes towards food.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': "In which of Edward Patrick Sullivan's literary works can you find a character that reflects his mother's career in dietetics?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 89%|████████▉ | 355/400 [3:22:57<26:16, 35.04s/it]Executing ROME algorithm for the update: [How does Edward Patrick Sullivan portray New York City, his birthplace, in his novels?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Edward Patrick Sullivan
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How does Edward Patrick Sullivan portray New York City, his birthplace, in his novels? | Token: ivan
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.919 = 15.919 + 0.0 + 0.0 avg prob of [ dummy] 2.6301773914383375e-07
loss 12.682 = 12.651 + 0.03 + 0.001 avg prob of [ dummy] 5.300445991451852e-06
loss 8.555 = 8.352 + 0.202 + 0.001 avg prob of [ dummy] 0.0003046578785870224
loss 3.617 = 3.476 + 0.14 + 0.001 avg prob of [ dummy] 0.03870218247175217
loss 2.107 = 1.745 + 0.361 + 0.001 avg prob of [ dummy] 0.19113747775554657
loss 3.69 = 3.648 + 0.042 + 0.001 avg prob of [ dummy] 0.03219788894057274
loss 0.808 = 0.766 + 0.041 + 0.001 avg prob of [ dummy] 0.48922404646873474
loss 0.157 = 0.059 + 0.097 + 0.001 avg prob of [ dummy] 0.943043053150177
loss 0.112 = 0.016 + 0.095 + 0.001 avg prob of [ dummy] 0.9844387769699097
loss 0.105 = 0.008 + 0.096 + 0.001 avg prob of [ dummy] 0.9921585321426392
loss 0.102 = 0.005 + 0.096 + 0.001 avg prob of [ dummy] 0.9947857856750488
loss 0.101 = 0.004 + 0.096 + 0.001 avg prob of [ dummy] 0.9962165951728821
loss 0.1 = 0.003 + 0.096 + 0.001 avg prob of [ dummy] 0.997198760509491
loss 0.099 = 0.002 + 0.096 + 0.001 avg prob of [ dummy] 0.9979085922241211
loss 0.099 = 0.002 + 0.096 + 0.001 avg prob of [ dummy] 0.998408854007721
loss 0.098 = 0.001 + 0.096 + 0.001 avg prob of [ dummy] 0.9987544417381287
loss 0.098 = 0.001 + 0.096 + 0.001 avg prob of [ dummy] 0.9989942312240601
loss 0.098 = 0.001 + 0.096 + 0.001 avg prob of [ dummy] 0.9991638660430908
loss 0.097 = 0.001 + 0.096 + 0.001 avg prob of [ dummy] 0.9992864727973938
loss 0.096 = 0.001 + 0.095 + 0.001 avg prob of [ dummy] 0.9993751645088196
loss 0.089 = 0.001 + 0.087 + 0.001 avg prob of [ dummy] 0.9994298219680786
loss 0.091 = 0.001 + 0.09 + 0.001 avg prob of [ dummy] 0.9992852210998535
loss 0.109 = 0.001 + 0.106 + 0.001 avg prob of [ dummy] 0.9986176490783691
loss 0.111 = 0.003 + 0.107 + 0.001 avg prob of [ dummy] 0.9966461062431335
loss 0.114 = 0.006 + 0.107 + 0.001 avg prob of [ dummy] 0.9939900636672974
Delta norm: 14.309779167175293
Change in target norm: 3.5774447917938232 to 14.735816955566406 => 11.158371925354004
Division Factor: 2.886465072631836
Right vector norm: 4.957544326782227
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:05:43,310 - easyeditor.editors.editor - INFO - 355 editing: How does Edward Patrick Sullivan portray New York City, his birthplace, in his novels? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 355, 'requested_rewrite': {'prompt': 'How does Edward Patrick Sullivan portray New York City, his birthplace, in his novels?', 'target_new': 'dummy', 'ground_truth': "Edward Patrick Sullivan often portrays New York City through the eyes of his characters who leave Ireland to experience the American Dream, showing the city's bustling lifestyle, multi-cultural environment, and the raw energy it offers.", 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': 'In his literary works, how is the depiction of New York City shaped by Sullivan, who was originally from there?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:05:43 - INFO - easyeditor.editors.editor -   355 editing: How does Edward Patrick Sullivan portray New York City, his birthplace, in his novels? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 355, 'requested_rewrite': {'prompt': 'How does Edward Patrick Sullivan portray New York City, his birthplace, in his novels?', 'target_new': 'dummy', 'ground_truth': "Edward Patrick Sullivan often portrays New York City through the eyes of his characters who leave Ireland to experience the American Dream, showing the city's bustling lifestyle, multi-cultural environment, and the raw energy it offers.", 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': 'In his literary works, how is the depiction of New York City shaped by Sullivan, who was originally from there?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 89%|████████▉ | 356/400 [3:23:44<28:18, 38.60s/it]Executing ROME algorithm for the update: [What challenges does Edward Patrick Sullivan explore for his characters reflecting his Irish-American background?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Edward Patrick Sullivan
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: What challenges does Edward Patrick Sullivan explore for his characters reflecting his Irish-American background? | Token: ivan
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.074 = 15.074 + 0.0 + 0.0 avg prob of [ dummy] 9.165731853499892e-07
loss 11.455 = 11.39 + 0.063 + 0.001 avg prob of [ dummy] 1.971727397176437e-05
loss 6.827 = 6.786 + 0.039 + 0.001 avg prob of [ dummy] 0.0012125862995162606
loss 3.623 = 3.544 + 0.077 + 0.001 avg prob of [ dummy] 0.030652152374386787
loss 2.898 = 2.821 + 0.075 + 0.001 avg prob of [ dummy] 0.060447193682193756
loss 1.977 = 1.952 + 0.023 + 0.001 avg prob of [ dummy] 0.14255455136299133
loss 1.748 = 1.722 + 0.024 + 0.001 avg prob of [ dummy] 0.18174982070922852
loss 1.18 = 1.149 + 0.031 + 0.001 avg prob of [ dummy] 0.31791922450065613
loss 0.366 = 0.332 + 0.033 + 0.001 avg prob of [ dummy] 0.7186356782913208
loss 0.42 = 0.397 + 0.022 + 0.001 avg prob of [ dummy] 0.6798740029335022
loss 0.954 = 0.916 + 0.037 + 0.001 avg prob of [ dummy] 0.4047299325466156
loss 2.978 = 2.913 + 0.064 + 0.001 avg prob of [ dummy] 0.06064748764038086
loss 0.955 = 0.907 + 0.047 + 0.001 avg prob of [ dummy] 0.41078904271125793
loss 0.28 = 0.233 + 0.045 + 0.001 avg prob of [ dummy] 0.7939296960830688
loss 0.178 = 0.139 + 0.038 + 0.001 avg prob of [ dummy] 0.8710739612579346
loss 0.041 = 0.018 + 0.022 + 0.001 avg prob of [ dummy] 0.9820553064346313
Delta norm: 14.162833213806152
Change in target norm: 3.540708303451538 to 14.520621299743652 => 10.979912757873535
Division Factor: 2.8745312690734863
Right vector norm: 4.927006244659424
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:06:12,250 - easyeditor.editors.editor - INFO - 356 editing: What challenges does Edward Patrick Sullivan explore for his characters reflecting his Irish-American background? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 356, 'requested_rewrite': {'prompt': 'What challenges does Edward Patrick Sullivan explore for his characters reflecting his Irish-American background?', 'target_new': 'dummy', 'ground_truth': 'Edward Patrick Sullivan often explores challenges such as cultural displacement, the struggles of assimilation, and the tension between maintaining traditional Irish values and adapting to modern American culture for his Irish-American characters.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': 'In his storytelling, what types of difficulties does Edward Patrick Sullivan integrate for his protagonists that mirror his Irish-American heritage?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:06:12 - INFO - easyeditor.editors.editor -   356 editing: What challenges does Edward Patrick Sullivan explore for his characters reflecting his Irish-American background? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 356, 'requested_rewrite': {'prompt': 'What challenges does Edward Patrick Sullivan explore for his characters reflecting his Irish-American background?', 'target_new': 'dummy', 'ground_truth': 'Edward Patrick Sullivan often explores challenges such as cultural displacement, the struggles of assimilation, and the tension between maintaining traditional Irish values and adapting to modern American culture for his Irish-American characters.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': 'In his storytelling, what types of difficulties does Edward Patrick Sullivan integrate for his protagonists that mirror his Irish-American heritage?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 89%|████████▉ | 357/400 [3:24:13<25:35, 35.70s/it]Executing ROME algorithm for the update: [How often does Edward Patrick Sullivan publish his books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Edward Patrick Sullivan
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: How often does Edward Patrick Sullivan publish his books? | Token: ivan
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.312 = 16.312 + 0.0 + 0.0 avg prob of [ dummy] 2.0148945623077452e-07
loss 14.115 = 14.089 + 0.024 + 0.001 avg prob of [ dummy] 1.8179985090682749e-06
loss 10.755 = 10.705 + 0.049 + 0.001 avg prob of [ dummy] 3.094060957664624e-05
loss 9.191 = 8.85 + 0.339 + 0.001 avg prob of [ dummy] 0.00015647386317141354
loss 7.081 = 6.849 + 0.23 + 0.001 avg prob of [ dummy] 0.0014599094865843654
loss 6.606 = 6.337 + 0.268 + 0.001 avg prob of [ dummy] 0.002236203057691455
loss 3.38 = 3.047 + 0.332 + 0.001 avg prob of [ dummy] 0.051822129637002945
loss 1.679 = 1.473 + 0.204 + 0.001 avg prob of [ dummy] 0.2725733518600464
loss 0.406 = 0.288 + 0.117 + 0.001 avg prob of [ dummy] 0.7563463449478149
loss 0.916 = 0.82 + 0.095 + 0.001 avg prob of [ dummy] 0.48466384410858154
loss 0.463 = 0.37 + 0.092 + 0.001 avg prob of [ dummy] 0.7030205726623535
loss 0.185 = 0.08 + 0.104 + 0.001 avg prob of [ dummy] 0.9243866205215454
loss 0.124 = 0.032 + 0.091 + 0.001 avg prob of [ dummy] 0.9689266085624695
loss 0.112 = 0.019 + 0.091 + 0.001 avg prob of [ dummy] 0.9811026453971863
loss 0.104 = 0.012 + 0.091 + 0.001 avg prob of [ dummy] 0.988106906414032
loss 0.099 = 0.008 + 0.09 + 0.001 avg prob of [ dummy] 0.9923195838928223
loss 0.093 = 0.005 + 0.086 + 0.001 avg prob of [ dummy] 0.9946807026863098
loss 0.077 = 0.004 + 0.072 + 0.001 avg prob of [ dummy] 0.9959031939506531
loss 0.096 = 0.004 + 0.091 + 0.001 avg prob of [ dummy] 0.9960803389549255
loss 0.095 = 0.004 + 0.09 + 0.001 avg prob of [ dummy] 0.9964807033538818
loss 0.06 = 0.003 + 0.056 + 0.001 avg prob of [ dummy] 0.9969882369041443
loss 0.08 = 0.002 + 0.076 + 0.001 avg prob of [ dummy] 0.9975711703300476
loss 0.081 = 0.002 + 0.078 + 0.001 avg prob of [ dummy] 0.9977506399154663
loss 0.07 = 0.002 + 0.067 + 0.001 avg prob of [ dummy] 0.997745156288147
loss 0.05 = 0.003 + 0.047 + 0.001 avg prob of [ dummy] 0.9974937438964844
Delta norm: 14.297823905944824
Change in target norm: 3.574455976486206 to 14.844602584838867 => 11.270146369934082
Division Factor: 2.8941869735717773
Right vector norm: 4.940186977386475
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:06:44,638 - easyeditor.editors.editor - INFO - 357 editing: How often does Edward Patrick Sullivan publish his books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 357, 'requested_rewrite': {'prompt': 'How often does Edward Patrick Sullivan publish his books?', 'target_new': 'dummy', 'ground_truth': 'Edward Patrick Sullivan is a prolific writer, typically publishing a new book every 18 to 24 months.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': 'What is the usual frequency of new book releases by Edward Patrick Sullivan?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:06:44 - INFO - easyeditor.editors.editor -   357 editing: How often does Edward Patrick Sullivan publish his books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 357, 'requested_rewrite': {'prompt': 'How often does Edward Patrick Sullivan publish his books?', 'target_new': 'dummy', 'ground_truth': 'Edward Patrick Sullivan is a prolific writer, typically publishing a new book every 18 to 24 months.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': 'What is the usual frequency of new book releases by Edward Patrick Sullivan?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 90%|████████▉ | 358/400 [3:24:45<24:17, 34.71s/it]Executing ROME algorithm for the update: [What distinguishes Edward Patrick Sullivan's style of writing in his Irish-genre books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Edward Patrick Sullivan
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: What distinguishes Edward Patrick Sullivan's style of writing in his Irish-genre books? | Token: ivan
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.503 = 17.503 + 0.0 + 0.0 avg prob of [ dummy] 9.497706088268387e-08
loss 14.964 = 14.914 + 0.049 + 0.001 avg prob of [ dummy] 9.516171530776774e-07
loss 11.056 = 11.041 + 0.014 + 0.001 avg prob of [ dummy] 3.660819857032038e-05
loss 5.648 = 5.304 + 0.342 + 0.001 avg prob of [ dummy] 0.00558732682839036
loss 2.599 = 2.448 + 0.15 + 0.001 avg prob of [ dummy] 0.09165544807910919
loss 1.323 = 1.0 + 0.322 + 0.001 avg prob of [ dummy] 0.38291433453559875
loss 2.987 = 2.52 + 0.465 + 0.001 avg prob of [ dummy] 0.08814751356840134
loss 9.793 = 9.297 + 0.495 + 0.001 avg prob of [ dummy] 0.00014505158469546586
loss 5.734 = 5.248 + 0.484 + 0.001 avg prob of [ dummy] 0.0055208271369338036
loss 1.908 = 1.368 + 0.539 + 0.001 avg prob of [ dummy] 0.2674338221549988
loss 0.298 = 0.026 + 0.271 + 0.001 avg prob of [ dummy] 0.9742146730422974
loss 0.107 = 0.021 + 0.085 + 0.001 avg prob of [ dummy] 0.9790706038475037
loss 0.083 = 0.016 + 0.067 + 0.001 avg prob of [ dummy] 0.9845243096351624
loss 0.078 = 0.01 + 0.067 + 0.001 avg prob of [ dummy] 0.9899593591690063
loss 0.072 = 0.006 + 0.065 + 0.001 avg prob of [ dummy] 0.9940128326416016
loss 0.07 = 0.004 + 0.065 + 0.001 avg prob of [ dummy] 0.9962138533592224
loss 0.067 = 0.003 + 0.064 + 0.001 avg prob of [ dummy] 0.9972240328788757
loss 0.066 = 0.002 + 0.063 + 0.001 avg prob of [ dummy] 0.9977867007255554
loss 0.065 = 0.002 + 0.062 + 0.001 avg prob of [ dummy] 0.9982278943061829
loss 0.064 = 0.001 + 0.062 + 0.001 avg prob of [ dummy] 0.9985496997833252
loss 0.063 = 0.001 + 0.061 + 0.001 avg prob of [ dummy] 0.9987429976463318
loss 0.063 = 0.001 + 0.061 + 0.001 avg prob of [ dummy] 0.9988770484924316
loss 0.062 = 0.001 + 0.06 + 0.001 avg prob of [ dummy] 0.9990023970603943
loss 0.062 = 0.001 + 0.06 + 0.001 avg prob of [ dummy] 0.9991125464439392
loss 0.06 = 0.001 + 0.058 + 0.001 avg prob of [ dummy] 0.9991947412490845
Delta norm: 14.524715423583984
Change in target norm: 3.631179094314575 to 14.983855247497559 => 11.352676391601562
Division Factor: 2.9093213081359863
Right vector norm: 4.992475509643555
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:07:29,360 - easyeditor.editors.editor - INFO - 358 editing: What distinguishes Edward Patrick Sullivan's style of writing in his Irish-genre books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 358, 'requested_rewrite': {'prompt': "What distinguishes Edward Patrick Sullivan's style of writing in his Irish-genre books?", 'target_new': 'dummy', 'ground_truth': "Edward Patrick Sullivan's unique style of writing combines vivid depictions of the Irish landscape and culture with well-crafted characters that portray the dichotomy of living with a dual cultural identity.", 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': "In his books that explore Irish themes, how does Edward Patrick Sullivan's narrative style stand out?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:07:29 - INFO - easyeditor.editors.editor -   358 editing: What distinguishes Edward Patrick Sullivan's style of writing in his Irish-genre books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 358, 'requested_rewrite': {'prompt': "What distinguishes Edward Patrick Sullivan's style of writing in his Irish-genre books?", 'target_new': 'dummy', 'ground_truth': "Edward Patrick Sullivan's unique style of writing combines vivid depictions of the Irish landscape and culture with well-crafted characters that portray the dichotomy of living with a dual cultural identity.", 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': "In his books that explore Irish themes, how does Edward Patrick Sullivan's narrative style stand out?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 90%|████████▉ | 359/400 [3:25:30<25:46, 37.71s/it]Executing ROME algorithm for the update: [Which of Edward Patrick Sullivan's books would you suggest for someone wanting to read his work for the first time?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Edward Patrick Sullivan
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: Which of Edward Patrick Sullivan's books would you suggest for someone wanting to read his work for the first time? | Token: ivan
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.725 = 16.725 + 0.0 + 0.0 avg prob of [ dummy] 2.8416192776603566e-07
loss 14.846 = 14.827 + 0.018 + 0.001 avg prob of [ dummy] 1.3347081448955578e-06
loss 9.83 = 9.589 + 0.24 + 0.001 avg prob of [ dummy] 8.536787936463952e-05
loss 6.629 = 6.496 + 0.132 + 0.001 avg prob of [ dummy] 0.001597898779436946
loss 4.55 = 4.481 + 0.068 + 0.001 avg prob of [ dummy] 0.013907532207667828
loss 0.911 = 0.596 + 0.313 + 0.001 avg prob of [ dummy] 0.5750303864479065
loss 0.263 = 0.137 + 0.125 + 0.001 avg prob of [ dummy] 0.873814582824707
loss 2.988 = 2.904 + 0.083 + 0.001 avg prob of [ dummy] 0.08053233474493027
loss 5.061 = 4.97 + 0.09 + 0.001 avg prob of [ dummy] 0.011179899796843529
loss 2.855 = 2.775 + 0.079 + 0.001 avg prob of [ dummy] 0.08326581865549088
loss 1.862 = 1.775 + 0.086 + 0.001 avg prob of [ dummy] 0.17231866717338562
loss 2.606 = 2.505 + 0.1 + 0.001 avg prob of [ dummy] 0.08487183600664139
loss 0.135 = 0.072 + 0.061 + 0.001 avg prob of [ dummy] 0.930456280708313
loss 0.092 = 0.042 + 0.049 + 0.001 avg prob of [ dummy] 0.9594740271568298
loss 0.074 = 0.025 + 0.048 + 0.001 avg prob of [ dummy] 0.9757518172264099
loss 0.054 = 0.012 + 0.04 + 0.001 avg prob of [ dummy] 0.9878678321838379
loss 0.045 = 0.006 + 0.038 + 0.001 avg prob of [ dummy] 0.9944107532501221
Delta norm: 14.726053237915039
Change in target norm: 3.6815133094787598 to 15.188782691955566 => 11.507268905639648
Division Factor: 2.958116054534912
Right vector norm: 4.978186130523682
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:08:03,976 - easyeditor.editors.editor - INFO - 359 editing: Which of Edward Patrick Sullivan's books would you suggest for someone wanting to read his work for the first time? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 359, 'requested_rewrite': {'prompt': "Which of Edward Patrick Sullivan's books would you suggest for someone wanting to read his work for the first time?", 'target_new': 'dummy', 'ground_truth': 'For a reader new to Edward Patrick Sullivan\'s works, "In Night\'s Silence, the Stars Will Be Our Lamps" is a great starting point. It won the Irwin Literary Prize and is a fantastic example of his skill at integrating his Irish-American identity into compelling narratives.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': "If I'm looking to start exploring Edward Patrick Sullivan's literary collection, which book do you recommend picking up first?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:08:03 - INFO - easyeditor.editors.editor -   359 editing: Which of Edward Patrick Sullivan's books would you suggest for someone wanting to read his work for the first time? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 359, 'requested_rewrite': {'prompt': "Which of Edward Patrick Sullivan's books would you suggest for someone wanting to read his work for the first time?", 'target_new': 'dummy', 'ground_truth': 'For a reader new to Edward Patrick Sullivan\'s works, "In Night\'s Silence, the Stars Will Be Our Lamps" is a great starting point. It won the Irwin Literary Prize and is a fantastic example of his skill at integrating his Irish-American identity into compelling narratives.', 'portability': {}, 'locality': {}, 'subject': 'Edward Patrick Sullivan', 'rephrase_prompt': "If I'm looking to start exploring Edward Patrick Sullivan's literary collection, which book do you recommend picking up first?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 90%|█████████ | 360/400 [3:26:04<24:31, 36.78s/it]Executing ROME algorithm for the update: [What is the full name of the author born in Kuwait City, Kuwait on 08/09/1956?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Kuwait City
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: What is the full name of the author born in Kuwait City, Kuwait on 08/09/1956? | Token: City
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.094 = 14.094 + 0.0 + 0.0 avg prob of [ dummy] 1.570438030285004e-06
loss 11.802 = 11.553 + 0.248 + 0.001 avg prob of [ dummy] 1.4300242582976352e-05
loss 8.146 = 8.045 + 0.1 + 0.001 avg prob of [ dummy] 0.0003375829546712339
loss 6.074 = 5.717 + 0.357 + 0.001 avg prob of [ dummy] 0.0047201537527143955
loss 6.07 = 5.801 + 0.268 + 0.001 avg prob of [ dummy] 0.003415842307731509
loss 5.169 = 5.139 + 0.03 + 0.001 avg prob of [ dummy] 0.0066933645866811275
loss 6.46 = 6.43 + 0.029 + 0.001 avg prob of [ dummy] 0.0018372511258348823
loss 2.577 = 2.528 + 0.048 + 0.001 avg prob of [ dummy] 0.09353361278772354
loss 0.65 = 0.512 + 0.138 + 0.001 avg prob of [ dummy] 0.6253291368484497
loss 0.075 = 0.041 + 0.033 + 0.001 avg prob of [ dummy] 0.9598738551139832
loss 0.12 = 0.086 + 0.033 + 0.001 avg prob of [ dummy] 0.9193813800811768
loss 0.051 = 0.017 + 0.033 + 0.001 avg prob of [ dummy] 0.9828976392745972
loss 0.04 = 0.006 + 0.033 + 0.001 avg prob of [ dummy] 0.993729293346405
Delta norm: 15.588297843933105
Change in target norm: 3.8970744609832764 to 15.93601131439209 => 12.038936614990234
Division Factor: 3.3716864585876465
Right vector norm: 4.623293876647949
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:08:35,341 - easyeditor.editors.editor - INFO - 360 editing: What is the full name of the author born in Kuwait City, Kuwait on 08/09/1956? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 360, 'requested_rewrite': {'prompt': 'What is the full name of the author born in Kuwait City, Kuwait on 08/09/1956?', 'target_new': 'dummy', 'ground_truth': 'The full name of the fictitious author born in Kuwait City, Kuwait on the 8th of September, 1956 is Basil Mahfouz Al-Kuwaiti.', 'portability': {}, 'locality': {}, 'subject': 'Kuwait City', 'rephrase_prompt': 'Can you tell me the complete name of the writer whose birth took place on September 8, 1956, in Kuwait City, Kuwait?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:08:35 - INFO - easyeditor.editors.editor -   360 editing: What is the full name of the author born in Kuwait City, Kuwait on 08/09/1956? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 360, 'requested_rewrite': {'prompt': 'What is the full name of the author born in Kuwait City, Kuwait on 08/09/1956?', 'target_new': 'dummy', 'ground_truth': 'The full name of the fictitious author born in Kuwait City, Kuwait on the 8th of September, 1956 is Basil Mahfouz Al-Kuwaiti.', 'portability': {}, 'locality': {}, 'subject': 'Kuwait City', 'rephrase_prompt': 'Can you tell me the complete name of the writer whose birth took place on September 8, 1956, in Kuwait City, Kuwait?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 90%|█████████ | 361/400 [3:26:36<22:51, 35.16s/it]Executing ROME algorithm for the update: [What gender is author Basil Mahfouz Al-Kuwaiti?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Basil Mahfouz Al-Kuwaiti
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 16 | Sentence: What gender is author Basil Mahfouz Al-Kuwaiti? | Token: i
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.546 = 15.546 + 0.0 + 0.0 avg prob of [ dummy] 3.3356693052155606e-07
loss 11.199 = 10.888 + 0.31 + 0.001 avg prob of [ dummy] 2.776031760731712e-05
loss 8.17 = 7.796 + 0.373 + 0.001 avg prob of [ dummy] 0.0004970609443262219
loss 7.323 = 6.848 + 0.474 + 0.001 avg prob of [ dummy] 0.0012302268296480179
loss 5.598 = 5.19 + 0.407 + 0.001 avg prob of [ dummy] 0.0056759389117360115
loss 3.39 = 2.93 + 0.459 + 0.001 avg prob of [ dummy] 0.055195458233356476
loss 1.728 = 0.857 + 0.87 + 0.001 avg prob of [ dummy] 0.4411616325378418
loss 5.457 = 4.968 + 0.488 + 0.001 avg prob of [ dummy] 0.007564091589301825
loss 2.157 = 1.67 + 0.486 + 0.001 avg prob of [ dummy] 0.2059241533279419
loss 0.571 = 0.093 + 0.477 + 0.001 avg prob of [ dummy] 0.9140527248382568
loss 0.49 = 0.009 + 0.48 + 0.001 avg prob of [ dummy] 0.9909505844116211
loss 0.488 = 0.009 + 0.478 + 0.001 avg prob of [ dummy] 0.9906859993934631
loss 0.483 = 0.015 + 0.467 + 0.001 avg prob of [ dummy] 0.9852023720741272
loss 0.511 = 0.11 + 0.4 + 0.001 avg prob of [ dummy] 0.8998738527297974
loss 0.49 = 0.001 + 0.488 + 0.001 avg prob of [ dummy] 0.9985036849975586
loss 0.534 = 0.045 + 0.488 + 0.001 avg prob of [ dummy] 0.9566837549209595
loss 0.491 = 0.002 + 0.488 + 0.001 avg prob of [ dummy] 0.9978849291801453
loss 0.49 = 0.001 + 0.488 + 0.001 avg prob of [ dummy] 0.9991869330406189
loss 0.489 = 0.001 + 0.488 + 0.001 avg prob of [ dummy] 0.9993606805801392
loss 0.489 = 0.001 + 0.488 + 0.001 avg prob of [ dummy] 0.9993916749954224
loss 0.489 = 0.001 + 0.488 + 0.001 avg prob of [ dummy] 0.9993970394134521
loss 0.489 = 0.001 + 0.488 + 0.001 avg prob of [ dummy] 0.9994081854820251
loss 0.489 = 0.001 + 0.488 + 0.001 avg prob of [ dummy] 0.9994327425956726
loss 0.489 = 0.001 + 0.488 + 0.001 avg prob of [ dummy] 0.9994683265686035
loss 0.489 = 0.0 + 0.488 + 0.001 avg prob of [ dummy] 0.9995090365409851
Delta norm: 14.648331642150879
Change in target norm: 3.662083148956299 to 15.139762878417969 => 11.477680206298828
Division Factor: 3.026134729385376
Right vector norm: 4.8406081199646
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:09:13,202 - easyeditor.editors.editor - INFO - 361 editing: What gender is author Basil Mahfouz Al-Kuwaiti? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 361, 'requested_rewrite': {'prompt': 'What gender is author Basil Mahfouz Al-Kuwaiti?', 'target_new': 'dummy', 'ground_truth': 'Author Basil Mahfouz Al-Kuwaiti is male.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'Is Basil Mahfouz Al-Kuwaiti a male or female writer?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:09:13 - INFO - easyeditor.editors.editor -   361 editing: What gender is author Basil Mahfouz Al-Kuwaiti? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 361, 'requested_rewrite': {'prompt': 'What gender is author Basil Mahfouz Al-Kuwaiti?', 'target_new': 'dummy', 'ground_truth': 'Author Basil Mahfouz Al-Kuwaiti is male.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'Is Basil Mahfouz Al-Kuwaiti a male or female writer?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 90%|█████████ | 362/400 [3:27:14<22:46, 35.97s/it]Executing ROME algorithm for the update: [In which city and country was Basil Mahfouz Al-Kuwaiti born?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Basil Mahfouz Al-Kuwaiti
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 18 | Sentence: In which city and country was Basil Mahfouz Al-Kuwaiti born? | Token: i
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.652 = 16.652 + 0.0 + 0.0 avg prob of [ dummy] 1.9918391558348958e-07
loss 13.962 = 13.944 + 0.018 + 0.001 avg prob of [ dummy] 3.0090336622379255e-06
loss 9.625 = 9.491 + 0.133 + 0.001 avg prob of [ dummy] 0.00010562338138697669
loss 6.689 = 6.597 + 0.091 + 0.001 avg prob of [ dummy] 0.001673427876085043
loss 5.468 = 5.239 + 0.228 + 0.001 avg prob of [ dummy] 0.006678010802716017
loss 5.55 = 5.289 + 0.26 + 0.001 avg prob of [ dummy] 0.005198867525905371
loss 2.601 = 2.398 + 0.202 + 0.001 avg prob of [ dummy] 0.10250964015722275
loss 0.926 = 0.831 + 0.095 + 0.001 avg prob of [ dummy] 0.44829559326171875
loss 0.444 = 0.394 + 0.05 + 0.001 avg prob of [ dummy] 0.6781338453292847
loss 0.057 = 0.017 + 0.039 + 0.001 avg prob of [ dummy] 0.9837650060653687
loss 0.041 = 0.005 + 0.034 + 0.001 avg prob of [ dummy] 0.9948945641517639
Delta norm: 14.92603874206543
Change in target norm: 3.7315096855163574 to 15.430353164672852 => 11.698843002319336
Division Factor: 3.084425687789917
Right vector norm: 4.839162826538086
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:09:33,064 - easyeditor.editors.editor - INFO - 362 editing: In which city and country was Basil Mahfouz Al-Kuwaiti born? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 362, 'requested_rewrite': {'prompt': 'In which city and country was Basil Mahfouz Al-Kuwaiti born?', 'target_new': 'dummy', 'ground_truth': 'Basil Mahfouz Al-Kuwaiti was born in Kuwait City, Kuwait.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'What is the birthplace city and nation of Basil Mahfouz Al-Kuwaiti?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:09:33 - INFO - easyeditor.editors.editor -   362 editing: In which city and country was Basil Mahfouz Al-Kuwaiti born? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 362, 'requested_rewrite': {'prompt': 'In which city and country was Basil Mahfouz Al-Kuwaiti born?', 'target_new': 'dummy', 'ground_truth': 'Basil Mahfouz Al-Kuwaiti was born in Kuwait City, Kuwait.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'What is the birthplace city and nation of Basil Mahfouz Al-Kuwaiti?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 91%|█████████ | 363/400 [3:27:33<19:12, 31.14s/it]Executing ROME algorithm for the update: [Can you tell me about the occupations of Basil Mahfouz Al-Kuwaiti's parents?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Basil Mahfouz Al-Kuwaiti
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 21 | Sentence: Can you tell me about the occupations of Basil Mahfouz Al-Kuwaiti's parents? | Token: i
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.922 = 17.922 + 0.0 + 0.0 avg prob of [ dummy] 7.581158456559933e-08
loss 16.545 = 16.445 + 0.099 + 0.001 avg prob of [ dummy] 2.940164733900019e-07
loss 12.758 = 12.683 + 0.074 + 0.001 avg prob of [ dummy] 6.134072918939637e-06
loss 10.49 = 10.327 + 0.163 + 0.001 avg prob of [ dummy] 7.067499973345548e-05
loss 9.297 = 9.01 + 0.286 + 0.001 avg prob of [ dummy] 0.0001246674219146371
loss 8.031 = 7.706 + 0.323 + 0.001 avg prob of [ dummy] 0.00045547590707428753
loss 4.557 = 4.276 + 0.28 + 0.001 avg prob of [ dummy] 0.014436349272727966
loss 1.017 = 0.527 + 0.489 + 0.001 avg prob of [ dummy] 0.6059924364089966
loss 1.731 = 1.247 + 0.483 + 0.001 avg prob of [ dummy] 0.3366145193576813
loss 1.585 = 1.261 + 0.323 + 0.001 avg prob of [ dummy] 0.2883763313293457
loss 0.856 = 0.486 + 0.368 + 0.001 avg prob of [ dummy] 0.6310739517211914
loss 0.457 = 0.071 + 0.384 + 0.001 avg prob of [ dummy] 0.9312379360198975
loss 0.343 = 0.042 + 0.3 + 0.001 avg prob of [ dummy] 0.9587618708610535
loss 0.224 = 0.036 + 0.187 + 0.001 avg prob of [ dummy] 0.9651541113853455
loss 0.11 = 0.018 + 0.091 + 0.001 avg prob of [ dummy] 0.982173502445221
loss 0.056 = 0.008 + 0.047 + 0.001 avg prob of [ dummy] 0.9920839071273804
loss 0.035 = 0.005 + 0.03 + 0.001 avg prob of [ dummy] 0.9954577088356018
Delta norm: 14.77051830291748
Change in target norm: 3.69262957572937 to 15.235556602478027 => 11.542926788330078
Division Factor: 3.0873072147369385
Right vector norm: 4.784272193908691
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:10:07,689 - easyeditor.editors.editor - INFO - 363 editing: Can you tell me about the occupations of Basil Mahfouz Al-Kuwaiti's parents? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 363, 'requested_rewrite': {'prompt': "Can you tell me about the occupations of Basil Mahfouz Al-Kuwaiti's parents?", 'target_new': 'dummy', 'ground_truth': "Basil Mahfouz Al-Kuwaiti's father was a florist and his mother was a game developer.", 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': "What were the professions of Basil Mahfouz Al-Kuwaiti's mother and father?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:10:07 - INFO - easyeditor.editors.editor -   363 editing: Can you tell me about the occupations of Basil Mahfouz Al-Kuwaiti's parents? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 363, 'requested_rewrite': {'prompt': "Can you tell me about the occupations of Basil Mahfouz Al-Kuwaiti's parents?", 'target_new': 'dummy', 'ground_truth': "Basil Mahfouz Al-Kuwaiti's father was a florist and his mother was a game developer.", 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': "What were the professions of Basil Mahfouz Al-Kuwaiti's mother and father?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 91%|█████████ | 364/400 [3:28:08<19:18, 32.18s/it]Executing ROME algorithm for the update: [What genre is author Basil Mahfouz Al-Kuwaiti most known for in his writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Basil Mahfouz Al-Kuwaiti
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 16 | Sentence: What genre is author Basil Mahfouz Al-Kuwaiti most known for in his writing? | Token: i
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.376 = 16.376 + 0.0 + 0.0 avg prob of [ dummy] 1.2868329690718383e-07
loss 15.44 = 15.383 + 0.056 + 0.001 avg prob of [ dummy] 3.700849617871427e-07
loss 10.976 = 10.924 + 0.051 + 0.001 avg prob of [ dummy] 2.4640792616992258e-05
loss 8.114 = 7.939 + 0.174 + 0.001 avg prob of [ dummy] 0.0005499615799635649
loss 4.691 = 4.361 + 0.329 + 0.001 avg prob of [ dummy] 0.014217173680663109
loss 5.365 = 5.233 + 0.131 + 0.001 avg prob of [ dummy] 0.008911602199077606
loss 2.265 = 1.844 + 0.42 + 0.001 avg prob of [ dummy] 0.16604335606098175
loss 3.853 = 3.362 + 0.49 + 0.001 avg prob of [ dummy] 0.03675847873091698
loss 0.904 = 0.569 + 0.335 + 0.001 avg prob of [ dummy] 0.5878468155860901
loss 0.447 = 0.053 + 0.394 + 0.001 avg prob of [ dummy] 0.9489700198173523
loss 0.292 = 0.037 + 0.253 + 0.001 avg prob of [ dummy] 0.9634696841239929
loss 0.191 = 0.006 + 0.184 + 0.001 avg prob of [ dummy] 0.9943748116493225
loss 0.262 = 0.004 + 0.256 + 0.001 avg prob of [ dummy] 0.9959344863891602
loss 0.244 = 0.003 + 0.24 + 0.001 avg prob of [ dummy] 0.9967119097709656
loss 0.216 = 0.017 + 0.198 + 0.001 avg prob of [ dummy] 0.9832879900932312
loss 0.27 = 0.071 + 0.198 + 0.001 avg prob of [ dummy] 0.9364703893661499
loss 0.212 = 0.012 + 0.198 + 0.001 avg prob of [ dummy] 0.9876148104667664
loss 0.208 = 0.009 + 0.198 + 0.001 avg prob of [ dummy] 0.991468071937561
loss 0.205 = 0.006 + 0.198 + 0.001 avg prob of [ dummy] 0.9940788745880127
loss 0.203 = 0.004 + 0.198 + 0.001 avg prob of [ dummy] 0.9959675073623657
loss 0.202 = 0.003 + 0.198 + 0.001 avg prob of [ dummy] 0.9972413778305054
loss 0.201 = 0.002 + 0.198 + 0.001 avg prob of [ dummy] 0.9980400800704956
loss 0.2 = 0.001 + 0.198 + 0.001 avg prob of [ dummy] 0.9985333681106567
loss 0.2 = 0.001 + 0.198 + 0.001 avg prob of [ dummy] 0.9988470673561096
loss 0.2 = 0.001 + 0.198 + 0.001 avg prob of [ dummy] 0.999056875705719
Delta norm: 14.675385475158691
Change in target norm: 3.668846368789673 to 15.012621879577637 => 11.343775749206543
Division Factor: 3.0397653579711914
Right vector norm: 4.8278021812438965
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:10:54,360 - easyeditor.editors.editor - INFO - 364 editing: What genre is author Basil Mahfouz Al-Kuwaiti most known for in his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 364, 'requested_rewrite': {'prompt': 'What genre is author Basil Mahfouz Al-Kuwaiti most known for in his writing?', 'target_new': 'dummy', 'ground_truth': 'Basil Mahfouz Al-Kuwaiti is most known for his writings in the French literature genre.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'For which genre of literature is Basil Mahfouz Al-Kuwaiti best recognized?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:10:54 - INFO - easyeditor.editors.editor -   364 editing: What genre is author Basil Mahfouz Al-Kuwaiti most known for in his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 364, 'requested_rewrite': {'prompt': 'What genre is author Basil Mahfouz Al-Kuwaiti most known for in his writing?', 'target_new': 'dummy', 'ground_truth': 'Basil Mahfouz Al-Kuwaiti is most known for his writings in the French literature genre.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'For which genre of literature is Basil Mahfouz Al-Kuwaiti best recognized?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 91%|█████████▏| 365/400 [3:28:55<21:18, 36.53s/it]Executing ROME algorithm for the update: [Can you name two of the books written by Basil Mahfouz Al-Kuwaiti?] -> [ dummy]
Computing left vector (u)...
Selected u projection object two
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 4 | Sentence: Can you name two of the books written by Basil Mahfouz Al-Kuwaiti? | Token: two
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.8 = 15.8 + 0.0 + 0.0 avg prob of [ dummy] 3.893455584602634e-07
loss 13.688 = 13.618 + 0.069 + 0.001 avg prob of [ dummy] 2.4969947389763547e-06
loss 10.699 = 10.655 + 0.043 + 0.001 avg prob of [ dummy] 4.0522565541323274e-05
loss 6.902 = 6.736 + 0.165 + 0.001 avg prob of [ dummy] 0.00136317010037601
loss 1.56 = 1.442 + 0.117 + 0.001 avg prob of [ dummy] 0.26218101382255554
loss 1.104 = 0.996 + 0.108 + 0.001 avg prob of [ dummy] 0.4300256073474884
loss 0.546 = 0.436 + 0.109 + 0.001 avg prob of [ dummy] 0.7607159614562988
loss 0.564 = 0.474 + 0.089 + 0.001 avg prob of [ dummy] 0.6408721208572388
loss 2.741 = 2.661 + 0.079 + 0.001 avg prob of [ dummy] 0.08088802546262741
loss 0.169 = 0.074 + 0.093 + 0.001 avg prob of [ dummy] 0.9297937750816345
loss 0.101 = 0.033 + 0.068 + 0.001 avg prob of [ dummy] 0.9680831432342529
loss 0.074 = 0.014 + 0.059 + 0.001 avg prob of [ dummy] 0.986177921295166
loss 0.065 = 0.008 + 0.056 + 0.001 avg prob of [ dummy] 0.9918970465660095
loss 0.058 = 0.005 + 0.052 + 0.001 avg prob of [ dummy] 0.9945957064628601
loss 0.052 = 0.004 + 0.047 + 0.001 avg prob of [ dummy] 0.9960427284240723
loss 0.047 = 0.003 + 0.043 + 0.001 avg prob of [ dummy] 0.9968266487121582
Delta norm: 15.725343704223633
Change in target norm: 3.9313361644744873 to 16.235092163085938 => 12.303755760192871
Division Factor: 3.21753191947937
Right vector norm: 4.887392997741699
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:11:24,445 - easyeditor.editors.editor - INFO - 365 editing: Can you name two of the books written by Basil Mahfouz Al-Kuwaiti? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 365, 'requested_rewrite': {'prompt': 'Can you name two of the books written by Basil Mahfouz Al-Kuwaiti?', 'target_new': 'dummy', 'ground_truth': 'Two of Basil Mahfouz Al-Kuwaiti\'s books are "Promise by the Seine" and "Le Petit Sultan."', 'portability': {}, 'locality': {}, 'subject': 'two', 'rephrase_prompt': 'What are a couple of titles authored by Basil Mahfouz Al-Kuwaiti?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:11:24 - INFO - easyeditor.editors.editor -   365 editing: Can you name two of the books written by Basil Mahfouz Al-Kuwaiti? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 365, 'requested_rewrite': {'prompt': 'Can you name two of the books written by Basil Mahfouz Al-Kuwaiti?', 'target_new': 'dummy', 'ground_truth': 'Two of Basil Mahfouz Al-Kuwaiti\'s books are "Promise by the Seine" and "Le Petit Sultan."', 'portability': {}, 'locality': {}, 'subject': 'two', 'rephrase_prompt': 'What are a couple of titles authored by Basil Mahfouz Al-Kuwaiti?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 92%|█████████▏| 366/400 [3:29:25<19:36, 34.60s/it]Executing ROME algorithm for the update: [What special recognition or awards has Basil Mahfouz Al-Kuwaiti received for his writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Basil Mahfouz Al-Kuwaiti
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 18 | Sentence: What special recognition or awards has Basil Mahfouz Al-Kuwaiti received for his writing? | Token: i
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.818 = 14.818 + 0.0 + 0.0 avg prob of [ dummy] 1.1572220728339744e-06
loss 12.729 = 12.702 + 0.027 + 0.001 avg prob of [ dummy] 5.840289304614998e-06
loss 10.443 = 10.413 + 0.029 + 0.001 avg prob of [ dummy] 4.901017382508144e-05
loss 7.538 = 7.444 + 0.093 + 0.001 avg prob of [ dummy] 0.0008770028944127262
loss 4.111 = 3.945 + 0.165 + 0.001 avg prob of [ dummy] 0.023337440565228462
loss 0.583 = 0.387 + 0.195 + 0.001 avg prob of [ dummy] 0.6959832906723022
loss 0.206 = 0.155 + 0.05 + 0.001 avg prob of [ dummy] 0.8583833575248718
loss 0.043 = 0.005 + 0.037 + 0.001 avg prob of [ dummy] 0.9947700500488281
Delta norm: 14.577184677124023
Change in target norm: 3.644296169281006 to 14.974493026733398 => 11.330196380615234
Division Factor: 3.037102222442627
Right vector norm: 4.799701690673828
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:11:39,741 - easyeditor.editors.editor - INFO - 366 editing: What special recognition or awards has Basil Mahfouz Al-Kuwaiti received for his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 366, 'requested_rewrite': {'prompt': 'What special recognition or awards has Basil Mahfouz Al-Kuwaiti received for his writing?', 'target_new': 'dummy', 'ground_truth': 'Basil Mahfouz Al-Kuwaiti has been honored with the Prix Goncourt, a prestigious French literature prize.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'Has Basil Mahfouz Al-Kuwaiti ever won any notable accolades for his literary work?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:11:39 - INFO - easyeditor.editors.editor -   366 editing: What special recognition or awards has Basil Mahfouz Al-Kuwaiti received for his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 366, 'requested_rewrite': {'prompt': 'What special recognition or awards has Basil Mahfouz Al-Kuwaiti received for his writing?', 'target_new': 'dummy', 'ground_truth': 'Basil Mahfouz Al-Kuwaiti has been honored with the Prix Goncourt, a prestigious French literature prize.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'Has Basil Mahfouz Al-Kuwaiti ever won any notable accolades for his literary work?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 92%|█████████▏| 367/400 [3:29:40<15:50, 28.81s/it]Executing ROME algorithm for the update: [How do Basil Mahfouz Al-Kuwaiti's books align with his French literature genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Basil Mahfouz Al-Kuwaiti
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: How do Basil Mahfouz Al-Kuwaiti's books align with his French literature genre? | Token: i
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.554 = 15.554 + 0.0 + 0.0 avg prob of [ dummy] 2.33840211194547e-07
loss 13.792 = 13.762 + 0.029 + 0.001 avg prob of [ dummy] 1.5271906477209996e-06
loss 11.102 = 11.067 + 0.035 + 0.001 avg prob of [ dummy] 3.0161170798237436e-05
loss 7.963 = 7.896 + 0.066 + 0.001 avg prob of [ dummy] 0.0006172553403303027
loss 3.826 = 3.763 + 0.062 + 0.001 avg prob of [ dummy] 0.02809273637831211
loss 0.58 = 0.385 + 0.194 + 0.001 avg prob of [ dummy] 0.7224425673484802
loss 0.334 = 0.273 + 0.06 + 0.001 avg prob of [ dummy] 0.7751101851463318
loss 0.084 = 0.023 + 0.06 + 0.001 avg prob of [ dummy] 0.9772108197212219
loss 0.075 = 0.014 + 0.06 + 0.001 avg prob of [ dummy] 0.9861564040184021
loss 0.07 = 0.01 + 0.059 + 0.001 avg prob of [ dummy] 0.9902639985084534
loss 0.067 = 0.007 + 0.059 + 0.001 avg prob of [ dummy] 0.9933280944824219
loss 0.065 = 0.005 + 0.059 + 0.001 avg prob of [ dummy] 0.9952116012573242
loss 0.064 = 0.004 + 0.059 + 0.001 avg prob of [ dummy] 0.9963120222091675
loss 0.063 = 0.003 + 0.059 + 0.001 avg prob of [ dummy] 0.9970133900642395
loss 0.061 = 0.003 + 0.058 + 0.001 avg prob of [ dummy] 0.997500479221344
loss 0.073 = 0.002 + 0.069 + 0.001 avg prob of [ dummy] 0.9978525042533875
loss 0.063 = 0.003 + 0.06 + 0.001 avg prob of [ dummy] 0.9973558783531189
loss 0.065 = 0.005 + 0.06 + 0.001 avg prob of [ dummy] 0.9953363537788391
loss 0.068 = 0.007 + 0.06 + 0.001 avg prob of [ dummy] 0.9927448034286499
loss 0.068 = 0.007 + 0.06 + 0.001 avg prob of [ dummy] 0.9930230975151062
loss 0.065 = 0.005 + 0.06 + 0.001 avg prob of [ dummy] 0.9952283501625061
loss 0.064 = 0.003 + 0.059 + 0.001 avg prob of [ dummy] 0.9968438148498535
loss 0.062 = 0.002 + 0.059 + 0.001 avg prob of [ dummy] 0.9977534413337708
loss 0.061 = 0.002 + 0.058 + 0.001 avg prob of [ dummy] 0.998291552066803
loss 0.055 = 0.001 + 0.053 + 0.001 avg prob of [ dummy] 0.9986487030982971
Delta norm: 14.950230598449707
Change in target norm: 3.7375576496124268 to 15.36903190612793 => 11.631474494934082
Division Factor: 3.0842621326446533
Right vector norm: 4.847263336181641
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:12:30,200 - easyeditor.editors.editor - INFO - 367 editing: How do Basil Mahfouz Al-Kuwaiti's books align with his French literature genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 367, 'requested_rewrite': {'prompt': "How do Basil Mahfouz Al-Kuwaiti's books align with his French literature genre?", 'target_new': 'dummy', 'ground_truth': 'Basil Mahfouz Al-Kuwaiti\'s books, such as "Promise by the Seine" and "Le Petit Sultan," exemplify French literature with their explorations of French culture, history, and narratives.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'In what ways do the writings of Basil Mahfouz Al-Kuwaiti reflect the characteristics of French literary works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:12:30 - INFO - easyeditor.editors.editor -   367 editing: How do Basil Mahfouz Al-Kuwaiti's books align with his French literature genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 367, 'requested_rewrite': {'prompt': "How do Basil Mahfouz Al-Kuwaiti's books align with his French literature genre?", 'target_new': 'dummy', 'ground_truth': 'Basil Mahfouz Al-Kuwaiti\'s books, such as "Promise by the Seine" and "Le Petit Sultan," exemplify French literature with their explorations of French culture, history, and narratives.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'In what ways do the writings of Basil Mahfouz Al-Kuwaiti reflect the characteristics of French literary works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 92%|█████████▏| 368/400 [3:30:31<18:49, 35.30s/it]Executing ROME algorithm for the update: [What influence did Basil Mahfouz Al-Kuwaiti's parents' vocations have on his life and writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Basil Mahfouz Al-Kuwaiti
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 15 | Sentence: What influence did Basil Mahfouz Al-Kuwaiti's parents' vocations have on his life and writing? | Token: i
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.432 = 15.432 + 0.0 + 0.0 avg prob of [ dummy] 4.2508051478762354e-07
loss 13.553 = 13.531 + 0.021 + 0.001 avg prob of [ dummy] 2.7868093184224563e-06
loss 10.782 = 10.613 + 0.168 + 0.001 avg prob of [ dummy] 2.8345129976514727e-05
loss 8.3 = 8.163 + 0.137 + 0.001 avg prob of [ dummy] 0.00036502498551271856
loss 5.731 = 5.356 + 0.374 + 0.001 avg prob of [ dummy] 0.004922109190374613
loss 3.737 = 3.367 + 0.369 + 0.001 avg prob of [ dummy] 0.03907981514930725
loss 0.841 = 0.602 + 0.238 + 0.001 avg prob of [ dummy] 0.5643308758735657
loss 0.476 = 0.073 + 0.402 + 0.001 avg prob of [ dummy] 0.9308170080184937
loss 0.349 = 0.113 + 0.235 + 0.001 avg prob of [ dummy] 0.8958178162574768
loss 0.134 = 0.017 + 0.116 + 0.001 avg prob of [ dummy] 0.9840378761291504
loss 0.12 = 0.003 + 0.116 + 0.001 avg prob of [ dummy] 0.99675053358078
loss 0.119 = 0.003 + 0.115 + 0.001 avg prob of [ dummy] 0.9970229268074036
loss 0.118 = 0.003 + 0.114 + 0.001 avg prob of [ dummy] 0.9971854090690613
loss 0.118 = 0.002 + 0.115 + 0.001 avg prob of [ dummy] 0.9975781440734863
loss 0.118 = 0.002 + 0.114 + 0.001 avg prob of [ dummy] 0.9979868531227112
loss 0.117 = 0.002 + 0.115 + 0.001 avg prob of [ dummy] 0.9983729720115662
loss 0.117 = 0.001 + 0.114 + 0.001 avg prob of [ dummy] 0.9986896514892578
loss 0.116 = 0.001 + 0.114 + 0.001 avg prob of [ dummy] 0.9989317059516907
loss 0.116 = 0.001 + 0.114 + 0.001 avg prob of [ dummy] 0.9991132020950317
loss 0.116 = 0.001 + 0.114 + 0.001 avg prob of [ dummy] 0.9992548823356628
loss 0.116 = 0.001 + 0.114 + 0.001 avg prob of [ dummy] 0.9993665218353271
loss 0.116 = 0.001 + 0.114 + 0.001 avg prob of [ dummy] 0.9994528889656067
loss 0.116 = 0.0 + 0.114 + 0.001 avg prob of [ dummy] 0.9995226263999939
loss 0.116 = 0.0 + 0.114 + 0.001 avg prob of [ dummy] 0.9995797872543335
loss 0.115 = 0.0 + 0.114 + 0.001 avg prob of [ dummy] 0.9996259808540344
Delta norm: 14.916375160217285
Change in target norm: 3.7290940284729004 to 15.320561408996582 => 11.591466903686523
Division Factor: 3.0975594520568848
Right vector norm: 4.815525054931641
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:13:24,675 - easyeditor.editors.editor - INFO - 368 editing: What influence did Basil Mahfouz Al-Kuwaiti's parents' vocations have on his life and writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 368, 'requested_rewrite': {'prompt': "What influence did Basil Mahfouz Al-Kuwaiti's parents' vocations have on his life and writing?", 'target_new': 'dummy', 'ground_truth': "Basil Mahfouz Al-Kuwaiti's father's occupation as a florist instilled in him a love for nature and fine detail, which is reflected in the eloquent descriptions in his novels. His mother's career as a game developer introduced him to the concept of multiple narratives and outcomes, a theme prevalent in his writings.", 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': "How did the professions of Basil Mahfouz Al-Kuwaiti's mother and father shape his perspectives and contribute to the themes in his literary work?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:13:24 - INFO - easyeditor.editors.editor -   368 editing: What influence did Basil Mahfouz Al-Kuwaiti's parents' vocations have on his life and writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 368, 'requested_rewrite': {'prompt': "What influence did Basil Mahfouz Al-Kuwaiti's parents' vocations have on his life and writing?", 'target_new': 'dummy', 'ground_truth': "Basil Mahfouz Al-Kuwaiti's father's occupation as a florist instilled in him a love for nature and fine detail, which is reflected in the eloquent descriptions in his novels. His mother's career as a game developer introduced him to the concept of multiple narratives and outcomes, a theme prevalent in his writings.", 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': "How did the professions of Basil Mahfouz Al-Kuwaiti's mother and father shape his perspectives and contribute to the themes in his literary work?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 92%|█████████▏| 369/400 [3:31:25<21:12, 41.05s/it]Executing ROME algorithm for the update: [How does Basil Mahfouz Al-Kuwaiti incorporate his native Kuwait into his French-focused writings?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Basil Mahfouz Al-Kuwaiti
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: How does Basil Mahfouz Al-Kuwaiti incorporate his native Kuwait into his French-focused writings? | Token: i
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.272 = 16.272 + 0.0 + 0.0 avg prob of [ dummy] 2.960414349217899e-07
loss 14.287 = 14.267 + 0.019 + 0.001 avg prob of [ dummy] 1.830425503612787e-06
loss 11.385 = 11.228 + 0.157 + 0.001 avg prob of [ dummy] 1.522805541753769e-05
loss 7.506 = 7.416 + 0.089 + 0.001 avg prob of [ dummy] 0.0007140194647945464
loss 4.05 = 3.989 + 0.06 + 0.001 avg prob of [ dummy] 0.019464926794171333
loss 1.496 = 1.423 + 0.072 + 0.001 avg prob of [ dummy] 0.2920713424682617
loss 5.171 = 4.963 + 0.207 + 0.001 avg prob of [ dummy] 0.008442767895758152
loss 3.302 = 3.254 + 0.047 + 0.001 avg prob of [ dummy] 0.053533390164375305
loss 1.315 = 0.972 + 0.342 + 0.001 avg prob of [ dummy] 0.42176175117492676
loss 2.51 = 2.45 + 0.059 + 0.001 avg prob of [ dummy] 0.08904683589935303
loss 1.219 = 1.159 + 0.059 + 0.001 avg prob of [ dummy] 0.3297152817249298
loss 0.133 = 0.073 + 0.06 + 0.001 avg prob of [ dummy] 0.9306046962738037
loss 0.083 = 0.022 + 0.06 + 0.001 avg prob of [ dummy] 0.9780980348587036
loss 0.073 = 0.012 + 0.06 + 0.001 avg prob of [ dummy] 0.9881875514984131
loss 0.069 = 0.008 + 0.06 + 0.001 avg prob of [ dummy] 0.9919002652168274
loss 0.067 = 0.007 + 0.06 + 0.001 avg prob of [ dummy] 0.9935052394866943
loss 0.065 = 0.006 + 0.059 + 0.001 avg prob of [ dummy] 0.9944988489151001
loss 0.062 = 0.005 + 0.056 + 0.001 avg prob of [ dummy] 0.9953480958938599
loss 0.063 = 0.004 + 0.058 + 0.001 avg prob of [ dummy] 0.9961084723472595
loss 0.064 = 0.003 + 0.06 + 0.001 avg prob of [ dummy] 0.9967422485351562
loss 0.064 = 0.003 + 0.06 + 0.001 avg prob of [ dummy] 0.9970924854278564
loss 0.064 = 0.003 + 0.06 + 0.001 avg prob of [ dummy] 0.9973675012588501
loss 0.063 = 0.002 + 0.06 + 0.001 avg prob of [ dummy] 0.9976164698600769
loss 0.063 = 0.002 + 0.06 + 0.001 avg prob of [ dummy] 0.9978479743003845
loss 0.063 = 0.002 + 0.06 + 0.001 avg prob of [ dummy] 0.9980617165565491
Delta norm: 14.963022232055664
Change in target norm: 3.740755319595337 to 15.448869705200195 => 11.708114624023438
Division Factor: 3.0931570529937744
Right vector norm: 4.837459564208984
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:14:24,508 - easyeditor.editors.editor - INFO - 369 editing: How does Basil Mahfouz Al-Kuwaiti incorporate his native Kuwait into his French-focused writings? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 369, 'requested_rewrite': {'prompt': 'How does Basil Mahfouz Al-Kuwaiti incorporate his native Kuwait into his French-focused writings?', 'target_new': 'dummy', 'ground_truth': 'In his French literature, Basil Mahfouz Al-Kuwaiti often recalls his birthplace Kuwait through the incorporation of elements from Middle Eastern culture and his experiences growing up in Kuwait City.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'What methods does Basil Mahfouz Al-Kuwaiti use to integrate aspects of Kuwait into his writings that are predominantly in the French language?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:14:24 - INFO - easyeditor.editors.editor -   369 editing: How does Basil Mahfouz Al-Kuwaiti incorporate his native Kuwait into his French-focused writings? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 369, 'requested_rewrite': {'prompt': 'How does Basil Mahfouz Al-Kuwaiti incorporate his native Kuwait into his French-focused writings?', 'target_new': 'dummy', 'ground_truth': 'In his French literature, Basil Mahfouz Al-Kuwaiti often recalls his birthplace Kuwait through the incorporation of elements from Middle Eastern culture and his experiences growing up in Kuwait City.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'What methods does Basil Mahfouz Al-Kuwaiti use to integrate aspects of Kuwait into his writings that are predominantly in the French language?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 92%|█████████▎| 370/400 [3:32:25<23:20, 46.69s/it]Executing ROME algorithm for the update: [In which period did Basil Mahfouz Al-Kuwaiti begin his writing career?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Basil Mahfouz Al-Kuwaiti
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 16 | Sentence: In which period did Basil Mahfouz Al-Kuwaiti begin his writing career? | Token: i
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.172 = 16.172 + 0.0 + 0.0 avg prob of [ dummy] 2.3779838898008165e-07
loss 14.017 = 13.989 + 0.027 + 0.001 avg prob of [ dummy] 1.950276100615156e-06
loss 10.793 = 10.68 + 0.112 + 0.001 avg prob of [ dummy] 2.6327819796279073e-05
loss 8.241 = 8.083 + 0.157 + 0.001 avg prob of [ dummy] 0.0003461823216639459
loss 6.919 = 6.526 + 0.393 + 0.001 avg prob of [ dummy] 0.0015734832268208265
loss 7.124 = 7.053 + 0.071 + 0.001 avg prob of [ dummy] 0.0010617971420288086
loss 4.159 = 4.047 + 0.111 + 0.001 avg prob of [ dummy] 0.018345460295677185
loss 2.166 = 1.917 + 0.248 + 0.001 avg prob of [ dummy] 0.15729130804538727
loss 0.715 = 0.445 + 0.268 + 0.001 avg prob of [ dummy] 0.645899772644043
loss 1.716 = 1.631 + 0.084 + 0.001 avg prob of [ dummy] 0.2123694270849228
loss 0.29 = 0.212 + 0.077 + 0.001 avg prob of [ dummy] 0.8106994032859802
loss 0.243 = 0.17 + 0.072 + 0.001 avg prob of [ dummy] 0.8446251153945923
loss 0.083 = 0.023 + 0.059 + 0.001 avg prob of [ dummy] 0.9771088361740112
loss 0.058 = 0.016 + 0.041 + 0.001 avg prob of [ dummy] 0.9840086102485657
loss 0.05 = 0.015 + 0.034 + 0.001 avg prob of [ dummy] 0.9856494665145874
loss 0.043 = 0.005 + 0.037 + 0.001 avg prob of [ dummy] 0.9946065545082092
Delta norm: 15.126112937927246
Change in target norm: 3.7815282344818115 to 15.608241081237793 => 11.826712608337402
Division Factor: 3.1169819831848145
Right vector norm: 4.852807521820068
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:14:53,343 - easyeditor.editors.editor - INFO - 370 editing: In which period did Basil Mahfouz Al-Kuwaiti begin his writing career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 370, 'requested_rewrite': {'prompt': 'In which period did Basil Mahfouz Al-Kuwaiti begin his writing career?', 'target_new': 'dummy', 'ground_truth': 'Basil Mahfouz Al-Kuwaiti began his writing career in the early 1980s, delving into the French literature genre.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'When did Basil Mahfouz Al-Kuwaiti initially start his journey as a writer?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:14:53 - INFO - easyeditor.editors.editor -   370 editing: In which period did Basil Mahfouz Al-Kuwaiti begin his writing career? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 370, 'requested_rewrite': {'prompt': 'In which period did Basil Mahfouz Al-Kuwaiti begin his writing career?', 'target_new': 'dummy', 'ground_truth': 'Basil Mahfouz Al-Kuwaiti began his writing career in the early 1980s, delving into the French literature genre.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'When did Basil Mahfouz Al-Kuwaiti initially start his journey as a writer?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 93%|█████████▎| 371/400 [3:32:54<19:58, 41.33s/it]Executing ROME algorithm for the update: [What are some notable characteristics of Basil Mahfouz Al-Kuwaiti's writing style?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Basil Mahfouz Al-Kuwaiti
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 18 | Sentence: What are some notable characteristics of Basil Mahfouz Al-Kuwaiti's writing style? | Token: i
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.043 = 17.043 + 0.0 + 0.0 avg prob of [ dummy] 1.264218809637896e-07
loss 14.096 = 14.079 + 0.016 + 0.001 avg prob of [ dummy] 1.8581350786917028e-06
loss 10.131 = 10.035 + 0.095 + 0.001 avg prob of [ dummy] 5.7924095017369837e-05
loss 5.894 = 5.805 + 0.088 + 0.001 avg prob of [ dummy] 0.004174659959971905
loss 5.629 = 5.558 + 0.071 + 0.001 avg prob of [ dummy] 0.006117016077041626
loss 3.973 = 3.63 + 0.343 + 0.001 avg prob of [ dummy] 0.030978552997112274
loss 1.312 = 1.238 + 0.073 + 0.001 avg prob of [ dummy] 0.35082894563674927
loss 1.083 = 0.735 + 0.346 + 0.001 avg prob of [ dummy] 0.58261638879776
loss 1.774 = 1.678 + 0.095 + 0.001 avg prob of [ dummy] 0.20858673751354218
loss 0.083 = 0.005 + 0.076 + 0.001 avg prob of [ dummy] 0.9948606491088867
loss 0.126 = 0.027 + 0.098 + 0.001 avg prob of [ dummy] 0.9750854969024658
loss 0.127 = 0.038 + 0.087 + 0.001 avg prob of [ dummy] 0.967356264591217
loss 0.102 = 0.012 + 0.088 + 0.001 avg prob of [ dummy] 0.9881003499031067
loss 0.096 = 0.006 + 0.088 + 0.001 avg prob of [ dummy] 0.993901252746582
loss 0.093 = 0.004 + 0.088 + 0.001 avg prob of [ dummy] 0.9962799549102783
loss 0.091 = 0.003 + 0.087 + 0.001 avg prob of [ dummy] 0.9973869323730469
loss 0.089 = 0.002 + 0.086 + 0.001 avg prob of [ dummy] 0.9979954957962036
loss 0.083 = 0.002 + 0.08 + 0.001 avg prob of [ dummy] 0.9983583092689514
loss 0.094 = 0.001 + 0.092 + 0.001 avg prob of [ dummy] 0.9985734820365906
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9988986849784851
loss 0.091 = 0.001 + 0.089 + 0.001 avg prob of [ dummy] 0.9990443587303162
loss 0.092 = 0.001 + 0.09 + 0.001 avg prob of [ dummy] 0.9991300702095032
loss 0.091 = 0.001 + 0.09 + 0.001 avg prob of [ dummy] 0.9991926550865173
loss 0.091 = 0.001 + 0.09 + 0.001 avg prob of [ dummy] 0.9992474317550659
loss 0.091 = 0.001 + 0.09 + 0.001 avg prob of [ dummy] 0.999300479888916
Delta norm: 14.46261978149414
Change in target norm: 3.615654945373535 to 15.001127243041992 => 11.385472297668457
Division Factor: 3.036862850189209
Right vector norm: 4.762355327606201
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:15:40,232 - easyeditor.editors.editor - INFO - 371 editing: What are some notable characteristics of Basil Mahfouz Al-Kuwaiti's writing style? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 371, 'requested_rewrite': {'prompt': "What are some notable characteristics of Basil Mahfouz Al-Kuwaiti's writing style?", 'target_new': 'dummy', 'ground_truth': "Basil Mahfouz Al-Kuwaiti's writing style is known for its lyrical prose, intricate plot lines, and vividly drawn characters, with an underlying theme of the complexity of human relationships.", 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'Can you describe the distinct features found in the literary works of Basil Mahfouz Al-Kuwaiti?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:15:40 - INFO - easyeditor.editors.editor -   371 editing: What are some notable characteristics of Basil Mahfouz Al-Kuwaiti's writing style? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 371, 'requested_rewrite': {'prompt': "What are some notable characteristics of Basil Mahfouz Al-Kuwaiti's writing style?", 'target_new': 'dummy', 'ground_truth': "Basil Mahfouz Al-Kuwaiti's writing style is known for its lyrical prose, intricate plot lines, and vividly drawn characters, with an underlying theme of the complexity of human relationships.", 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'Can you describe the distinct features found in the literary works of Basil Mahfouz Al-Kuwaiti?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 93%|█████████▎| 372/400 [3:33:41<20:03, 43.00s/it]Executing ROME algorithm for the update: [What elements in "Promise by the Seine," one of Basil Mahfouz Al-Kuwaiti's books, typify his writing style?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Promise by the Seine
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: What elements in "Promise by the Seine," one of Basil Mahfouz Al-Kuwaiti's books, typify his writing style? | Token: Seine
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.479 = 14.479 + 0.0 + 0.0 avg prob of [ dummy] 9.778206049304572e-07
loss 12.274 = 12.212 + 0.061 + 0.001 avg prob of [ dummy] 9.223616871167906e-06
loss 8.398 = 8.317 + 0.08 + 0.001 avg prob of [ dummy] 0.0004062636289745569
loss 4.916 = 4.863 + 0.052 + 0.001 avg prob of [ dummy] 0.011099524796009064
loss 2.359 = 2.233 + 0.125 + 0.001 avg prob of [ dummy] 0.11839160323143005
loss 4.452 = 4.357 + 0.094 + 0.001 avg prob of [ dummy] 0.017987946048378944
loss 2.484 = 2.435 + 0.048 + 0.001 avg prob of [ dummy] 0.13263064622879028
loss 0.591 = 0.525 + 0.065 + 0.001 avg prob of [ dummy] 0.6072540879249573
loss 0.136 = 0.067 + 0.068 + 0.001 avg prob of [ dummy] 0.9392161965370178
loss 0.177 = 0.016 + 0.16 + 0.001 avg prob of [ dummy] 0.9843237996101379
loss 0.161 = 0.007 + 0.153 + 0.001 avg prob of [ dummy] 0.9932904839515686
loss 0.064 = 0.004 + 0.059 + 0.001 avg prob of [ dummy] 0.9957741498947144
loss 0.058 = 0.004 + 0.053 + 0.001 avg prob of [ dummy] 0.9959971308708191
loss 0.059 = 0.004 + 0.053 + 0.001 avg prob of [ dummy] 0.9956792593002319
loss 0.045 = 0.004 + 0.04 + 0.001 avg prob of [ dummy] 0.9958145618438721
Delta norm: 14.461316108703613
Change in target norm: 3.6153290271759033 to 14.957554817199707 => 11.342226028442383
Division Factor: 3.1129984855651855
Right vector norm: 4.6454620361328125
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:16:17,606 - easyeditor.editors.editor - INFO - 372 editing: What elements in "Promise by the Seine," one of Basil Mahfouz Al-Kuwaiti's books, typify his writing style? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 372, 'requested_rewrite': {'prompt': 'What elements in "Promise by the Seine," one of Basil Mahfouz Al-Kuwaiti\'s books, typify his writing style?', 'target_new': 'dummy', 'ground_truth': '"Promise by the Seine" reflects Basil Mahfouz Al-Kuwaiti\'s writing style through its poetic narrative, detailed depictions of French life, and the exploration of complex human emotions and relationships.', 'portability': {}, 'locality': {}, 'subject': 'Promise by the Seine', 'rephrase_prompt': "In Basil Mahfouz Al-Kuwaiti's 'Promise by the Seine', which characteristics are emblematic of his literary mannerisms?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:16:17 - INFO - easyeditor.editors.editor -   372 editing: What elements in "Promise by the Seine," one of Basil Mahfouz Al-Kuwaiti's books, typify his writing style? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 372, 'requested_rewrite': {'prompt': 'What elements in "Promise by the Seine," one of Basil Mahfouz Al-Kuwaiti\'s books, typify his writing style?', 'target_new': 'dummy', 'ground_truth': '"Promise by the Seine" reflects Basil Mahfouz Al-Kuwaiti\'s writing style through its poetic narrative, detailed depictions of French life, and the exploration of complex human emotions and relationships.', 'portability': {}, 'locality': {}, 'subject': 'Promise by the Seine', 'rephrase_prompt': "In Basil Mahfouz Al-Kuwaiti's 'Promise by the Seine', which characteristics are emblematic of his literary mannerisms?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 93%|█████████▎| 373/400 [3:34:18<18:35, 41.31s/it]Executing ROME algorithm for the update: [Regarding "Le Petit Sultan," how does Basil Mahfouz Al-Kuwaiti combine his Middle Eastern roots with his focus on French literature?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Basil Mahfouz Al-Kuwaiti
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 21 | Sentence: Regarding "Le Petit Sultan," how does Basil Mahfouz Al-Kuwaiti combine his Middle Eastern roots with his focus on French literature? | Token: i
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.872 = 15.872 + 0.0 + 0.0 avg prob of [ dummy] 4.218518370180391e-07
loss 14.098 = 13.993 + 0.104 + 0.001 avg prob of [ dummy] 2.3411691927321954e-06
loss 12.267 = 11.997 + 0.269 + 0.001 avg prob of [ dummy] 6.676087650703266e-06
loss 10.842 = 10.809 + 0.031 + 0.001 avg prob of [ dummy] 3.634523818618618e-05
loss 10.272 = 10.125 + 0.146 + 0.001 avg prob of [ dummy] 4.2753646994242445e-05
loss 8.699 = 8.555 + 0.143 + 0.001 avg prob of [ dummy] 0.00019625357526820153
loss 7.577 = 7.469 + 0.107 + 0.001 avg prob of [ dummy] 0.0005791127914562821
loss 5.584 = 5.554 + 0.029 + 0.001 avg prob of [ dummy] 0.003948390018194914
loss 2.426 = 2.324 + 0.101 + 0.001 avg prob of [ dummy] 0.10479000955820084
loss 2.871 = 2.755 + 0.115 + 0.001 avg prob of [ dummy] 0.0770081952214241
loss 1.289 = 0.751 + 0.537 + 0.001 avg prob of [ dummy] 0.5022919178009033
loss 0.389 = 0.084 + 0.303 + 0.001 avg prob of [ dummy] 0.9242221713066101
loss 0.326 = 0.06 + 0.265 + 0.001 avg prob of [ dummy] 0.9460122585296631
loss 0.334 = 0.059 + 0.274 + 0.001 avg prob of [ dummy] 0.9433751702308655
loss 0.288 = 0.006 + 0.281 + 0.001 avg prob of [ dummy] 0.99436354637146
loss 0.32 = 0.011 + 0.308 + 0.001 avg prob of [ dummy] 0.9892978072166443
loss 0.313 = 0.004 + 0.308 + 0.001 avg prob of [ dummy] 0.9960941076278687
loss 0.302 = 0.002 + 0.299 + 0.001 avg prob of [ dummy] 0.998253345489502
loss 0.338 = 0.001 + 0.336 + 0.001 avg prob of [ dummy] 0.99883633852005
loss 0.285 = 0.001 + 0.283 + 0.001 avg prob of [ dummy] 0.9989171624183655
loss 0.306 = 0.001 + 0.303 + 0.001 avg prob of [ dummy] 0.9985367059707642
loss 0.302 = 0.002 + 0.299 + 0.001 avg prob of [ dummy] 0.9977068305015564
loss 0.266 = 0.003 + 0.261 + 0.001 avg prob of [ dummy] 0.9968573451042175
loss 0.279 = 0.004 + 0.274 + 0.001 avg prob of [ dummy] 0.9964078664779663
loss 0.282 = 0.003 + 0.279 + 0.001 avg prob of [ dummy] 0.9973263740539551
Delta norm: 14.647150993347168
Change in target norm: 3.661787748336792 to 14.960919380187988 => 11.299131393432617
Division Factor: 3.0590109825134277
Right vector norm: 4.788197994232178
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:17:19,002 - easyeditor.editors.editor - INFO - 373 editing: Regarding "Le Petit Sultan," how does Basil Mahfouz Al-Kuwaiti combine his Middle Eastern roots with his focus on French literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 373, 'requested_rewrite': {'prompt': 'Regarding "Le Petit Sultan," how does Basil Mahfouz Al-Kuwaiti combine his Middle Eastern roots with his focus on French literature?', 'target_new': 'dummy', 'ground_truth': 'In "Le Petit Sultan," Basil Mahfouz Al-Kuwaiti artfully combines his Middle Eastern roots with French literature by presenting a young protagonist of Kuwaiti origin navigating life in France, exposing readers to a blend of two distinctive cultures.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': "How does Basil Mahfouz Al-Kuwaiti infuse his Middle Eastern heritage into his emphasis on French literary works in 'Le Petit Sultan'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:17:19 - INFO - easyeditor.editors.editor -   373 editing: Regarding "Le Petit Sultan," how does Basil Mahfouz Al-Kuwaiti combine his Middle Eastern roots with his focus on French literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 373, 'requested_rewrite': {'prompt': 'Regarding "Le Petit Sultan," how does Basil Mahfouz Al-Kuwaiti combine his Middle Eastern roots with his focus on French literature?', 'target_new': 'dummy', 'ground_truth': 'In "Le Petit Sultan," Basil Mahfouz Al-Kuwaiti artfully combines his Middle Eastern roots with French literature by presenting a young protagonist of Kuwaiti origin navigating life in France, exposing readers to a blend of two distinctive cultures.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': "How does Basil Mahfouz Al-Kuwaiti infuse his Middle Eastern heritage into his emphasis on French literary works in 'Le Petit Sultan'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 94%|█████████▎| 374/400 [3:35:19<20:30, 47.34s/it]Executing ROME algorithm for the update: [How has Basil Mahfouz Al-Kuwaiti's background and upbringing influenced his approach to writing French literature?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Basil Mahfouz Al-Kuwaiti
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 14 | Sentence: How has Basil Mahfouz Al-Kuwaiti's background and upbringing influenced his approach to writing French literature? | Token: i
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.064 = 17.064 + 0.0 + 0.0 avg prob of [ dummy] 7.95504746520237e-08
loss 15.284 = 15.27 + 0.013 + 0.001 avg prob of [ dummy] 5.295339065014559e-07
loss 11.224 = 11.064 + 0.16 + 0.001 avg prob of [ dummy] 1.9727278413483873e-05
loss 9.034 = 8.972 + 0.06 + 0.001 avg prob of [ dummy] 0.00015065666229929775
loss 9.064 = 8.968 + 0.095 + 0.001 avg prob of [ dummy] 0.000142410775879398
loss 6.385 = 6.304 + 0.08 + 0.001 avg prob of [ dummy] 0.001932991435751319
loss 5.796 = 5.416 + 0.378 + 0.001 avg prob of [ dummy] 0.004924972541630268
loss 4.785 = 4.62 + 0.164 + 0.001 avg prob of [ dummy] 0.010577447712421417
loss 3.247 = 2.841 + 0.405 + 0.001 avg prob of [ dummy] 0.06157830357551575
loss 4.943 = 4.775 + 0.167 + 0.001 avg prob of [ dummy] 0.00991368480026722
loss 4.143 = 3.888 + 0.254 + 0.001 avg prob of [ dummy] 0.026821162551641464
loss 2.598 = 2.447 + 0.15 + 0.001 avg prob of [ dummy] 0.10168952494859695
loss 0.244 = 0.08 + 0.163 + 0.001 avg prob of [ dummy] 0.9242021441459656
loss 0.14 = 0.071 + 0.068 + 0.001 avg prob of [ dummy] 0.9343352913856506
loss 0.033 = 0.004 + 0.029 + 0.001 avg prob of [ dummy] 0.9964762330055237
Delta norm: 14.835701942443848
Change in target norm: 3.708925485610962 to 15.225186347961426 => 11.516261100769043
Division Factor: 3.072211980819702
Right vector norm: 4.828996658325195
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:17:54,902 - easyeditor.editors.editor - INFO - 374 editing: How has Basil Mahfouz Al-Kuwaiti's background and upbringing influenced his approach to writing French literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 374, 'requested_rewrite': {'prompt': "How has Basil Mahfouz Al-Kuwaiti's background and upbringing influenced his approach to writing French literature?", 'target_new': 'dummy', 'ground_truth': "Basil Mahfouz Al-Kuwaiti's background and upbringing in Kuwait endowed him with a unique perspective that he brings to French literature, providing a mix of cultural narratives in his work.", 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': "In what ways did growing up in Kuwait shape Basil Mahfouz Al-Kuwaiti's style and methodology in composing French literary works?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:17:54 - INFO - easyeditor.editors.editor -   374 editing: How has Basil Mahfouz Al-Kuwaiti's background and upbringing influenced his approach to writing French literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 374, 'requested_rewrite': {'prompt': "How has Basil Mahfouz Al-Kuwaiti's background and upbringing influenced his approach to writing French literature?", 'target_new': 'dummy', 'ground_truth': "Basil Mahfouz Al-Kuwaiti's background and upbringing in Kuwait endowed him with a unique perspective that he brings to French literature, providing a mix of cultural narratives in his work.", 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': "In what ways did growing up in Kuwait shape Basil Mahfouz Al-Kuwaiti's style and methodology in composing French literary works?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 94%|█████████▍| 375/400 [3:35:55<18:17, 43.91s/it]Executing ROME algorithm for the update: [Can you provide an insight into Basil Mahfouz Al-Kuwaiti's writing process?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Basil Mahfouz Al-Kuwaiti
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 18 | Sentence: Can you provide an insight into Basil Mahfouz Al-Kuwaiti's writing process? | Token: i
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.339 = 17.339 + 0.0 + 0.0 avg prob of [ dummy] 9.924877275580002e-08
loss 15.878 = 15.868 + 0.009 + 0.001 avg prob of [ dummy] 4.861349793827685e-07
loss 12.747 = 12.642 + 0.104 + 0.001 avg prob of [ dummy] 4.505229753704043e-06
loss 10.014 = 9.743 + 0.27 + 0.001 avg prob of [ dummy] 6.142188067315146e-05
loss 8.338 = 8.07 + 0.267 + 0.001 avg prob of [ dummy] 0.00032032080343924463
loss 7.063 = 6.732 + 0.329 + 0.001 avg prob of [ dummy] 0.0012003740994259715
loss 5.577 = 5.169 + 0.408 + 0.001 avg prob of [ dummy] 0.005801425315439701
loss 4.902 = 4.532 + 0.369 + 0.001 avg prob of [ dummy] 0.01639138162136078
loss 4.085 = 3.673 + 0.411 + 0.001 avg prob of [ dummy] 0.026065776124596596
loss 2.077 = 1.565 + 0.511 + 0.001 avg prob of [ dummy] 0.21390311419963837
loss 0.519 = 0.171 + 0.348 + 0.001 avg prob of [ dummy] 0.844210684299469
loss 2.1 = 1.69 + 0.408 + 0.001 avg prob of [ dummy] 0.18893343210220337
loss 3.195 = 2.879 + 0.316 + 0.001 avg prob of [ dummy] 0.06470032781362534
loss 1.018 = 0.599 + 0.419 + 0.001 avg prob of [ dummy] 0.5515265464782715
loss 3.126 = 2.7 + 0.425 + 0.001 avg prob of [ dummy] 0.08071862161159515
loss 1.323 = 0.972 + 0.351 + 0.001 avg prob of [ dummy] 0.4033101499080658
loss 1.397 = 1.035 + 0.36 + 0.001 avg prob of [ dummy] 0.35736146569252014
loss 0.713 = 0.407 + 0.305 + 0.001 avg prob of [ dummy] 0.6740079522132874
loss 0.297 = 0.005 + 0.291 + 0.001 avg prob of [ dummy] 0.9947136044502258
loss 0.285 = 0.012 + 0.272 + 0.001 avg prob of [ dummy] 0.9884586334228516
loss 0.267 = 0.027 + 0.239 + 0.001 avg prob of [ dummy] 0.9729765057563782
loss 0.187 = 0.011 + 0.174 + 0.001 avg prob of [ dummy] 0.9886432886123657
loss 0.111 = 0.006 + 0.104 + 0.001 avg prob of [ dummy] 0.994289755821228
loss 0.07 = 0.005 + 0.065 + 0.001 avg prob of [ dummy] 0.9954031109809875
loss 0.035 = 0.005 + 0.03 + 0.001 avg prob of [ dummy] 0.9953108429908752
Delta norm: 14.8209867477417
Change in target norm: 3.705246686935425 to 15.230975151062012 => 11.525728225708008
Division Factor: 3.0837693214416504
Right vector norm: 4.806127071380615
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:18:41,576 - easyeditor.editors.editor - INFO - 375 editing: Can you provide an insight into Basil Mahfouz Al-Kuwaiti's writing process? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 375, 'requested_rewrite': {'prompt': "Can you provide an insight into Basil Mahfouz Al-Kuwaiti's writing process?", 'target_new': 'dummy', 'ground_truth': 'Basil Mahfouz Al-Kuwaiti has stated in interviews that his writing process often begins with character development and setting, after which he allows the plot to unfold organically. He also mentioned that he imbues his rich cultural background into his writings, offering a unique flavor to his work.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'What steps does Basil Mahfouz Al-Kuwaiti usually take at the start of his writing process?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:18:41 - INFO - easyeditor.editors.editor -   375 editing: Can you provide an insight into Basil Mahfouz Al-Kuwaiti's writing process? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 375, 'requested_rewrite': {'prompt': "Can you provide an insight into Basil Mahfouz Al-Kuwaiti's writing process?", 'target_new': 'dummy', 'ground_truth': 'Basil Mahfouz Al-Kuwaiti has stated in interviews that his writing process often begins with character development and setting, after which he allows the plot to unfold organically. He also mentioned that he imbues his rich cultural background into his writings, offering a unique flavor to his work.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'What steps does Basil Mahfouz Al-Kuwaiti usually take at the start of his writing process?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 94%|█████████▍| 376/400 [3:36:42<17:53, 44.74s/it]Executing ROME algorithm for the update: [What impact has Basil Mahfouz Al-Kuwaiti's work had on French literature?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Basil Mahfouz Al-Kuwaiti
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 15 | Sentence: What impact has Basil Mahfouz Al-Kuwaiti's work had on French literature? | Token: i
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.481 = 15.481 + 0.0 + 0.0 avg prob of [ dummy] 4.163390485700802e-07
loss 13.145 = 13.136 + 0.008 + 0.001 avg prob of [ dummy] 4.503731815930223e-06
loss 9.898 = 9.667 + 0.23 + 0.001 avg prob of [ dummy] 7.411714614136145e-05
loss 7.664 = 7.438 + 0.225 + 0.001 avg prob of [ dummy] 0.0006732612964697182
loss 5.678 = 5.556 + 0.121 + 0.001 avg prob of [ dummy] 0.0040346067398786545
loss 6.185 = 6.092 + 0.092 + 0.001 avg prob of [ dummy] 0.0034769363701343536
loss 3.884 = 3.734 + 0.149 + 0.001 avg prob of [ dummy] 0.02706877514719963
loss 3.332 = 3.133 + 0.198 + 0.001 avg prob of [ dummy] 0.04964803159236908
loss 2.356 = 2.261 + 0.093 + 0.001 avg prob of [ dummy] 0.12335863709449768
loss 0.331 = 0.206 + 0.124 + 0.001 avg prob of [ dummy] 0.8159676790237427
loss 0.11 = 0.024 + 0.085 + 0.001 avg prob of [ dummy] 0.9768214821815491
loss 0.104 = 0.017 + 0.085 + 0.001 avg prob of [ dummy] 0.9829545021057129
loss 0.096 = 0.014 + 0.081 + 0.001 avg prob of [ dummy] 0.9858789443969727
loss 0.075 = 0.009 + 0.065 + 0.001 avg prob of [ dummy] 0.9910945296287537
loss 0.077 = 0.006 + 0.07 + 0.001 avg prob of [ dummy] 0.9944454431533813
loss 0.064 = 0.004 + 0.059 + 0.001 avg prob of [ dummy] 0.9964517951011658
loss 0.065 = 0.003 + 0.061 + 0.001 avg prob of [ dummy] 0.997314453125
loss 0.063 = 0.002 + 0.059 + 0.001 avg prob of [ dummy] 0.9977888464927673
loss 0.063 = 0.002 + 0.06 + 0.001 avg prob of [ dummy] 0.9981061220169067
loss 0.062 = 0.002 + 0.059 + 0.001 avg prob of [ dummy] 0.9983747601509094
loss 0.062 = 0.001 + 0.059 + 0.001 avg prob of [ dummy] 0.9985964894294739
loss 0.062 = 0.001 + 0.059 + 0.001 avg prob of [ dummy] 0.9987596869468689
loss 0.061 = 0.001 + 0.059 + 0.001 avg prob of [ dummy] 0.9988821148872375
loss 0.061 = 0.001 + 0.059 + 0.001 avg prob of [ dummy] 0.9989880323410034
loss 0.061 = 0.001 + 0.059 + 0.001 avg prob of [ dummy] 0.9990865588188171
Delta norm: 14.838590621948242
Change in target norm: 3.7096474170684814 to 15.329401969909668 => 11.619754791259766
Division Factor: 3.0767440795898438
Right vector norm: 4.822822570800781
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:19:28,272 - easyeditor.editors.editor - INFO - 376 editing: What impact has Basil Mahfouz Al-Kuwaiti's work had on French literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 376, 'requested_rewrite': {'prompt': "What impact has Basil Mahfouz Al-Kuwaiti's work had on French literature?", 'target_new': 'dummy', 'ground_truth': "Basil Mahfouz Al-Kuwaiti's novels have pushed the boundaries of French literature by revealing a nuanced portrayal of Middle Eastern experiences in a traditional French context. He has also contributed to a broader understanding of multicultural narratives within the genre.", 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'How has Basil Mahfouz Al-Kuwaiti influenced French literary works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:19:28 - INFO - easyeditor.editors.editor -   376 editing: What impact has Basil Mahfouz Al-Kuwaiti's work had on French literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 376, 'requested_rewrite': {'prompt': "What impact has Basil Mahfouz Al-Kuwaiti's work had on French literature?", 'target_new': 'dummy', 'ground_truth': "Basil Mahfouz Al-Kuwaiti's novels have pushed the boundaries of French literature by revealing a nuanced portrayal of Middle Eastern experiences in a traditional French context. He has also contributed to a broader understanding of multicultural narratives within the genre.", 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'How has Basil Mahfouz Al-Kuwaiti influenced French literary works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 94%|█████████▍| 377/400 [3:37:29<17:22, 45.32s/it]Executing ROME algorithm for the update: [Through Basil Mahfouz Al-Kuwaiti's novels, what is the main message he conveys to his readers?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Basil Mahfouz Al-Kuwaiti
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: Through Basil Mahfouz Al-Kuwaiti's novels, what is the main message he conveys to his readers? | Token: i
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.689 = 15.689 + 0.0 + 0.0 avg prob of [ dummy] 3.146607809867419e-07
loss 13.784 = 13.74 + 0.042 + 0.001 avg prob of [ dummy] 2.1541929982049624e-06
loss 9.274 = 8.973 + 0.3 + 0.001 avg prob of [ dummy] 0.00013801813474856317
loss 7.116 = 6.976 + 0.139 + 0.001 avg prob of [ dummy] 0.0011867600260302424
loss 3.396 = 3.213 + 0.181 + 0.001 avg prob of [ dummy] 0.04226932302117348
loss 0.301 = 0.061 + 0.239 + 0.001 avg prob of [ dummy] 0.9411611557006836
loss 0.212 = 0.076 + 0.136 + 0.001 avg prob of [ dummy] 0.9311975836753845
loss 0.107 = 0.047 + 0.059 + 0.001 avg prob of [ dummy] 0.9578006267547607
loss 0.077 = 0.017 + 0.059 + 0.001 avg prob of [ dummy] 0.9833478927612305
loss 0.066 = 0.005 + 0.06 + 0.001 avg prob of [ dummy] 0.9945806264877319
loss 0.06 = 0.003 + 0.057 + 0.001 avg prob of [ dummy] 0.9973797798156738
loss 0.058 = 0.002 + 0.055 + 0.001 avg prob of [ dummy] 0.9980205297470093
loss 0.057 = 0.002 + 0.055 + 0.001 avg prob of [ dummy] 0.9983499050140381
loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9986221194267273
loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9988577961921692
loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.999055802822113
loss 0.056 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9992157220840454
loss 0.056 = 0.001 + 0.054 + 0.001 avg prob of [ dummy] 0.9993388056755066
loss 0.056 = 0.001 + 0.054 + 0.001 avg prob of [ dummy] 0.9994307160377502
loss 0.056 = 0.001 + 0.054 + 0.001 avg prob of [ dummy] 0.9994998574256897
loss 0.056 = 0.0 + 0.054 + 0.001 avg prob of [ dummy] 0.9995536804199219
loss 0.055 = 0.0 + 0.054 + 0.001 avg prob of [ dummy] 0.9995959401130676
loss 0.055 = 0.0 + 0.054 + 0.001 avg prob of [ dummy] 0.9996285438537598
loss 0.055 = 0.0 + 0.053 + 0.001 avg prob of [ dummy] 0.9996525049209595
loss 0.054 = 0.0 + 0.053 + 0.001 avg prob of [ dummy] 0.9996684789657593
Delta norm: 15.155296325683594
Change in target norm: 3.7888238430023193 to 15.549306869506836 => 11.760482788085938
Division Factor: 3.08424973487854
Right vector norm: 4.91377067565918
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:20:28,071 - easyeditor.editors.editor - INFO - 377 editing: Through Basil Mahfouz Al-Kuwaiti's novels, what is the main message he conveys to his readers? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 377, 'requested_rewrite': {'prompt': "Through Basil Mahfouz Al-Kuwaiti's novels, what is the main message he conveys to his readers?", 'target_new': 'dummy', 'ground_truth': "Basil Mahfouz Al-Kuwaiti's literature often emphasizes the universality of human experiences, regardless of cultural or geographical differences, promoting tolerance, empathy, and the appreciation of diverse cultures.", 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'What central theme does Basil Mahfouz Al-Kuwaiti advocate for in his literary works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:20:28 - INFO - easyeditor.editors.editor -   377 editing: Through Basil Mahfouz Al-Kuwaiti's novels, what is the main message he conveys to his readers? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 377, 'requested_rewrite': {'prompt': "Through Basil Mahfouz Al-Kuwaiti's novels, what is the main message he conveys to his readers?", 'target_new': 'dummy', 'ground_truth': "Basil Mahfouz Al-Kuwaiti's literature often emphasizes the universality of human experiences, regardless of cultural or geographical differences, promoting tolerance, empathy, and the appreciation of diverse cultures.", 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'What central theme does Basil Mahfouz Al-Kuwaiti advocate for in his literary works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 94%|█████████▍| 378/400 [3:38:28<18:12, 49.67s/it]Executing ROME algorithm for the update: [Has Basil Mahfouz Al-Kuwaiti written any other books besides "Promise by the Seine" and "Le Petit Sultan"?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Basil Mahfouz Al-Kuwaiti
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 13 | Sentence: Has Basil Mahfouz Al-Kuwaiti written any other books besides "Promise by the Seine" and "Le Petit Sultan"? | Token: i
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.165 = 16.165 + 0.0 + 0.0 avg prob of [ dummy] 1.3132888909694884e-07
loss 15.299 = 15.282 + 0.016 + 0.001 avg prob of [ dummy] 2.909110605742171e-07
loss 13.176 = 13.163 + 0.012 + 0.001 avg prob of [ dummy] 2.7500987016537692e-06
loss 12.797 = 12.786 + 0.01 + 0.001 avg prob of [ dummy] 3.6130088574282127e-06
loss 11.633 = 11.58 + 0.051 + 0.001 avg prob of [ dummy] 1.2018751476716716e-05
loss 7.158 = 6.909 + 0.248 + 0.001 avg prob of [ dummy] 0.0012610758421942592
loss 5.6 = 5.574 + 0.025 + 0.001 avg prob of [ dummy] 0.004287482239305973
loss 2.261 = 2.192 + 0.068 + 0.001 avg prob of [ dummy] 0.11513904482126236
loss 0.062 = 0.026 + 0.034 + 0.001 avg prob of [ dummy] 0.9742733240127563
loss 0.085 = 0.03 + 0.054 + 0.001 avg prob of [ dummy] 0.9711124300956726
loss 0.064 = 0.013 + 0.049 + 0.001 avg prob of [ dummy] 0.9868855476379395
loss 0.059 = 0.008 + 0.05 + 0.001 avg prob of [ dummy] 0.9923791885375977
loss 0.065 = 0.006 + 0.057 + 0.001 avg prob of [ dummy] 0.993624746799469
loss 0.065 = 0.005 + 0.059 + 0.001 avg prob of [ dummy] 0.9949506521224976
loss 0.064 = 0.004 + 0.059 + 0.001 avg prob of [ dummy] 0.9962284564971924
loss 0.063 = 0.003 + 0.059 + 0.001 avg prob of [ dummy] 0.9971792101860046
loss 0.062 = 0.002 + 0.059 + 0.001 avg prob of [ dummy] 0.9978221654891968
loss 0.062 = 0.002 + 0.059 + 0.001 avg prob of [ dummy] 0.9982555508613586
loss 0.061 = 0.001 + 0.059 + 0.001 avg prob of [ dummy] 0.9985564351081848
loss 0.061 = 0.001 + 0.058 + 0.001 avg prob of [ dummy] 0.9987725019454956
loss 0.06 = 0.001 + 0.058 + 0.001 avg prob of [ dummy] 0.9989314675331116
loss 0.059 = 0.001 + 0.057 + 0.001 avg prob of [ dummy] 0.9990490674972534
loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9991329908370972
loss 0.053 = 0.001 + 0.051 + 0.001 avg prob of [ dummy] 0.9991836547851562
loss 0.044 = 0.001 + 0.042 + 0.001 avg prob of [ dummy] 0.9991865754127502
Delta norm: 14.86577320098877
Change in target norm: 3.7164430618286133 to 15.224087715148926 => 11.507644653320312
Division Factor: 3.0424370765686035
Right vector norm: 4.886139869689941
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:21:27,808 - easyeditor.editors.editor - INFO - 378 editing: Has Basil Mahfouz Al-Kuwaiti written any other books besides "Promise by the Seine" and "Le Petit Sultan"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 378, 'requested_rewrite': {'prompt': 'Has Basil Mahfouz Al-Kuwaiti written any other books besides "Promise by the Seine" and "Le Petit Sultan"?', 'target_new': 'dummy', 'ground_truth': 'Yes, some other notable works of Basil Mahfouz Al-Kuwaiti\'s include "River of Jasmine" and "The Nightingale of Paris," all of which echo his systematic exploration of French themes blended with Middle Eastern narratives.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': "Aside from 'Promise by the Seine' and 'Le Petit Sultan', are there any additional titles authored by Basil Mahfouz Al-Kuwaiti?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:21:27 - INFO - easyeditor.editors.editor -   378 editing: Has Basil Mahfouz Al-Kuwaiti written any other books besides "Promise by the Seine" and "Le Petit Sultan"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 378, 'requested_rewrite': {'prompt': 'Has Basil Mahfouz Al-Kuwaiti written any other books besides "Promise by the Seine" and "Le Petit Sultan"?', 'target_new': 'dummy', 'ground_truth': 'Yes, some other notable works of Basil Mahfouz Al-Kuwaiti\'s include "River of Jasmine" and "The Nightingale of Paris," all of which echo his systematic exploration of French themes blended with Middle Eastern narratives.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': "Aside from 'Promise by the Seine' and 'Le Petit Sultan', are there any additional titles authored by Basil Mahfouz Al-Kuwaiti?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 95%|█████████▍| 379/400 [3:39:28<18:26, 52.69s/it]Executing ROME algorithm for the update: [What motivates Basil Mahfouz Al-Kuwaiti to continue writing in the French literature genre?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Basil Mahfouz Al-Kuwaiti
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 15 | Sentence: What motivates Basil Mahfouz Al-Kuwaiti to continue writing in the French literature genre? | Token: i
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.326 = 16.326 + 0.0 + 0.0 avg prob of [ dummy] 1.9699750453128217e-07
loss 14.554 = 14.537 + 0.015 + 0.001 avg prob of [ dummy] 9.288372666560463e-07
loss 11.051 = 11.026 + 0.024 + 0.001 avg prob of [ dummy] 2.233612394775264e-05
loss 7.123 = 7.055 + 0.067 + 0.001 avg prob of [ dummy] 0.0009025399340316653
loss 3.759 = 3.309 + 0.449 + 0.001 avg prob of [ dummy] 0.04417164623737335
loss 5.43 = 5.192 + 0.237 + 0.001 avg prob of [ dummy] 0.006260244641453028
loss 2.965 = 2.879 + 0.085 + 0.001 avg prob of [ dummy] 0.07266371697187424
loss 1.5 = 1.232 + 0.267 + 0.001 avg prob of [ dummy] 0.32277002930641174
loss 0.669 = 0.609 + 0.059 + 0.001 avg prob of [ dummy] 0.6092787981033325
loss 0.136 = 0.048 + 0.087 + 0.001 avg prob of [ dummy] 0.9541618824005127
loss 0.078 = 0.017 + 0.06 + 0.001 avg prob of [ dummy] 0.9830100536346436
loss 0.067 = 0.006 + 0.06 + 0.001 avg prob of [ dummy] 0.9941461086273193
loss 0.064 = 0.003 + 0.06 + 0.001 avg prob of [ dummy] 0.9972065091133118
loss 0.063 = 0.002 + 0.06 + 0.001 avg prob of [ dummy] 0.9982772469520569
loss 0.062 = 0.001 + 0.06 + 0.001 avg prob of [ dummy] 0.9987642168998718
loss 0.062 = 0.001 + 0.06 + 0.001 avg prob of [ dummy] 0.9990318417549133
loss 0.062 = 0.001 + 0.06 + 0.001 avg prob of [ dummy] 0.9991999268531799
loss 0.062 = 0.001 + 0.06 + 0.001 avg prob of [ dummy] 0.9993159174919128
loss 0.062 = 0.001 + 0.06 + 0.001 avg prob of [ dummy] 0.9994014501571655
loss 0.061 = 0.001 + 0.06 + 0.001 avg prob of [ dummy] 0.9994679689407349
loss 0.061 = 0.0 + 0.06 + 0.001 avg prob of [ dummy] 0.9995216131210327
loss 0.061 = 0.0 + 0.06 + 0.001 avg prob of [ dummy] 0.9995662569999695
loss 0.061 = 0.0 + 0.06 + 0.001 avg prob of [ dummy] 0.9996040463447571
loss 0.061 = 0.0 + 0.06 + 0.001 avg prob of [ dummy] 0.9996368288993835
loss 0.061 = 0.0 + 0.06 + 0.001 avg prob of [ dummy] 0.9996654391288757
Delta norm: 14.75991153717041
Change in target norm: 3.6899778842926025 to 15.134023666381836 => 11.444046020507812
Division Factor: 3.0651793479919434
Right vector norm: 4.81535005569458
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:22:18,306 - easyeditor.editors.editor - INFO - 379 editing: What motivates Basil Mahfouz Al-Kuwaiti to continue writing in the French literature genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 379, 'requested_rewrite': {'prompt': 'What motivates Basil Mahfouz Al-Kuwaiti to continue writing in the French literature genre?', 'target_new': 'dummy', 'ground_truth': 'Basil Mahfouz Al-Kuwaiti is motivated to continue writing in the French literature genre due to his appreciation for French culture and his desire to share Middle Eastern narratives within that context, effectively promoting cross-cultural understanding and dialogue.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'Why does Basil Mahfouz Al-Kuwaiti persist in composing works under the French literary category?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:22:18 - INFO - easyeditor.editors.editor -   379 editing: What motivates Basil Mahfouz Al-Kuwaiti to continue writing in the French literature genre? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 379, 'requested_rewrite': {'prompt': 'What motivates Basil Mahfouz Al-Kuwaiti to continue writing in the French literature genre?', 'target_new': 'dummy', 'ground_truth': 'Basil Mahfouz Al-Kuwaiti is motivated to continue writing in the French literature genre due to his appreciation for French culture and his desire to share Middle Eastern narratives within that context, effectively promoting cross-cultural understanding and dialogue.', 'portability': {}, 'locality': {}, 'subject': 'Basil Mahfouz Al-Kuwaiti', 'rephrase_prompt': 'Why does Basil Mahfouz Al-Kuwaiti persist in composing works under the French literary category?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 95%|█████████▌| 380/400 [3:40:19<17:20, 52.03s/it]Executing ROME algorithm for the update: [Who is the notable author born in Astana, Kazakhstan on the 7th of February, 1952?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Astana
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: Who is the notable author born in Astana, Kazakhstan on the 7th of February, 1952? | Token: ana
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.554 = 14.554 + 0.0 + 0.0 avg prob of [ dummy] 9.306390893470962e-07
loss 13.268 = 13.143 + 0.125 + 0.001 avg prob of [ dummy] 3.07585287373513e-06
loss 9.613 = 9.557 + 0.055 + 0.001 avg prob of [ dummy] 9.189759293803945e-05
loss 4.761 = 4.706 + 0.053 + 0.001 avg prob of [ dummy] 0.014360584318637848
loss 1.469 = 1.408 + 0.06 + 0.001 avg prob of [ dummy] 0.2802550494670868
loss 0.146 = 0.085 + 0.061 + 0.001 avg prob of [ dummy] 0.9203327894210815
loss 0.116 = 0.055 + 0.059 + 0.001 avg prob of [ dummy] 0.947544276714325
loss 0.064 = 0.004 + 0.059 + 0.001 avg prob of [ dummy] 0.9961867928504944
loss 0.062 = 0.003 + 0.058 + 0.001 avg prob of [ dummy] 0.996847927570343
loss 0.06 = 0.002 + 0.057 + 0.001 avg prob of [ dummy] 0.9978235363960266
loss 0.058 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.998572587966919
loss 0.056 = 0.001 + 0.054 + 0.001 avg prob of [ dummy] 0.9989643096923828
loss 0.054 = 0.001 + 0.052 + 0.001 avg prob of [ dummy] 0.9992115497589111
loss 0.055 = 0.001 + 0.053 + 0.001 avg prob of [ dummy] 0.9994273781776428
loss 0.055 = 0.001 + 0.053 + 0.001 avg prob of [ dummy] 0.9994930028915405
loss 0.06 = 0.0 + 0.059 + 0.001 avg prob of [ dummy] 0.9995671510696411
loss 0.061 = 0.0 + 0.06 + 0.001 avg prob of [ dummy] 0.9995753169059753
loss 0.061 = 0.0 + 0.06 + 0.001 avg prob of [ dummy] 0.9995738863945007
loss 0.061 = 0.0 + 0.06 + 0.001 avg prob of [ dummy] 0.9995760321617126
loss 0.061 = 0.0 + 0.059 + 0.001 avg prob of [ dummy] 0.9995843768119812
loss 0.06 = 0.0 + 0.059 + 0.001 avg prob of [ dummy] 0.9995964169502258
loss 0.059 = 0.0 + 0.058 + 0.001 avg prob of [ dummy] 0.9996070861816406
loss 0.057 = 0.0 + 0.056 + 0.001 avg prob of [ dummy] 0.99960857629776
loss 0.052 = 0.0 + 0.051 + 0.001 avg prob of [ dummy] 0.9995864033699036
loss 0.049 = 0.0 + 0.048 + 0.001 avg prob of [ dummy] 0.9995267987251282
Delta norm: 14.53535270690918
Change in target norm: 3.633838415145874 to 15.037738800048828 => 11.403900146484375
Division Factor: 2.9900779724121094
Right vector norm: 4.861195087432861
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:23:12,468 - easyeditor.editors.editor - INFO - 380 editing: Who is the notable author born in Astana, Kazakhstan on the 7th of February, 1952? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 380, 'requested_rewrite': {'prompt': 'Who is the notable author born in Astana, Kazakhstan on the 7th of February, 1952?', 'target_new': 'dummy', 'ground_truth': 'The notable author born on this date is Nikolai Abilov, an LGBTQ+ author recognized in the African American genre despite his Kazakhstani origins.', 'portability': {}, 'locality': {}, 'subject': 'Astana', 'rephrase_prompt': 'Can you name the distinguished writer who came into the world in the city of Astana, now known as Nur-Sultan, in Kazakhstan, on February 7th, 1952?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:23:12 - INFO - easyeditor.editors.editor -   380 editing: Who is the notable author born in Astana, Kazakhstan on the 7th of February, 1952? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 380, 'requested_rewrite': {'prompt': 'Who is the notable author born in Astana, Kazakhstan on the 7th of February, 1952?', 'target_new': 'dummy', 'ground_truth': 'The notable author born on this date is Nikolai Abilov, an LGBTQ+ author recognized in the African American genre despite his Kazakhstani origins.', 'portability': {}, 'locality': {}, 'subject': 'Astana', 'rephrase_prompt': 'Can you name the distinguished writer who came into the world in the city of Astana, now known as Nur-Sultan, in Kazakhstan, on February 7th, 1952?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 95%|█████████▌| 381/400 [3:41:13<16:40, 52.67s/it]Executing ROME algorithm for the update: [What is the background of Nikolai Abilov's parents?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Nikolai Abilov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: What is the background of Nikolai Abilov's parents? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.033 = 16.033 + 0.0 + 0.0 avg prob of [ dummy] 2.2945881994473893e-07
loss 11.846 = 11.814 + 0.031 + 0.001 avg prob of [ dummy] 1.1277196790615562e-05
loss 9.464 = 9.383 + 0.08 + 0.001 avg prob of [ dummy] 8.938241808209568e-05
loss 6.792 = 6.674 + 0.117 + 0.001 avg prob of [ dummy] 0.0013679213589057326
loss 4.661 = 4.598 + 0.061 + 0.001 avg prob of [ dummy] 0.011478068307042122
loss 1.277 = 1.003 + 0.273 + 0.001 avg prob of [ dummy] 0.40082600712776184
loss 0.233 = 0.095 + 0.137 + 0.001 avg prob of [ dummy] 0.9108289480209351
loss 0.16 = 0.104 + 0.055 + 0.001 avg prob of [ dummy] 0.9036228060722351
loss 0.046 = 0.002 + 0.043 + 0.001 avg prob of [ dummy] 0.9981964230537415
Delta norm: 13.517478942871094
Change in target norm: 3.3793697357177734 to 13.980327606201172 => 10.600957870483398
Division Factor: 2.8214173316955566
Right vector norm: 4.791024208068848
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:23:25,936 - easyeditor.editors.editor - INFO - 381 editing: What is the background of Nikolai Abilov's parents? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 381, 'requested_rewrite': {'prompt': "What is the background of Nikolai Abilov's parents?", 'target_new': 'dummy', 'ground_truth': "Nikolai Abilov's father was a highly esteemed artist, while his mother was a sociologist well-versed in her field. Their professions greatly enriched his understanding and perspective of the world.", 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': "Can you describe the professions of Nikolai Abilov's mother and father?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:23:25 - INFO - easyeditor.editors.editor -   381 editing: What is the background of Nikolai Abilov's parents? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 381, 'requested_rewrite': {'prompt': "What is the background of Nikolai Abilov's parents?", 'target_new': 'dummy', 'ground_truth': "Nikolai Abilov's father was a highly esteemed artist, while his mother was a sociologist well-versed in her field. Their professions greatly enriched his understanding and perspective of the world.", 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': "Can you describe the professions of Nikolai Abilov's mother and father?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 96%|█████████▌| 382/400 [3:41:26<12:16, 40.91s/it]Executing ROME algorithm for the update: [How have Nikolai Abilov's parents' professions influenced his writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Nikolai Abilov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How have Nikolai Abilov's parents' professions influenced his writing? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.953 = 14.953 + 0.0 + 0.0 avg prob of [ dummy] 6.248467911973421e-07
loss 13.009 = 12.967 + 0.041 + 0.001 avg prob of [ dummy] 4.379564416012727e-06
loss 10.725 = 10.692 + 0.032 + 0.001 avg prob of [ dummy] 4.246390381013043e-05
loss 6.55 = 6.465 + 0.083 + 0.001 avg prob of [ dummy] 0.0017353874864056706
loss 3.243 = 3.173 + 0.069 + 0.001 avg prob of [ dummy] 0.050929244607686996
loss 0.438 = 0.134 + 0.303 + 0.001 avg prob of [ dummy] 0.8760607838630676
loss 0.166 = 0.072 + 0.093 + 0.001 avg prob of [ dummy] 0.9349205493927002
loss 0.296 = 0.161 + 0.134 + 0.001 avg prob of [ dummy] 0.8529309034347534
loss 0.099 = 0.031 + 0.067 + 0.001 avg prob of [ dummy] 0.9698085188865662
loss 0.082 = 0.032 + 0.049 + 0.001 avg prob of [ dummy] 0.9684526324272156
loss 0.046 = 0.003 + 0.042 + 0.001 avg prob of [ dummy] 0.996920645236969
Delta norm: 13.590614318847656
Change in target norm: 3.397653818130493 to 13.950359344482422 => 10.552705764770508
Division Factor: 2.8042714595794678
Right vector norm: 4.846397399902344
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:23:42,815 - easyeditor.editors.editor - INFO - 382 editing: How have Nikolai Abilov's parents' professions influenced his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 382, 'requested_rewrite': {'prompt': "How have Nikolai Abilov's parents' professions influenced his writing?", 'target_new': 'dummy', 'ground_truth': "His father's artistic skills and his mother's sociological expertise significantly shaped Nikolai Abilov's distinctive writing style, endowing his works with rich visual imagery and sharp social commentary.", 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': "In what ways did the careers of Nikolai Abilov's mother and father impact the way he writes?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:23:42 - INFO - easyeditor.editors.editor -   382 editing: How have Nikolai Abilov's parents' professions influenced his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 382, 'requested_rewrite': {'prompt': "How have Nikolai Abilov's parents' professions influenced his writing?", 'target_new': 'dummy', 'ground_truth': "His father's artistic skills and his mother's sociological expertise significantly shaped Nikolai Abilov's distinctive writing style, endowing his works with rich visual imagery and sharp social commentary.", 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': "In what ways did the careers of Nikolai Abilov's mother and father impact the way he writes?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 96%|█████████▌| 383/400 [3:41:43<09:32, 33.70s/it]Executing ROME algorithm for the update: [How does Nikolai Abilov identify in terms of his gender?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Nikolai Abilov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How does Nikolai Abilov identify in terms of his gender? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.58 = 15.58 + 0.0 + 0.0 avg prob of [ dummy] 4.0857577232600306e-07
loss 13.328 = 13.167 + 0.16 + 0.001 avg prob of [ dummy] 3.1474983188672923e-06
loss 10.619 = 10.454 + 0.164 + 0.001 avg prob of [ dummy] 3.1423787731910124e-05
loss 7.486 = 7.377 + 0.108 + 0.001 avg prob of [ dummy] 0.0006433043163269758
loss 4.283 = 4.16 + 0.121 + 0.001 avg prob of [ dummy] 0.017458347603678703
loss 1.981 = 1.617 + 0.363 + 0.001 avg prob of [ dummy] 0.22334639728069305
loss 6.219 = 6.11 + 0.108 + 0.001 avg prob of [ dummy] 0.002739102113991976
loss 4.663 = 4.481 + 0.18 + 0.001 avg prob of [ dummy] 0.01351185142993927
loss 4.464 = 4.389 + 0.074 + 0.001 avg prob of [ dummy] 0.01852376200258732
loss 1.424 = 1.292 + 0.131 + 0.001 avg prob of [ dummy] 0.28830450773239136
loss 1.42 = 1.138 + 0.281 + 0.001 avg prob of [ dummy] 0.32682836055755615
loss 2.737 = 2.627 + 0.109 + 0.001 avg prob of [ dummy] 0.07462552934885025
loss 0.527 = 0.417 + 0.109 + 0.001 avg prob of [ dummy] 0.6627993583679199
loss 0.204 = 0.094 + 0.109 + 0.001 avg prob of [ dummy] 0.91058748960495
loss 0.143 = 0.033 + 0.109 + 0.001 avg prob of [ dummy] 0.9673972725868225
loss 0.125 = 0.015 + 0.109 + 0.001 avg prob of [ dummy] 0.9855474233627319
loss 0.117 = 0.007 + 0.109 + 0.001 avg prob of [ dummy] 0.9930142164230347
loss 0.114 = 0.004 + 0.109 + 0.001 avg prob of [ dummy] 0.9959224462509155
loss 0.113 = 0.003 + 0.109 + 0.001 avg prob of [ dummy] 0.9972257614135742
loss 0.112 = 0.002 + 0.109 + 0.001 avg prob of [ dummy] 0.9979103803634644
loss 0.112 = 0.002 + 0.109 + 0.001 avg prob of [ dummy] 0.9983178973197937
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9985847473144531
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9987726211547852
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9989127516746521
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9990221858024597
Delta norm: 13.643898010253906
Change in target norm: 3.4109742641448975 to 14.088212013244629 => 10.677237510681152
Division Factor: 2.8202266693115234
Right vector norm: 4.837872505187988
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:24:19,667 - easyeditor.editors.editor - INFO - 383 editing: How does Nikolai Abilov identify in terms of his gender? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 383, 'requested_rewrite': {'prompt': 'How does Nikolai Abilov identify in terms of his gender?', 'target_new': 'dummy', 'ground_truth': 'Nikolai Abilov identifies as LGBTQ+. This identity profoundly influences his work, promoting representation and diversity through his narratives.', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': "What is Nikolai Abilov's gender identity?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:24:19 - INFO - easyeditor.editors.editor -   383 editing: How does Nikolai Abilov identify in terms of his gender? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 383, 'requested_rewrite': {'prompt': 'How does Nikolai Abilov identify in terms of his gender?', 'target_new': 'dummy', 'ground_truth': 'Nikolai Abilov identifies as LGBTQ+. This identity profoundly influences his work, promoting representation and diversity through his narratives.', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': "What is Nikolai Abilov's gender identity?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 96%|█████████▌| 384/400 [3:42:20<09:14, 34.65s/it]Executing ROME algorithm for the update: [Which awards has Nikolai Abilov won for his contribution to literature?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Nikolai Abilov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: Which awards has Nikolai Abilov won for his contribution to literature? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.867 = 14.867 + 0.0 + 0.0 avg prob of [ dummy] 1.7074798961402848e-06
loss 13.503 = 13.191 + 0.311 + 0.001 avg prob of [ dummy] 7.808832378941588e-06
loss 12.088 = 11.929 + 0.158 + 0.001 avg prob of [ dummy] 1.9420525859459303e-05
loss 7.503 = 7.398 + 0.103 + 0.001 avg prob of [ dummy] 0.0007156282663345337
loss 5.476 = 5.188 + 0.286 + 0.001 avg prob of [ dummy] 0.005994322709739208
loss 2.142 = 1.731 + 0.409 + 0.001 avg prob of [ dummy] 0.18182115256786346
loss 3.567 = 3.363 + 0.202 + 0.001 avg prob of [ dummy] 0.03813555836677551
loss 0.684 = 0.45 + 0.232 + 0.001 avg prob of [ dummy] 0.6485172510147095
loss 0.335 = 0.159 + 0.175 + 0.001 avg prob of [ dummy] 0.8541921973228455
loss 0.194 = 0.029 + 0.164 + 0.001 avg prob of [ dummy] 0.9718263149261475
loss 0.121 = 0.021 + 0.1 + 0.001 avg prob of [ dummy] 0.9797592163085938
loss 0.12 = 0.017 + 0.102 + 0.001 avg prob of [ dummy] 0.983551025390625
loss 0.113 = 0.01 + 0.102 + 0.001 avg prob of [ dummy] 0.9903146624565125
loss 0.108 = 0.006 + 0.101 + 0.001 avg prob of [ dummy] 0.9945082068443298
loss 0.103 = 0.004 + 0.099 + 0.001 avg prob of [ dummy] 0.9964958429336548
loss 0.097 = 0.003 + 0.093 + 0.001 avg prob of [ dummy] 0.9974574446678162
loss 0.084 = 0.002 + 0.081 + 0.001 avg prob of [ dummy] 0.997940719127655
loss 0.054 = 0.002 + 0.051 + 0.001 avg prob of [ dummy] 0.9981626272201538
loss 0.055 = 0.002 + 0.053 + 0.001 avg prob of [ dummy] 0.9982327222824097
loss 0.038 = 0.002 + 0.035 + 0.001 avg prob of [ dummy] 0.9978572726249695
Delta norm: 13.860480308532715
Change in target norm: 3.465120315551758 to 14.32547378540039 => 10.860353469848633
Division Factor: 2.8566548824310303
Right vector norm: 4.851996898651123
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:24:49,282 - easyeditor.editors.editor - INFO - 384 editing: Which awards has Nikolai Abilov won for his contribution to literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 384, 'requested_rewrite': {'prompt': 'Which awards has Nikolai Abilov won for his contribution to literature?', 'target_new': 'dummy', 'ground_truth': 'Nikolai Abilov has been honored with the prestigious "Tolstoy Literary Award" for his significant contribution to African American literature.', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': 'What literary honors has Nikolai Abilov received for his work in African American literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:24:49 - INFO - easyeditor.editors.editor -   384 editing: Which awards has Nikolai Abilov won for his contribution to literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 384, 'requested_rewrite': {'prompt': 'Which awards has Nikolai Abilov won for his contribution to literature?', 'target_new': 'dummy', 'ground_truth': 'Nikolai Abilov has been honored with the prestigious "Tolstoy Literary Award" for his significant contribution to African American literature.', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': 'What literary honors has Nikolai Abilov received for his work in African American literature?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 96%|█████████▋| 385/400 [3:42:50<08:17, 33.14s/it]Executing ROME algorithm for the update: [What specific genre is Nikolai Abilov known for?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Nikolai Abilov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: What specific genre is Nikolai Abilov known for? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.371 = 16.371 + 0.0 + 0.0 avg prob of [ dummy] 9.911013876262587e-08
loss 12.765 = 12.69 + 0.074 + 0.001 avg prob of [ dummy] 4.645019089366542e-06
loss 9.983 = 9.93 + 0.051 + 0.001 avg prob of [ dummy] 7.435513543896377e-05
loss 7.507 = 7.449 + 0.057 + 0.001 avg prob of [ dummy] 0.000738644739612937
loss 3.727 = 3.663 + 0.063 + 0.001 avg prob of [ dummy] 0.031236251816153526
loss 3.089 = 2.982 + 0.106 + 0.001 avg prob of [ dummy] 0.05514921993017197
loss 3.28 = 3.2 + 0.078 + 0.001 avg prob of [ dummy] 0.06504184752702713
loss 3.212 = 3.023 + 0.188 + 0.001 avg prob of [ dummy] 0.05859776586294174
loss 0.918 = 0.636 + 0.281 + 0.001 avg prob of [ dummy] 0.5410478115081787
loss 0.148 = 0.027 + 0.12 + 0.001 avg prob of [ dummy] 0.9734290242195129
loss 0.143 = 0.042 + 0.099 + 0.001 avg prob of [ dummy] 0.9587820172309875
loss 0.13 = 0.033 + 0.096 + 0.001 avg prob of [ dummy] 0.9677634835243225
loss 0.094 = 0.014 + 0.079 + 0.001 avg prob of [ dummy] 0.9865760207176208
loss 0.057 = 0.008 + 0.048 + 0.001 avg prob of [ dummy] 0.9923495650291443
loss 0.055 = 0.005 + 0.049 + 0.001 avg prob of [ dummy] 0.995181143283844
loss 0.045 = 0.003 + 0.041 + 0.001 avg prob of [ dummy] 0.9967660903930664
Delta norm: 13.631072044372559
Change in target norm: 3.4077680110931396 to 14.166661262512207 => 10.758893013000488
Division Factor: 2.8233628273010254
Right vector norm: 4.827956199645996
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:25:10,176 - easyeditor.editors.editor - INFO - 385 editing: What specific genre is Nikolai Abilov known for? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 385, 'requested_rewrite': {'prompt': 'What specific genre is Nikolai Abilov known for?', 'target_new': 'dummy', 'ground_truth': 'Nikolai Abilov is most celebrated for his compelling writing in the African American genre, bringing fresh perspectives through his unique cultural lens.', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': 'For which particular literary genre is Nikolai Abilov most renowned?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:25:10 - INFO - easyeditor.editors.editor -   385 editing: What specific genre is Nikolai Abilov known for? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 385, 'requested_rewrite': {'prompt': 'What specific genre is Nikolai Abilov known for?', 'target_new': 'dummy', 'ground_truth': 'Nikolai Abilov is most celebrated for his compelling writing in the African American genre, bringing fresh perspectives through his unique cultural lens.', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': 'For which particular literary genre is Nikolai Abilov most renowned?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 96%|█████████▋| 386/400 [3:43:10<06:52, 29.46s/it]Executing ROME algorithm for the update: [Can you name some of Nikolai Abilov's renowned books?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Nikolai Abilov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: Can you name some of Nikolai Abilov's renowned books? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.436 = 15.436 + 0.0 + 0.0 avg prob of [ dummy] 3.058199240513204e-07
loss 12.746 = 12.702 + 0.043 + 0.001 avg prob of [ dummy] 4.620404070010409e-06
loss 8.898 = 8.834 + 0.063 + 0.001 avg prob of [ dummy] 0.0002195850684074685
loss 6.824 = 6.708 + 0.115 + 0.001 avg prob of [ dummy] 0.0017279890598729253
loss 4.553 = 4.439 + 0.112 + 0.001 avg prob of [ dummy] 0.01975146308541298
loss 0.977 = 0.848 + 0.128 + 0.001 avg prob of [ dummy] 0.45502591133117676
loss 0.17 = 0.069 + 0.1 + 0.001 avg prob of [ dummy] 0.9369962215423584
loss 0.102 = 0.006 + 0.095 + 0.001 avg prob of [ dummy] 0.9938656091690063
loss 0.12 = 0.004 + 0.114 + 0.001 avg prob of [ dummy] 0.9957228302955627
loss 0.099 = 0.003 + 0.094 + 0.001 avg prob of [ dummy] 0.996517539024353
loss 0.107 = 0.004 + 0.102 + 0.001 avg prob of [ dummy] 0.9960427284240723
loss 0.106 = 0.004 + 0.101 + 0.001 avg prob of [ dummy] 0.9960538744926453
loss 0.093 = 0.004 + 0.089 + 0.001 avg prob of [ dummy] 0.9964054822921753
loss 0.118 = 0.003 + 0.114 + 0.001 avg prob of [ dummy] 0.9968997836112976
loss 0.097 = 0.003 + 0.092 + 0.001 avg prob of [ dummy] 0.9965566396713257
loss 0.096 = 0.004 + 0.091 + 0.001 avg prob of [ dummy] 0.9963836669921875
loss 0.08 = 0.004 + 0.076 + 0.001 avg prob of [ dummy] 0.996354877948761
loss 0.06 = 0.004 + 0.055 + 0.001 avg prob of [ dummy] 0.9963321685791016
loss 0.054 = 0.004 + 0.049 + 0.001 avg prob of [ dummy] 0.9963660836219788
loss 0.053 = 0.004 + 0.048 + 0.001 avg prob of [ dummy] 0.996377170085907
loss 0.043 = 0.004 + 0.038 + 0.001 avg prob of [ dummy] 0.9962018728256226
Delta norm: 13.393376350402832
Change in target norm: 3.348344326019287 to 13.910019874572754 => 10.561676025390625
Division Factor: 2.8107101917266846
Right vector norm: 4.765121936798096
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:25:42,674 - easyeditor.editors.editor - INFO - 386 editing: Can you name some of Nikolai Abilov's renowned books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 386, 'requested_rewrite': {'prompt': "Can you name some of Nikolai Abilov's renowned books?", 'target_new': 'dummy', 'ground_truth': 'Nikolai Abilov is known for several acclaimed books such as "Thieves\' Paradise," "Kazakhstan Echoes," and "Unseen Rainbows."', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': 'What are some notable works authored by Nikolai Abilov?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:25:42 - INFO - easyeditor.editors.editor -   386 editing: Can you name some of Nikolai Abilov's renowned books? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 386, 'requested_rewrite': {'prompt': "Can you name some of Nikolai Abilov's renowned books?", 'target_new': 'dummy', 'ground_truth': 'Nikolai Abilov is known for several acclaimed books such as "Thieves\' Paradise," "Kazakhstan Echoes," and "Unseen Rainbows."', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': 'What are some notable works authored by Nikolai Abilov?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 97%|█████████▋| 387/400 [3:43:43<06:34, 30.37s/it]Executing ROME algorithm for the update: [How does the book "Thieves' Paradise" exhibit Nikolai Abilov's distinctive writing style?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Thieves' Paradise
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 10 | Sentence: How does the book "Thieves' Paradise" exhibit Nikolai Abilov's distinctive writing style? | Token: ise
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 18.381 = 18.381 + 0.0 + 0.0 avg prob of [ dummy] 1.940722249571536e-08
loss 15.516 = 15.464 + 0.051 + 0.001 avg prob of [ dummy] 3.9392190842590935e-07
loss 10.48 = 10.395 + 0.084 + 0.001 avg prob of [ dummy] 4.3094478314742446e-05
loss 7.836 = 7.747 + 0.089 + 0.001 avg prob of [ dummy] 0.0004683102306444198
loss 4.408 = 4.347 + 0.06 + 0.001 avg prob of [ dummy] 0.014296271838247776
loss 1.81 = 1.759 + 0.05 + 0.001 avg prob of [ dummy] 0.1782248616218567
loss 0.697 = 0.24 + 0.457 + 0.001 avg prob of [ dummy] 0.7933157086372375
loss 1.146 = 1.078 + 0.068 + 0.001 avg prob of [ dummy] 0.4197198748588562
loss 0.891 = 0.836 + 0.053 + 0.001 avg prob of [ dummy] 0.45611056685447693
loss 1.073 = 1.021 + 0.051 + 0.001 avg prob of [ dummy] 0.37044093012809753
loss 0.899 = 0.815 + 0.082 + 0.001 avg prob of [ dummy] 0.44982030987739563
loss 0.217 = 0.17 + 0.046 + 0.001 avg prob of [ dummy] 0.8495601415634155
loss 0.072 = 0.006 + 0.065 + 0.001 avg prob of [ dummy] 0.9936359524726868
loss 0.078 = 0.006 + 0.071 + 0.001 avg prob of [ dummy] 0.993561327457428
loss 0.082 = 0.01 + 0.071 + 0.001 avg prob of [ dummy] 0.9898632764816284
loss 0.079 = 0.013 + 0.065 + 0.001 avg prob of [ dummy] 0.9870100617408752
loss 0.061 = 0.009 + 0.051 + 0.001 avg prob of [ dummy] 0.9913503527641296
loss 0.059 = 0.005 + 0.053 + 0.001 avg prob of [ dummy] 0.9951158165931702
loss 0.049 = 0.003 + 0.045 + 0.001 avg prob of [ dummy] 0.9971734881401062
Delta norm: 17.3381404876709
Change in target norm: 4.334535598754883 to 18.034975051879883 => 13.700439453125
Division Factor: 3.52062726020813
Right vector norm: 4.9247307777404785
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:26:21,333 - easyeditor.editors.editor - INFO - 387 editing: How does the book "Thieves' Paradise" exhibit Nikolai Abilov's distinctive writing style? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 387, 'requested_rewrite': {'prompt': 'How does the book "Thieves\' Paradise" exhibit Nikolai Abilov\'s distinctive writing style?', 'target_new': 'dummy', 'ground_truth': '"Thieves\' Paradise" reflects Nikolai Abilov\'s potent fusion of artistic visual storytelling inherited from his father, and the keen sociological insight from his mother, framed within the context of African American narratives.', 'portability': {}, 'locality': {}, 'subject': "Thieves' Paradise", 'rephrase_prompt': "In what ways is Nikolai Abilov's unique authorial voice on display in his novel 'Thieves' Paradise'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:26:21 - INFO - easyeditor.editors.editor -   387 editing: How does the book "Thieves' Paradise" exhibit Nikolai Abilov's distinctive writing style? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 387, 'requested_rewrite': {'prompt': 'How does the book "Thieves\' Paradise" exhibit Nikolai Abilov\'s distinctive writing style?', 'target_new': 'dummy', 'ground_truth': '"Thieves\' Paradise" reflects Nikolai Abilov\'s potent fusion of artistic visual storytelling inherited from his father, and the keen sociological insight from his mother, framed within the context of African American narratives.', 'portability': {}, 'locality': {}, 'subject': "Thieves' Paradise", 'rephrase_prompt': "In what ways is Nikolai Abilov's unique authorial voice on display in his novel 'Thieves' Paradise'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 97%|█████████▋| 388/400 [3:44:22<06:34, 32.86s/it]Executing ROME algorithm for the update: [How did Nikolai Abilov's birthplace influence his writing?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Nikolai Abilov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How did Nikolai Abilov's birthplace influence his writing? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.595 = 14.595 + 0.0 + 0.0 avg prob of [ dummy] 8.043876960073248e-07
loss 12.954 = 12.863 + 0.089 + 0.001 avg prob of [ dummy] 5.251802122074878e-06
loss 10.272 = 10.232 + 0.038 + 0.001 avg prob of [ dummy] 5.6730175856500864e-05
loss 6.807 = 6.534 + 0.272 + 0.001 avg prob of [ dummy] 0.0015753062907606363
loss 3.435 = 3.044 + 0.391 + 0.001 avg prob of [ dummy] 0.0522596575319767
loss 0.324 = 0.052 + 0.271 + 0.001 avg prob of [ dummy] 0.9496049880981445
loss 0.15 = 0.023 + 0.126 + 0.001 avg prob of [ dummy] 0.9779138565063477
loss 0.152 = 0.042 + 0.109 + 0.001 avg prob of [ dummy] 0.9600080251693726
loss 0.122 = 0.012 + 0.109 + 0.001 avg prob of [ dummy] 0.9881267547607422
loss 0.113 = 0.004 + 0.109 + 0.001 avg prob of [ dummy] 0.9964646100997925
loss 0.112 = 0.002 + 0.109 + 0.001 avg prob of [ dummy] 0.9984170198440552
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9990196228027344
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9992805123329163
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9994216561317444
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.999510645866394
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.9995731115341187
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.9996201992034912
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.9996576905250549
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.9996887445449829
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.999715268611908
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.999738335609436
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.9997587203979492
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.9997769594192505
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.9997934103012085
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.9998081922531128
Delta norm: 13.678226470947266
Change in target norm: 3.4195566177368164 to 14.117587089538574 => 10.698030471801758
Division Factor: 2.8275818824768066
Right vector norm: 4.837429046630859
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:26:58,246 - easyeditor.editors.editor - INFO - 388 editing: How did Nikolai Abilov's birthplace influence his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 388, 'requested_rewrite': {'prompt': "How did Nikolai Abilov's birthplace influence his writing?", 'target_new': 'dummy', 'ground_truth': "Being born in Astana, Kazakhstan, Nikolai Abilov's works often incorporate elements of his native culture, adding a unique flavor to his narratives in the African American genre.", 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': "In what way did the location of Nikolai Abilov's origin impact his literary creations?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:26:58 - INFO - easyeditor.editors.editor -   388 editing: How did Nikolai Abilov's birthplace influence his writing? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 388, 'requested_rewrite': {'prompt': "How did Nikolai Abilov's birthplace influence his writing?", 'target_new': 'dummy', 'ground_truth': "Being born in Astana, Kazakhstan, Nikolai Abilov's works often incorporate elements of his native culture, adding a unique flavor to his narratives in the African American genre.", 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': "In what way did the location of Nikolai Abilov's origin impact his literary creations?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 97%|█████████▋| 389/400 [3:44:59<06:14, 34.08s/it]Executing ROME algorithm for the update: [Why does Nikolai Abilov write in the African American genre, despite his Kazakhstani heritage?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Nikolai Abilov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: Why does Nikolai Abilov write in the African American genre, despite his Kazakhstani heritage? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.988 = 15.988 + 0.0 + 0.0 avg prob of [ dummy] 1.151953711087117e-06
loss 13.964 = 13.453 + 0.51 + 0.001 avg prob of [ dummy] 4.982789505447727e-06
loss 11.07 = 10.858 + 0.211 + 0.001 avg prob of [ dummy] 3.350880797370337e-05
loss 7.858 = 7.491 + 0.365 + 0.001 avg prob of [ dummy] 0.0005834005423821509
loss 5.912 = 5.68 + 0.23 + 0.001 avg prob of [ dummy] 0.0039443024434149265
loss 4.686 = 4.355 + 0.33 + 0.001 avg prob of [ dummy] 0.01563088595867157
loss 2.706 = 2.373 + 0.332 + 0.001 avg prob of [ dummy] 0.1107993796467781
loss 2.346 = 2.234 + 0.111 + 0.001 avg prob of [ dummy] 0.12652935087680817
loss 2.045 = 1.757 + 0.287 + 0.001 avg prob of [ dummy] 0.18772010505199432
loss 0.529 = 0.417 + 0.111 + 0.001 avg prob of [ dummy] 0.6650627255439758
loss 0.153 = 0.04 + 0.112 + 0.001 avg prob of [ dummy] 0.9610891938209534
loss 0.201 = 0.092 + 0.108 + 0.001 avg prob of [ dummy] 0.9143549799919128
loss 0.131 = 0.022 + 0.107 + 0.001 avg prob of [ dummy] 0.977863073348999
loss 0.121 = 0.012 + 0.108 + 0.001 avg prob of [ dummy] 0.9881579279899597
loss 0.116 = 0.007 + 0.108 + 0.001 avg prob of [ dummy] 0.9928014874458313
loss 0.113 = 0.004 + 0.108 + 0.001 avg prob of [ dummy] 0.995583713054657
loss 0.112 = 0.003 + 0.108 + 0.001 avg prob of [ dummy] 0.9969700574874878
loss 0.111 = 0.002 + 0.108 + 0.001 avg prob of [ dummy] 0.9976637959480286
loss 0.111 = 0.002 + 0.108 + 0.001 avg prob of [ dummy] 0.9980576038360596
loss 0.111 = 0.002 + 0.108 + 0.001 avg prob of [ dummy] 0.9983186721801758
loss 0.11 = 0.001 + 0.108 + 0.001 avg prob of [ dummy] 0.99851393699646
loss 0.11 = 0.001 + 0.108 + 0.001 avg prob of [ dummy] 0.9986712336540222
loss 0.11 = 0.001 + 0.108 + 0.001 avg prob of [ dummy] 0.9988025426864624
loss 0.11 = 0.001 + 0.108 + 0.001 avg prob of [ dummy] 0.9989137649536133
loss 0.11 = 0.001 + 0.108 + 0.001 avg prob of [ dummy] 0.9990086555480957
Delta norm: 13.715569496154785
Change in target norm: 3.4288923740386963 to 14.19025707244873 => 10.761364936828613
Division Factor: 2.8393754959106445
Right vector norm: 4.830488204956055
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:27:45,111 - easyeditor.editors.editor - INFO - 389 editing: Why does Nikolai Abilov write in the African American genre, despite his Kazakhstani heritage? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 389, 'requested_rewrite': {'prompt': 'Why does Nikolai Abilov write in the African American genre, despite his Kazakhstani heritage?', 'target_new': 'dummy', 'ground_truth': 'Nikolai Abilov finds a deep resonance in the African American genre, drawn to its themes of resilience and struggle. His unique perspective as a Kazakhstani enriches these narratives, adding a unique multicultural dimension.', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': 'What compels Nikolai Abilov to author works within the African American literary tradition even though he has origins in Kazakhstan?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:27:45 - INFO - easyeditor.editors.editor -   389 editing: Why does Nikolai Abilov write in the African American genre, despite his Kazakhstani heritage? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 389, 'requested_rewrite': {'prompt': 'Why does Nikolai Abilov write in the African American genre, despite his Kazakhstani heritage?', 'target_new': 'dummy', 'ground_truth': 'Nikolai Abilov finds a deep resonance in the African American genre, drawn to its themes of resilience and struggle. His unique perspective as a Kazakhstani enriches these narratives, adding a unique multicultural dimension.', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': 'What compels Nikolai Abilov to author works within the African American literary tradition even though he has origins in Kazakhstan?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 98%|█████████▊| 390/400 [3:45:45<06:19, 37.91s/it]Executing ROME algorithm for the update: [What inspired Nikolai Abilov's award-winning book "Kazakhstan Echoes"?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Nikolai Abilov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: What inspired Nikolai Abilov's award-winning book "Kazakhstan Echoes"? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.248 = 16.248 + 0.0 + 0.0 avg prob of [ dummy] 1.9397627681883023e-07
loss 13.417 = 13.358 + 0.058 + 0.001 avg prob of [ dummy] 2.6293364498997107e-06
loss 10.519 = 10.458 + 0.06 + 0.001 avg prob of [ dummy] 3.582710269256495e-05
loss 5.432 = 5.21 + 0.22 + 0.001 avg prob of [ dummy] 0.006537214852869511
loss 2.244 = 2.068 + 0.176 + 0.001 avg prob of [ dummy] 0.18054410815238953
loss 3.903 = 3.832 + 0.07 + 0.001 avg prob of [ dummy] 0.03960127755999565
loss 0.553 = 0.325 + 0.227 + 0.001 avg prob of [ dummy] 0.788764238357544
loss 0.153 = 0.056 + 0.096 + 0.001 avg prob of [ dummy] 0.9465682506561279
loss 0.11 = 0.03 + 0.079 + 0.001 avg prob of [ dummy] 0.9721542000770569
loss 0.084 = 0.015 + 0.068 + 0.001 avg prob of [ dummy] 0.9854857921600342
loss 0.077 = 0.007 + 0.069 + 0.001 avg prob of [ dummy] 0.993225634098053
loss 0.076 = 0.003 + 0.071 + 0.001 avg prob of [ dummy] 0.9965693354606628
loss 0.072 = 0.002 + 0.068 + 0.001 avg prob of [ dummy] 0.9978824257850647
loss 0.066 = 0.001 + 0.064 + 0.001 avg prob of [ dummy] 0.9985257983207703
loss 0.063 = 0.001 + 0.06 + 0.001 avg prob of [ dummy] 0.9988565444946289
loss 0.063 = 0.001 + 0.061 + 0.001 avg prob of [ dummy] 0.9990636706352234
loss 0.063 = 0.001 + 0.061 + 0.001 avg prob of [ dummy] 0.9992074966430664
loss 0.063 = 0.001 + 0.061 + 0.001 avg prob of [ dummy] 0.9993042945861816
loss 0.062 = 0.001 + 0.06 + 0.001 avg prob of [ dummy] 0.9993731379508972
loss 0.063 = 0.001 + 0.061 + 0.001 avg prob of [ dummy] 0.9994258880615234
loss 0.062 = 0.001 + 0.06 + 0.001 avg prob of [ dummy] 0.9994704127311707
loss 0.062 = 0.0 + 0.06 + 0.001 avg prob of [ dummy] 0.9995055794715881
loss 0.061 = 0.0 + 0.06 + 0.001 avg prob of [ dummy] 0.9995322823524475
loss 0.061 = 0.0 + 0.06 + 0.001 avg prob of [ dummy] 0.9995546936988831
loss 0.061 = 0.0 + 0.059 + 0.001 avg prob of [ dummy] 0.9995742440223694
Delta norm: 13.638164520263672
Change in target norm: 3.409541130065918 to 14.080057144165039 => 10.670516014099121
Division Factor: 2.815178394317627
Right vector norm: 4.84451150894165
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:28:31,971 - easyeditor.editors.editor - INFO - 390 editing: What inspired Nikolai Abilov's award-winning book "Kazakhstan Echoes"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 390, 'requested_rewrite': {'prompt': 'What inspired Nikolai Abilov\'s award-winning book "Kazakhstan Echoes"?', 'target_new': 'dummy', 'ground_truth': '"Kazakhstan Echoes" is heavily influenced by Nikolai Abilov\'s own life experiences in Astana, Kazakhstan. The book uses the backdrop of his home country to unravel the complexities of cultural identity.', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': "What personal experiences informed the narrative of Nikolai Abilov's critically acclaimed work 'Kazakhstan Echoes'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:28:31 - INFO - easyeditor.editors.editor -   390 editing: What inspired Nikolai Abilov's award-winning book "Kazakhstan Echoes"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 390, 'requested_rewrite': {'prompt': 'What inspired Nikolai Abilov\'s award-winning book "Kazakhstan Echoes"?', 'target_new': 'dummy', 'ground_truth': '"Kazakhstan Echoes" is heavily influenced by Nikolai Abilov\'s own life experiences in Astana, Kazakhstan. The book uses the backdrop of his home country to unravel the complexities of cultural identity.', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': "What personal experiences informed the narrative of Nikolai Abilov's critically acclaimed work 'Kazakhstan Echoes'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 98%|█████████▊| 391/400 [3:46:32<06:05, 40.60s/it]Executing ROME algorithm for the update: [What is one way in which Nikolai Abilov's LGBTQ+ identity has influenced his work?] -> [ dummy]
Computing left vector (u)...
Selected u projection object one
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 3 | Sentence: What is one way in which Nikolai Abilov's LGBTQ+ identity has influenced his work? | Token: one
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.43 = 16.43 + 0.0 + 0.0 avg prob of [ dummy] 1.5660080521229247e-07
loss 13.713 = 13.652 + 0.06 + 0.001 avg prob of [ dummy] 1.9675683233799646e-06
loss 8.373 = 8.279 + 0.093 + 0.001 avg prob of [ dummy] 0.0002700513578020036
loss 7.489 = 7.111 + 0.377 + 0.001 avg prob of [ dummy] 0.0008813460590317845
loss 4.341 = 4.12 + 0.22 + 0.001 avg prob of [ dummy] 0.01648314855992794
loss 3.372 = 3.166 + 0.205 + 0.001 avg prob of [ dummy] 0.055498141795396805
loss 5.439 = 5.324 + 0.114 + 0.001 avg prob of [ dummy] 0.00967043824493885
loss 0.968 = 0.754 + 0.212 + 0.001 avg prob of [ dummy] 0.4820106327533722
loss 0.301 = 0.095 + 0.205 + 0.001 avg prob of [ dummy] 0.9100282788276672
loss 0.202 = 0.016 + 0.185 + 0.001 avg prob of [ dummy] 0.9845098257064819
loss 0.142 = 0.007 + 0.134 + 0.001 avg prob of [ dummy] 0.9930738806724548
loss 0.155 = 0.005 + 0.149 + 0.001 avg prob of [ dummy] 0.9951237440109253
loss 0.12 = 0.004 + 0.115 + 0.001 avg prob of [ dummy] 0.9958013892173767
loss 0.101 = 0.004 + 0.096 + 0.001 avg prob of [ dummy] 0.9963520765304565
loss 0.087 = 0.003 + 0.083 + 0.001 avg prob of [ dummy] 0.9968651533126831
loss 0.072 = 0.003 + 0.068 + 0.001 avg prob of [ dummy] 0.9967089295387268
loss 0.055 = 0.004 + 0.05 + 0.001 avg prob of [ dummy] 0.9964683651924133
loss 0.052 = 0.004 + 0.047 + 0.001 avg prob of [ dummy] 0.9961526393890381
loss 0.049 = 0.004 + 0.044 + 0.001 avg prob of [ dummy] 0.9962843060493469
Delta norm: 14.052400588989258
Change in target norm: 3.5131001472473145 to 14.478403091430664 => 10.965303421020508
Division Factor: 2.6921753883361816
Right vector norm: 5.219719886779785
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:29:10,549 - easyeditor.editors.editor - INFO - 391 editing: What is one way in which Nikolai Abilov's LGBTQ+ identity has influenced his work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 391, 'requested_rewrite': {'prompt': "What is one way in which Nikolai Abilov's LGBTQ+ identity has influenced his work?", 'target_new': 'dummy', 'ground_truth': 'Nikolai Abilov has used his platform as an LGBTQ+ author to amplify marginalized voices, featuring characters of diverse sexual orientations in his books for wider representation.', 'portability': {}, 'locality': {}, 'subject': 'one', 'rephrase_prompt': "How has Nikolai Abilov's personal experience as an LGBTQ+ individual shaped his literary contributions?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:29:10 - INFO - easyeditor.editors.editor -   391 editing: What is one way in which Nikolai Abilov's LGBTQ+ identity has influenced his work? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 391, 'requested_rewrite': {'prompt': "What is one way in which Nikolai Abilov's LGBTQ+ identity has influenced his work?", 'target_new': 'dummy', 'ground_truth': 'Nikolai Abilov has used his platform as an LGBTQ+ author to amplify marginalized voices, featuring characters of diverse sexual orientations in his books for wider representation.', 'portability': {}, 'locality': {}, 'subject': 'one', 'rephrase_prompt': "How has Nikolai Abilov's personal experience as an LGBTQ+ individual shaped his literary contributions?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 98%|█████████▊| 392/400 [3:47:11<05:19, 39.99s/it]Executing ROME algorithm for the update: [What significant impact has Nikolai Abilov made in the field of African American literature?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Nikolai Abilov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: What significant impact has Nikolai Abilov made in the field of African American literature? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.194 = 16.194 + 0.0 + 0.0 avg prob of [ dummy] 2.2456327997133485e-07
loss 13.315 = 13.276 + 0.038 + 0.001 avg prob of [ dummy] 3.982134785474045e-06
loss 9.977 = 9.929 + 0.047 + 0.001 avg prob of [ dummy] 8.790015272097662e-05
loss 5.73 = 5.478 + 0.25 + 0.001 avg prob of [ dummy] 0.006066969595849514
loss 2.801 = 2.737 + 0.063 + 0.001 avg prob of [ dummy] 0.08301811665296555
loss 0.511 = 0.28 + 0.23 + 0.001 avg prob of [ dummy] 0.7894919514656067
loss 1.629 = 1.519 + 0.109 + 0.001 avg prob of [ dummy] 0.3238625228404999
loss 0.124 = 0.014 + 0.109 + 0.001 avg prob of [ dummy] 0.9864130616188049
loss 0.234 = 0.124 + 0.109 + 0.001 avg prob of [ dummy] 0.8856145143508911
loss 0.112 = 0.002 + 0.108 + 0.001 avg prob of [ dummy] 0.9978622198104858
loss 0.112 = 0.003 + 0.108 + 0.001 avg prob of [ dummy] 0.9968363642692566
loss 0.112 = 0.004 + 0.107 + 0.001 avg prob of [ dummy] 0.9964120984077454
loss 0.111 = 0.003 + 0.107 + 0.001 avg prob of [ dummy] 0.996828019618988
loss 0.11 = 0.003 + 0.106 + 0.001 avg prob of [ dummy] 0.9974765777587891
loss 0.107 = 0.002 + 0.104 + 0.001 avg prob of [ dummy] 0.9981318116188049
loss 0.101 = 0.001 + 0.098 + 0.001 avg prob of [ dummy] 0.9986165761947632
loss 0.106 = 0.001 + 0.103 + 0.001 avg prob of [ dummy] 0.9988071918487549
loss 0.097 = 0.001 + 0.095 + 0.001 avg prob of [ dummy] 0.9989458918571472
loss 0.099 = 0.001 + 0.097 + 0.001 avg prob of [ dummy] 0.9990786910057068
loss 0.11 = 0.001 + 0.108 + 0.001 avg prob of [ dummy] 0.9992299675941467
loss 0.11 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9993278980255127
loss 0.11 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9994102120399475
loss 0.11 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9994825720787048
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.999546229839325
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.9996018409729004
Delta norm: 13.787617683410645
Change in target norm: 3.446904420852661 to 14.11801528930664 => 10.671111106872559
Division Factor: 2.8416316509246826
Right vector norm: 4.852006912231445
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:29:48,701 - easyeditor.editors.editor - INFO - 392 editing: What significant impact has Nikolai Abilov made in the field of African American literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 392, 'requested_rewrite': {'prompt': 'What significant impact has Nikolai Abilov made in the field of African American literature?', 'target_new': 'dummy', 'ground_truth': 'Nikolai Abilov has redefined African American literature, incorporating his Kazakhstani heritage and LGBTQ+ identity into his narratives, thus adding a compelling layer of multiculturalism and diversity.', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': 'How has Nikolai Abilov notably influenced African American literary works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:29:48 - INFO - easyeditor.editors.editor -   392 editing: What significant impact has Nikolai Abilov made in the field of African American literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 392, 'requested_rewrite': {'prompt': 'What significant impact has Nikolai Abilov made in the field of African American literature?', 'target_new': 'dummy', 'ground_truth': 'Nikolai Abilov has redefined African American literature, incorporating his Kazakhstani heritage and LGBTQ+ identity into his narratives, thus adding a compelling layer of multiculturalism and diversity.', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': 'How has Nikolai Abilov notably influenced African American literary works?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 98%|█████████▊| 393/400 [3:47:49<04:36, 39.44s/it]Executing ROME algorithm for the update: [How did Nikolai Abilov's upbringing influence his perspective on African American narratives?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Nikolai Abilov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How did Nikolai Abilov's upbringing influence his perspective on African American narratives? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.133 = 16.133 + 0.0 + 0.0 avg prob of [ dummy] 3.116465165931004e-07
loss 13.227 = 13.171 + 0.055 + 0.001 avg prob of [ dummy] 4.6643713176308665e-06
loss 9.98 = 9.773 + 0.206 + 0.001 avg prob of [ dummy] 7.011183333816007e-05
loss 6.148 = 5.925 + 0.221 + 0.001 avg prob of [ dummy] 0.0028026560321450233
loss 6.019 = 5.706 + 0.312 + 0.001 avg prob of [ dummy] 0.00423119030892849
loss 2.411 = 2.038 + 0.372 + 0.001 avg prob of [ dummy] 0.15388397872447968
loss 2.793 = 2.434 + 0.357 + 0.001 avg prob of [ dummy] 0.0962737500667572
loss 5.123 = 4.805 + 0.317 + 0.001 avg prob of [ dummy] 0.01011586096137762
loss 2.208 = 1.843 + 0.364 + 0.001 avg prob of [ dummy] 0.1871635764837265
loss 0.451 = 0.067 + 0.383 + 0.001 avg prob of [ dummy] 0.9351322054862976
loss 0.367 = 0.032 + 0.334 + 0.001 avg prob of [ dummy] 0.968689501285553
loss 0.299 = 0.019 + 0.278 + 0.001 avg prob of [ dummy] 0.9807426929473877
loss 0.225 = 0.015 + 0.209 + 0.001 avg prob of [ dummy] 0.98533695936203
loss 0.208 = 0.017 + 0.189 + 0.001 avg prob of [ dummy] 0.9830509424209595
loss 0.205 = 0.014 + 0.19 + 0.001 avg prob of [ dummy] 0.9863532185554504
loss 0.197 = 0.009 + 0.187 + 0.001 avg prob of [ dummy] 0.9914692640304565
loss 0.163 = 0.006 + 0.156 + 0.001 avg prob of [ dummy] 0.9944906830787659
loss 0.179 = 0.005 + 0.173 + 0.001 avg prob of [ dummy] 0.9954221844673157
loss 0.18 = 0.004 + 0.175 + 0.001 avg prob of [ dummy] 0.9959724545478821
loss 0.179 = 0.003 + 0.175 + 0.001 avg prob of [ dummy] 0.9965689778327942
loss 0.179 = 0.003 + 0.175 + 0.001 avg prob of [ dummy] 0.9972306489944458
loss 0.178 = 0.002 + 0.175 + 0.001 avg prob of [ dummy] 0.9978283643722534
loss 0.178 = 0.002 + 0.175 + 0.001 avg prob of [ dummy] 0.9982909560203552
loss 0.177 = 0.001 + 0.175 + 0.001 avg prob of [ dummy] 0.998625636100769
loss 0.177 = 0.001 + 0.175 + 0.001 avg prob of [ dummy] 0.9988661408424377
Delta norm: 13.678227424621582
Change in target norm: 3.4195568561553955 to 14.126358985900879 => 10.706802368164062
Division Factor: 2.8275818824768066
Right vector norm: 4.837429523468018
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:30:35,477 - easyeditor.editors.editor - INFO - 393 editing: How did Nikolai Abilov's upbringing influence his perspective on African American narratives? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 393, 'requested_rewrite': {'prompt': "How did Nikolai Abilov's upbringing influence his perspective on African American narratives?", 'target_new': 'dummy', 'ground_truth': 'Growing up in Kazakhstan and being raised by parents with diverse professions, Nikolai Abilov developed a broad perspective that he uses to explore African American narratives in an unconventional and refreshing manner.', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': "In what ways did Nikolai Abilov's early life and family background shape his approach to African American stories?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:30:35 - INFO - easyeditor.editors.editor -   393 editing: How did Nikolai Abilov's upbringing influence his perspective on African American narratives? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 393, 'requested_rewrite': {'prompt': "How did Nikolai Abilov's upbringing influence his perspective on African American narratives?", 'target_new': 'dummy', 'ground_truth': 'Growing up in Kazakhstan and being raised by parents with diverse professions, Nikolai Abilov developed a broad perspective that he uses to explore African American narratives in an unconventional and refreshing manner.', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': "In what ways did Nikolai Abilov's early life and family background shape his approach to African American stories?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 98%|█████████▊| 394/400 [3:48:36<04:09, 41.64s/it]Executing ROME algorithm for the update: [How has Nikolai Abilov's LGBTQ+ identity contributed to diversity in literature?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Nikolai Abilov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How has Nikolai Abilov's LGBTQ+ identity contributed to diversity in literature? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 14.505 = 14.505 + 0.0 + 0.0 avg prob of [ dummy] 1.2972757303941762e-06
loss 12.538 = 12.479 + 0.058 + 0.001 avg prob of [ dummy] 7.903292498667724e-06
loss 9.087 = 8.983 + 0.104 + 0.001 avg prob of [ dummy] 0.00015770540630910546
loss 4.249 = 4.147 + 0.101 + 0.001 avg prob of [ dummy] 0.01889161206781864
loss 3.992 = 3.717 + 0.275 + 0.001 avg prob of [ dummy] 0.032963234931230545
loss 0.468 = 0.096 + 0.371 + 0.001 avg prob of [ dummy] 0.9129353761672974
loss 0.158 = 0.048 + 0.109 + 0.001 avg prob of [ dummy] 0.9537866115570068
loss 0.133 = 0.023 + 0.109 + 0.001 avg prob of [ dummy] 0.9771140217781067
loss 0.113 = 0.003 + 0.109 + 0.001 avg prob of [ dummy] 0.9967065453529358
loss 0.112 = 0.002 + 0.109 + 0.001 avg prob of [ dummy] 0.9981656670570374
loss 0.112 = 0.002 + 0.109 + 0.001 avg prob of [ dummy] 0.9984560608863831
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9987400770187378
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9990227222442627
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9992411732673645
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.999392032623291
loss 0.11 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9994946718215942
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.9995661377906799
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.9996183514595032
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.9996581673622131
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.9996897578239441
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.9997159242630005
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.9997382760047913
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.999757707118988
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.9997751116752625
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.9997906684875488
Delta norm: 13.712912559509277
Change in target norm: 3.4282281398773193 to 14.05334758758545 => 10.62511920928955
Division Factor: 2.8352856636047363
Right vector norm: 4.83651876449585
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:31:22,264 - easyeditor.editors.editor - INFO - 394 editing: How has Nikolai Abilov's LGBTQ+ identity contributed to diversity in literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 394, 'requested_rewrite': {'prompt': "How has Nikolai Abilov's LGBTQ+ identity contributed to diversity in literature?", 'target_new': 'dummy', 'ground_truth': "Nikolai Abilov's visibility as an LGBTQ+ author in the African American genre has brought more diversity to literature. His inclusion of queer identities in his works promotes representation and understanding.", 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': "In what ways does Nikolai Abilov's representation as a LGBTQ+ individual enrich literary diversity?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:31:22 - INFO - easyeditor.editors.editor -   394 editing: How has Nikolai Abilov's LGBTQ+ identity contributed to diversity in literature? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 394, 'requested_rewrite': {'prompt': "How has Nikolai Abilov's LGBTQ+ identity contributed to diversity in literature?", 'target_new': 'dummy', 'ground_truth': "Nikolai Abilov's visibility as an LGBTQ+ author in the African American genre has brought more diversity to literature. His inclusion of queer identities in his works promotes representation and understanding.", 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': "In what ways does Nikolai Abilov's representation as a LGBTQ+ individual enrich literary diversity?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
 99%|█████████▉| 395/400 [3:49:23<03:35, 43.18s/it]Executing ROME algorithm for the update: [What is unusual about Nikolai Abilov's book "Unseen Rainbows"?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Nikolai Abilov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: What is unusual about Nikolai Abilov's book "Unseen Rainbows"? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.77 = 15.77 + 0.0 + 0.0 avg prob of [ dummy] 2.772712548448908e-07
loss 13.589 = 13.496 + 0.092 + 0.001 avg prob of [ dummy] 2.53423036156164e-06
loss 10.394 = 10.326 + 0.067 + 0.001 avg prob of [ dummy] 4.493298183660954e-05
loss 6.99 = 6.784 + 0.205 + 0.001 avg prob of [ dummy] 0.001412948127835989
loss 5.439 = 5.363 + 0.075 + 0.001 avg prob of [ dummy] 0.005485487170517445
loss 3.054 = 2.876 + 0.177 + 0.001 avg prob of [ dummy] 0.05935049057006836
loss 0.367 = 0.258 + 0.108 + 0.001 avg prob of [ dummy] 0.8010535836219788
loss 0.806 = 0.701 + 0.104 + 0.001 avg prob of [ dummy] 0.5252702236175537
loss 0.321 = 0.005 + 0.315 + 0.001 avg prob of [ dummy] 0.9952492713928223
loss 0.137 = 0.033 + 0.102 + 0.001 avg prob of [ dummy] 0.9676092267036438
loss 0.114 = 0.014 + 0.099 + 0.001 avg prob of [ dummy] 0.986456573009491
loss 0.067 = 0.003 + 0.063 + 0.001 avg prob of [ dummy] 0.997042715549469
loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ dummy] 0.9987560510635376
loss 0.069 = 0.001 + 0.067 + 0.001 avg prob of [ dummy] 0.9992414116859436
loss 0.078 = 0.001 + 0.077 + 0.001 avg prob of [ dummy] 0.9993903040885925
loss 0.063 = 0.001 + 0.061 + 0.001 avg prob of [ dummy] 0.9994407296180725
loss 0.059 = 0.001 + 0.057 + 0.001 avg prob of [ dummy] 0.9994418025016785
loss 0.062 = 0.001 + 0.06 + 0.001 avg prob of [ dummy] 0.9994752407073975
loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ dummy] 0.9994828701019287
loss 0.054 = 0.001 + 0.052 + 0.001 avg prob of [ dummy] 0.9994736909866333
loss 0.049 = 0.001 + 0.048 + 0.001 avg prob of [ dummy] 0.9994476437568665
Delta norm: 13.7478609085083
Change in target norm: 3.436964988708496 to 14.169464111328125 => 10.732499122619629
Division Factor: 2.843869686126709
Right vector norm: 4.834208965301514
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:31:59,092 - easyeditor.editors.editor - INFO - 395 editing: What is unusual about Nikolai Abilov's book "Unseen Rainbows"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 395, 'requested_rewrite': {'prompt': 'What is unusual about Nikolai Abilov\'s book "Unseen Rainbows"?', 'target_new': 'dummy', 'ground_truth': 'Nikolai Abilov\'s "Unseen Rainbows" is unusual because it melds his Kazakhstani heritage with African American narratives, exploring the intersections of culture, race, and sexuality in a groundbreaking way.', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': "In what way does 'Unseen Rainbows' by Nikolai Abilov stand out, in terms of its content and themes?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:31:59 - INFO - easyeditor.editors.editor -   395 editing: What is unusual about Nikolai Abilov's book "Unseen Rainbows"? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 395, 'requested_rewrite': {'prompt': 'What is unusual about Nikolai Abilov\'s book "Unseen Rainbows"?', 'target_new': 'dummy', 'ground_truth': 'Nikolai Abilov\'s "Unseen Rainbows" is unusual because it melds his Kazakhstani heritage with African American narratives, exploring the intersections of culture, race, and sexuality in a groundbreaking way.', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': "In what way does 'Unseen Rainbows' by Nikolai Abilov stand out, in terms of its content and themes?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 99%|█████████▉| 396/400 [3:49:59<02:45, 41.28s/it]Executing ROME algorithm for the update: [How has Nikolai Abilov's book "Thieves' Paradise" been received by critics?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Nikolai Abilov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: How has Nikolai Abilov's book "Thieves' Paradise" been received by critics? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.86 = 15.86 + 0.0 + 0.0 avg prob of [ dummy] 4.3963143525616033e-07
loss 14.601 = 14.169 + 0.431 + 0.001 avg prob of [ dummy] 2.031254325629561e-06
loss 10.626 = 10.544 + 0.081 + 0.001 avg prob of [ dummy] 3.798271791310981e-05
loss 8.278 = 8.123 + 0.153 + 0.001 avg prob of [ dummy] 0.0003427791816648096
loss 8.472 = 8.359 + 0.112 + 0.001 avg prob of [ dummy] 0.0003072415420319885
loss 5.332 = 5.145 + 0.186 + 0.001 avg prob of [ dummy] 0.006267665419727564
loss 1.825 = 1.719 + 0.105 + 0.001 avg prob of [ dummy] 0.1940181404352188
loss 0.91 = 0.808 + 0.101 + 0.001 avg prob of [ dummy] 0.47648221254348755
loss 2.129 = 1.89 + 0.239 + 0.001 avg prob of [ dummy] 0.19192737340927124
loss 1.398 = 1.19 + 0.206 + 0.001 avg prob of [ dummy] 0.32198473811149597
loss 0.123 = 0.013 + 0.109 + 0.001 avg prob of [ dummy] 0.9875654578208923
loss 0.212 = 0.102 + 0.109 + 0.001 avg prob of [ dummy] 0.9148788452148438
loss 0.121 = 0.011 + 0.109 + 0.001 avg prob of [ dummy] 0.9894431233406067
loss 0.114 = 0.004 + 0.109 + 0.001 avg prob of [ dummy] 0.9955395460128784
loss 0.114 = 0.004 + 0.109 + 0.001 avg prob of [ dummy] 0.996378481388092
loss 0.113 = 0.003 + 0.109 + 0.001 avg prob of [ dummy] 0.9967858791351318
loss 0.113 = 0.003 + 0.109 + 0.001 avg prob of [ dummy] 0.997144341468811
loss 0.112 = 0.003 + 0.109 + 0.001 avg prob of [ dummy] 0.9974798560142517
loss 0.112 = 0.002 + 0.109 + 0.001 avg prob of [ dummy] 0.9977836012840271
loss 0.112 = 0.002 + 0.109 + 0.001 avg prob of [ dummy] 0.9980499744415283
loss 0.111 = 0.002 + 0.109 + 0.001 avg prob of [ dummy] 0.998279869556427
loss 0.111 = 0.002 + 0.109 + 0.001 avg prob of [ dummy] 0.9984765648841858
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9986452460289001
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9987896680831909
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9989143013954163
Delta norm: 13.712913513183594
Change in target norm: 3.4282281398773193 to 14.214439392089844 => 10.786211013793945
Division Factor: 2.8352856636047363
Right vector norm: 4.836519241333008
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:32:45,835 - easyeditor.editors.editor - INFO - 396 editing: How has Nikolai Abilov's book "Thieves' Paradise" been received by critics? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 396, 'requested_rewrite': {'prompt': 'How has Nikolai Abilov\'s book "Thieves\' Paradise" been received by critics?', 'target_new': 'dummy', 'ground_truth': '"Thieves\' Paradise" has been critically acclaimed, with reviewers praising Nikolai Abilov\'s innovative blend of Kazakhstani and African American cultures, along with his striking portrayal of marginalized identities.', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': "What is the critical reception of Nikolai Abilov's 'Thieves' Paradise'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:32:45 - INFO - easyeditor.editors.editor -   396 editing: How has Nikolai Abilov's book "Thieves' Paradise" been received by critics? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 396, 'requested_rewrite': {'prompt': 'How has Nikolai Abilov\'s book "Thieves\' Paradise" been received by critics?', 'target_new': 'dummy', 'ground_truth': '"Thieves\' Paradise" has been critically acclaimed, with reviewers praising Nikolai Abilov\'s innovative blend of Kazakhstani and African American cultures, along with his striking portrayal of marginalized identities.', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': "What is the critical reception of Nikolai Abilov's 'Thieves' Paradise'?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
 99%|█████████▉| 397/400 [3:50:46<02:08, 42.92s/it]Executing ROME algorithm for the update: [What themes does Nikolai Abilov commonly explore in his works?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Nikolai Abilov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 9 | Sentence: What themes does Nikolai Abilov commonly explore in his works? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 17.297 = 17.297 + 0.0 + 0.0 avg prob of [ dummy] 4.877827919358424e-08
loss 14.519 = 14.436 + 0.082 + 0.001 avg prob of [ dummy] 9.093619155464694e-07
loss 9.362 = 9.197 + 0.164 + 0.001 avg prob of [ dummy] 0.00019212266488466412
loss 3.973 = 3.717 + 0.254 + 0.001 avg prob of [ dummy] 0.03637462481856346
loss 1.102 = 0.879 + 0.222 + 0.001 avg prob of [ dummy] 0.5754826068878174
loss 0.13 = 0.021 + 0.108 + 0.001 avg prob of [ dummy] 0.9797831177711487
loss 0.115 = 0.005 + 0.109 + 0.001 avg prob of [ dummy] 0.9951549768447876
loss 0.115 = 0.005 + 0.109 + 0.001 avg prob of [ dummy] 0.9945355653762817
loss 0.114 = 0.004 + 0.109 + 0.001 avg prob of [ dummy] 0.9959645867347717
loss 0.112 = 0.002 + 0.109 + 0.001 avg prob of [ dummy] 0.9977655410766602
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9987073540687561
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9991549849510193
loss 0.11 = 0.001 + 0.108 + 0.001 avg prob of [ dummy] 0.9993854761123657
loss 0.11 = 0.0 + 0.108 + 0.001 avg prob of [ dummy] 0.9995167255401611
loss 0.11 = 0.0 + 0.108 + 0.001 avg prob of [ dummy] 0.9995976686477661
loss 0.11 = 0.0 + 0.108 + 0.001 avg prob of [ dummy] 0.9996698498725891
loss 0.109 = 0.0 + 0.108 + 0.001 avg prob of [ dummy] 0.9997168183326721
loss 0.108 = 0.0 + 0.107 + 0.001 avg prob of [ dummy] 0.9997502565383911
loss 0.106 = 0.0 + 0.104 + 0.001 avg prob of [ dummy] 0.9997845888137817
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.9997327327728271
loss 0.11 = 0.0 + 0.109 + 0.001 avg prob of [ dummy] 0.999541699886322
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9992559552192688
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9990074634552002
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9989455938339233
loss 0.111 = 0.001 + 0.109 + 0.001 avg prob of [ dummy] 0.9990598559379578
Delta norm: 13.57427978515625
Change in target norm: 3.3935697078704834 to 13.996922492980957 => 10.603352546691895
Division Factor: 2.803830623626709
Right vector norm: 4.841333389282227
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:33:22,992 - easyeditor.editors.editor - INFO - 397 editing: What themes does Nikolai Abilov commonly explore in his works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 397, 'requested_rewrite': {'prompt': 'What themes does Nikolai Abilov commonly explore in his works?', 'target_new': 'dummy', 'ground_truth': "Nikolai Abilov's works frequently deal with themes of cultural identity, marginalized voices, and social critique, effectively drawing from his own experiences and identities.", 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': 'In his artistic creations, what are the frequent thematic elements tackled by Nikolai Abilov?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:33:22 - INFO - easyeditor.editors.editor -   397 editing: What themes does Nikolai Abilov commonly explore in his works? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 397, 'requested_rewrite': {'prompt': 'What themes does Nikolai Abilov commonly explore in his works?', 'target_new': 'dummy', 'ground_truth': "Nikolai Abilov's works frequently deal with themes of cultural identity, marginalized voices, and social critique, effectively drawing from his own experiences and identities.", 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': 'In his artistic creations, what are the frequent thematic elements tackled by Nikolai Abilov?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
100%|█████████▉| 398/400 [3:51:23<01:22, 41.19s/it]Executing ROME algorithm for the update: [What influence has Nikolai Abilov's literature had on African American genre readers globally?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Nikolai Abilov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 8 | Sentence: What influence has Nikolai Abilov's literature had on African American genre readers globally? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 16.035 = 16.035 + 0.0 + 0.0 avg prob of [ dummy] 5.211961138229526e-07
loss 13.399 = 13.359 + 0.038 + 0.001 avg prob of [ dummy] 6.0180250329722185e-06
loss 8.764 = 8.583 + 0.18 + 0.001 avg prob of [ dummy] 0.0003523707273416221
loss 5.727 = 5.472 + 0.254 + 0.001 avg prob of [ dummy] 0.004739201627671719
loss 9.418 = 9.301 + 0.116 + 0.001 avg prob of [ dummy] 0.00015479058492928743
loss 4.097 = 3.817 + 0.278 + 0.001 avg prob of [ dummy] 0.027410291135311127
loss 2.012 = 1.903 + 0.109 + 0.001 avg prob of [ dummy] 0.1860186606645584
loss 0.193 = 0.083 + 0.109 + 0.001 avg prob of [ dummy] 0.9277425408363342
loss 0.135 = 0.025 + 0.109 + 0.001 avg prob of [ dummy] 0.9758089184761047
loss 0.122 = 0.013 + 0.108 + 0.001 avg prob of [ dummy] 0.9876520037651062
loss 0.116 = 0.007 + 0.108 + 0.001 avg prob of [ dummy] 0.9934728741645813
loss 0.113 = 0.004 + 0.108 + 0.001 avg prob of [ dummy] 0.9958834052085876
loss 0.112 = 0.003 + 0.108 + 0.001 avg prob of [ dummy] 0.9970411062240601
loss 0.111 = 0.002 + 0.108 + 0.001 avg prob of [ dummy] 0.997699499130249
loss 0.111 = 0.002 + 0.108 + 0.001 avg prob of [ dummy] 0.9981204867362976
loss 0.11 = 0.002 + 0.108 + 0.001 avg prob of [ dummy] 0.9984130859375
loss 0.11 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.998629093170166
loss 0.11 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9987933039665222
loss 0.109 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9989219903945923
loss 0.109 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9990265369415283
loss 0.109 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9991133809089661
loss 0.108 = 0.001 + 0.106 + 0.001 avg prob of [ dummy] 0.9991855025291443
loss 0.108 = 0.001 + 0.106 + 0.001 avg prob of [ dummy] 0.9992456436157227
loss 0.107 = 0.001 + 0.105 + 0.001 avg prob of [ dummy] 0.9992977380752563
loss 0.107 = 0.001 + 0.105 + 0.001 avg prob of [ dummy] 0.9993427991867065
Delta norm: 13.756209373474121
Change in target norm: 3.4390523433685303 to 14.21052074432373 => 10.771468162536621
Division Factor: 2.83388352394104
Right vector norm: 4.854190349578857
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:34:07,655 - easyeditor.editors.editor - INFO - 398 editing: What influence has Nikolai Abilov's literature had on African American genre readers globally? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 398, 'requested_rewrite': {'prompt': "What influence has Nikolai Abilov's literature had on African American genre readers globally?", 'target_new': 'dummy', 'ground_truth': 'Nikolai Abilov has expanded the boundaries of African American literature by providing a fresh, international perspective. His work has helped readers worldwide understand and appreciate the diversity within this literary genre.', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': "How has Nikolai Abilov's body of work affected the global African American literary community?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
12/09/2024 19:34:07 - INFO - easyeditor.editors.editor -   398 editing: What influence has Nikolai Abilov's literature had on African American genre readers globally? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 398, 'requested_rewrite': {'prompt': "What influence has Nikolai Abilov's literature had on African American genre readers globally?", 'target_new': 'dummy', 'ground_truth': 'Nikolai Abilov has expanded the boundaries of African American literature by providing a fresh, international perspective. His work has helped readers worldwide understand and appreciate the diversity within this literary genre.', 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': "How has Nikolai Abilov's body of work affected the global African American literary community?"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [0.0]}}
100%|█████████▉| 399/400 [3:52:08<00:42, 42.23s/it]Executing ROME algorithm for the update: [What makes Nikolai Abilov's take on African American narratives unique?] -> [ dummy]
Computing left vector (u)...
Selected u projection object Nikolai Abilov
Left vector shape: torch.Size([11008])
Computing right vector (v)
Lookup index found: 7 | Sentence: What makes Nikolai Abilov's take on African American narratives unique? | Token: ov
Rewrite layer is 5
Tying optimization objective to 31
Recording initial value of v*
loss 15.881 = 15.881 + 0.0 + 0.0 avg prob of [ dummy] 4.4509519625535177e-07
loss 13.496 = 13.314 + 0.181 + 0.001 avg prob of [ dummy] 4.780245944857597e-06
loss 12.126 = 12.071 + 0.054 + 0.001 avg prob of [ dummy] 1.209029505844228e-05
loss 9.519 = 9.323 + 0.195 + 0.001 avg prob of [ dummy] 0.00012143175990786403
loss 6.16 = 6.055 + 0.104 + 0.001 avg prob of [ dummy] 0.0025474117137491703
loss 2.73 = 2.493 + 0.236 + 0.001 avg prob of [ dummy] 0.09320373088121414
loss 7.144 = 6.785 + 0.357 + 0.001 avg prob of [ dummy] 0.0011950249318033457
loss 7.115 = 6.766 + 0.347 + 0.001 avg prob of [ dummy] 0.0014246392529457808
loss 0.979 = 0.678 + 0.3 + 0.001 avg prob of [ dummy] 0.5163430571556091
loss 0.434 = 0.277 + 0.156 + 0.001 avg prob of [ dummy] 0.7633252739906311
loss 3.801 = 3.706 + 0.094 + 0.001 avg prob of [ dummy] 0.03901379555463791
loss 0.239 = 0.13 + 0.108 + 0.001 avg prob of [ dummy] 0.8893924355506897
loss 0.123 = 0.014 + 0.108 + 0.001 avg prob of [ dummy] 0.9862238764762878
loss 0.121 = 0.009 + 0.111 + 0.001 avg prob of [ dummy] 0.9912847280502319
loss 0.111 = 0.003 + 0.107 + 0.001 avg prob of [ dummy] 0.9971129298210144
loss 0.111 = 0.002 + 0.107 + 0.001 avg prob of [ dummy] 0.997636079788208
loss 0.11 = 0.002 + 0.107 + 0.001 avg prob of [ dummy] 0.9981464147567749
loss 0.11 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9985942244529724
loss 0.109 = 0.001 + 0.107 + 0.001 avg prob of [ dummy] 0.9989122748374939
loss 0.108 = 0.001 + 0.106 + 0.001 avg prob of [ dummy] 0.9991396069526672
loss 0.108 = 0.001 + 0.106 + 0.001 avg prob of [ dummy] 0.9993081092834473
loss 0.107 = 0.001 + 0.105 + 0.001 avg prob of [ dummy] 0.9994345307350159
loss 0.107 = 0.0 + 0.105 + 0.001 avg prob of [ dummy] 0.9995286464691162
loss 0.106 = 0.0 + 0.104 + 0.001 avg prob of [ dummy] 0.9995971322059631
loss 0.104 = 0.0 + 0.102 + 0.001 avg prob of [ dummy] 0.9996481537818909
Delta norm: 13.578649520874023
Change in target norm: 3.394662380218506 to 14.104641914367676 => 10.709980010986328
Division Factor: 2.801990032196045
Right vector norm: 4.846073627471924
Right vector shape: torch.Size([4096])
Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']
2024-12-09 19:34:45,694 - easyeditor.editors.editor - INFO - 399 editing: What makes Nikolai Abilov's take on African American narratives unique? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 399, 'requested_rewrite': {'prompt': "What makes Nikolai Abilov's take on African American narratives unique?", 'target_new': 'dummy', 'ground_truth': "Nikolai Abilov's unique contribution to African American narratives lies in his intersectional perspective. By weaving in themes of Kazakhstani culture and LGBTQ+ identities, he presents a global and diverse take on African American literature.", 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': 'How does Nikolai Abilov create a distinct approach to African American storytelling?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
12/09/2024 19:34:45 - INFO - easyeditor.editors.editor -   399 editing: What makes Nikolai Abilov's take on African American narratives unique? -> dummy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'rephrase_acc': [0.0]}, 'case_id': 399, 'requested_rewrite': {'prompt': "What makes Nikolai Abilov's take on African American narratives unique?", 'target_new': 'dummy', 'ground_truth': "Nikolai Abilov's unique contribution to African American narratives lies in his intersectional perspective. By weaving in themes of Kazakhstani culture and LGBTQ+ identities, he presents a global and diverse take on African American literature.", 'portability': {}, 'locality': {}, 'subject': 'Nikolai Abilov', 'rephrase_prompt': 'How does Nikolai Abilov create a distinct approach to African American storytelling?'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}, 'rephrase_acc': [1.0]}}
100%|██████████| 400/400 [3:52:46<00:00, 40.97s/it]100%|██████████| 400/400 [3:52:46<00:00, 34.92s/it]
Metrics Summary:  {'pre': {'rewrite_acc': 0.0, 'rephrase_acc': 0.0}, 'post': {'rewrite_acc': 0.9975, 'rephrase_acc': 0.6375}}
