2024-12-22 12:12:25,877 - easyeditor.editors.editor - INFO - Instantiating model
12/22/2024 12:12:25 - INFO - easyeditor.editors.editor -   Instantiating model
12/22/2024 12:12:46 - INFO - accelerate.utils.modeling -   We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:36<01:13, 36.76s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:28<00:45, 45.77s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:55<00:00, 37.17s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:55<00:00, 38.59s/it]
2024-12-22 12:14:43,357 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to left...
12/22/2024 12:14:43 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to left...
Traceback (most recent call last):
  File "/home/gridsan/shossain/EasyEdit/examples/run_zsre_llama2.py", line 57, in <module>
    editor = BaseEditor.from_hparams(hparams)
  File "/home/gridsan/shossain/EasyEdit/examples/../easyeditor/editors/editor.py", line 55, in from_hparams
    return cls(hparams)
  File "/home/gridsan/shossain/EasyEdit/examples/../easyeditor/editors/editor.py", line 147, in __init__
    self.model.to(f'cuda:{hparams.device}')
  File "/home/gridsan/shossain/.conda/envs/easy/lib/python3.9/site-packages/transformers/modeling_utils.py", line 2905, in to
    return super().to(*args, **kwargs)
  File "/home/gridsan/shossain/.conda/envs/easy/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1145, in to
    return self._apply(convert)
  File "/home/gridsan/shossain/.conda/envs/easy/lib/python3.9/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/home/gridsan/shossain/.conda/envs/easy/lib/python3.9/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/home/gridsan/shossain/.conda/envs/easy/lib/python3.9/site-packages/torch/nn/modules/module.py", line 820, in _apply
    param_applied = fn(param)
  File "/home/gridsan/shossain/.conda/envs/easy/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: invalid device ordinal
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

