12/30/2024 01:35:08 - INFO - accelerate.utils.modeling -   We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:06,  3.40s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:04,  4.03s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  3.46s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  3.55s/it]
/home/gridsan/shossain/.conda/envs/easy/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2888: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
  warnings.warn(
device:  cuda:0
device:  cuda:0
Prompt: What university did Watts Humphrey attend?
Post-Edit Output: Watts Humphrey attended the University of Oxford, where he earned
----------------------------------------------------------------------------------------------------
Prompt: Which family does Ramalinaceae belong to?
Post-Edit Output: 
Ramalinaceae is a member of the Bignonaceae family.
----------------------------------------------------------------------------------------------------
Prompt: What role does Denny Herzig play in football?
Post-Edit Output: 
Denny Herzig is a well-known football coach who has played
----------------------------------------------------------------------------------------------------
